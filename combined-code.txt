################################################################################
#                                                                              #
#                    TERRAFORM COST ESTIMATION SYSTEM                          #
#                         Combined Source Code                                 #
#                                                                              #
#                    Generated: 2026-01-17 12:44:52                          #
#                                                                              #
################################################################################

================================================================================
                           DIRECTORY STRUCTURE
================================================================================
cost estimation/
|-- adapters/
|   |-- ci/
|   |   +-- adapter.go
|   |-- cli/
|   |   +-- adapter.go
|   |-- git/
|   |   +-- adapter.go
|   |-- http/
|   |   +-- adapter.go
|   |-- pricing/
|   |   +-- adapter.go
|   |-- storage/
|   |   +-- adapter.go
|   |-- terraform/
|   |   |-- hcl/
|   |   |   |-- cty_safe.go
|   |   |   +-- scanner.go
|   |   |-- plan/
|   |   +-- adapter.go
|   |-- terragrunt/
|   |   +-- adapter.go
|   +-- webhook/
|       +-- adapter.go
|-- api/
|   |-- envelope/
|   |   |-- audit.go
|   |   |-- convert.go
|   |   +-- envelope.go
|   |-- handlers/
|   |-- v1/
|   |   |-- mapping/
|   |   |   |-- diff.go
|   |   |   +-- estimate.go
|   |   |-- types/
|   |   |   |-- diff.go
|   |   |   |-- estimate.go
|   |   |   +-- request.go
|   |   |-- diff.go
|   |   |-- handler.go
|   |   |-- mapper.go
|   |   +-- types.go
|   |-- diff.go
|   |-- handler.go
|   |-- server.go
|   +-- types.go
|-- clouds/
|   |-- aws/
|   |   |-- analytics/
|   |   |   |-- opensearch.go
|   |   |   +-- redshift.go
|   |   |-- apigateway/
|   |   |   +-- api_gateway.go
|   |   |-- assets/
|   |   |   |-- compute.go
|   |   |   |-- database.go
|   |   |   |-- ec2.go
|   |   |   |-- network.go
|   |   |   |-- other.go
|   |   |   +-- storage.go
|   |   |-- backup/
|   |   |   +-- backup.go
|   |   |-- cdn/
|   |   |   +-- cloudfront.go
|   |   |-- compute/
|   |   |   |-- autoscaling.go
|   |   |   |-- ec2.go
|   |   |   +-- ec2_host.go
|   |   |-- containers/
|   |   |   |-- ecr.go
|   |   |   |-- ecs.go
|   |   |   +-- eks.go
|   |   |-- database/
|   |   |   |-- aurora.go
|   |   |   |-- dynamodb.go
|   |   |   |-- elasticache.go
|   |   |   |-- rds.go
|   |   |   +-- rds_cluster_instance.go
|   |   |-- dns/
|   |   |   +-- route53.go
|   |   |-- messaging/
|   |   |   +-- sqs_sns.go
|   |   |-- monitoring/
|   |   |   +-- cloudtrail.go
|   |   |-- networking/
|   |   |   |-- endpoints.go
|   |   |   |-- lb.go
|   |   |   +-- nat_gateway.go
|   |   |-- observability/
|   |   |   +-- cloudwatch.go
|   |   |-- pricing/
|   |   |   +-- source.go
|   |   |-- secrets/
|   |   |   +-- secrets_manager.go
|   |   |-- security/
|   |   |   +-- waf.go
|   |   |-- serverless/
|   |   |   |-- lambda.go
|   |   |   |-- lambda_provisioned.go
|   |   |   +-- step_functions.go
|   |   |-- storage/
|   |   |   |-- ebs.go
|   |   |   |-- ebs_snapshot.go
|   |   |   |-- efs_fsx.go
|   |   |   +-- s3.go
|   |   |-- streaming/
|   |   |   |-- kinesis.go
|   |   |   +-- msk_firehose.go
|   |   |-- usage/
|   |   |   +-- estimators.go
|   |   |-- plugin.go
|   |   +-- register.go
|   |-- azure/
|   |   |-- compute/
|   |   |   +-- vm.go
|   |   +-- register.go
|   |-- gcp/
|   |   |-- compute/
|   |   |   +-- instance.go
|   |   +-- register.go
|   |-- registry.go
|   +-- types.go
|-- cmd/
|   |-- cli/
|   |   |-- cmd/
|   |   |   |-- estimate.go
|   |   |   |-- pricing_restore.go
|   |   |   |-- pricing_update.go
|   |   |   +-- root.go
|   |   +-- main.go
|   +-- server/
|       +-- main.go
|-- core/
|   |-- asset/
|   |   |-- builder.go
|   |   +-- registry.go
|   |-- capabilities/
|   |   |-- checkers.go
|   |   |-- examples.go
|   |   +-- interfaces.go
|   |-- catalog/
|   |   |-- aws.go
|   |   |-- azure.go
|   |   |-- catalog.go
|   |   |-- gcp.go
|   |   +-- validation.go
|   |-- confidence/
|   |   +-- strict_confidence.go
|   |-- cost/
|   |   |-- confidence.go
|   |   |-- engine.go
|   |   +-- graph.go
|   |-- detection/
|   |   +-- detector.go
|   |-- determinism/
|   |   +-- stable.go
|   |-- diff/
|   |   |-- dependency_diff.go
|   |   +-- differ.go
|   |-- enforcement/
|   |   +-- pipeline.go
|   |-- engine/
|   |   |-- engine.go
|   |   |-- orchestrator.go
|   |   +-- sealed_builder.go
|   |-- expansion/
|   |   |-- expander.go
|   |   |-- expander_test.go
|   |   +-- sealed_expander.go
|   |-- explanation/
|   |   |-- api_types.go
|   |   |-- cost_explanation.go
|   |   |-- diff_narrative.go
|   |   +-- symbolic.go
|   |-- expression/
|   |   |-- context.go
|   |   |-- reference.go
|   |   +-- value.go
|   |-- graph/
|   |   |-- bypass_prevention.go
|   |   |-- canonical_graph.go
|   |   |-- concurrent.go
|   |   |-- cost_lineage.go
|   |   |-- dependency_cost.go
|   |   |-- derived_cost.go
|   |   |-- enforced_asset.go
|   |   |-- enforced_cost.go
|   |   |-- epistemic_cardinality.go
|   |   |-- expansion_guard.go
|   |   |-- infrastructure.go
|   |   |-- invariant_checker.go
|   |   |-- invariant_test.go
|   |   +-- no_placeholder.go
|   |-- guards/
|   |   +-- invariants.go
|   |-- input/
|   |   +-- envelope.go
|   |-- mapper/
|   |   |-- helpers.go
|   |   |-- interface.go
|   |   |-- metadata.go
|   |   +-- registry.go
|   |-- model/
|   |   |-- definition.go
|   |   |-- enforced_identity.go
|   |   +-- identity.go
|   |-- output/
|   |   |-- formats/
|   |   +-- formatter.go
|   |-- policy/
|   |   |-- deep_policy.go
|   |   |-- diff_policy.go
|   |   |-- evaluator.go
|   |   |-- explanation.go
|   |   +-- full_lineage.go
|   |-- pricing/
|   |   |-- primitives/
|   |   |   |-- compute.go
|   |   |   |-- requests.go
|   |   |   |-- storage.go
|   |   |   |-- symbolic.go
|   |   |   |-- tiered.go
|   |   |   |-- transfer.go
|   |   |   +-- types.go
|   |   |-- alias_rate_key.go
|   |   |-- cache_governance.go
|   |   |-- enforcer.go
|   |   |-- immutable_store.go
|   |   |-- pricing_gate.go
|   |   |-- pricing_test.go
|   |   |-- resolver.go
|   |   |-- snapshot.go
|   |   +-- strict_rate_key.go
|   |-- scanner/
|   |   |-- registry.go
|   |   +-- scanner.go
|   |-- terraform/
|   |   |-- data_barrier.go
|   |   |-- dependencies.go
|   |   |-- determinism_class.go
|   |   |-- dynamic.go
|   |   |-- function_class.go
|   |   |-- module_outputs.go
|   |   |-- phased_expansion.go
|   |   |-- pipeline.go
|   |   |-- provider.go
|   |   |-- provider_binding.go
|   |   |-- provider_context.go
|   |   |-- provider_finalization.go
|   |   |-- safe_expansion.go
|   |   |-- strict_mode.go
|   |   |-- strict_module_output.go
|   |   |-- strict_unknown.go
|   |   +-- unknown.go
|   |-- types/
|   |   |-- asset.go
|   |   |-- cost.go
|   |   |-- pricing.go
|   |   |-- project.go
|   |   |-- types.go
|   |   +-- usage.go
|   |-- ui/
|   |   |-- runner.go
|   |   +-- terminal.go
|   +-- usage/
|       |-- assumptions.go
|       |-- estimator.go
|       |-- registry.go
|       +-- strict_defaults.go
|-- db/
|   |-- ingestion/
|   |   |-- aws.go
|   |   |-- aws_api.go
|   |   |-- azure.go
|   |   |-- backup.go
|   |   |-- coverage.go
|   |   |-- dimension_filter.go
|   |   |-- drift.go
|   |   |-- gcp.go
|   |   |-- governance.go
|   |   |-- pipeline.go
|   |   +-- pipeline_test.go
|   |-- migrations/
|   |   |-- 001_pricing_schema.sql
|   |   |-- 002_pricing_dimensions.sql
|   |   +-- 003_scale_hardening.sql
|   |-- postgres.go
|   |-- resolver.go
|   |-- strict_resolver.go
|   +-- types.go
|-- docs/
|   +-- COST_FORMULA_EXTRACTION.md
|-- examples/
|   +-- aws-simple/
|       +-- main.tf
|-- frontend/
|   |-- src/
|   |   |-- components/
|   |   |   |-- CostTree/
|   |   |   |   |-- CostLineagePopover.tsx
|   |   |   |   |-- CostNode.tsx
|   |   |   |   |-- CostTree.tsx
|   |   |   |   +-- index.ts
|   |   |   |-- Diff/
|   |   |   |   |-- DiffNarrative.tsx
|   |   |   |   |-- DiffSummary.tsx
|   |   |   |   +-- index.ts
|   |   |   |-- ConfidenceBadge.tsx
|   |   |   |-- CostBreakdown.tsx
|   |   |   |-- CostSummaryCard.tsx
|   |   |   |-- CoverageBar.tsx
|   |   |   |-- CoverageChart.tsx
|   |   |   |-- Header.tsx
|   |   |   |-- index.ts
|   |   |   |-- ResourceList.tsx
|   |   |   |-- SymbolicExplanationPanel.tsx
|   |   |   +-- UnsupportedWarning.tsx
|   |   |-- App.tsx
|   |   |-- index.css
|   |   |-- main.tsx
|   |   +-- types.ts
|   |-- Dockerfile
|   |-- index.html
|   |-- nginx.conf
|   |-- package.json
|   |-- package-lock.json
|   |-- postcss.config.js
|   |-- tailwind.config.js
|   |-- tsconfig.json
|   |-- tsconfig.node.json
|   +-- vite.config.ts
|-- internal/
|   |-- config/
|   |   +-- config.go
|   |-- errors/
|   |   +-- errors.go
|   +-- logging/
|       +-- logging.go
|-- pkg/
|   +-- client/
|-- storage/
|   |-- estimates/
|   +-- pricing/
|-- testdata/
|   |-- expected_outputs/
|   |-- pricing/
|   |   +-- snapshots/
|   +-- terraform/
|       |-- bad_configs/
|       |   |-- circular_dependency.tf
|       |   |-- duplicate_resource.tf
|       |   |-- invalid_for_each.tf
|       |   |-- missing_required.tf
|       |   |-- syntax_error.tf
|       |   +-- type_mismatch.tf
|       |-- basic/
|       |   |-- high_cost.tf
|       |   |-- mixed_resources.tf
|       |   |-- multiple_resources.tf
|       |   +-- single_resource.tf
|       |-- dynamic_blocks/
|       |   |-- conditional_dynamic.tf
|       |   |-- multiple_dynamic.tf
|       |   |-- nested_dynamic.tf
|       |   +-- single_dynamic.tf
|       |-- edge_cases/
|       |   |-- circular_reference.tf
|       |   |-- complex_locals.tf
|       |   |-- conditional_resource.tf
|       |   |-- data_source_dependency.tf
|       |   |-- lifecycle.tf
|       |   |-- moved_import.tf
|       |   |-- null_optional.tf
|       |   |-- self_reference.tf
|       |   |-- sensitive_values.tf
|       |   |-- splat_expression.tf
|       |   |-- terraform_functions.tf
|       |   |-- unknown_count.tf
|       |   +-- workspaces.tf
|       |-- expansion/
|       |   |-- complex_for_each.tf
|       |   |-- count_from_length.tf
|       |   |-- count_variable.tf
|       |   |-- count_zero.tf
|       |   |-- for_each_fileset.tf
|       |   |-- for_each_map.tf
|       |   |-- for_each_set.tf
|       |   |-- for_each_toset.tf
|       |   |-- nested_count_for_each.tf
|       |   +-- triple_nested.tf
|       |-- modules/
|       |   |-- local_module.tf
|       |   |-- module_count.tf
|       |   |-- module_with_outputs.tf
|       |   +-- nested_modules.tf
|       +-- providers/
|           |-- alias_basic.tf
|           |-- alias_module_inherit.tf
|           |-- multi_region_modules.tf
|           +-- multiple_same_type.tf
|-- ui/
|   |-- app.js
|   |-- index.html
|   +-- styles.css
|-- .gitignore
|-- combine-code.ps1
|-- docker-compose.yml
|-- Dockerfile
|-- go.mod
|-- go.sum
|-- infracost-code.txt
|-- README.md
+-- SUPPORTED_SERVICES.md

================================================================================
                              SOURCE FILES
================================================================================

################################################################################
# FILE: :\good projects\cost estimation\.gitignore
# TYPE: text
# SIZE: 2517 bytes
################################################################################
# =========================
# Go
# =========================
# Binaries
*.exe
*.exe~
*.dll
*.so
*.dylib
terraform-cost
terraform-cost-server

# Test binary
*.test

# Output of go coverage tool
*.out

# Go workspace file
go.work

# Vendor directory (if not using modules)
# vendor/

# =========================
# IDE / Editor
# =========================
# VS Code
.vscode/
*.code-workspace

# JetBrains (GoLand, IntelliJ)
.idea/
*.iml
*.iws
*.ipr

# Vim
*.swp
*.swo
*~

# Emacs
*~
\#*\#
/.emacs.desktop
/.emacs.desktop.lock
*.elc

# Sublime Text
*.sublime-workspace
*.sublime-project

# =========================
# OS Generated
# =========================
# macOS
.DS_Store
.AppleDouble
.LSOverride
._*
.Spotlight-V100
.Trashes

# Windows
Thumbs.db
Thumbs.db:encryptable
ehthumbs.db
ehthumbs_vista.db
*.stackdump
Desktop.ini
$RECYCLE.BIN/
*.lnk

# Linux
*~

# =========================
# Terraform (test files)
# =========================
*.tfstate
*.tfstate.*
*.tfstate.backup
.terraform/
.terraform.lock.hcl
crash.log
crash.*.log
override.tf
override.tf.json
*_override.tf
*_override.tf.json
.terraformrc
terraform.rc

# =========================
# Application Specific
# =========================
# Local config
.terraform-cost.json
.terraform-cost.yaml
.terraform-cost.yml
config.local.json
config.local.yaml

# Cache
.cache/
cache/
*.cache

# Data directory
data/
*.db
*.sqlite
*.sqlite3

# Pricing data exports
pricing-*.json
pricing-*.csv

# Logs
logs/
*.log

# Temp files
tmp/
temp/
*.tmp

# Build artifacts
dist/
build/


# Secrets (NEVER commit these)

*.pem
*.key
*.crt
*.p12
*.pfx
.env
.env.*
!.env.example

# =========================
# Docker
# =========================
# Ignore local docker overrides
docker-compose.override.yml
docker-compose.local.yml
.docker/

# =========================
# CI/CD
# =========================
# GitHub Actions local testing
.act/

# =========================
# Testing
# =========================
# Test output
testdata/output/
*.test.json

# Benchmarks
*.bench

# =========================
# Documentation
# =========================
# Generated docs
docs/_build/
site/

# =========================
# Project directories to ignore
# =========================
# User's terraform projects mounted in docker
projects/

# Local examples with real data
examples/local/
examples/private/

################################################################################
# FILE: :\good projects\cost estimation\combine-code.ps1
# TYPE: powershell
# SIZE: 10256 bytes
################################################################################
<#
.SYNOPSIS
    Combines all source code files into a single combined-code.txt file.

.DESCRIPTION
    This script:
    1. Generates a directory tree structure
    2. Combines all relevant source files into a single file
    3. Excludes binary files, dependencies, and build artifacts
    4. Includes file separators with full paths for easy navigation

.PARAMETER OutputFile
    The output file path. Default: combined-code.txt

.PARAMETER ProjectPath
    The project root path. Default: current directory

.EXAMPLE
    .\combine-code.ps1
    .\combine-code.ps1 -OutputFile "all-code.txt" -ProjectPath "D:\my-project"
#>

param(
    [string]$OutputFile = "combined-code.txt",
    [string]$ProjectPath = "."
)

# Resolve to absolute path
$ProjectPath = Resolve-Path $ProjectPath

Write-Host "==================================" -ForegroundColor Cyan
Write-Host "  Code Combiner Script" -ForegroundColor Cyan
Write-Host "==================================" -ForegroundColor Cyan
Write-Host ""
Write-Host "Project Path: $ProjectPath" -ForegroundColor Yellow
Write-Host "Output File:  $OutputFile" -ForegroundColor Yellow
Write-Host ""

# File extensions to include
$IncludeExtensions = @(
    "*.go",
    "*.mod",
    "*.sum",
    "*.tf",
    "*.tfvars",
    "*.json",
    "*.yaml",
    "*.yml",
    "*.toml",
    "*.md",
    "*.txt",
    "*.sh",
    "*.ps1",
    "*.sql",
    "*.hcl",
    "Dockerfile*",
    "docker-compose*",
    "Makefile",
    ".gitignore",
    ".dockerignore"
)

# Directories to exclude
$ExcludeDirectories = @(
    ".git",
    ".idea",
    ".vscode",
    "node_modules",
    "vendor",
    ".terraform",
    "dist",
    "build",
    "bin",
    "__pycache__",
    ".cache",
    "cache",
    "tmp",
    "temp",
    "logs",
    "coverage"
)

# Files to exclude
$ExcludeFiles = @(
    "combined-code.txt",
    "*.exe",
    "*.dll",
    "*.so",
    "*.dylib",
    "*.zip",
    "*.tar",
    "*.gz",
    "*.db",
    "*.sqlite",
    "*.log",
    "*.tfstate",
    "*.tfstate.backup",
    "go.sum",
    "infracost-code.txt"
)

# Create output file and clear if exists
$OutputFullPath = Join-Path $ProjectPath $OutputFile
if (Test-Path $OutputFullPath) {
    Remove-Item $OutputFullPath -Force
}

# =================================
# Section 1: Directory Structure
# =================================
Write-Host "Generating directory structure..." -ForegroundColor Green

$timestamp = Get-Date -Format "yyyy-MM-dd HH:mm:ss"
$content = @"
################################################################################
#                                                                              #
#                    TERRAFORM COST ESTIMATION SYSTEM                          #
#                         Combined Source Code                                 #
#                                                                              #
#                    Generated: $timestamp                          #
#                                                                              #
################################################################################

================================================================================
                           DIRECTORY STRUCTURE
================================================================================

"@

# Generate directory tree using ASCII characters
function Get-DirectoryTree {
    param(
        [string]$Path,
        [string]$Prefix = "",
        [int]$MaxDepth = 10,
        [int]$CurrentDepth = 0
    )

    if ($CurrentDepth -ge $MaxDepth) { return "" }

    $output = ""
    $items = Get-ChildItem -Path $Path -Force | Where-Object {
        $item = $_
        $isExcluded = $false
        
        # Check if directory should be excluded
        if ($item.PSIsContainer) {
            foreach ($exclude in $ExcludeDirectories) {
                if ($item.Name -eq $exclude) {
                    $isExcluded = $true
                    break
                }
            }
        }
        
        -not $isExcluded
    } | Sort-Object { -not $_.PSIsContainer }, Name

    $count = $items.Count
    $index = 0

    foreach ($item in $items) {
        $index++
        $isLast = ($index -eq $count)
        
        # Use ASCII characters instead of Unicode
        if ($isLast) {
            $connector = "+-- "
            $extension = "    "
        } else {
            $connector = "|-- "
            $extension = "|   "
        }

        if ($item.PSIsContainer) {
            $output += "$Prefix$connector$($item.Name)/`n"
            $output += Get-DirectoryTree -Path $item.FullName -Prefix "$Prefix$extension" -MaxDepth $MaxDepth -CurrentDepth ($CurrentDepth + 1)
        } else {
            $output += "$Prefix$connector$($item.Name)`n"
        }
    }

    return $output
}

$projectName = Split-Path $ProjectPath -Leaf
$content += "$projectName/`n"
$content += Get-DirectoryTree -Path $ProjectPath

$content += @"

================================================================================
                              SOURCE FILES
================================================================================

"@

# =================================
# Section 2: Combine Source Files
# =================================
Write-Host "Collecting source files..." -ForegroundColor Green

# Collect all files matching our patterns
$allFiles = @()

foreach ($pattern in $IncludeExtensions) {
    $files = Get-ChildItem -Path $ProjectPath -Filter $pattern -Recurse -File -ErrorAction SilentlyContinue | Where-Object {
        $file = $_
        $include = $true
        
        # Check if in excluded directory
        foreach ($excludeDir in $ExcludeDirectories) {
            if ($file.FullName -like "*\$excludeDir\*" -or $file.FullName -like "*/$excludeDir/*") {
                $include = $false
                break
            }
        }
        
        # Check if file should be excluded
        foreach ($excludeFile in $ExcludeFiles) {
            if ($file.Name -like $excludeFile) {
                $include = $false
                break
            }
        }
        
        $include
    }
    
    $allFiles += $files
}

# Remove duplicates and sort
$allFiles = $allFiles | Sort-Object FullName -Unique

Write-Host "Found $($allFiles.Count) files to combine" -ForegroundColor Yellow

# Group files by directory for better organization
$filesByDir = $allFiles | Group-Object { Split-Path $_.FullName -Parent }

$processedCount = 0
foreach ($group in $filesByDir | Sort-Object Name) {
    foreach ($file in $group.Group | Sort-Object Name) {
        $relativePath = $file.FullName.Substring($ProjectPath.Path.Length + 1)
        $processedCount++
        
        Write-Host "  [$processedCount/$($allFiles.Count)] $relativePath" -ForegroundColor Gray
        
        # Determine file type for syntax highlighting hint
        $fileType = switch -Regex ($file.Extension) {
            "\.go$" { "go" }
            "\.tf$|\.hcl$" { "hcl" }
            "\.json$" { "json" }
            "\.ya?ml$" { "yaml" }
            "\.md$" { "markdown" }
            "\.ps1$" { "powershell" }
            "\.sh$" { "bash" }
            "\.sql$" { "sql" }
            default { "text" }
        }
        
        $fileSize = $file.Length
        $separator = @"

################################################################################
# FILE: $relativePath
# TYPE: $fileType
# SIZE: $fileSize bytes
################################################################################

"@
        $content += $separator
        
        try {
            $fileContent = Get-Content -Path $file.FullName -Raw -ErrorAction Stop
            if ($fileContent) {
                $content += $fileContent
                # Ensure file ends with newline
                if (-not $fileContent.EndsWith("`n")) {
                    $content += "`n"
                }
            }
        } catch {
            $content += "# ERROR: Could not read file - $($_.Exception.Message)`n"
        }
    }
}

# =================================
# Section 3: Summary
# =================================
$summaryTimestamp = Get-Date -Format "yyyy-MM-dd HH:mm:ss"
$content += @"

################################################################################
#                              END OF FILE                                     #
################################################################################

================================================================================
                                SUMMARY
================================================================================

Total Files Combined: $($allFiles.Count)
Generated: $summaryTimestamp
Project: $projectName

Files by Type:
"@

# Count files by extension
$extensionCounts = $allFiles | Group-Object Extension | Sort-Object Count -Descending
foreach ($ext in $extensionCounts) {
    $extName = if ($ext.Name) { $ext.Name } else { "(no extension)" }
    $content += "  $extName : $($ext.Count) files`n"
}

$content += @"

================================================================================
"@

# Write to output file
Write-Host ""
Write-Host "Writing output file..." -ForegroundColor Green
$content | Out-File -FilePath $OutputFullPath -Encoding UTF8

# Get output file size
$outputSize = (Get-Item $OutputFullPath).Length
$outputSizeMB = [math]::Round($outputSize / 1MB, 2)
$outputSizeKB = [math]::Round($outputSize / 1KB, 2)

Write-Host ""
Write-Host "==================================" -ForegroundColor Cyan
Write-Host "  Complete!" -ForegroundColor Green
Write-Host "==================================" -ForegroundColor Cyan
Write-Host ""
Write-Host "Output: $OutputFullPath" -ForegroundColor Yellow
Write-Host "Size:   $outputSizeKB KB ($outputSizeMB MB)" -ForegroundColor Yellow
Write-Host "Files:  $($allFiles.Count) combined" -ForegroundColor Yellow
Write-Host ""

################################################################################
# FILE: :\good projects\cost estimation\docker-compose.yml
# TYPE: yaml
# SIZE: 3175 bytes
################################################################################
version: "3.9"

services:
  # =========================
  # CLI Service (for batch jobs)
  # =========================
  terraform-cost:
    build:
      context: .
      dockerfile: Dockerfile
    image: terraform-cost:latest
    container_name: terraform-cost-cli
    volumes:
      # Mount your Terraform projects here
      - ./projects:/projects:ro
      # Persist cache and data
      - terraform-cost-cache:/app/cache
      - terraform-cost-data:/app/data
      # Custom config (optional)
      - ./config:/app/config:ro
    environment:
      - TERRAFORM_COST_LOG_LEVEL=info
      - TERRAFORM_COST_DEFAULT_REGION=us-east-1
    # Override command for different operations
    command: ["estimate", "/projects"]
    networks:
      - terraform-cost-network

  # =========================
  # API Server (future)
  # =========================
  # terraform-cost-api:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.server
  #   image: terraform-cost-api:latest
  #   container_name: terraform-cost-api
  #   ports:
  #     - "8080:8080"
  #   volumes:
  #     - terraform-cost-cache:/app/cache
  #     - terraform-cost-data:/app/data
  #   environment:
  #     - TERRAFORM_COST_API_PORT=8080
  #     - TERRAFORM_COST_LOG_LEVEL=info
  #   healthcheck:
  #     test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 10s
  #   networks:
  #     - terraform-cost-network
  #   restart: unless-stopped

  # =========================
  # Pricing Database (future)
  # =========================
  # pricing-db:
  #   image: postgres:16-alpine
  #   container_name: terraform-cost-db
  #   environment:
  #     - POSTGRES_DB=terraform_cost
  #     - POSTGRES_USER=terraform_cost
  #     - POSTGRES_PASSWORD_FILE=/run/secrets/db_password
  #   volumes:
  #     - pricing-db-data:/var/lib/postgresql/data
  #     - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
  #   secrets:
  #     - db_password
  #   healthcheck:
  #     test: ["CMD-SHELL", "pg_isready -U terraform_cost -d terraform_cost"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #   networks:
  #     - terraform-cost-network
  #   restart: unless-stopped

  # =========================
  # Redis Cache (future)
  # =========================
  # cache:
  #   image: redis:7-alpine
  #   container_name: terraform-cost-cache
  #   command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
  #   volumes:
  #     - redis-data:/data
  #   healthcheck:
  #     test: ["CMD", "redis-cli", "ping"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #   networks:
  #     - terraform-cost-network
  #   restart: unless-stopped

volumes:
  terraform-cost-cache:
    driver: local
  terraform-cost-data:
    driver: local
  # pricing-db-data:
  #   driver: local
  # redis-data:
  #   driver: local

networks:
  terraform-cost-network:
    driver: bridge

# secrets:
#   db_password:
#     file: ./secrets/db_password.txt

################################################################################
# FILE: :\good projects\cost estimation\Dockerfile
# TYPE: text
# SIZE: 1805 bytes
################################################################################
# =========================
# Build Stage
# =========================
FROM golang:1.22-alpine AS builder

# Install build dependencies
RUN apk add --no-cache git ca-certificates tzdata

# Create non-root user for security
RUN adduser -D -g '' appuser

WORKDIR /build

# Copy go mod files first for better caching
COPY go.mod go.sum ./
RUN go mod download && go mod verify

# Copy source code
COPY . .

# Build the CLI binary
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build \
    -ldflags='-w -s -extldflags "-static"' \
    -o /build/terraform-cost \
    ./cmd/cli

# Build the server binary (if exists)
# RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build \
#     -ldflags='-w -s -extldflags "-static"' \
#     -o /build/terraform-cost-server \
#     ./cmd/server

# =========================
# Production Stage
# =========================
FROM alpine:3.19

# Install runtime dependencies
RUN apk add --no-cache ca-certificates tzdata

# Import user from builder
COPY --from=builder /etc/passwd /etc/passwd
COPY --from=builder /etc/group /etc/group

# Create directories
RUN mkdir -p /app/data /app/cache /app/config && \
    chown -R appuser:appuser /app

WORKDIR /app

# Copy binary from builder
COPY --from=builder /build/terraform-cost /app/terraform-cost

# Copy examples for testing
COPY --from=builder /build/examples /app/examples

# Use non-root user
USER appuser

# Environment variables
ENV HOME=/app \
    TERRAFORM_COST_CACHE_DIR=/app/cache \
    TERRAFORM_COST_DATA_DIR=/app/data

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD ["/app/terraform-cost", "version"]

# Default entrypoint
ENTRYPOINT ["/app/terraform-cost"]

# Default command (show help)
CMD ["--help"]

################################################################################
# FILE: :\good projects\cost estimation\go.mod
# TYPE: text
# SIZE: 812 bytes
################################################################################
module terraform-cost

go 1.25.5

require (
	github.com/hashicorp/hcl/v2 v2.24.0
	github.com/shopspring/decimal v1.4.0
	github.com/spf13/cobra v1.10.2
	go.uber.org/zap v1.27.1
)

require (
	github.com/agext/levenshtein v1.2.1 // indirect
	github.com/apparentlymart/go-textseg/v15 v15.0.0 // indirect
	github.com/google/uuid v1.6.0 // indirect
	github.com/inconshreveable/mousetrap v1.1.0 // indirect
	github.com/lib/pq v1.10.9 // indirect
	github.com/mitchellh/go-wordwrap v1.0.1 // indirect
	github.com/spf13/pflag v1.0.9 // indirect
	github.com/zclconf/go-cty v1.16.3 // indirect
	go.uber.org/multierr v1.10.0 // indirect
	golang.org/x/mod v0.17.0 // indirect
	golang.org/x/sync v0.14.0 // indirect
	golang.org/x/text v0.25.0 // indirect
	golang.org/x/tools v0.21.1-0.20240508182429-e35e4ccd0d2d // indirect
)

################################################################################
# FILE: :\good projects\cost estimation\README.md
# TYPE: markdown
# SIZE: 3871 bytes
################################################################################
# Terraform Cost Estimation System

A production-grade, cloud-agnostic infrastructure cost estimation tool for Terraform configurations.

## Features

- **Cloud-Agnostic Core**: Support for AWS, Azure, and GCP (AWS fully implemented)
- **Asset Graph**: Provider-agnostic infrastructure DAG for diff and explainability
- **Cost Graph**: Full lineage tracking for every cost calculation
- **Reproducible Estimates**: Versioned pricing snapshots
- **Policy Engine**: Budget limits, thresholds, and guardrails
- **Multiple Outputs**: CLI tables, JSON, HTML, PR comments

## Quick Start

### Using Docker (Recommended)

```bash
# Build the image
docker build -t terraform-cost .

# Run estimation on a Terraform project
docker run -v /path/to/your/terraform:/projects terraform-cost estimate /projects

# Using docker-compose
docker-compose run terraform-cost estimate /projects
```

### Building from Source

```bash
# Clone the repository
git clone https://github.com/your-org/terraform-cost.git
cd terraform-cost

# Install dependencies
go mod download

# Build
go build -o terraform-cost ./cmd/cli

# Run
./terraform-cost estimate ./your-terraform-project
```

## Usage

```bash
# Basic estimation
terraform-cost estimate ./my-terraform-project

# JSON output
terraform-cost estimate --format json ./infrastructure

# With custom usage file
terraform-cost estimate --usage usage.yml ./infrastructure

# Show version
terraform-cost version
```

## Project Structure

```
terraform-cost/
â”œâ”€â”€ cmd/                    # CLI and server entry points
â”‚   â”œâ”€â”€ cli/
â”‚   â””â”€â”€ server/
â”œâ”€â”€ core/                   # Cloud-agnostic core engine
â”‚   â”œâ”€â”€ types/              # Domain types
â”‚   â”œâ”€â”€ scanner/            # Infrastructure scanning
â”‚   â”œâ”€â”€ asset/              # Asset graph
â”‚   â”œâ”€â”€ usage/              # Usage estimation
â”‚   â”œâ”€â”€ cost/               # Cost calculation
â”‚   â”œâ”€â”€ pricing/            # Pricing resolution
â”‚   â”œâ”€â”€ policy/             # Policy evaluation
â”‚   â””â”€â”€ output/             # Output formatting
â”œâ”€â”€ clouds/                 # Cloud provider plugins
â”‚   â”œâ”€â”€ aws/
â”‚   â”œâ”€â”€ azure/
â”‚   â””â”€â”€ gcp/
â”œâ”€â”€ adapters/               # External system adapters
â”‚   â””â”€â”€ terraform/
â”œâ”€â”€ internal/               # Internal utilities
â””â”€â”€ examples/               # Example Terraform configs
```

## Supported AWS Resources

| Category   | Resources |
|------------|-----------|
| Compute    | EC2, Auto Scaling, Lambda, ECS, EKS |
| Storage    | S3, EBS, EFS |
| Database   | RDS, DynamoDB, ElastiCache |
| Network    | NAT Gateway, VPC Endpoints, ALB/NLB/ELB |
| Security   | KMS, Secrets Manager |
| Monitoring | CloudWatch Log Groups |

## Architecture

```
Input â†’ Scanner â†’ Asset Graph â†’ Usage Estimation â†’ Cost Graph â†’ Pricing â†’ Policy â†’ Output
```

### Key Design Principles

1. **Hard Separation of Concerns**: Scanners don't know about pricing
2. **Cloud Providers are Plugins**: Core engine is cloud-agnostic
3. **Deterministic & Reproducible**: Every estimate uses versioned pricing
4. **Everything is a Graph**: Enables diff, lineage, and explainability

## Configuration

Create `.terraform-cost.json` in your home directory or project root:

```json
{
  "pricing": {
    "default_currency": "USD",
    "cache_enabled": true
  },
  "output": {
    "default_format": "cli",
    "show_details": true
  },
  "aws": {
    "default_region": "us-east-1"
  }
}
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `go test ./...`
5. Submit a pull request

## License

MIT License - see [LICENSE](LICENSE) for details.

################################################################################
# FILE: :\good projects\cost estimation\SUPPORTED_SERVICES.md
# TYPE: markdown
# SIZE: 6124 bytes
################################################################################
# Supported Services

This document defines the cost coverage status of the Terraform Cost Estimation platform.

> **Philosophy**: We support ~30 services that cover ~95% of real-world cloud spend.
> Unsupported resources are **explicit**, not hidden.

## Coverage Summary

| Status | AWS | Azure | GCP | Total |
|--------|-----|-------|-----|-------|
| âœ… **Numeric** | 13 | 1 | 1 | 15 |
| âš ï¸ **Symbolic** (usage-dependent) | 2 | 0 | 0 | 2 |
| â¬œ **Indirect** (free) | 15+ | - | - | 15+ |
| âŒ **Planned** | 5 | 10+ | 10+ | 25+ |

---

## AWS Services

### âœ… Fully Supported (Numeric Cost)

| Resource Type | Est. Spend | Components | Status |
|--------------|------------|------------|--------|
| `aws_instance` | ~25% | compute, root_storage, ebs_optimized | âœ… |
| `aws_ebs_volume` | ~8% | storage, iops, throughput | âœ… |
| `aws_db_instance` | ~12% | instance, storage, iops, backup | âœ… |
| `aws_dynamodb_table` | ~3% | capacity, storage, replicas | âœ… |
| `aws_s3_bucket` | ~6% | storage, requests, data_transfer | âœ… |
| `aws_lambda_function` | ~4% | requests, duration, ephemeral_storage | âœ… |
| `aws_nat_gateway` | ~5% | hourly, data_processed | âœ… |
| `aws_lb` | ~4% | hourly, LCU | âœ… |
| `aws_eks_cluster` | ~3% | control_plane | âœ… |
| `aws_eks_node_group` | - | nodes (EC2 pricing) | âœ… |
| `aws_elasticache_cluster` | ~2.5% | cache_nodes | âœ… |
| `aws_elasticache_replication_group` | - | cache_nodes (clustered) | âœ… |
| `aws_cloudwatch_metric_alarm` | ~0.5% | alarms | âœ… |
| `aws_autoscaling_group` | indirect | projects instance costs | âœ… |

**Total estimated coverage: ~73% of typical AWS spend**

---

### âš ï¸ Usage-Based (Symbolic without usage data)

| Resource Type | Status | Notes |
|--------------|--------|-------|
| `aws_cloudwatch_log_group` | âš ï¸ | Requires `monthly_ingestion_gb`, `storage_gb` |

---

### ðŸ”¸ Planned (Next Priority)

| Resource Type | Est. Spend | Status |
|--------------|------------|--------|
| `aws_rds_cluster` (Aurora) | ~5% | TODO |
| `aws_redshift_cluster` | ~2% | TODO |
| `aws_opensearch_domain` | ~2% | TODO |
| `aws_kinesis_stream` | ~1.5% | TODO |
| `aws_api_gateway_rest_api` | ~1% | TODO |

**Adding these would bring coverage to ~85%**

---

### â¬œ Indirect Cost (Free Resources)

| Resource Type | Notes |
|--------------|-------|
| `aws_vpc` | VPC itself is free |
| `aws_subnet` | Subnets are free |
| `aws_security_group` | SGs are free |
| `aws_route_table` | Route tables are free |
| `aws_internet_gateway` | IGW is free (data transfer costs) |
| `aws_iam_role` | IAM is free |
| `aws_iam_policy` | IAM is free |
| `aws_launch_template` | Config only |
| `aws_ecs_service` | ECS is free (EC2/Fargate costs) |
| `aws_ecs_task_definition` | Config only |

---

## Azure Services

### ðŸ”¸ Placeholder (In Development)

| Resource Type | Status |
|--------------|--------|
| `azurerm_linux_virtual_machine` | Stub |
| `azurerm_storage_account` | TODO |
| `azurerm_sql_database` | TODO |

---

## GCP Services

### ðŸ”¸ Placeholder (In Development)

| Resource Type | Status |
|--------------|--------|
| `google_compute_instance` | Stub |
| `google_storage_bucket` | TODO |
| `google_sql_database_instance` | TODO |

---

## Directory Structure

```
clouds/
â”œâ”€â”€ types.go              # Core interfaces
â”œâ”€â”€ registry.go           # Plugin registry
â”‚
â”œâ”€â”€ aws/
â”‚   â”œâ”€â”€ compute/
â”‚   â”‚   â”œâ”€â”€ ec2.go        # aws_instance
â”‚   â”‚   â””â”€â”€ autoscaling.go
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ s3.go
â”‚   â”‚   â””â”€â”€ ebs.go
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ rds.go
â”‚   â”‚   â”œâ”€â”€ dynamodb.go
â”‚   â”‚   â””â”€â”€ elasticache.go
â”‚   â”œâ”€â”€ networking/
â”‚   â”‚   â”œâ”€â”€ nat_gateway.go
â”‚   â”‚   â””â”€â”€ lb.go
â”‚   â”œâ”€â”€ containers/
â”‚   â”‚   â””â”€â”€ eks.go
â”‚   â”œâ”€â”€ observability/
â”‚   â”‚   â””â”€â”€ cloudwatch.go
â”‚   â””â”€â”€ serverless/
â”‚       â””â”€â”€ lambda.go
â”‚
â”œâ”€â”€ azure/
â”‚   â””â”€â”€ compute/
â”‚       â””â”€â”€ vm.go         # Stub
â”‚
â””â”€â”€ gcp/
    â””â”€â”€ compute/
        â””â”€â”€ instance.go   # Stub
```

---

## Coverage Report

Every estimation includes a coverage report:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    COST COVERAGE REPORT                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Numeric cost:      87.3%  (15 resources)                 â•‘
â•‘  Symbolic cost:      8.2%  (2 resources)                  â•‘
â•‘  Unsupported:        4.5%  (1 resource)                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Strict Mode Thresholds

| Mode | Max Unsupported | Max Symbolic | Min Numeric |
|------|----------------|--------------|-------------|
| Permissive | 100% | 100% | 0% |
| Default | 5% | 10% | 80% |
| Production | 0% | 5% | 95% |

---

## Cost Behavior Classification

| Behavior | Description | Engine Action |
|----------|-------------|---------------|
| `direct` | Always billable | Require mapper |
| `usage_based` | Billable with usage | Mapper + usage data |
| `indirect` | Free, enables costs | Emit zero-cost node |
| `free` | Explicitly free | No cost |
| `unsupported` | Not modeled | Symbolic bucket |

---

## Adding New Services

1. **Classify** in `core/coverage/aws_profiles.go`
2. **Implement mapper** in `clouds/aws/<category>/<service>.go`
3. **Add tests** with Terraform examples
4. **Update this document**

Priority: **Cost impact > feature count**

################################################################################
# FILE: :\good projects\cost estimation\adapters\ci\adapter.go
# TYPE: go
# SIZE: 18420 bytes
################################################################################
// Package adapter provides production-grade CI adapter for the cost estimation engine.
// This adapter provides CI-specific output formats and policy enforcement.
package adapter

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"sort"
	"strings"
	"time"

	"terraform-cost/core/engine"
	"terraform-cost/core/model"
	"terraform-cost/core/pricing"
	"terraform-cost/core/terraform"
)

// isStrict returns true if strict mode is enabled (unified check)
func (a *CIAdapter) isStrict() bool {
	return a.config.StrictMode || a.config.Mode == ModeStrict
}

// CIAdapter is a production-grade CI adapter
type CIAdapter struct {
	engine   *engine.Engine
	pipeline *terraform.Pipeline
	output   io.Writer
	config   *CIConfig
}

// CIConfig configures CI behavior
type CIConfig struct {
	// Mode controls CI behavior
	Mode CIMode `json:"mode"`

	// OutputFormat for results
	OutputFormat CIOutputFormat `json:"output_format"`

	// Budget threshold (monthly)
	BudgetLimit float64 `json:"budget_limit"`

	// MaxSymbolicPercent allowed
	MaxSymbolicPercent float64 `json:"max_symbolic_percent"`

	// MaxUnsupportedPercent allowed
	MaxUnsupportedPercent float64 `json:"max_unsupported_percent"`

	// MinConfidence required
	MinConfidence float64 `json:"min_confidence"`

	// FailOnWarnings treats warnings as errors
	FailOnWarnings bool `json:"fail_on_warnings"`

	// CommentPrefix for PR comments
	CommentPrefix string `json:"comment_prefix"`

	// StrictMode fails on symbolic costs
	StrictMode bool `json:"strict_mode"`
}

// CIMode controls CI behavior
type CIMode string

const (
	// ModeInformational only comments, no check result
	ModeInformational CIMode = "informational"

	// ModeWarning comments and warns but doesn't block
	ModeWarning CIMode = "warning"

	// ModeBlocking fails the check on policy violations
	ModeBlocking CIMode = "blocking"

	// ModeStrict fails on any symbolic or unsupported
	ModeStrict CIMode = "strict"
)

// CIOutputFormat specifies output format
type CIOutputFormat string

const (
	FormatJSON     CIOutputFormat = "json"
	FormatMarkdown CIOutputFormat = "markdown"
	FormatTable    CIOutputFormat = "table"
	FormatGitHub   CIOutputFormat = "github"
	FormatGitLab   CIOutputFormat = "gitlab"
)

// DefaultCIConfig returns production defaults
func DefaultCIConfig() *CIConfig {
	return &CIConfig{
		Mode:                  ModeBlocking,
		OutputFormat:          FormatMarkdown,
		BudgetLimit:           0, // No limit
		MaxSymbolicPercent:    20,
		MaxUnsupportedPercent: 10,
		MinConfidence:         0.7,
		FailOnWarnings:        false,
		CommentPrefix:         "ðŸ’° Terraform Cost Estimate",
		StrictMode:            false,
	}
}

// NewCIAdapter creates a CI adapter
func NewCIAdapter(eng *engine.Engine, pipeline *terraform.Pipeline, config *CIConfig) *CIAdapter {
	if config == nil {
		config = DefaultCIConfig()
	}
	return &CIAdapter{
		engine:   eng,
		pipeline: pipeline,
		output:   os.Stdout,
		config:   config,
	}
}

// SetOutput sets the output writer
func (a *CIAdapter) SetOutput(w io.Writer) {
	a.output = w
}

// CIRequest is the CI input
type CIRequest struct {
	// Path to Terraform project
	Path string

	// PlanFile is the tfplan file path
	PlanFile string

	// Provider (aws, azure, gcp)
	Provider string

	// Region
	Region string

	// SnapshotID to use
	SnapshotID string

	// UsageFile for overrides
	UsageFile string

	// BaseFile for diff comparison
	BaseFile string
}

// CIResult is the CI output
type CIResult struct {
	// Success indicates estimation succeeded
	Success bool `json:"success"`

	// ExitCode for CI
	ExitCode int `json:"exit_code"`

	// CheckConclusion for GitHub
	CheckConclusion string `json:"check_conclusion"` // success, neutral, failure

	// Summary for check run
	Summary string `json:"summary"`

	// TotalCost monthly
	TotalCost float64 `json:"total_cost"`

	// Confidence (0-1)
	Confidence float64 `json:"confidence"`

	// Coverage breakdown
	Coverage CICoverage `json:"coverage"`

	// PolicyViolations
	PolicyViolations []PolicyViolation `json:"policy_violations,omitempty"`

	// Warnings
	Warnings []string `json:"warnings,omitempty"`

	// Diff if comparing
	Diff *CIDiff `json:"diff,omitempty"`

	// Resources with costs
	Resources []CIResourceCost `json:"resources"`

	// Snapshot used
	Snapshot CISnapshot `json:"snapshot"`

	// Metadata
	Metadata CIMetadata `json:"metadata"`
}

// CICoverage is coverage breakdown
type CICoverage struct {
	NumericPercent     float64 `json:"numeric_percent"`
	SymbolicPercent    float64 `json:"symbolic_percent"`
	IndirectPercent    float64 `json:"indirect_percent"`
	UnsupportedPercent float64 `json:"unsupported_percent"`
}

// CIDiff is cost comparison
type CIDiff struct {
	OldCost       float64 `json:"old_cost"`
	NewCost       float64 `json:"new_cost"`
	Delta         float64 `json:"delta"`
	DeltaPercent  float64 `json:"delta_percent"`
	CreatedCount  int     `json:"created_count"`
	DestroyedCount int    `json:"destroyed_count"`
	UpdatedCount  int     `json:"updated_count"`
}

// CIResourceCost is per-resource cost
type CIResourceCost struct {
	Address      string  `json:"address"`
	Type         string  `json:"type"`
	MonthlyCost  float64 `json:"monthly_cost"`
	Confidence   float64 `json:"confidence"`
	CoverageType string  `json:"coverage_type"`
	ChangeType   string  `json:"change_type,omitempty"` // create, destroy, update
	Delta        float64 `json:"delta,omitempty"`
}

// CISnapshot is snapshot info
type CISnapshot struct {
	ID          string `json:"id"`
	Provider    string `json:"provider"`
	Region      string `json:"region"`
	ContentHash string `json:"content_hash"`
}

// CIMetadata is execution context
type CIMetadata struct {
	Timestamp time.Time `json:"timestamp"`
	Duration  string    `json:"duration"`
	Version   string    `json:"version"`
	Mode      string    `json:"mode"`
}

// PolicyViolation is a policy failure
type PolicyViolation struct {
	Rule      string  `json:"rule"`
	Message   string  `json:"message"`
	Severity  string  `json:"severity"` // error, warning
	Threshold float64 `json:"threshold,omitempty"`
	Actual    float64 `json:"actual,omitempty"`
}

// Run executes the CI estimation
func (a *CIAdapter) Run(ctx context.Context, req *CIRequest) (*CIResult, error) {
	start := time.Now()

	// 1. Run Terraform pipeline
	scanInput := &terraform.ScanInput{
		RootPath:  req.Path,
		Workspace: "default",
	}

	pipelineResult, err := a.pipeline.Execute(ctx, scanInput)
	if err != nil {
		return a.failResult(fmt.Sprintf("Failed to scan terraform: %v", err), start), nil
	}

	// 2. Build snapshot request
	snapshotReq := engine.SnapshotRequest{
		Provider: req.Provider,
		Region:   req.Region,
	}
	if req.SnapshotID != "" {
		snapshotReq.SnapshotID = pricing.SnapshotID(req.SnapshotID)
	}

	// 3. Load usage overrides
	overrides := make(map[model.InstanceID]map[string]float64)
	if req.UsageFile != "" {
		if data, err := os.ReadFile(req.UsageFile); err == nil {
			var raw map[string]map[string]float64
			if json.Unmarshal(data, &raw) == nil {
				for k, v := range raw {
					overrides[model.InstanceID(k)] = v
				}
			}
		}
	}

	// 4. Execute estimation
	engineReq := &engine.EstimateRequest{
		Graph:           pipelineResult.Graph,
		SnapshotRequest: snapshotReq,
		UsageOverrides:  overrides,
	}

	result, err := a.engine.Estimate(ctx, engineReq)
	if err != nil {
		return a.failResult(fmt.Sprintf("Estimation failed: %v", err), start), nil
	}

	// 5. Build CI result
	ciResult := a.buildCIResult(result, start)

	// 6. Evaluate policies
	a.evaluatePolicies(ciResult)

	// 7. Output in requested format
	if err := a.output(ciResult); err != nil {
		return nil, err
	}

	return ciResult, nil
}

func (a *CIAdapter) buildCIResult(result *engine.EstimationResult, start time.Time) *CIResult {
	ciResult := &CIResult{
		Success:    true,
		ExitCode:   0,
		TotalCost:  result.TotalMonthlyCost.Float64(),
		Confidence: result.Confidence.Score,
		Warnings:   result.Warnings,
		Metadata: CIMetadata{
			Timestamp: time.Now(),
			Duration:  time.Since(start).String(),
			Version:   "1.0.0",
			Mode:      string(a.config.Mode),
		},
	}

	// FIX #1: Populate coverage from engine result
	if result.CoverageReport != nil {
		ciResult.Coverage = CICoverage{
			NumericPercent:     result.CoverageReport.NumericPercent,
			SymbolicPercent:    result.CoverageReport.SymbolicPercent,
			IndirectPercent:    result.CoverageReport.IndirectPercent,
			UnsupportedPercent: result.CoverageReport.UnsupportedPercent,
		}
	} else {
		// Fallback: calculate from resources if CoverageReport not available
		numericCount := 0
		symbolicCount := 0
		unsupportedCount := 0
		totalCount := 0
		result.InstanceCosts.Range(func(id model.InstanceID, cost *engine.InstanceCost) bool {
			totalCount++
			switch cost.CoverageType {
			case engine.CoverageTypeNumeric:
				numericCount++
			case engine.CoverageTypeSymbolic:
				symbolicCount++
			case engine.CoverageTypeUnsupported:
				unsupportedCount++
			}
			return true
		})
		if totalCount > 0 {
			ciResult.Coverage = CICoverage{
				NumericPercent:     float64(numericCount) / float64(totalCount) * 100,
				SymbolicPercent:    float64(symbolicCount) / float64(totalCount) * 100,
				UnsupportedPercent: float64(unsupportedCount) / float64(totalCount) * 100,
			}
		}
	}

	// Snapshot
	if result.Snapshot != nil {
		ciResult.Snapshot = CISnapshot{
			ID:          string(result.Snapshot.ID),
			Provider:    result.Snapshot.Provider,
			Region:      result.Snapshot.Region,
			ContentHash: result.Snapshot.ContentHash.Hex(),
		}
	}

	// Resources: collect all first
	var resources []CIResourceCost
	result.InstanceCosts.Range(func(id model.InstanceID, cost *engine.InstanceCost) bool {
		// FIX #3: Set CoverageType from core coverage classification
		coverageType := "numeric" // default
		switch cost.CoverageType {
		case engine.CoverageTypeSymbolic:
			coverageType = "symbolic"
		case engine.CoverageTypeUnsupported:
			coverageType = "unsupported"
		case engine.CoverageTypeIndirect:
			coverageType = "indirect"
		}

		rc := CIResourceCost{
			Address:      string(cost.Address),
			Type:         string(cost.ResourceType),
			MonthlyCost:  cost.MonthlyCost.Float64(),
			Confidence:   cost.Confidence.Score,
			CoverageType: coverageType,
		}
		resources = append(resources, rc)
		return true
	})

	// FIX #2: Sort resources by cost descending for consistent output
	sort.Slice(resources, func(i, j int) bool {
		return resources[i].MonthlyCost > resources[j].MonthlyCost
	})

	ciResult.Resources = resources

	return ciResult
}

func (a *CIAdapter) evaluatePolicies(result *CIResult) {
	// Budget check
	if a.config.BudgetLimit > 0 && result.TotalCost > a.config.BudgetLimit {
		result.PolicyViolations = append(result.PolicyViolations, PolicyViolation{
			Rule:      "budget_limit",
			Message:   fmt.Sprintf("Monthly cost $%.2f exceeds budget $%.2f", result.TotalCost, a.config.BudgetLimit),
			Severity:  "error",
			Threshold: a.config.BudgetLimit,
			Actual:    result.TotalCost,
		})
	}

	// Symbolic check
	if result.Coverage.SymbolicPercent > a.config.MaxSymbolicPercent {
		severity := "warning"
		if a.isStrict() { // FIX #4: Use unified isStrict() helper
			severity = "error"
		}
		result.PolicyViolations = append(result.PolicyViolations, PolicyViolation{
			Rule:      "symbolic_limit",
			Message:   fmt.Sprintf("Symbolic coverage %.1f%% exceeds limit %.1f%%", result.Coverage.SymbolicPercent, a.config.MaxSymbolicPercent),
			Severity:  severity,
			Threshold: a.config.MaxSymbolicPercent,
			Actual:    result.Coverage.SymbolicPercent,
		})
	}

	// Unsupported check
	if result.Coverage.UnsupportedPercent > a.config.MaxUnsupportedPercent {
		result.PolicyViolations = append(result.PolicyViolations, PolicyViolation{
			Rule:      "unsupported_limit",
			Message:   fmt.Sprintf("Unsupported coverage %.1f%% exceeds limit %.1f%%", result.Coverage.UnsupportedPercent, a.config.MaxUnsupportedPercent),
			Severity:  "warning",
			Threshold: a.config.MaxUnsupportedPercent,
			Actual:    result.Coverage.UnsupportedPercent,
		})
	}

	// Confidence check
	if result.Confidence < a.config.MinConfidence {
		result.PolicyViolations = append(result.PolicyViolations, PolicyViolation{
			Rule:      "confidence_minimum",
			Message:   fmt.Sprintf("Confidence %.0f%% below minimum %.0f%%", result.Confidence*100, a.config.MinConfidence*100),
			Severity:  "warning",
			Threshold: a.config.MinConfidence,
			Actual:    result.Confidence,
		})
	}

	// Determine exit code and check conclusion
	hasErrors := false
	hasWarnings := false
	for _, v := range result.PolicyViolations {
		if v.Severity == "error" {
			hasErrors = true
		} else {
			hasWarnings = true
		}
	}

	switch a.config.Mode {
	case ModeInformational:
		result.ExitCode = 0
		result.CheckConclusion = "success"
	case ModeWarning:
		result.ExitCode = 0
		if hasErrors || hasWarnings {
			result.CheckConclusion = "neutral"
		} else {
			result.CheckConclusion = "success"
		}
	case ModeBlocking, ModeStrict:
		if hasErrors {
			result.ExitCode = 1
			result.CheckConclusion = "failure"
		} else if hasWarnings && a.config.FailOnWarnings {
			result.ExitCode = 1
			result.CheckConclusion = "failure"
		} else {
			result.ExitCode = 0
			result.CheckConclusion = "success"
		}
	}

	// Build summary
	result.Summary = a.buildSummary(result)
}

func (a *CIAdapter) buildSummary(result *CIResult) string {
	var sb strings.Builder

	sb.WriteString(fmt.Sprintf("Total Monthly Cost: $%.2f\n", result.TotalCost))
	sb.WriteString(fmt.Sprintf("Confidence: %.0f%%\n", result.Confidence*100))
	sb.WriteString(fmt.Sprintf("Coverage: %.0f%% numeric | %.0f%% symbolic | %.0f%% unsupported\n",
		result.Coverage.NumericPercent,
		result.Coverage.SymbolicPercent,
		result.Coverage.UnsupportedPercent,
	))

	if len(result.PolicyViolations) > 0 {
		sb.WriteString("\nPolicy Violations:\n")
		for _, v := range result.PolicyViolations {
			icon := "âš ï¸"
			if v.Severity == "error" {
				icon = "âŒ"
			}
			sb.WriteString(fmt.Sprintf("%s %s: %s\n", icon, v.Rule, v.Message))
		}
	}

	return sb.String()
}

func (a *CIAdapter) failResult(message string, start time.Time) *CIResult {
	return &CIResult{
		Success:         false,
		ExitCode:        1,
		CheckConclusion: "failure",
		Summary:         message,
		Metadata: CIMetadata{
			Timestamp: time.Now(),
			Duration:  time.Since(start).String(),
			Version:   "1.0.0",
		},
	}
}

func (a *CIAdapter) output(result *CIResult) error {
	switch a.config.OutputFormat {
	case FormatJSON:
		return a.outputJSON(result)
	case FormatMarkdown, FormatGitHub:
		return a.outputMarkdown(result)
	case FormatTable:
		return a.outputTable(result)
	default:
		return a.outputMarkdown(result)
	}
}

func (a *CIAdapter) outputJSON(result *CIResult) error {
	enc := json.NewEncoder(a.output)
	enc.SetIndent("", "  ")
	return enc.Encode(result)
}

func (a *CIAdapter) outputMarkdown(result *CIResult) error {
	var sb strings.Builder

	sb.WriteString(fmt.Sprintf("## %s\n\n", a.config.CommentPrefix))

	// Summary
	delta := ""
	if result.Diff != nil {
		sign := "+"
		if result.Diff.Delta < 0 {
			sign = ""
		}
		delta = fmt.Sprintf(" (%s$%.2f)", sign, result.Diff.Delta)
	}

	sb.WriteString(fmt.Sprintf("**Total Monthly Cost:** $%.2f%s\n", result.TotalCost, delta))
	sb.WriteString(fmt.Sprintf("**Confidence:** %.0f%%\n", result.Confidence*100))
	sb.WriteString(fmt.Sprintf("**Coverage:** %.0f%% numeric | %.0f%% symbolic | %.0f%% unsupported\n\n",
		result.Coverage.NumericPercent,
		result.Coverage.SymbolicPercent,
		result.Coverage.UnsupportedPercent,
	))

	// Top resources
	sb.WriteString("### Top Resources by Cost\n")
	count := 5
	if len(result.Resources) < count {
		count = len(result.Resources)
	}
	for i := 0; i < count; i++ {
		r := result.Resources[i]
		icon := "ðŸŸ¢"
		if r.CoverageType == "symbolic" {
			icon = "ðŸŸ¡"
		} else if r.CoverageType == "unsupported" {
			icon = "ðŸ”´"
		}
		sb.WriteString(fmt.Sprintf("- %s `%s`: $%.2f\n", icon, r.Address, r.MonthlyCost))
	}
	sb.WriteString("\n")

	// Policy violations
	if len(result.PolicyViolations) > 0 {
		sb.WriteString("### Policy Violations\n")
		for _, v := range result.PolicyViolations {
			icon := "âš ï¸"
			if v.Severity == "error" {
				icon = "âŒ"
			}
			sb.WriteString(fmt.Sprintf("- %s **%s**: %s\n", icon, v.Rule, v.Message))
		}
		sb.WriteString("\n")
	}

	// Snapshot
	sb.WriteString("---\n")
	sb.WriteString(fmt.Sprintf("ðŸ“¦ Snapshot: `%s/%s` @ %s\n",
		result.Snapshot.Provider,
		result.Snapshot.Region,
		result.Snapshot.ID[:8],
	))

	_, err := a.output.Write([]byte(sb.String()))
	return err
}

func (a *CIAdapter) outputTable(result *CIResult) error {
	var sb strings.Builder

	sb.WriteString("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
	sb.WriteString(fmt.Sprintf("â”‚ Total Monthly Cost           $%-28.2f â”‚\n", result.TotalCost))
	sb.WriteString(fmt.Sprintf("â”‚ Confidence                   %-29.0f%% â”‚\n", result.Confidence*100))
	sb.WriteString("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n")
	sb.WriteString(fmt.Sprintf("â”‚ Numeric: %.0f%%  Symbolic: %.0f%%  Unsupported: %.0f%%            â”‚\n",
		result.Coverage.NumericPercent,
		result.Coverage.SymbolicPercent,
		result.Coverage.UnsupportedPercent,
	))
	sb.WriteString("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")

	_, err := a.output.Write([]byte(sb.String()))
	return err
}

################################################################################
# FILE: :\good projects\cost estimation\adapters\cli\adapter.go
# TYPE: go
# SIZE: 10369 bytes
################################################################################
// Package adapter provides thin adapters over the core engine.
// CLI, HTTP, and CI adapters are all thin wrappers.
package adapter

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"time"

	"terraform-cost/core/engine"
	"terraform-cost/core/model"
	"terraform-cost/core/pricing"
	"terraform-cost/core/terraform"
)

// CLIAdapter is a THIN wrapper around the core engine.
// It handles input/output only - all logic is in the engine.
type CLIAdapter struct {
	engine   *engine.Engine
	pipeline *terraform.Pipeline
	output   io.Writer
	format   OutputFormat
}

// OutputFormat specifies the output format
type OutputFormat int

const (
	FormatTable OutputFormat = iota
	FormatJSON
	FormatMarkdown
)

// NewCLIAdapter creates a new CLI adapter
func NewCLIAdapter(eng *engine.Engine, pipeline *terraform.Pipeline) *CLIAdapter {
	return &CLIAdapter{
		engine:   eng,
		pipeline: pipeline,
		output:   os.Stdout,
		format:   FormatTable,
	}
}

// SetOutput sets the output writer
func (a *CLIAdapter) SetOutput(w io.Writer) {
	a.output = w
}

// SetFormat sets the output format
func (a *CLIAdapter) SetFormat(f OutputFormat) {
	a.format = f
}

// CLIRequest is the CLI input
type CLIRequest struct {
	// Path to Terraform project
	Path string

	// Variables from CLI
	Variables map[string]any

	// Snapshot specification
	SnapshotID string
	Provider   string
	Region     string

	// Usage overrides file
	UsageFile string

	// Output options
	Format     string
	ShowLineage bool
}

// Run executes the estimation
func (a *CLIAdapter) Run(ctx context.Context, req *CLIRequest) error {
	// 1. Run Terraform pipeline
	scanInput := &terraform.ScanInput{
		RootPath:  req.Path,
		Workspace: "default",
	}

	pipelineResult, err := a.pipeline.Execute(ctx, scanInput)
	if err != nil {
		return fmt.Errorf("failed to scan terraform: %w", err)
	}

	// 2. Build estimation request
	snapshotReq := engine.SnapshotRequest{
		Provider: req.Provider,
		Region:   req.Region,
	}
	if req.SnapshotID != "" {
		snapshotReq.SnapshotID = pricing.SnapshotID(req.SnapshotID)
	}

	// Load usage overrides if provided
	overrides := make(map[model.InstanceID]map[string]float64)
	if req.UsageFile != "" {
		var err error
		overrides, err = a.loadUsageOverrides(req.UsageFile)
		if err != nil {
			fmt.Fprintf(a.output, "Warning: could not load usage file: %v\n", err)
		}
	}

	// 3. Delegate to engine
	estimateReq := &engine.EstimateRequest{
		Graph:           pipelineResult.Graph,
		SnapshotRequest: snapshotReq,
		UsageOverrides:  overrides,
	}

	result, err := a.engine.Estimate(ctx, estimateReq)
	if err != nil {
		return fmt.Errorf("estimation failed: %w", err)
	}

	// 4. Format and output
	switch a.format {
	case FormatJSON:
		return a.outputJSON(result)
	case FormatMarkdown:
		return a.outputMarkdown(result)
	default:
		return a.outputTable(result, req.ShowLineage)
	}
}

func (a *CLIAdapter) loadUsageOverrides(path string) (map[model.InstanceID]map[string]float64, error) {
	data, err := os.ReadFile(path)
	if err != nil {
		return nil, err
	}

	var raw map[string]map[string]float64
	if err := json.Unmarshal(data, &raw); err != nil {
		return nil, err
	}

	result := make(map[model.InstanceID]map[string]float64)
	for k, v := range raw {
		result[model.InstanceID(k)] = v
	}
	return result, nil
}

func (a *CLIAdapter) outputTable(result *engine.EstimationResult, showLineage bool) error {
	fmt.Fprintln(a.output, "")
	fmt.Fprintln(a.output, "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Fprintln(a.output, "â•‘                     COST ESTIMATION REPORT                        â•‘")
	fmt.Fprintln(a.output, "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Fprintln(a.output, "")

	// Snapshot info
	fmt.Fprintf(a.output, "Pricing Snapshot: %s (verified: %s)\n",
		result.Snapshot.ID, result.Snapshot.ContentHash.String())
	fmt.Fprintf(a.output, "Effective Date:   %s\n", result.Snapshot.EffectiveAt.Format(time.RFC3339))
	fmt.Fprintf(a.output, "Provider/Region:  %s / %s\n", result.Snapshot.Provider, result.Snapshot.Region)
	fmt.Fprintln(a.output, "")

	// Instance costs
	fmt.Fprintln(a.output, "COSTS BY INSTANCE")
	fmt.Fprintln(a.output, "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	fmt.Fprintf(a.output, "%-40s %12s %10s\n", "INSTANCE", "MONTHLY", "CONFIDENCE")
	fmt.Fprintln(a.output, "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

	result.InstanceCosts.Range(func(id model.InstanceID, cost *engine.InstanceCost) bool {
		confStr := fmt.Sprintf("%.0f%%", cost.Confidence.Score*100)
		if cost.Confidence.Score < 0.7 {
			confStr += " âš "
		}
		fmt.Fprintf(a.output, "%-40s %12s %10s\n",
			truncate(string(cost.Address), 40),
			cost.MonthlyCost.String(),
			confStr)

		// Show components if requested
		if showLineage {
			for _, comp := range cost.Components {
				fmt.Fprintf(a.output, "  â””â”€ %-36s %12s\n",
					comp.Name, comp.MonthlyCost.String())
			}
		}
		return true
	})

	fmt.Fprintln(a.output, "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	fmt.Fprintf(a.output, "%-40s %12s %10s\n",
		"TOTAL",
		result.TotalMonthlyCost.String(),
		fmt.Sprintf("%.0f%%", result.Confidence.Score*100))
	fmt.Fprintln(a.output, "")

	// Warnings
	if len(result.Warnings) > 0 {
		fmt.Fprintln(a.output, "WARNINGS")
		fmt.Fprintln(a.output, "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		for _, w := range result.Warnings {
			fmt.Fprintf(a.output, "âš  %s\n", w)
		}
		fmt.Fprintln(a.output, "")
	}

	// Policy results
	if result.PolicyResult != nil {
		fmt.Fprintln(a.output, "POLICY RESULTS")
		fmt.Fprintln(a.output, "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		for _, p := range result.PolicyResult.Policies {
			status := "âœ“ PASS"
			if !p.Passed {
				status = "âœ— FAIL"
			}
			fmt.Fprintf(a.output, "%s  %s: %s\n", status, p.Name, p.Message)
		}
		fmt.Fprintln(a.output, "")
	}

	return nil
}

func (a *CLIAdapter) outputJSON(result *engine.EstimationResult) error {
	// Convert to JSON-friendly structure
	output := map[string]interface{}{
		"snapshot": map[string]interface{}{
			"id":           result.Snapshot.ID,
			"content_hash": result.Snapshot.ContentHash.Hex(),
			"effective_at": result.Snapshot.EffectiveAt,
			"provider":     result.Snapshot.Provider,
			"region":       result.Snapshot.Region,
		},
		"total_monthly_cost": result.TotalMonthlyCost.StringRaw(),
		"total_hourly_cost":  result.TotalHourlyCost.StringRaw(),
		"confidence":         result.Confidence.Score,
		"instance_count":     result.InstanceCosts.Len(),
		"estimated_at":       result.EstimatedAt,
		"duration_ms":        result.Duration.Milliseconds(),
		"warnings":           result.Warnings,
		"degraded":           result.Degraded,
	}

	// Add instance costs
	instances := make(map[string]interface{})
	result.InstanceCosts.Range(func(id model.InstanceID, cost *engine.InstanceCost) bool {
		components := make([]map[string]interface{}, len(cost.Components))
		for i, c := range cost.Components {
			components[i] = map[string]interface{}{
				"name":         c.Name,
				"monthly_cost": c.MonthlyCost.StringRaw(),
				"hourly_cost":  c.HourlyCost.StringRaw(),
				"usage_value":  c.UsageValue,
				"usage_unit":   c.UsageUnit,
				"confidence":   c.Confidence,
			}
		}

		instances[string(id)] = map[string]interface{}{
			"address":       cost.Address,
			"definition_id": cost.DefinitionID,
			"monthly_cost":  cost.MonthlyCost.StringRaw(),
			"hourly_cost":   cost.HourlyCost.StringRaw(),
			"confidence":    cost.Confidence.Score,
			"components":    components,
		}
		return true
	})
	output["instances"] = instances

	encoder := json.NewEncoder(a.output)
	encoder.SetIndent("", "  ")
	return encoder.Encode(output)
}

func (a *CLIAdapter) outputMarkdown(result *engine.EstimationResult) error {
	fmt.Fprintln(a.output, "# Cost Estimation Report")
	fmt.Fprintln(a.output, "")
	fmt.Fprintf(a.output, "**Total Monthly Cost:** %s\n", result.TotalMonthlyCost.String())
	fmt.Fprintf(a.output, "**Confidence:** %.0f%%\n", result.Confidence.Score*100)
	fmt.Fprintln(a.output, "")

	fmt.Fprintln(a.output, "## Summary")
	fmt.Fprintln(a.output, "")
	fmt.Fprintln(a.output, "| Instance | Monthly Cost | Confidence |")
	fmt.Fprintln(a.output, "|----------|-------------|------------|")

	result.InstanceCosts.Range(func(id model.InstanceID, cost *engine.InstanceCost) bool {
		fmt.Fprintf(a.output, "| `%s` | %s | %.0f%% |\n",
			cost.Address, cost.MonthlyCost.String(), cost.Confidence.Score*100)
		return true
	})

	fmt.Fprintln(a.output, "")
	fmt.Fprintf(a.output, "| **Total** | **%s** | **%.0f%%** |\n",
		result.TotalMonthlyCost.String(), result.Confidence.Score*100)

	return nil
}

func truncate(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen-3] + "..."
}

// HTTPAdapter would be similar - thin wrapper delegating to engine
// type HTTPAdapter struct { ... }

// CIAdapter would be similar - outputs in CI-friendly format
// type CIAdapter struct { ... }

################################################################################
# FILE: :\good projects\cost estimation\adapters\git\adapter.go
# TYPE: go
# SIZE: 11313 bytes
################################################################################
// Package git provides production-grade Git adapter for the cost estimation engine.
// This adapter extracts git context for reproducible estimations and PR integration.
package git

import (
	"bytes"
	"context"
	"errors"
	"fmt"
	"os/exec"
	"path/filepath"
	"regexp"
	"strings"
	"time"
)

// Adapter is the Git adapter
type Adapter struct {
	repoPath string
	gitPath  string
}

// Config configures the Git adapter
type Config struct {
	// RepoPath is the repository path
	RepoPath string `json:"repo_path"`

	// GitPath is the git executable path (defaults to "git")
	GitPath string `json:"git_path"`
}

// New creates a new Git adapter
func New(config *Config) (*Adapter, error) {
	if config == nil {
		config = &Config{}
	}

	repoPath := config.RepoPath
	if repoPath == "" {
		repoPath = "."
	}

	absPath, err := filepath.Abs(repoPath)
	if err != nil {
		return nil, fmt.Errorf("failed to resolve repo path: %w", err)
	}

	gitPath := config.GitPath
	if gitPath == "" {
		gitPath = "git"
	}

	return &Adapter{
		repoPath: absPath,
		gitPath:  gitPath,
	}, nil
}

// Context represents git context for an estimation
type Context struct {
	// IsRepo indicates if path is a git repository
	IsRepo bool `json:"is_repo"`

	// Branch is the current branch
	Branch string `json:"branch"`

	// Commit is the current commit SHA
	Commit string `json:"commit"`

	// ShortCommit is shortened SHA
	ShortCommit string `json:"short_commit"`

	// CommitTime is when the commit was made
	CommitTime time.Time `json:"commit_time"`

	// Author is the commit author
	Author string `json:"author"`

	// AuthorEmail is the author email
	AuthorEmail string `json:"author_email"`

	// Message is the commit message
	Message string `json:"message"`

	// Tag is the current tag if any
	Tag string `json:"tag,omitempty"`

	// IsDirty indicates uncommitted changes
	IsDirty bool `json:"is_dirty"`

	// RemoteURL is the origin URL
	RemoteURL string `json:"remote_url,omitempty"`

	// Repository is the parsed repository name
	Repository string `json:"repository,omitempty"`

	// Owner is the repository owner
	Owner string `json:"owner,omitempty"`

	// PRNumber if in a PR context
	PRNumber int `json:"pr_number,omitempty"`

	// BaseBranch for PR comparison
	BaseBranch string `json:"base_branch,omitempty"`
}

// GetContext retrieves the current git context
func (a *Adapter) GetContext(ctx context.Context) (*Context, error) {
	// Check if git repo
	isRepo, err := a.isGitRepo(ctx)
	if err != nil {
		return nil, err
	}

	gitCtx := &Context{IsRepo: isRepo}
	if !isRepo {
		return gitCtx, nil
	}

	// Get branch
	if branch, err := a.getCurrentBranch(ctx); err == nil {
		gitCtx.Branch = branch
	}

	// Get commit info
	if commit, err := a.getCommit(ctx, "HEAD"); err == nil {
		gitCtx.Commit = commit
		if len(commit) >= 7 {
			gitCtx.ShortCommit = commit[:7]
		}
	}

	// Get commit time
	if commitTime, err := a.getCommitTime(ctx, "HEAD"); err == nil {
		gitCtx.CommitTime = commitTime
	}

	// Get author
	if author, email, err := a.getAuthor(ctx, "HEAD"); err == nil {
		gitCtx.Author = author
		gitCtx.AuthorEmail = email
	}

	// Get message
	if message, err := a.getCommitMessage(ctx, "HEAD"); err == nil {
		gitCtx.Message = message
	}

	// Get tag
	if tag, err := a.getCurrentTag(ctx); err == nil {
		gitCtx.Tag = tag
	}

	// Check dirty
	if dirty, err := a.isDirty(ctx); err == nil {
		gitCtx.IsDirty = dirty
	}

	// Get remote
	if remoteURL, err := a.getRemoteURL(ctx, "origin"); err == nil {
		gitCtx.RemoteURL = remoteURL
		owner, repo := parseRemoteURL(remoteURL)
		gitCtx.Owner = owner
		gitCtx.Repository = repo
	}

	return gitCtx, nil
}

// GetChangedFiles returns files changed between two refs
func (a *Adapter) GetChangedFiles(ctx context.Context, base, head string) ([]string, error) {
	if base == "" {
		base = "HEAD~1"
	}
	if head == "" {
		head = "HEAD"
	}

	output, err := a.run(ctx, "diff", "--name-only", base, head)
	if err != nil {
		return nil, fmt.Errorf("failed to get changed files: %w", err)
	}

	var files []string
	for _, line := range strings.Split(strings.TrimSpace(output), "\n") {
		if line != "" {
			files = append(files, line)
		}
	}
	return files, nil
}

// GetTerraformChanges returns changed Terraform files
func (a *Adapter) GetTerraformChanges(ctx context.Context, base, head string) ([]string, error) {
	files, err := a.GetChangedFiles(ctx, base, head)
	if err != nil {
		return nil, err
	}

	var tfFiles []string
	for _, file := range files {
		ext := filepath.Ext(file)
		if ext == ".tf" || ext == ".tfvars" || ext == ".hcl" {
			tfFiles = append(tfFiles, file)
		}
	}
	return tfFiles, nil
}

// HasTerraformChanges checks if there are Terraform changes
func (a *Adapter) HasTerraformChanges(ctx context.Context, base, head string) (bool, error) {
	files, err := a.GetTerraformChanges(ctx, base, head)
	if err != nil {
		return false, err
	}
	return len(files) > 0, nil
}

// GetBaseRef returns the base ref for comparison
func (a *Adapter) GetBaseRef(ctx context.Context, prNumber int) (string, error) {
	// Try to get merge base with main/master
	for _, branch := range []string{"main", "master", "develop"} {
		if _, err := a.getCommit(ctx, "origin/"+branch); err == nil {
			mergeBase, err := a.run(ctx, "merge-base", "HEAD", "origin/"+branch)
			if err == nil {
				return strings.TrimSpace(mergeBase), nil
			}
		}
	}

	// Fall back to parent commit
	return "HEAD~1", nil
}

// Checkout checks out a ref
func (a *Adapter) Checkout(ctx context.Context, ref string) error {
	_, err := a.run(ctx, "checkout", ref)
	return err
}

// Stash stashes changes
func (a *Adapter) Stash(ctx context.Context) error {
	_, err := a.run(ctx, "stash", "push", "-m", "terraform-cost-temp")
	return err
}

// StashPop pops the stash
func (a *Adapter) StashPop(ctx context.Context) error {
	_, err := a.run(ctx, "stash", "pop")
	return err
}

// Fetch fetches from remote
func (a *Adapter) Fetch(ctx context.Context, remote string) error {
	if remote == "" {
		remote = "origin"
	}
	_, err := a.run(ctx, "fetch", remote)
	return err
}

// Private methods

func (a *Adapter) isGitRepo(ctx context.Context) (bool, error) {
	_, err := a.run(ctx, "rev-parse", "--git-dir")
	if err != nil {
		var exitErr *exec.ExitError
		if errors.As(err, &exitErr) {
			return false, nil
		}
		return false, err
	}
	return true, nil
}

func (a *Adapter) getCurrentBranch(ctx context.Context) (string, error) {
	output, err := a.run(ctx, "rev-parse", "--abbrev-ref", "HEAD")
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(output), nil
}

func (a *Adapter) getCommit(ctx context.Context, ref string) (string, error) {
	output, err := a.run(ctx, "rev-parse", ref)
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(output), nil
}

func (a *Adapter) getCommitTime(ctx context.Context, ref string) (time.Time, error) {
	output, err := a.run(ctx, "show", "-s", "--format=%cI", ref)
	if err != nil {
		return time.Time{}, err
	}
	return time.Parse(time.RFC3339, strings.TrimSpace(output))
}

func (a *Adapter) getAuthor(ctx context.Context, ref string) (string, string, error) {
	name, err := a.run(ctx, "show", "-s", "--format=%an", ref)
	if err != nil {
		return "", "", err
	}
	email, err := a.run(ctx, "show", "-s", "--format=%ae", ref)
	if err != nil {
		return "", "", err
	}
	return strings.TrimSpace(name), strings.TrimSpace(email), nil
}

func (a *Adapter) getCommitMessage(ctx context.Context, ref string) (string, error) {
	output, err := a.run(ctx, "show", "-s", "--format=%s", ref)
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(output), nil
}

func (a *Adapter) getCurrentTag(ctx context.Context) (string, error) {
	output, err := a.run(ctx, "describe", "--tags", "--exact-match", "HEAD")
	if err != nil {
		return "", nil // No tag is not an error
	}
	return strings.TrimSpace(output), nil
}

func (a *Adapter) isDirty(ctx context.Context) (bool, error) {
	output, err := a.run(ctx, "status", "--porcelain")
	if err != nil {
		return false, err
	}
	return strings.TrimSpace(output) != "", nil
}

func (a *Adapter) getRemoteURL(ctx context.Context, remote string) (string, error) {
	output, err := a.run(ctx, "remote", "get-url", remote)
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(output), nil
}

func (a *Adapter) run(ctx context.Context, args ...string) (string, error) {
	cmd := exec.CommandContext(ctx, a.gitPath, args...)
	cmd.Dir = a.repoPath

	var stdout, stderr bytes.Buffer
	cmd.Stdout = &stdout
	cmd.Stderr = &stderr

	if err := cmd.Run(); err != nil {
		return "", fmt.Errorf("git %s failed: %w: %s", strings.Join(args, " "), err, stderr.String())
	}

	return stdout.String(), nil
}

// parseRemoteURL parses owner/repo from git remote URL
func parseRemoteURL(url string) (owner, repo string) {
	// SSH format: git@github.com:owner/repo.git
	sshRegex := regexp.MustCompile(`git@[^:]+:([^/]+)/(.+?)(?:\.git)?$`)
	if matches := sshRegex.FindStringSubmatch(url); len(matches) == 3 {
		return matches[1], matches[2]
	}

	// HTTPS format: https://github.com/owner/repo.git
	httpsRegex := regexp.MustCompile(`https?://[^/]+/([^/]+)/(.+?)(?:\.git)?$`)
	if matches := httpsRegex.FindStringSubmatch(url); len(matches) == 3 {
		return matches[1], matches[2]
	}

	return "", ""
}

// PRInfo contains pull request information
type PRInfo struct {
	Number     int       `json:"number"`
	Title      string    `json:"title"`
	Author     string    `json:"author"`
	BaseBranch string    `json:"base_branch"`
	HeadBranch string    `json:"head_branch"`
	BaseSHA    string    `json:"base_sha"`
	HeadSHA    string    `json:"head_sha"`
	IsDraft    bool      `json:"is_draft"`
	CreatedAt  time.Time `json:"created_at"`
	UpdatedAt  time.Time `json:"updated_at"`
}

// DiffStats contains diff statistics
type DiffStats struct {
	FilesChanged   int `json:"files_changed"`
	Insertions     int `json:"insertions"`
	Deletions      int `json:"deletions"`
	TerraformFiles int `json:"terraform_files"`
}

// GetDiffStats returns diff statistics between refs
func (a *Adapter) GetDiffStats(ctx context.Context, base, head string) (*DiffStats, error) {
	if base == "" {
		base = "HEAD~1"
	}
	if head == "" {
		head = "HEAD"
	}

	output, err := a.run(ctx, "diff", "--stat", "--numstat", base, head)
	if err != nil {
		return nil, err
	}

	stats := &DiffStats{}
	for _, line := range strings.Split(output, "\n") {
		parts := strings.Fields(line)
		if len(parts) >= 3 {
			stats.FilesChanged++
			// numstat format: insertions deletions filename
			if parts[0] != "-" {
				var ins int
				fmt.Sscanf(parts[0], "%d", &ins)
				stats.Insertions += ins
			}
			if parts[1] != "-" {
				var del int
				fmt.Sscanf(parts[1], "%d", &del)
				stats.Deletions += del
			}
			filename := parts[2]
			ext := filepath.Ext(filename)
			if ext == ".tf" || ext == ".tfvars" || ext == ".hcl" {
				stats.TerraformFiles++
			}
		}
	}

	return stats, nil
}

################################################################################
# FILE: :\good projects\cost estimation\adapters\http\adapter.go
# TYPE: go
# SIZE: 15000 bytes
################################################################################
// Package http provides a production-grade HTTP adapter for the cost estimation engine.
// This adapter exposes the engine functionality via a RESTful API.
package http

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"sync"
	"time"

	"terraform-cost/core/engine"
	"terraform-cost/core/model"
	"terraform-cost/core/pricing"
	"terraform-cost/core/terraform"
)

// Config holds HTTP adapter configuration
type Config struct {
	// Address to listen on
	Address string `json:"address"`
	
	// ReadTimeout for requests
	ReadTimeout time.Duration `json:"read_timeout"`
	
	// WriteTimeout for responses
	WriteTimeout time.Duration `json:"write_timeout"`
	
	// MaxBodySize limits request body size
	MaxBodySize int64 `json:"max_body_size"`
	
	// EnableCORS enables CORS headers
	EnableCORS bool `json:"enable_cors"`
	
	// AllowedOrigins for CORS
	AllowedOrigins []string `json:"allowed_origins"`
	
	// RateLimit per IP (requests per second)
	RateLimit float64 `json:"rate_limit"`
	
	// EnableMetrics enables Prometheus metrics
	EnableMetrics bool `json:"enable_metrics"`
}

// DefaultConfig returns sensible defaults
func DefaultConfig() *Config {
	return &Config{
		Address:        ":8080",
		ReadTimeout:    30 * time.Second,
		WriteTimeout:   60 * time.Second,
		MaxBodySize:    10 * 1024 * 1024, // 10MB
		EnableCORS:     true,
		AllowedOrigins: []string{"*"},
		RateLimit:      10,
		EnableMetrics:  true,
	}
}

// Adapter is the HTTP adapter
type Adapter struct {
	engine   *engine.Engine
	pipeline *terraform.Pipeline
	config   *Config
	server   *http.Server
	
	// Metrics
	requestCount   int64
	errorCount     int64
	totalLatencyMs int64
	mu             sync.RWMutex
}

// New creates a new HTTP adapter
func New(eng *engine.Engine, pipeline *terraform.Pipeline, config *Config) *Adapter {
	if config == nil {
		config = DefaultConfig()
	}
	
	return &Adapter{
		engine:   eng,
		pipeline: pipeline,
		config:   config,
	}
}

// Router returns the HTTP handler
func (a *Adapter) Router() http.Handler {
	mux := http.NewServeMux()
	
	// Health endpoints
	mux.HandleFunc("GET /health", a.handleHealth)
	mux.HandleFunc("GET /ready", a.handleReady)
	
	// API v1 endpoints
	mux.HandleFunc("POST /api/v1/estimate", a.handleEstimate)
	mux.HandleFunc("POST /api/v1/diff", a.handleDiff)
	mux.HandleFunc("GET /api/v1/snapshots", a.handleListSnapshots)
	mux.HandleFunc("GET /api/v1/snapshots/{id}", a.handleGetSnapshot)
	mux.HandleFunc("GET /api/v1/coverage", a.handleCoverage)
	
	// Metrics
	if a.config.EnableMetrics {
		mux.HandleFunc("GET /metrics", a.handleMetrics)
	}
	
	// Apply middleware
	handler := a.corsMiddleware(mux)
	handler = a.loggingMiddleware(handler)
	handler = a.recoveryMiddleware(handler)
	
	return handler
}

// Start starts the HTTP server
func (a *Adapter) Start() error {
	a.server = &http.Server{
		Addr:         a.config.Address,
		Handler:      a.Router(),
		ReadTimeout:  a.config.ReadTimeout,
		WriteTimeout: a.config.WriteTimeout,
	}
	
	return a.server.ListenAndServe()
}

// Shutdown gracefully shuts down the server
func (a *Adapter) Shutdown(ctx context.Context) error {
	if a.server != nil {
		return a.server.Shutdown(ctx)
	}
	return nil
}

// EstimateRequest is the API request body
type EstimateRequest struct {
	// TerraformPlan is the JSON plan output
	TerraformPlan json.RawMessage `json:"terraform_plan,omitempty"`
	
	// HCLPath is the path to HCL files (for local)
	HCLPath string `json:"hcl_path,omitempty"`
	
	// HCLContent is inline HCL content
	HCLContent string `json:"hcl_content,omitempty"`
	
	// Variables for Terraform
	Variables map[string]interface{} `json:"variables,omitempty"`
	
	// SnapshotID to use (optional, uses latest if empty)
	SnapshotID string `json:"snapshot_id,omitempty"`
	
	// Provider (aws, azure, gcp)
	Provider string `json:"provider"`
	
	// Region
	Region string `json:"region"`
	
	// Alias for multi-account
	Alias string `json:"alias,omitempty"`
	
	// UsageOverrides for symbolic costs
	UsageOverrides map[string]map[string]float64 `json:"usage_overrides,omitempty"`
	
	// StrictMode fails on symbolic costs
	StrictMode bool `json:"strict_mode,omitempty"`
	
	// IncludeLineage includes pricing lineage
	IncludeLineage bool `json:"include_lineage,omitempty"`
}

// EstimateResponse is the API response
type EstimateResponse struct {
	// Success indicates if estimation succeeded
	Success bool `json:"success"`
	
	// Error message if failed
	Error string `json:"error,omitempty"`
	
	// TotalMonthlyCost is the total cost
	TotalMonthlyCost string `json:"total_monthly_cost"`
	
	// TotalHourlyCost is hourly cost
	TotalHourlyCost string `json:"total_hourly_cost"`
	
	// Confidence (0-1)
	Confidence float64 `json:"confidence"`
	
	// Coverage breakdown
	Coverage CoverageResponse `json:"coverage"`
	
	// Resources with costs
	Resources []ResourceCostResponse `json:"resources"`
	
	// SymbolicReasons for symbolic costs
	SymbolicReasons map[string][]string `json:"symbolic_reasons,omitempty"`
	
	// UnsupportedTypes that couldn't be estimated
	UnsupportedTypes []string `json:"unsupported_types,omitempty"`
	
	// Snapshot used for pricing
	Snapshot SnapshotResponse `json:"snapshot"`
	
	// Lineage for auditability
	Lineage []LineageEntry `json:"lineage,omitempty"`
	
	// Warnings during estimation
	Warnings []string `json:"warnings,omitempty"`
	
	// Metadata
	Metadata ResponseMetadata `json:"metadata"`
}

// CoverageResponse is coverage breakdown
type CoverageResponse struct {
	NumericPercent     float64 `json:"numeric_percent"`
	SymbolicPercent    float64 `json:"symbolic_percent"`
	IndirectPercent    float64 `json:"indirect_percent"`
	UnsupportedPercent float64 `json:"unsupported_percent"`
	TotalResources     int     `json:"total_resources"`
	CoveredResources   int     `json:"covered_resources"`
}

// ResourceCostResponse is per-resource cost
type ResourceCostResponse struct {
	Address      string                    `json:"address"`
	Type         string                    `json:"type"`
	MonthlyCost  string                    `json:"monthly_cost"`
	HourlyCost   string                    `json:"hourly_cost"`
	Confidence   float64                   `json:"confidence"`
	CoverageType string                    `json:"coverage_type"`
	Components   []ComponentCostResponse   `json:"components,omitempty"`
}

// ComponentCostResponse is per-component cost
type ComponentCostResponse struct {
	Name        string  `json:"name"`
	Category    string  `json:"category"`
	MonthlyCost string  `json:"monthly_cost"`
	UsageValue  float64 `json:"usage_value"`
	UsageUnit   string  `json:"usage_unit"`
	IsSymbolic  bool    `json:"is_symbolic"`
	Reason      string  `json:"reason,omitempty"`
}

// SnapshotResponse is snapshot info
type SnapshotResponse struct {
	ID           string    `json:"id"`
	Provider     string    `json:"provider"`
	Region       string    `json:"region"`
	Alias        string    `json:"alias"`
	ContentHash  string    `json:"content_hash"`
	EffectiveAt  time.Time `json:"effective_at"`
	RateCount    int       `json:"rate_count"`
}

// LineageEntry traces a rate lookup
type LineageEntry struct {
	Resource    string            `json:"resource"`
	Component   string            `json:"component"`
	RateKey     map[string]string `json:"rate_key"`
	SnapshotID  string            `json:"snapshot_id"`
	Price       string            `json:"price"`
	Unit        string            `json:"unit"`
	ResolvedAt  time.Time         `json:"resolved_at"`
}

// ResponseMetadata is response context
type ResponseMetadata struct {
	RequestID   string        `json:"request_id"`
	Duration    time.Duration `json:"duration_ms"`
	Version     string        `json:"version"`
	Timestamp   time.Time     `json:"timestamp"`
}

// Handler implementations

func (a *Adapter) handleHealth(w http.ResponseWriter, r *http.Request) {
	a.writeJSON(w, http.StatusOK, map[string]string{"status": "healthy"})
}

func (a *Adapter) handleReady(w http.ResponseWriter, r *http.Request) {
	// Check engine health
	a.writeJSON(w, http.StatusOK, map[string]string{"status": "ready"})
}

func (a *Adapter) handleEstimate(w http.ResponseWriter, r *http.Request) {
	start := time.Now()
	ctx := r.Context()
	
	// Parse request
	var req EstimateRequest
	if err := a.parseJSON(r, &req); err != nil {
		a.writeError(w, http.StatusBadRequest, "invalid request body: "+err.Error())
		return
	}
	
	// Validate
	if req.Provider == "" {
		a.writeError(w, http.StatusBadRequest, "provider is required")
		return
	}
	if req.Region == "" {
		a.writeError(w, http.StatusBadRequest, "region is required")
		return
	}
	
	// Build snapshot request
	snapshotReq := engine.SnapshotRequest{
		Provider: req.Provider,
		Region:   req.Region,
	}
	if req.SnapshotID != "" {
		snapshotReq.SnapshotID = pricing.SnapshotID(req.SnapshotID)
	}
	
	// Convert usage overrides
	overrides := make(map[model.InstanceID]map[string]float64)
	for k, v := range req.UsageOverrides {
		overrides[model.InstanceID(k)] = v
	}
	
	// Execute estimation
	engineReq := &engine.EstimateRequest{
		SnapshotRequest: snapshotReq,
		UsageOverrides:  overrides,
	}
	
	result, err := a.engine.Estimate(ctx, engineReq)
	if err != nil {
		a.writeError(w, http.StatusInternalServerError, "estimation failed: "+err.Error())
		return
	}
	
	// Build response
	resp := a.buildEstimateResponse(result, r.Header.Get("X-Request-ID"), start)
	a.writeJSON(w, http.StatusOK, resp)
}

func (a *Adapter) handleDiff(w http.ResponseWriter, r *http.Request) {
	// TODO: Implement diff endpoint
	a.writeJSON(w, http.StatusOK, map[string]string{"status": "not implemented"})
}

func (a *Adapter) handleListSnapshots(w http.ResponseWriter, r *http.Request) {
	// TODO: Implement snapshot listing
	a.writeJSON(w, http.StatusOK, map[string]string{"status": "not implemented"})
}

func (a *Adapter) handleGetSnapshot(w http.ResponseWriter, r *http.Request) {
	// TODO: Implement snapshot retrieval
	a.writeJSON(w, http.StatusOK, map[string]string{"status": "not implemented"})
}

func (a *Adapter) handleCoverage(w http.ResponseWriter, r *http.Request) {
	// TODO: Implement coverage endpoint
	a.writeJSON(w, http.StatusOK, map[string]string{"status": "not implemented"})
}

func (a *Adapter) handleMetrics(w http.ResponseWriter, r *http.Request) {
	a.mu.RLock()
	defer a.mu.RUnlock()
	
	avgLatency := float64(0)
	if a.requestCount > 0 {
		avgLatency = float64(a.totalLatencyMs) / float64(a.requestCount)
	}
	
	metrics := fmt.Sprintf(`# HELP terraform_cost_requests_total Total requests
# TYPE terraform_cost_requests_total counter
terraform_cost_requests_total %d

# HELP terraform_cost_errors_total Total errors
# TYPE terraform_cost_errors_total counter
terraform_cost_errors_total %d

# HELP terraform_cost_latency_avg_ms Average latency
# TYPE terraform_cost_latency_avg_ms gauge
terraform_cost_latency_avg_ms %.2f
`, a.requestCount, a.errorCount, avgLatency)
	
	w.Header().Set("Content-Type", "text/plain")
	w.Write([]byte(metrics))
}

func (a *Adapter) buildEstimateResponse(result *engine.EstimationResult, requestID string, start time.Time) *EstimateResponse {
	resp := &EstimateResponse{
		Success:          true,
		TotalMonthlyCost: result.TotalMonthlyCost.String(),
		TotalHourlyCost:  result.TotalHourlyCost.String(),
		Confidence:       result.Confidence.Score,
		Warnings:         result.Warnings,
		Metadata: ResponseMetadata{
			RequestID: requestID,
			Duration:  time.Since(start),
			Version:   "1.0.0",
			Timestamp: time.Now(),
		},
	}
	
	// Snapshot
	if result.Snapshot != nil {
		resp.Snapshot = SnapshotResponse{
			ID:          string(result.Snapshot.ID),
			Provider:    result.Snapshot.Provider,
			Region:      result.Snapshot.Region,
			ContentHash: result.Snapshot.ContentHash.Hex(),
			EffectiveAt: result.Snapshot.EffectiveAt,
		}
	}
	
	// Resources
	resp.Resources = make([]ResourceCostResponse, 0)
	result.InstanceCosts.Range(func(id model.InstanceID, cost *engine.InstanceCost) bool {
		rc := ResourceCostResponse{
			Address:     string(cost.Address),
			Type:        string(cost.ResourceType),
			MonthlyCost: cost.MonthlyCost.String(),
			HourlyCost:  cost.HourlyCost.String(),
			Confidence:  cost.Confidence.Score,
		}
		
		// Components
		for _, comp := range cost.Components {
			cc := ComponentCostResponse{
				Name:        comp.Name,
				MonthlyCost: comp.MonthlyCost.String(),
				UsageValue:  comp.UsageValue,
				UsageUnit:   comp.UsageUnit,
				IsSymbolic:  comp.Confidence < 0.7,
			}
			rc.Components = append(rc.Components, cc)
		}
		
		resp.Resources = append(resp.Resources, rc)
		return true
	})
	
	return resp
}

// Middleware

func (a *Adapter) corsMiddleware(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if a.config.EnableCORS {
			origin := "*"
			if len(a.config.AllowedOrigins) > 0 && a.config.AllowedOrigins[0] != "*" {
				origin = a.config.AllowedOrigins[0]
			}
			w.Header().Set("Access-Control-Allow-Origin", origin)
			w.Header().Set("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
			w.Header().Set("Access-Control-Allow-Headers", "Content-Type, X-Request-ID")
		}
		
		if r.Method == "OPTIONS" {
			w.WriteHeader(http.StatusNoContent)
			return
		}
		
		next.ServeHTTP(w, r)
	})
}

func (a *Adapter) loggingMiddleware(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		start := time.Now()
		next.ServeHTTP(w, r)
		
		a.mu.Lock()
		a.requestCount++
		a.totalLatencyMs += time.Since(start).Milliseconds()
		a.mu.Unlock()
	})
}

func (a *Adapter) recoveryMiddleware(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		defer func() {
			if err := recover(); err != nil {
				a.mu.Lock()
				a.errorCount++
				a.mu.Unlock()
				
				a.writeError(w, http.StatusInternalServerError, "internal server error")
			}
		}()
		next.ServeHTTP(w, r)
	})
}

// Helpers

func (a *Adapter) parseJSON(r *http.Request, v interface{}) error {
	defer r.Body.Close()
	body, err := io.ReadAll(io.LimitReader(r.Body, a.config.MaxBodySize))
	if err != nil {
		return err
	}
	return json.Unmarshal(body, v)
}

func (a *Adapter) writeJSON(w http.ResponseWriter, status int, v interface{}) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(status)
	json.NewEncoder(w).Encode(v)
}

func (a *Adapter) writeError(w http.ResponseWriter, status int, message string) {
	a.writeJSON(w, status, map[string]interface{}{
		"success": false,
		"error":   message,
	})
}

################################################################################
# FILE: :\good projects\cost estimation\adapters\pricing\adapter.go
# TYPE: go
# SIZE: 7939 bytes
################################################################################
// Package pricing provides production-grade pricing adapter for multiple cloud providers.
// This adapter abstracts cloud-specific pricing API details and provides a unified interface.
package pricing

import (
	"context"
	"fmt"
	"sync"
	"time"

	"terraform-cost/db"

	"github.com/shopspring/decimal"
)

// CloudAdapter is the unified pricing adapter interface
type CloudAdapter interface {
	// Cloud returns the cloud provider
	Cloud() db.CloudProvider
	
	// FetchPricing fetches pricing for a region
	FetchPricing(ctx context.Context, region string) (*FetchResult, error)
	
	// SupportedRegions returns supported regions
	SupportedRegions() []string
	
	// SupportedServices returns supported services
	SupportedServices() []string
	
	// Healthcheck verifies connectivity
	Healthcheck(ctx context.Context) error
}

// FetchResult contains fetched pricing data
type FetchResult struct {
	Cloud       db.CloudProvider
	Region      string
	Rates       []Rate
	FetchedAt   time.Time
	Source      string
	APIVersion  string
	RateCounts  map[string]int // by service
}

// Rate is a normalized pricing rate
type Rate struct {
	Service       string
	ProductFamily string
	SKU           string
	Attributes    map[string]string
	Price         decimal.Decimal
	Unit          string
	Currency      string
	TierMin       *decimal.Decimal
	TierMax       *decimal.Decimal
	EffectiveFrom *time.Time
	EffectiveTo   *time.Time
}

// AdapterRegistry manages cloud adapters
type AdapterRegistry struct {
	adapters map[db.CloudProvider]CloudAdapter
	mu       sync.RWMutex
}

// NewAdapterRegistry creates a new registry
func NewAdapterRegistry() *AdapterRegistry {
	return &AdapterRegistry{
		adapters: make(map[db.CloudProvider]CloudAdapter),
	}
}

// Register registers an adapter
func (r *AdapterRegistry) Register(adapter CloudAdapter) {
	r.mu.Lock()
	defer r.mu.Unlock()
	r.adapters[adapter.Cloud()] = adapter
}

// Get returns an adapter for a cloud
func (r *AdapterRegistry) Get(cloud db.CloudProvider) (CloudAdapter, bool) {
	r.mu.RLock()
	defer r.mu.RUnlock()
	adapter, ok := r.adapters[cloud]
	return adapter, ok
}

// List returns all registered clouds
func (r *AdapterRegistry) List() []db.CloudProvider {
	r.mu.RLock()
	defer r.mu.RUnlock()
	clouds := make([]db.CloudProvider, 0, len(r.adapters))
	for cloud := range r.adapters {
		clouds = append(clouds, cloud)
	}
	return clouds
}

// FetchConfig configures fetch behavior
type FetchConfig struct {
	// Services to fetch (empty = all)
	Services []string
	
	// Concurrency for parallel fetching
	Concurrency int
	
	// Timeout per service
	Timeout time.Duration
	
	// RetryCount for failed requests
	RetryCount int
	
	// RetryDelay between retries
	RetryDelay time.Duration
	
	// FilterFunc filters rates during fetch
	FilterFunc func(Rate) bool
}

// DefaultFetchConfig returns sensible defaults
func DefaultFetchConfig() *FetchConfig {
	return &FetchConfig{
		Concurrency: 5,
		Timeout:     60 * time.Second,
		RetryCount:  3,
		RetryDelay:  1 * time.Second,
	}
}

// RateNormalizer normalizes cloud-specific rates
type RateNormalizer interface {
	// Normalize converts raw API response to normalized rates
	Normalize(raw interface{}) ([]Rate, error)
	
	// NormalizeUnit standardizes unit names
	NormalizeUnit(unit string) string
	
	// NormalizeAttributes standardizes attribute keys
	NormalizeAttributes(attrs map[string]string) map[string]string
}

// BaseNormalizer provides common normalization logic
type BaseNormalizer struct {
	unitMapping map[string]string
	attrMapping map[string]string
}

// NewBaseNormalizer creates a base normalizer
func NewBaseNormalizer() *BaseNormalizer {
	return &BaseNormalizer{
		unitMapping: map[string]string{
			"Hrs":          "hours",
			"hrs":          "hours",
			"GB-Mo":        "GB-month",
			"GB-month":     "GB-month",
			"GB":           "GB",
			"Requests":     "requests",
			"requests":     "requests",
			"GB-Second":    "GB-seconds",
			"GB-Seconds":   "GB-seconds",
			"Quantity":     "units",
			"LCU-Hrs":      "LCU-hours",
		},
		attrMapping: map[string]string{
			"instanceType":      "instance_type",
			"instanceFamily":    "instance_family",
			"operatingSystem":   "os",
			"tenancy":           "tenancy",
			"storageClass":      "storage_class",
			"databaseEngine":    "engine",
			"productFamily":     "product_family",
		},
	}
}

// NormalizeUnit normalizes a unit string
func (n *BaseNormalizer) NormalizeUnit(unit string) string {
	if normalized, ok := n.unitMapping[unit]; ok {
		return normalized
	}
	return unit
}

// NormalizeAttributes normalizes attribute keys
func (n *BaseNormalizer) NormalizeAttributes(attrs map[string]string) map[string]string {
	result := make(map[string]string)
	for k, v := range attrs {
		key := k
		if normalized, ok := n.attrMapping[k]; ok {
			key = normalized
		}
		result[key] = v
	}
	return result
}

// CachingAdapter wraps an adapter with caching
type CachingAdapter struct {
	inner    CloudAdapter
	cache    map[string]*cachedResult
	ttl      time.Duration
	mu       sync.RWMutex
}

type cachedResult struct {
	result    *FetchResult
	expiresAt time.Time
}

// NewCachingAdapter creates a caching wrapper
func NewCachingAdapter(inner CloudAdapter, ttl time.Duration) *CachingAdapter {
	return &CachingAdapter{
		inner: inner,
		cache: make(map[string]*cachedResult),
		ttl:   ttl,
	}
}

func (a *CachingAdapter) Cloud() db.CloudProvider {
	return a.inner.Cloud()
}

func (a *CachingAdapter) FetchPricing(ctx context.Context, region string) (*FetchResult, error) {
	key := fmt.Sprintf("%s:%s", a.inner.Cloud(), region)
	
	// Check cache
	a.mu.RLock()
	if cached, ok := a.cache[key]; ok && time.Now().Before(cached.expiresAt) {
		a.mu.RUnlock()
		return cached.result, nil
	}
	a.mu.RUnlock()
	
	// Fetch
	result, err := a.inner.FetchPricing(ctx, region)
	if err != nil {
		return nil, err
	}
	
	// Cache
	a.mu.Lock()
	a.cache[key] = &cachedResult{
		result:    result,
		expiresAt: time.Now().Add(a.ttl),
	}
	a.mu.Unlock()
	
	return result, nil
}

func (a *CachingAdapter) SupportedRegions() []string {
	return a.inner.SupportedRegions()
}

func (a *CachingAdapter) SupportedServices() []string {
	return a.inner.SupportedServices()
}

func (a *CachingAdapter) Healthcheck(ctx context.Context) error {
	return a.inner.Healthcheck(ctx)
}

// MetricsAdapter wraps an adapter with metrics
type MetricsAdapter struct {
	inner        CloudAdapter
	fetchCount   int64
	fetchErrors  int64
	totalLatency int64
	mu           sync.RWMutex
}

// NewMetricsAdapter creates a metrics wrapper
func NewMetricsAdapter(inner CloudAdapter) *MetricsAdapter {
	return &MetricsAdapter{
		inner: inner,
	}
}

func (a *MetricsAdapter) Cloud() db.CloudProvider {
	return a.inner.Cloud()
}

func (a *MetricsAdapter) FetchPricing(ctx context.Context, region string) (*FetchResult, error) {
	start := time.Now()
	result, err := a.inner.FetchPricing(ctx, region)
	
	a.mu.Lock()
	a.fetchCount++
	a.totalLatency += time.Since(start).Milliseconds()
	if err != nil {
		a.fetchErrors++
	}
	a.mu.Unlock()
	
	return result, err
}

func (a *MetricsAdapter) SupportedRegions() []string {
	return a.inner.SupportedRegions()
}

func (a *MetricsAdapter) SupportedServices() []string {
	return a.inner.SupportedServices()
}

func (a *MetricsAdapter) Healthcheck(ctx context.Context) error {
	return a.inner.Healthcheck(ctx)
}

// Metrics returns adapter metrics
func (a *MetricsAdapter) Metrics() (fetchCount, fetchErrors, avgLatencyMs int64) {
	a.mu.RLock()
	defer a.mu.RUnlock()
	
	avg := int64(0)
	if a.fetchCount > 0 {
		avg = a.totalLatency / a.fetchCount
	}
	return a.fetchCount, a.fetchErrors, avg
}

################################################################################
# FILE: :\good projects\cost estimation\adapters\storage\adapter.go
# TYPE: go
# SIZE: 12044 bytes
################################################################################
// Package storage provides production-grade storage adapter for estimation results.
// Supports multiple backends: file, S3, GCS, Azure Blob, PostgreSQL.
package storage

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"sync"
	"time"

	"github.com/google/uuid"
)

// Backend is a storage backend type
type Backend string

const (
	BackendFile     Backend = "file"
	BackendS3       Backend = "s3"
	BackendGCS      Backend = "gcs"
	BackendAzure    Backend = "azure"
	BackendPostgres Backend = "postgres"
	BackendMemory   Backend = "memory"
)

// Store is the storage interface
type Store interface {
	// Save stores an estimation result
	Save(ctx context.Context, result *StoredResult) error

	// Get retrieves an estimation by ID
	Get(ctx context.Context, id string) (*StoredResult, error)

	// List lists estimations with filters
	List(ctx context.Context, filter *ListFilter) ([]*StoredResult, error)

	// Delete removes an estimation
	Delete(ctx context.Context, id string) error

	// GetLatest gets the latest estimation for a project
	GetLatest(ctx context.Context, projectID string) (*StoredResult, error)

	// Compare compares two estimations
	Compare(ctx context.Context, oldID, newID string) (*CompareResult, error)

	// Close closes the store
	Close() error
}

// StoredResult is a stored estimation
type StoredResult struct {
	// ID is unique identifier
	ID string `json:"id"`

	// ProjectID groups estimations
	ProjectID string `json:"project_id"`

	// TotalCost monthly
	TotalCost float64 `json:"total_cost"`

	// Confidence (0-1)
	Confidence float64 `json:"confidence"`

	// Coverage breakdown
	Coverage CoverageData `json:"coverage"`

	// ResourceCount
	ResourceCount int `json:"resource_count"`

	// SnapshotID used
	SnapshotID string `json:"snapshot_id"`

	// Provider (aws, azure, gcp)
	Provider string `json:"provider"`

	// Region
	Region string `json:"region"`

	// GitInfo if available
	GitInfo *GitInfo `json:"git_info,omitempty"`

	// CreatedAt timestamp
	CreatedAt time.Time `json:"created_at"`

	// Metadata
	Metadata map[string]string `json:"metadata,omitempty"`

	// RawResult is the full result (compressed)
	RawResult []byte `json:"raw_result,omitempty"`
}

// CoverageData is coverage breakdown
type CoverageData struct {
	NumericPercent     float64 `json:"numeric_percent"`
	SymbolicPercent    float64 `json:"symbolic_percent"`
	UnsupportedPercent float64 `json:"unsupported_percent"`
}

// GitInfo contains git context
type GitInfo struct {
	Branch     string `json:"branch"`
	Commit     string `json:"commit"`
	CommitTime time.Time `json:"commit_time"`
	Author     string `json:"author"`
	Message    string `json:"message"`
	Tag        string `json:"tag,omitempty"`
}

// ListFilter filters result listing
type ListFilter struct {
	ProjectID  string
	Provider   string
	Region     string
	Since      time.Time
	Until      time.Time
	MinCost    float64
	MaxCost    float64
	Limit      int
	Offset     int
	OrderBy    string
	OrderDesc  bool
}

// CompareResult is a comparison between two estimations
type CompareResult struct {
	OldID         string    `json:"old_id"`
	NewID         string    `json:"new_id"`
	OldCost       float64   `json:"old_cost"`
	NewCost       float64   `json:"new_cost"`
	Delta         float64   `json:"delta"`
	DeltaPercent  float64   `json:"delta_percent"`
	OldConfidence float64   `json:"old_confidence"`
	NewConfidence float64   `json:"new_confidence"`
	CreatedAt     time.Time `json:"created_at"`
}

// FileStore is a file-based storage backend
type FileStore struct {
	basePath string
	mu       sync.RWMutex
}

// NewFileStore creates a file store
func NewFileStore(basePath string) (*FileStore, error) {
	if err := os.MkdirAll(basePath, 0755); err != nil {
		return nil, fmt.Errorf("failed to create storage directory: %w", err)
	}
	return &FileStore{basePath: basePath}, nil
}

func (s *FileStore) Save(ctx context.Context, result *StoredResult) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	if result.ID == "" {
		result.ID = uuid.New().String()
	}
	if result.CreatedAt.IsZero() {
		result.CreatedAt = time.Now()
	}

	// Create project directory
	projectDir := filepath.Join(s.basePath, result.ProjectID)
	if err := os.MkdirAll(projectDir, 0755); err != nil {
		return fmt.Errorf("failed to create project directory: %w", err)
	}

	// Write result file
	filePath := filepath.Join(projectDir, result.ID+".json")
	data, err := json.MarshalIndent(result, "", "  ")
	if err != nil {
		return fmt.Errorf("failed to marshal result: %w", err)
	}

	if err := os.WriteFile(filePath, data, 0644); err != nil {
		return fmt.Errorf("failed to write result: %w", err)
	}

	return nil
}

func (s *FileStore) Get(ctx context.Context, id string) (*StoredResult, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	// Search all project directories
	entries, err := os.ReadDir(s.basePath)
	if err != nil {
		return nil, fmt.Errorf("failed to read storage: %w", err)
	}

	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}

		filePath := filepath.Join(s.basePath, entry.Name(), id+".json")
		data, err := os.ReadFile(filePath)
		if err == nil {
			var result StoredResult
			if err := json.Unmarshal(data, &result); err != nil {
				return nil, fmt.Errorf("failed to unmarshal result: %w", err)
			}
			return &result, nil
		}
	}

	return nil, fmt.Errorf("result not found: %s", id)
}

func (s *FileStore) List(ctx context.Context, filter *ListFilter) ([]*StoredResult, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	var results []*StoredResult

	// Walk storage
	err := filepath.Walk(s.basePath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil // Skip errors
		}
		if info.IsDir() || filepath.Ext(path) != ".json" {
			return nil
		}

		data, err := os.ReadFile(path)
		if err != nil {
			return nil
		}

		var result StoredResult
		if err := json.Unmarshal(data, &result); err != nil {
			return nil
		}

		// Apply filters
		if filter != nil {
			if filter.ProjectID != "" && result.ProjectID != filter.ProjectID {
				return nil
			}
			if filter.Provider != "" && result.Provider != filter.Provider {
				return nil
			}
			if !filter.Since.IsZero() && result.CreatedAt.Before(filter.Since) {
				return nil
			}
			if !filter.Until.IsZero() && result.CreatedAt.After(filter.Until) {
				return nil
			}
			if filter.MinCost > 0 && result.TotalCost < filter.MinCost {
				return nil
			}
			if filter.MaxCost > 0 && result.TotalCost > filter.MaxCost {
				return nil
			}
		}

		results = append(results, &result)
		return nil
	})

	if err != nil {
		return nil, err
	}

	// Apply limit/offset
	if filter != nil {
		if filter.Offset > 0 && filter.Offset < len(results) {
			results = results[filter.Offset:]
		}
		if filter.Limit > 0 && filter.Limit < len(results) {
			results = results[:filter.Limit]
		}
	}

	return results, nil
}

func (s *FileStore) Delete(ctx context.Context, id string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	entries, err := os.ReadDir(s.basePath)
	if err != nil {
		return fmt.Errorf("failed to read storage: %w", err)
	}

	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}

		filePath := filepath.Join(s.basePath, entry.Name(), id+".json")
		if _, err := os.Stat(filePath); err == nil {
			return os.Remove(filePath)
		}
	}

	return fmt.Errorf("result not found: %s", id)
}

func (s *FileStore) GetLatest(ctx context.Context, projectID string) (*StoredResult, error) {
	results, err := s.List(ctx, &ListFilter{
		ProjectID: projectID,
		Limit:     1,
		OrderBy:   "created_at",
		OrderDesc: true,
	})
	if err != nil {
		return nil, err
	}
	if len(results) == 0 {
		return nil, fmt.Errorf("no results for project: %s", projectID)
	}
	return results[0], nil
}

func (s *FileStore) Compare(ctx context.Context, oldID, newID string) (*CompareResult, error) {
	oldResult, err := s.Get(ctx, oldID)
	if err != nil {
		return nil, fmt.Errorf("failed to get old result: %w", err)
	}

	newResult, err := s.Get(ctx, newID)
	if err != nil {
		return nil, fmt.Errorf("failed to get new result: %w", err)
	}

	delta := newResult.TotalCost - oldResult.TotalCost
	deltaPercent := 0.0
	if oldResult.TotalCost > 0 {
		deltaPercent = delta / oldResult.TotalCost * 100
	}

	return &CompareResult{
		OldID:         oldID,
		NewID:         newID,
		OldCost:       oldResult.TotalCost,
		NewCost:       newResult.TotalCost,
		Delta:         delta,
		DeltaPercent:  deltaPercent,
		OldConfidence: oldResult.Confidence,
		NewConfidence: newResult.Confidence,
		CreatedAt:     time.Now(),
	}, nil
}

func (s *FileStore) Close() error {
	return nil
}

// MemoryStore is an in-memory storage backend (for testing)
type MemoryStore struct {
	results map[string]*StoredResult
	mu      sync.RWMutex
}

// NewMemoryStore creates a memory store
func NewMemoryStore() *MemoryStore {
	return &MemoryStore{
		results: make(map[string]*StoredResult),
	}
}

func (s *MemoryStore) Save(ctx context.Context, result *StoredResult) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	if result.ID == "" {
		result.ID = uuid.New().String()
	}
	if result.CreatedAt.IsZero() {
		result.CreatedAt = time.Now()
	}

	s.results[result.ID] = result
	return nil
}

func (s *MemoryStore) Get(ctx context.Context, id string) (*StoredResult, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	result, ok := s.results[id]
	if !ok {
		return nil, fmt.Errorf("result not found: %s", id)
	}
	return result, nil
}

func (s *MemoryStore) List(ctx context.Context, filter *ListFilter) ([]*StoredResult, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	var results []*StoredResult
	for _, result := range s.results {
		results = append(results, result)
	}
	return results, nil
}

func (s *MemoryStore) Delete(ctx context.Context, id string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	delete(s.results, id)
	return nil
}

func (s *MemoryStore) GetLatest(ctx context.Context, projectID string) (*StoredResult, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	var latest *StoredResult
	for _, result := range s.results {
		if result.ProjectID == projectID {
			if latest == nil || result.CreatedAt.After(latest.CreatedAt) {
				latest = result
			}
		}
	}

	if latest == nil {
		return nil, fmt.Errorf("no results for project: %s", projectID)
	}
	return latest, nil
}

func (s *MemoryStore) Compare(ctx context.Context, oldID, newID string) (*CompareResult, error) {
	oldResult, err := s.Get(ctx, oldID)
	if err != nil {
		return nil, err
	}

	newResult, err := s.Get(ctx, newID)
	if err != nil {
		return nil, err
	}

	delta := newResult.TotalCost - oldResult.TotalCost
	deltaPercent := 0.0
	if oldResult.TotalCost > 0 {
		deltaPercent = delta / oldResult.TotalCost * 100
	}

	return &CompareResult{
		OldID:         oldID,
		NewID:         newID,
		OldCost:       oldResult.TotalCost,
		NewCost:       newResult.TotalCost,
		Delta:         delta,
		DeltaPercent:  deltaPercent,
		OldConfidence: oldResult.Confidence,
		NewConfidence: newResult.Confidence,
		CreatedAt:     time.Now(),
	}, nil
}

func (s *MemoryStore) Close() error {
	return nil
}

// StoreFactory creates stores by backend type
func StoreFactory(backend Backend, config map[string]string) (Store, error) {
	switch backend {
	case BackendFile:
		path := config["path"]
		if path == "" {
			path = ".terraform-cost"
		}
		return NewFileStore(path)
	case BackendMemory:
		return NewMemoryStore(), nil
	default:
		return nil, fmt.Errorf("unsupported backend: %s", backend)
	}
}

// Ensure interfaces are implemented
var _ io.Closer = (*FileStore)(nil)
var _ io.Closer = (*MemoryStore)(nil)

################################################################################
# FILE: :\good projects\cost estimation\adapters\terraform\adapter.go
# TYPE: go
# SIZE: 16210 bytes
################################################################################
// Package terraform provides production-grade Terraform adapter for the cost estimation engine.
// This adapter handles Terraform plan parsing, HCL scanning, and state extraction.
package terraform

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
	"time"
)

// Adapter is the Terraform adapter
type Adapter struct {
	terraformPath string
	workDir       string
	config        *Config
}

// Config configures the Terraform adapter
type Config struct {
	// TerraformPath is the terraform executable path
	TerraformPath string `json:"terraform_path"`

	// WorkDir is the working directory
	WorkDir string `json:"work_dir"`

	// Workspace is the Terraform workspace
	Workspace string `json:"workspace"`

	// VarFiles are additional var files
	VarFiles []string `json:"var_files"`

	// Vars are inline variables
	Vars map[string]string `json:"vars"`

	// BackendConfig for remote backends
	BackendConfig map[string]string `json:"backend_config"`

	// Timeout for Terraform commands
	Timeout time.Duration `json:"timeout"`

	// Parallelism for plan/apply
	Parallelism int `json:"parallelism"`

	// NoColor disables color output
	NoColor bool `json:"no_color"`

	// LockTimeout for state locking
	LockTimeout time.Duration `json:"lock_timeout"`
}

// DefaultConfig returns sensible defaults
func DefaultConfig() *Config {
	return &Config{
		TerraformPath: "terraform",
		WorkDir:       ".",
		Workspace:     "default",
		Timeout:       30 * time.Minute,
		Parallelism:   10,
		NoColor:       true,
		LockTimeout:   5 * time.Minute,
	}
}

// New creates a new Terraform adapter
func New(config *Config) (*Adapter, error) {
	if config == nil {
		config = DefaultConfig()
	}

	workDir, err := filepath.Abs(config.WorkDir)
	if err != nil {
		return nil, fmt.Errorf("failed to resolve work dir: %w", err)
	}

	return &Adapter{
		terraformPath: config.TerraformPath,
		workDir:       workDir,
		config:        config,
	}, nil
}

// PlanOutput represents parsed Terraform plan output
type PlanOutput struct {
	// FormatVersion is the plan format version
	FormatVersion string `json:"format_version"`

	// TerraformVersion is the Terraform version
	TerraformVersion string `json:"terraform_version"`

	// ResourceChanges contains resource changes
	ResourceChanges []ResourceChange `json:"resource_changes"`

	// Configuration contains the configuration
	Configuration *Configuration `json:"configuration,omitempty"`

	// PlannedValues contains planned values
	PlannedValues *PlannedValues `json:"planned_values,omitempty"`

	// PriorState is the prior state
	PriorState *State `json:"prior_state,omitempty"`

	// Variables are the input variables
	Variables map[string]Variable `json:"variables,omitempty"`
}

// ResourceChange represents a single resource change
type ResourceChange struct {
	// Address is the resource address
	Address string `json:"address"`

	// ModuleAddress is the module path
	ModuleAddress string `json:"module_address,omitempty"`

	// Mode is data or managed
	Mode string `json:"mode"`

	// Type is the resource type
	Type string `json:"type"`

	// Name is the resource name
	Name string `json:"name"`

	// Index for count/for_each
	Index interface{} `json:"index,omitempty"`

	// ProviderName is the provider
	ProviderName string `json:"provider_name"`

	// Change contains the change details
	Change Change `json:"change"`

	// ActionReason explains why action is needed
	ActionReason string `json:"action_reason,omitempty"`
}

// Change represents the change details
type Change struct {
	// Actions are the change actions
	Actions []string `json:"actions"`

	// Before is the state before
	Before map[string]interface{} `json:"before"`

	// After is the state after
	After map[string]interface{} `json:"after"`

	// AfterUnknown marks unknown values
	AfterUnknown map[string]interface{} `json:"after_unknown"`

	// BeforeSensitive marks sensitive values
	BeforeSensitive interface{} `json:"before_sensitive"`

	// AfterSensitive marks sensitive values
	AfterSensitive interface{} `json:"after_sensitive"`
}

// Configuration represents Terraform configuration
type Configuration struct {
	// ProviderConfig contains provider configs
	ProviderConfig map[string]ProviderConfig `json:"provider_config,omitempty"`

	// RootModule is the root module
	RootModule ModuleConfig `json:"root_module"`
}

// ProviderConfig is provider configuration
type ProviderConfig struct {
	Name        string                 `json:"name"`
	FullName    string                 `json:"full_name"`
	VersionConstraint string           `json:"version_constraint,omitempty"`
	Expressions map[string]interface{} `json:"expressions,omitempty"`
}

// ModuleConfig is module configuration
type ModuleConfig struct {
	Resources []ResourceConfig `json:"resources,omitempty"`
	ModuleCalls map[string]ModuleCall `json:"module_calls,omitempty"`
	Variables map[string]VariableConfig `json:"variables,omitempty"`
	Outputs map[string]OutputConfig `json:"outputs,omitempty"`
}

// ResourceConfig is resource configuration
type ResourceConfig struct {
	Address           string                 `json:"address"`
	Mode              string                 `json:"mode"`
	Type              string                 `json:"type"`
	Name              string                 `json:"name"`
	ProviderConfigKey string                 `json:"provider_config_key"`
	Expressions       map[string]interface{} `json:"expressions,omitempty"`
	SchemaVersion     int                    `json:"schema_version"`
	CountExpression   interface{}            `json:"count_expression,omitempty"`
	ForEachExpression interface{}            `json:"for_each_expression,omitempty"`
}

// ModuleCall is a module call
type ModuleCall struct {
	Source            string                 `json:"source"`
	VersionConstraint string                 `json:"version_constraint,omitempty"`
	Expressions       map[string]interface{} `json:"expressions,omitempty"`
	CountExpression   interface{}            `json:"count_expression,omitempty"`
	ForEachExpression interface{}            `json:"for_each_expression,omitempty"`
	Module            ModuleConfig           `json:"module"`
}

// VariableConfig is variable configuration
type VariableConfig struct {
	Default     interface{} `json:"default,omitempty"`
	Description string      `json:"description,omitempty"`
	Sensitive   bool        `json:"sensitive,omitempty"`
}

// OutputConfig is output configuration
type OutputConfig struct {
	Expression  interface{} `json:"expression,omitempty"`
	Description string      `json:"description,omitempty"`
	Sensitive   bool        `json:"sensitive,omitempty"`
}

// PlannedValues contains planned values
type PlannedValues struct {
	RootModule PlannedModule `json:"root_module"`
	Outputs    map[string]OutputValue `json:"outputs,omitempty"`
}

// PlannedModule is a planned module
type PlannedModule struct {
	Resources    []PlannedResource `json:"resources,omitempty"`
	ChildModules []PlannedModule   `json:"child_modules,omitempty"`
	Address      string            `json:"address,omitempty"`
}

// PlannedResource is a planned resource
type PlannedResource struct {
	Address       string                 `json:"address"`
	Mode          string                 `json:"mode"`
	Type          string                 `json:"type"`
	Name          string                 `json:"name"`
	Index         interface{}            `json:"index,omitempty"`
	ProviderName  string                 `json:"provider_name"`
	SchemaVersion int                    `json:"schema_version"`
	Values        map[string]interface{} `json:"values"`
	SensitiveValues interface{}          `json:"sensitive_values"`
}

// OutputValue is an output value
type OutputValue struct {
	Sensitive bool        `json:"sensitive"`
	Value     interface{} `json:"value"`
	Type      interface{} `json:"type,omitempty"`
}

// State represents Terraform state
type State struct {
	FormatVersion   string       `json:"format_version"`
	TerraformVersion string      `json:"terraform_version"`
	Values          *PlannedValues `json:"values,omitempty"`
}

// Variable is an input variable
type Variable struct {
	Value interface{} `json:"value"`
}

// Init initializes the Terraform working directory
func (a *Adapter) Init(ctx context.Context) error {
	args := []string{"init", "-input=false"}

	if a.config.NoColor {
		args = append(args, "-no-color")
	}

	// Add backend config
	for k, v := range a.config.BackendConfig {
		args = append(args, fmt.Sprintf("-backend-config=%s=%s", k, v))
	}

	_, err := a.run(ctx, args...)
	return err
}

// Plan generates a Terraform plan
func (a *Adapter) Plan(ctx context.Context, outFile string) error {
	args := []string{"plan", "-input=false", "-out=" + outFile}

	if a.config.NoColor {
		args = append(args, "-no-color")
	}

	if a.config.Parallelism > 0 {
		args = append(args, fmt.Sprintf("-parallelism=%d", a.config.Parallelism))
	}

	if a.config.LockTimeout > 0 {
		args = append(args, fmt.Sprintf("-lock-timeout=%s", a.config.LockTimeout))
	}

	// Add var files
	for _, varFile := range a.config.VarFiles {
		args = append(args, "-var-file="+varFile)
	}

	// Add vars
	for k, v := range a.config.Vars {
		args = append(args, fmt.Sprintf("-var=%s=%s", k, v))
	}

	_, err := a.run(ctx, args...)
	return err
}

// ShowPlanJSON shows plan in JSON format
func (a *Adapter) ShowPlanJSON(ctx context.Context, planFile string) (*PlanOutput, error) {
	args := []string{"show", "-json", planFile}

	if a.config.NoColor {
		args = append(args, "-no-color")
	}

	output, err := a.run(ctx, args...)
	if err != nil {
		return nil, err
	}

	var plan PlanOutput
	if err := json.Unmarshal([]byte(output), &plan); err != nil {
		return nil, fmt.Errorf("failed to parse plan JSON: %w", err)
	}

	return &plan, nil
}

// ParsePlanFile parses an existing plan file
func (a *Adapter) ParsePlanFile(ctx context.Context, planFile string) (*PlanOutput, error) {
	return a.ShowPlanJSON(ctx, planFile)
}

// ParsePlanJSON parses plan JSON directly
func (a *Adapter) ParsePlanJSON(data []byte) (*PlanOutput, error) {
	var plan PlanOutput
	if err := json.Unmarshal(data, &plan); err != nil {
		return nil, fmt.Errorf("failed to parse plan JSON: %w", err)
	}
	return &plan, nil
}

// Validate validates Terraform configuration
func (a *Adapter) Validate(ctx context.Context) error {
	args := []string{"validate", "-json"}

	if a.config.NoColor {
		args = append(args, "-no-color")
	}

	_, err := a.run(ctx, args...)
	return err
}

// SelectWorkspace selects a workspace
func (a *Adapter) SelectWorkspace(ctx context.Context, workspace string) error {
	// Try to select
	_, err := a.run(ctx, "workspace", "select", workspace)
	if err != nil {
		// Try to create
		_, err = a.run(ctx, "workspace", "new", workspace)
	}
	return err
}

// GetWorkspace returns the current workspace
func (a *Adapter) GetWorkspace(ctx context.Context) (string, error) {
	output, err := a.run(ctx, "workspace", "show")
	if err != nil {
		return "", err
	}
	return strings.TrimSpace(output), nil
}

// State returns current state
func (a *Adapter) State(ctx context.Context) (*State, error) {
	output, err := a.run(ctx, "show", "-json")
	if err != nil {
		return nil, err
	}

	var state State
	if err := json.Unmarshal([]byte(output), &state); err != nil {
		return nil, fmt.Errorf("failed to parse state JSON: %w", err)
	}

	return &state, nil
}

// Providers returns the required providers
func (a *Adapter) Providers(ctx context.Context) ([]string, error) {
	output, err := a.run(ctx, "providers")
	if err != nil {
		return nil, err
	}

	var providers []string
	for _, line := range strings.Split(output, "\n") {
		line = strings.TrimSpace(line)
		if strings.HasPrefix(line, "provider[") {
			// Extract provider name
			start := strings.Index(line, "[") + 1
			end := strings.Index(line, "]")
			if start > 0 && end > start {
				providers = append(providers, line[start:end])
			}
		}
	}

	return providers, nil
}

// Version returns Terraform version
func (a *Adapter) Version(ctx context.Context) (string, error) {
	output, err := a.run(ctx, "version", "-json")
	if err != nil {
		// Try without -json for older versions
		output, err = a.run(ctx, "version")
		if err != nil {
			return "", err
		}
		lines := strings.Split(output, "\n")
		if len(lines) > 0 {
			return strings.TrimPrefix(lines[0], "Terraform v"), nil
		}
		return "", nil
	}

	var result struct {
		TerraformVersion string `json:"terraform_version"`
	}
	if err := json.Unmarshal([]byte(output), &result); err != nil {
		return "", err
	}

	return result.TerraformVersion, nil
}

// FindTerraformFiles finds all Terraform files in directory
func (a *Adapter) FindTerraformFiles(ctx context.Context) ([]string, error) {
	var files []string

	err := filepath.Walk(a.workDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil
		}

		// Skip hidden directories and common non-terraform dirs
		if info.IsDir() {
			name := info.Name()
			if strings.HasPrefix(name, ".") || name == "node_modules" || name == "vendor" {
				return filepath.SkipDir
			}
			return nil
		}

		ext := filepath.Ext(path)
		if ext == ".tf" || ext == ".tf.json" {
			relPath, _ := filepath.Rel(a.workDir, path)
			files = append(files, relPath)
		}

		return nil
	})

	return files, err
}

// run executes a Terraform command
func (a *Adapter) run(ctx context.Context, args ...string) (string, error) {
	ctx, cancel := context.WithTimeout(ctx, a.config.Timeout)
	defer cancel()

	cmd := exec.CommandContext(ctx, a.terraformPath, args...)
	cmd.Dir = a.workDir

	var stdout, stderr bytes.Buffer
	cmd.Stdout = &stdout
	cmd.Stderr = &stderr

	if err := cmd.Run(); err != nil {
		return "", fmt.Errorf("terraform %s failed: %w: %s", strings.Join(args, " "), err, stderr.String())
	}

	return stdout.String(), nil
}

// ExtractResources extracts resources from plan for cost estimation
func (a *Adapter) ExtractResources(plan *PlanOutput) []ResourceInfo {
	var resources []ResourceInfo

	for _, change := range plan.ResourceChanges {
		// Skip data sources
		if change.Mode == "data" {
			continue
		}

		// Determine action
		action := "no_change"
		if len(change.Change.Actions) > 0 {
			if contains(change.Change.Actions, "create") {
				action = "create"
			} else if contains(change.Change.Actions, "delete") {
				action = "destroy"
			} else if contains(change.Change.Actions, "update") {
				action = "update"
			}
		}

		resources = append(resources, ResourceInfo{
			Address:       change.Address,
			Type:          change.Type,
			Name:          change.Name,
			Provider:      change.ProviderName,
			ModuleAddress: change.ModuleAddress,
			Index:         change.Index,
			Action:        action,
			Values:        change.Change.After,
			PriorValues:   change.Change.Before,
			Unknown:       change.Change.AfterUnknown,
		})
	}

	return resources
}

// ResourceInfo is extracted resource information
type ResourceInfo struct {
	Address       string                 `json:"address"`
	Type          string                 `json:"type"`
	Name          string                 `json:"name"`
	Provider      string                 `json:"provider"`
	ModuleAddress string                 `json:"module_address,omitempty"`
	Index         interface{}            `json:"index,omitempty"`
	Action        string                 `json:"action"`
	Values        map[string]interface{} `json:"values"`
	PriorValues   map[string]interface{} `json:"prior_values,omitempty"`
	Unknown       map[string]interface{} `json:"unknown,omitempty"`
}

func contains(slice []string, item string) bool {
	for _, s := range slice {
		if s == item {
			return true
		}
	}
	return false
}

################################################################################
# FILE: :\good projects\cost estimation\adapters\terraform\hcl\cty_safe.go
# TYPE: go
# SIZE: 5911 bytes
################################################################################
// Package hcl - Safe CTY value conversion
// CTY values are NEVER blindly passed through.
// Unknown values MUST be explicitly handled.
package hcl

import (
	"fmt"

	"github.com/zclconf/go-cty/cty"
)

// SafeValue represents a safely-converted CTY value
type SafeValue struct {
	// The Go value (if known)
	Value interface{}

	// Is this value known?
	IsKnown bool

	// Is this value null?
	IsNull bool

	// Type information
	Type SafeValueType

	// Original CTY type name
	CtyType string

	// Why is this unknown?
	UnknownReason string

	// Confidence impact for using this value
	ConfidenceImpact float64
}

// SafeValueType indicates the type of value
type SafeValueType int

const (
	SafeTypeUnknown SafeValueType = iota
	SafeTypeNull
	SafeTypeString
	SafeTypeNumber
	SafeTypeBool
	SafeTypeList
	SafeTypeMap
	SafeTypeTuple
	SafeTypeObject
)

// String returns the type name
func (t SafeValueType) String() string {
	switch t {
	case SafeTypeString:
		return "string"
	case SafeTypeNumber:
		return "number"
	case SafeTypeBool:
		return "bool"
	case SafeTypeList:
		return "list"
	case SafeTypeMap:
		return "map"
	case SafeTypeTuple:
		return "tuple"
	case SafeTypeObject:
		return "object"
	case SafeTypeNull:
		return "null"
	default:
		return "unknown"
	}
}

// CtyToSafe safely converts a cty.Value to a SafeValue
// This NEVER loses type information or unknown status
func CtyToSafe(val cty.Value) SafeValue {
	result := SafeValue{
		CtyType: val.Type().FriendlyName(),
	}

	// Check for unknown FIRST - this is critical
	if !val.IsKnown() {
		result.IsKnown = false
		result.Type = SafeTypeUnknown
		result.UnknownReason = "value not yet known (computed at apply time)"
		result.ConfidenceImpact = 0.3 // Significant impact
		return result
	}

	// Check for null
	if val.IsNull() {
		result.IsNull = true
		result.IsKnown = true
		result.Type = SafeTypeNull
		result.Value = nil
		return result
	}

	result.IsKnown = true

	// Convert based on type
	switch {
	case val.Type() == cty.String:
		result.Type = SafeTypeString
		result.Value = val.AsString()

	case val.Type() == cty.Number:
		result.Type = SafeTypeNumber
		f, _ := val.AsBigFloat().Float64()
		result.Value = f

	case val.Type() == cty.Bool:
		result.Type = SafeTypeBool
		result.Value = val.True()

	case val.Type().IsListType() || val.Type().IsSetType():
		result.Type = SafeTypeList
		result.Value = convertList(val)

	case val.Type().IsTupleType():
		result.Type = SafeTypeTuple
		result.Value = convertTuple(val)

	case val.Type().IsMapType():
		result.Type = SafeTypeMap
		result.Value = convertMap(val)

	case val.Type().IsObjectType():
		result.Type = SafeTypeObject
		result.Value = convertObject(val)

	default:
		// Unknown type - mark as unknown
		result.IsKnown = false
		result.Type = SafeTypeUnknown
		result.UnknownReason = fmt.Sprintf("unhandled CTY type: %s", val.Type().FriendlyName())
		result.ConfidenceImpact = 0.2
	}

	return result
}

func convertList(val cty.Value) []interface{} {
	if !val.CanIterateElements() {
		return nil
	}

	result := make([]interface{}, 0, val.LengthInt())
	iter := val.ElementIterator()
	for iter.Next() {
		_, v := iter.Element()
		safe := CtyToSafe(v)
		if safe.IsKnown && !safe.IsNull {
			result = append(result, safe.Value)
		} else {
			// Include placeholder for unknown elements
			result = append(result, nil)
		}
	}
	return result
}

func convertTuple(val cty.Value) []interface{} {
	return convertList(val) // Same logic
}

func convertMap(val cty.Value) map[string]interface{} {
	if !val.CanIterateElements() {
		return nil
	}

	result := make(map[string]interface{})
	iter := val.ElementIterator()
	for iter.Next() {
		k, v := iter.Element()
		safe := CtyToSafe(v)
		if safe.IsKnown && !safe.IsNull {
			result[k.AsString()] = safe.Value
		} else {
			result[k.AsString()] = nil
		}
	}
	return result
}

func convertObject(val cty.Value) map[string]interface{} {
	return convertMap(val) // Same logic for objects
}

// AsString returns the value as a string, or empty if not a string
func (v SafeValue) AsString() string {
	if !v.IsKnown || v.IsNull || v.Type != SafeTypeString {
		return ""
	}
	if s, ok := v.Value.(string); ok {
		return s
	}
	return ""
}

// AsFloat returns the value as a float64, or 0 if not a number
func (v SafeValue) AsFloat() float64 {
	if !v.IsKnown || v.IsNull || v.Type != SafeTypeNumber {
		return 0
	}
	if f, ok := v.Value.(float64); ok {
		return f
	}
	return 0
}

// AsInt returns the value as an int
func (v SafeValue) AsInt() int {
	return int(v.AsFloat())
}

// AsBool returns the value as a bool
func (v SafeValue) AsBool() bool {
	if !v.IsKnown || v.IsNull || v.Type != SafeTypeBool {
		return false
	}
	if b, ok := v.Value.(bool); ok {
		return b
	}
	return false
}

// AsList returns the value as a slice
func (v SafeValue) AsList() []interface{} {
	if !v.IsKnown || v.IsNull {
		return nil
	}
	if l, ok := v.Value.([]interface{}); ok {
		return l
	}
	return nil
}

// AsMap returns the value as a map
func (v SafeValue) AsMap() map[string]interface{} {
	if !v.IsKnown || v.IsNull {
		return nil
	}
	if m, ok := v.Value.(map[string]interface{}); ok {
		return m
	}
	return nil
}

// MustBeKnown returns an error if the value is unknown
func (v SafeValue) MustBeKnown(context string) error {
	if !v.IsKnown {
		return &UnknownValueError{
			Context: context,
			Reason:  v.UnknownReason,
		}
	}
	return nil
}

// UnknownValueError indicates a value that should be known is unknown
type UnknownValueError struct {
	Context string
	Reason  string
}

func (e *UnknownValueError) Error() string {
	return fmt.Sprintf("unknown value in %s: %s", e.Context, e.Reason)
}

################################################################################
# FILE: :\good projects\cost estimation\adapters\terraform\hcl\scanner.go
# TYPE: go
# SIZE: 12019 bytes
################################################################################
// Package hcl provides Terraform HCL parsing with DEFERRED evaluation.
// Expressions are NOT evaluated immediately - they are captured as unevaluated
// and resolved only after variables, locals, and references are available.
package hcl

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"

	"github.com/hashicorp/hcl/v2"
	"github.com/hashicorp/hcl/v2/hclparse"
	"github.com/hashicorp/hcl/v2/hclsyntax"

	"terraform-cost/core/scanner"
	"terraform-cost/core/types"
)

// Scanner implements the scanner.Scanner interface for Terraform HCL
// CRITICAL: This scanner does NOT evaluate expressions.
// It captures expressions as unevaluated for later resolution.
type Scanner struct {
	parser *hclparse.Parser
}

// NewScanner creates a new HCL scanner
func NewScanner() *Scanner {
	return &Scanner{
		parser: hclparse.NewParser(),
	}
}

// Name returns the scanner name
func (s *Scanner) Name() string {
	return "terraform-hcl"
}

// CanScan determines if this scanner can handle the input
func (s *Scanner) CanScan(ctx context.Context, input *types.ProjectInput) (bool, error) {
	// Look for .tf files
	hasTfFiles := false
	err := filepath.Walk(input.Path, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.IsDir() && strings.HasSuffix(path, ".tf") {
			hasTfFiles = true
			return filepath.SkipAll // Found one, that's enough
		}
		return nil
	})

	if err != nil && err != filepath.SkipAll {
		return false, err
	}

	return hasTfFiles, nil
}

// Scan parses HCL files and returns raw assets with UNEVALUATED expressions
func (s *Scanner) Scan(ctx context.Context, input *types.ProjectInput) (*scanner.ScanResult, error) {
	result := &scanner.ScanResult{
		Assets:    make([]types.RawAsset, 0),
		Modules:   make([]scanner.ModuleReference, 0),
		Variables: make(map[string]interface{}),
		Warnings:  make([]scanner.ScanWarning, 0),
		Errors:    make([]scanner.ScanError, 0),
	}

	// Find all .tf files
	var tfFiles []string
	err := filepath.Walk(input.Path, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.IsDir() && strings.HasSuffix(path, ".tf") {
			tfFiles = append(tfFiles, path)
		}
		return nil
	})

	if err != nil {
		return nil, fmt.Errorf("failed to walk directory: %w", err)
	}

	// Parse each file - DO NOT EVALUATE
	for _, file := range tfFiles {
		assets, modules, warnings, errs := s.parseFile(ctx, file, input.Path)
		result.Assets = append(result.Assets, assets...)
		result.Modules = append(result.Modules, modules...)
		result.Warnings = append(result.Warnings, warnings...)
		result.Errors = append(result.Errors, errs...)
	}

	// Load tfvars if present
	result.Variables = s.loadVariables(input.Path)

	return result, nil
}

func (s *Scanner) parseFile(ctx context.Context, file, basePath string) ([]types.RawAsset, []scanner.ModuleReference, []scanner.ScanWarning, []scanner.ScanError) {
	var assets []types.RawAsset
	var modules []scanner.ModuleReference
	var warnings []scanner.ScanWarning
	var errors []scanner.ScanError

	src, err := os.ReadFile(file)
	if err != nil {
		errors = append(errors, scanner.ScanError{
			File:    file,
			Message: fmt.Sprintf("failed to read file: %v", err),
			Err:     err,
		})
		return assets, modules, warnings, errors
	}

	hclFile, diags := s.parser.ParseHCL(src, file)
	if diags.HasErrors() {
		for _, diag := range diags {
			if diag.Severity == hcl.DiagError {
				line := 0
				if diag.Subject != nil {
					line = diag.Subject.Start.Line
				}
				errors = append(errors, scanner.ScanError{
					File:    file,
					Line:    line,
					Message: diag.Summary + ": " + diag.Detail,
				})
			}
		}
		return assets, modules, warnings, errors
	}

	// Extract blocks from the file body
	body := hclFile.Body
	content, _, _ := body.PartialContent(&hcl.BodySchema{
		Blocks: []hcl.BlockHeaderSchema{
			{Type: "resource", LabelNames: []string{"type", "name"}},
			{Type: "data", LabelNames: []string{"type", "name"}},
			{Type: "module", LabelNames: []string{"name"}},
			{Type: "variable", LabelNames: []string{"name"}},
			{Type: "locals"},
			{Type: "provider", LabelNames: []string{"name"}},
		},
	})

	relPath, _ := filepath.Rel(basePath, file)

	for _, block := range content.Blocks {
		switch block.Type {
		case "resource":
			asset := s.parseResourceDeferred(block, relPath, false)
			if asset != nil {
				assets = append(assets, *asset)
			}
		case "data":
			asset := s.parseResourceDeferred(block, relPath, true)
			if asset != nil {
				assets = append(assets, *asset)
			}
		case "module":
			mod := s.parseModuleDeferred(block)
			if mod != nil {
				modules = append(modules, *mod)
			}
		}
	}

	return assets, modules, warnings, errors
}

// parseResourceDeferred captures expressions WITHOUT evaluating them
func (s *Scanner) parseResourceDeferred(block *hcl.Block, file string, isDataSource bool) *types.RawAsset {
	if len(block.Labels) < 2 {
		return nil
	}

	resourceType := block.Labels[0]
	resourceName := block.Labels[1]

	// Determine provider from resource type
	provider := types.ProviderUnknown
	if strings.HasPrefix(resourceType, "aws_") {
		provider = types.ProviderAWS
	} else if strings.HasPrefix(resourceType, "azurerm_") {
		provider = types.ProviderAzure
	} else if strings.HasPrefix(resourceType, "google_") {
		provider = types.ProviderGCP
	}

	// Extract attributes as UNEVALUATED expressions
	attrs := s.extractAttributesDeferred(block.Body)

	address := types.ResourceAddress(fmt.Sprintf("%s.%s", resourceType, resourceName))
	if isDataSource {
		address = types.ResourceAddress(fmt.Sprintf("data.%s.%s", resourceType, resourceName))
	}

	line := 0
	if block.DefRange.Start.Line > 0 {
		line = block.DefRange.Start.Line
	}

	return &types.RawAsset{
		Address:      address,
		Provider:     provider,
		Type:         resourceType,
		Name:         resourceName,
		Attributes:   attrs,
		IsDataSource: isDataSource,
		SourceFile:   file,
		SourceLine:   line,
	}
}

func (s *Scanner) parseModuleDeferred(block *hcl.Block) *scanner.ModuleReference {
	if len(block.Labels) < 1 {
		return nil
	}

	name := block.Labels[0]
	attrs := s.extractAttributesDeferred(block.Body)

	source := ""
	if src := attrs.Get("source"); src != nil {
		if attr, ok := src.(types.Attribute); ok && !attr.IsComputed && !attr.IsUnknown {
			if srcStr, ok := attr.Value.(string); ok {
				source = srcStr
			}
		}
	}

	version := ""
	if ver := attrs.Get("version"); ver != nil {
		if attr, ok := ver.(types.Attribute); ok && !attr.IsComputed && !attr.IsUnknown {
			if verStr, ok := attr.Value.(string); ok {
				version = verStr
			}
		}
	}

	return &scanner.ModuleReference{
		Key:     name,
		Source:  source,
		Version: version,
	}
}

// extractAttributesDeferred captures expressions WITHOUT evaluating them
// This is the CRITICAL fix - we do NOT call attr.Expr.Value(nil)
func (s *Scanner) extractAttributesDeferred(body hcl.Body) types.Attributes {
	attrs := make(types.Attributes)

	// Get all attributes from the body
	content, _, _ := body.PartialContent(&hcl.BodySchema{})

	for name, attr := range content.Attributes {
		// Analyze the expression to determine if it needs context
		exprInfo := s.analyzeExpression(attr.Expr)

		if exprInfo.IsLiteral {
			// Safe to evaluate literals immediately
			val, diags := attr.Expr.Value(nil)
			if !diags.HasErrors() {
				attrs[name] = types.Attribute{
					Value:      s.ctyToGo(val),
					IsComputed: false,
					IsUnknown:  false,
				}
				continue
			}
		}

		// Expression requires context - mark as unevaluated
		attrs[name] = types.Attribute{
			Value:             nil,
			IsComputed:        exprInfo.RequiresContext,
			IsUnknown:         exprInfo.HasUnknownRefs,
			Expression:        s.expressionToString(attr.Expr),
			ExpressionType:    exprInfo.Type,
			References:        exprInfo.References,
			ConfidenceImpact:  exprInfo.ConfidenceImpact,
		}
	}

	return attrs
}

// ExpressionInfo describes an unevaluated expression
type ExpressionInfo struct {
	IsLiteral        bool
	RequiresContext  bool
	HasUnknownRefs   bool
	Type             string   // "literal", "variable", "local", "reference", "function", "conditional"
	References       []string // Referenced addresses
	ConfidenceImpact float64  // How much this reduces confidence (0.0 - 1.0)
}

// analyzeExpression determines what kind of expression this is
func (s *Scanner) analyzeExpression(expr hcl.Expression) ExpressionInfo {
	info := ExpressionInfo{
		IsLiteral:        true,
		RequiresContext:  false,
		HasUnknownRefs:   false,
		Type:             "literal",
		References:       []string{},
		ConfidenceImpact: 0.0,
	}

	// Get all variable references
	refs := expr.Variables()
	if len(refs) > 0 {
		info.IsLiteral = false
		info.RequiresContext = true
		info.ConfidenceImpact = 0.1 // Base impact for having references

		for _, ref := range refs {
			refStr := formatTraversal(ref)
			info.References = append(info.References, refStr)

			// Classify reference type
			if len(ref) > 0 {
				root := ref.RootName()
				switch root {
				case "var":
					info.Type = "variable"
					info.ConfidenceImpact += 0.1 // Variable adds uncertainty
				case "local":
					info.Type = "local"
					// Locals are resolvable
				case "count":
					info.Type = "count_reference"
					info.ConfidenceImpact += 0.2 // Count adds more uncertainty
				case "each":
					info.Type = "for_each_reference"
					info.ConfidenceImpact += 0.2
				case "data":
					info.Type = "data_source"
					info.HasUnknownRefs = true // Data sources are runtime
					info.ConfidenceImpact += 0.3
				default:
					// Resource reference
					info.Type = "resource_reference"
					info.HasUnknownRefs = true
					info.ConfidenceImpact += 0.3
				}
			}
		}
	}

	// Check for function calls
	if synExpr, ok := expr.(*hclsyntax.FunctionCallExpr); ok {
		info.IsLiteral = false
		info.RequiresContext = true
		info.Type = "function:" + synExpr.Name
		info.ConfidenceImpact += 0.1
	}

	// Check for conditional
	if _, ok := expr.(*hclsyntax.ConditionalExpr); ok {
		info.IsLiteral = false
		info.RequiresContext = true
		info.Type = "conditional"
		info.ConfidenceImpact += 0.15
	}

	// Cap confidence impact
	if info.ConfidenceImpact > 0.5 {
		info.ConfidenceImpact = 0.5
	}

	return info
}

func formatTraversal(traversal hcl.Traversal) string {
	parts := make([]string, 0, len(traversal))
	for _, t := range traversal {
		switch tt := t.(type) {
		case hcl.TraverseRoot:
			parts = append(parts, tt.Name)
		case hcl.TraverseAttr:
			parts = append(parts, "."+tt.Name)
		case hcl.TraverseIndex:
			parts = append(parts, "[...]")
		}
	}
	return strings.Join(parts, "")
}

func (s *Scanner) expressionToString(expr hcl.Expression) string {
	// Get the source range and extract the text
	rng := expr.Range()
	return fmt.Sprintf("<%s:%d-%d>", rng.Filename, rng.Start.Line, rng.End.Line)
}

func (s *Scanner) ctyToGo(val interface{}) interface{} {
	// This is a simplified conversion
	// In production, use cty.Value methods properly
	return val
}

func (s *Scanner) loadVariables(basePath string) map[string]interface{} {
	vars := make(map[string]interface{})

	// Look for terraform.tfvars
	tfvarsPath := filepath.Join(basePath, "terraform.tfvars")
	if _, err := os.Stat(tfvarsPath); err == nil {
		// Parse tfvars file
		// Simplified - in production, properly parse HCL
	}

	// Look for *.auto.tfvars
	matches, _ := filepath.Glob(filepath.Join(basePath, "*.auto.tfvars"))
	for range matches {
		// Parse each file
	}

	return vars
}

func init() {
	// Register this scanner
	scanner.Register(NewScanner())
}

################################################################################
# FILE: :\good projects\cost estimation\adapters\terragrunt\adapter.go
# TYPE: go
# SIZE: 14986 bytes
################################################################################
// Package terragrunt provides production-grade Terragrunt adapter for the cost estimation engine.
// This adapter handles Terragrunt configuration parsing and multi-module estimation.
package terragrunt

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
	"sync"
	"time"
)

// Adapter is the Terragrunt adapter
type Adapter struct {
	terragruntPath string
	terraformPath  string
	workDir        string
	config         *Config
}

// Config configures the Terragrunt adapter
type Config struct {
	// TerragruntPath is the terragrunt executable path
	TerragruntPath string `json:"terragrunt_path"`

	// TerraformPath is the terraform executable path
	TerraformPath string `json:"terraform_path"`

	// WorkDir is the working directory
	WorkDir string `json:"work_dir"`

	// Timeout for commands
	Timeout time.Duration `json:"timeout"`

	// Parallelism for run-all commands
	Parallelism int `json:"parallelism"`

	// IgnoreDependencyErrors continues on dependency errors
	IgnoreDependencyErrors bool `json:"ignore_dependency_errors"`

	// IncludeDirs filters modules to include
	IncludeDirs []string `json:"include_dirs"`

	// ExcludeDirs filters modules to exclude
	ExcludeDirs []string `json:"exclude_dirs"`

	// NoColor disables color output
	NoColor bool `json:"no_color"`

	// NonInteractive disables prompts
	NonInteractive bool `json:"non_interactive"`
}

// DefaultConfig returns sensible defaults
func DefaultConfig() *Config {
	return &Config{
		TerragruntPath:         "terragrunt",
		TerraformPath:          "terraform",
		WorkDir:                ".",
		Timeout:                60 * time.Minute,
		Parallelism:            5,
		IgnoreDependencyErrors: false,
		NoColor:                true,
		NonInteractive:         true,
	}
}

// New creates a new Terragrunt adapter
func New(config *Config) (*Adapter, error) {
	if config == nil {
		config = DefaultConfig()
	}

	workDir, err := filepath.Abs(config.WorkDir)
	if err != nil {
		return nil, fmt.Errorf("failed to resolve work dir: %w", err)
	}

	return &Adapter{
		terragruntPath: config.TerragruntPath,
		terraformPath:  config.TerraformPath,
		workDir:        workDir,
		config:         config,
	}, nil
}

// Module represents a Terragrunt module
type Module struct {
	// Path is the module directory path
	Path string `json:"path"`

	// RelativePath from workDir
	RelativePath string `json:"relative_path"`

	// Dependencies are module dependencies
	Dependencies []string `json:"dependencies,omitempty"`

	// Inputs are the module inputs
	Inputs map[string]interface{} `json:"inputs,omitempty"`

	// TerraformSource is the terraform source
	TerraformSource string `json:"terraform_source,omitempty"`

	// IncludeConfigs are included configs
	IncludeConfigs []string `json:"include_configs,omitempty"`
}

// ModuleOutput is the output from a module estimation
type ModuleOutput struct {
	// Module is the module info
	Module *Module `json:"module"`

	// Success indicates if estimation succeeded
	Success bool `json:"success"`

	// Error message if failed
	Error string `json:"error,omitempty"`

	// TotalCost is the module cost
	TotalCost float64 `json:"total_cost"`

	// Resources in the module
	ResourceCount int `json:"resource_count"`

	// PlanJSON is the Terraform plan JSON
	PlanJSON json.RawMessage `json:"plan_json,omitempty"`

	// Duration of the estimation
	Duration time.Duration `json:"duration"`
}

// RunAllOutput is the output from run-all command
type RunAllOutput struct {
	// Modules are the module outputs
	Modules []*ModuleOutput `json:"modules"`

	// TotalCost across all modules
	TotalCost float64 `json:"total_cost"`

	// TotalResources across all modules
	TotalResources int `json:"total_resources"`

	// SuccessCount is number of successful modules
	SuccessCount int `json:"success_count"`

	// FailureCount is number of failed modules
	FailureCount int `json:"failure_count"`

	// Duration of the entire run
	Duration time.Duration `json:"duration"`
}

// FindModules finds all Terragrunt modules
func (a *Adapter) FindModules(ctx context.Context) ([]*Module, error) {
	// Use graph-dependencies to find modules
	output, err := a.run(ctx, "graph-dependencies")
	if err != nil {
		// Fall back to finding terragrunt.hcl files
		return a.findModulesByFile(ctx)
	}

	// Parse dependencies
	modules, err := a.parseGraphOutput(output)
	if err != nil {
		return a.findModulesByFile(ctx)
	}

	return modules, nil
}

// findModulesByFile finds modules by searching for terragrunt.hcl
func (a *Adapter) findModulesByFile(ctx context.Context) ([]*Module, error) {
	var modules []*Module

	err := filepath.Walk(a.workDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil
		}

		// Skip hidden directories
		if info.IsDir() && strings.HasPrefix(info.Name(), ".") {
			return filepath.SkipDir
		}

		// Check for terragrunt.hcl
		if info.Name() == "terragrunt.hcl" {
			dir := filepath.Dir(path)
			relPath, _ := filepath.Rel(a.workDir, dir)

			// Apply filters
			if a.shouldInclude(relPath) {
				modules = append(modules, &Module{
					Path:         dir,
					RelativePath: relPath,
				})
			}
		}

		return nil
	})

	return modules, err
}

// parseGraphOutput parses terragrunt graph-dependencies output
func (a *Adapter) parseGraphOutput(output string) ([]*Module, error) {
	moduleMap := make(map[string]*Module)

	// Parse DOT format
	for _, line := range strings.Split(output, "\n") {
		line = strings.TrimSpace(line)

		// Extract module paths from edges and nodes
		if strings.Contains(line, "->") {
			// Edge: "moduleA" -> "moduleB"
			parts := strings.Split(line, "->")
			for _, part := range parts {
				part = strings.Trim(strings.TrimSpace(part), "\"")
				if part != "" && !strings.HasPrefix(part, "digraph") {
					if _, ok := moduleMap[part]; !ok {
						moduleMap[part] = &Module{
							Path:         filepath.Join(a.workDir, part),
							RelativePath: part,
						}
					}
				}
			}
		} else if strings.Contains(line, "\"") && !strings.Contains(line, "{") && !strings.Contains(line, "}") {
			// Node: "modulePath"
			part := strings.Trim(line, "\" \t;")
			if part != "" && !strings.HasPrefix(part, "digraph") {
				if _, ok := moduleMap[part]; !ok {
					moduleMap[part] = &Module{
						Path:         filepath.Join(a.workDir, part),
						RelativePath: part,
					}
				}
			}
		}
	}

	var modules []*Module
	for _, m := range moduleMap {
		if a.shouldInclude(m.RelativePath) {
			modules = append(modules, m)
		}
	}

	return modules, nil
}

// shouldInclude checks if a module should be included
func (a *Adapter) shouldInclude(path string) bool {
	// Check excludes
	for _, exclude := range a.config.ExcludeDirs {
		if strings.Contains(path, exclude) {
			return false
		}
	}

	// Check includes (if specified)
	if len(a.config.IncludeDirs) > 0 {
		for _, include := range a.config.IncludeDirs {
			if strings.Contains(path, include) {
				return true
			}
		}
		return false
	}

	return true
}

// GetInputs gets the inputs for a module
func (a *Adapter) GetInputs(ctx context.Context, modulePath string) (map[string]interface{}, error) {
	output, err := a.runInDir(ctx, modulePath, "terragrunt-info")
	if err != nil {
		return nil, err
	}

	var info struct {
		Inputs map[string]interface{} `json:"Inputs"`
	}
	if err := json.Unmarshal([]byte(output), &info); err != nil {
		return nil, fmt.Errorf("failed to parse terragrunt-info: %w", err)
	}

	return info.Inputs, nil
}

// PlanModule generates Terraform plan for a single module
func (a *Adapter) PlanModule(ctx context.Context, module *Module, outFile string) error {
	args := []string{"plan", "-out=" + outFile, "-input=false"}

	if a.config.NoColor {
		args = append(args, "-no-color")
	}

	if a.config.NonInteractive {
		args = append(args, "--terragrunt-non-interactive")
	}

	_, err := a.runInDir(ctx, module.Path, args...)
	return err
}

// ShowPlanJSON shows plan in JSON format for a module
func (a *Adapter) ShowPlanJSON(ctx context.Context, module *Module, planFile string) (json.RawMessage, error) {
	args := []string{"show", "-json", planFile}

	if a.config.NoColor {
		args = append(args, "-no-color")
	}

	output, err := a.runInDir(ctx, module.Path, args...)
	if err != nil {
		return nil, err
	}

	return json.RawMessage(output), nil
}

// RunAll runs estimation on all modules
func (a *Adapter) RunAll(ctx context.Context) (*RunAllOutput, error) {
	start := time.Now()

	modules, err := a.FindModules(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to find modules: %w", err)
	}

	output := &RunAllOutput{
		Modules: make([]*ModuleOutput, 0, len(modules)),
	}

	// Process modules in parallel
	var wg sync.WaitGroup
	results := make(chan *ModuleOutput, len(modules))
	semaphore := make(chan struct{}, a.config.Parallelism)

	for _, module := range modules {
		wg.Add(1)
		go func(m *Module) {
			defer wg.Done()

			semaphore <- struct{}{}
			defer func() { <-semaphore }()

			result := a.processModule(ctx, m)
			results <- result
		}(module)
	}

	// Close results when done
	go func() {
		wg.Wait()
		close(results)
	}()

	// Collect results
	for result := range results {
		output.Modules = append(output.Modules, result)
		if result.Success {
			output.SuccessCount++
			output.TotalCost += result.TotalCost
			output.TotalResources += result.ResourceCount
		} else {
			output.FailureCount++
		}
	}

	output.Duration = time.Since(start)
	return output, nil
}

// processModule processes a single module
func (a *Adapter) processModule(ctx context.Context, module *Module) *ModuleOutput {
	start := time.Now()

	result := &ModuleOutput{
		Module: module,
	}

	// Create temp plan file
	planFile := filepath.Join(module.Path, ".terraform-cost-plan")
	defer os.Remove(planFile)

	// Generate plan
	if err := a.PlanModule(ctx, module, planFile); err != nil {
		result.Error = fmt.Sprintf("plan failed: %v", err)
		result.Duration = time.Since(start)
		return result
	}

	// Get plan JSON
	planJSON, err := a.ShowPlanJSON(ctx, module, planFile)
	if err != nil {
		result.Error = fmt.Sprintf("show plan failed: %v", err)
		result.Duration = time.Since(start)
		return result
	}

	result.Success = true
	result.PlanJSON = planJSON
	result.Duration = time.Since(start)

	// Count resources from plan JSON
	var plan struct {
		ResourceChanges []struct {
			Address string `json:"address"`
			Mode    string `json:"mode"`
		} `json:"resource_changes"`
	}
	if err := json.Unmarshal(planJSON, &plan); err == nil {
		for _, rc := range plan.ResourceChanges {
			if rc.Mode == "managed" {
				result.ResourceCount++
			}
		}
	}

	return result
}

// Init initializes all modules
func (a *Adapter) Init(ctx context.Context) error {
	args := []string{"run-all", "init", "--terragrunt-non-interactive"}

	if a.config.NoColor {
		args = append(args, "-no-color")
	}

	if a.config.Parallelism > 0 {
		args = append(args, fmt.Sprintf("--terragrunt-parallelism=%d", a.config.Parallelism))
	}

	if a.config.IgnoreDependencyErrors {
		args = append(args, "--terragrunt-ignore-dependency-errors")
	}

	_, err := a.run(ctx, args...)
	return err
}

// Validate validates all modules
func (a *Adapter) Validate(ctx context.Context) error {
	args := []string{"run-all", "validate", "--terragrunt-non-interactive"}

	if a.config.NoColor {
		args = append(args, "-no-color")
	}

	_, err := a.run(ctx, args...)
	return err
}

// Version returns Terragrunt version
func (a *Adapter) Version(ctx context.Context) (string, error) {
	output, err := a.run(ctx, "--version")
	if err != nil {
		return "", err
	}

	// Parse "terragrunt version v0.xx.xx"
	parts := strings.Fields(output)
	if len(parts) >= 3 {
		return strings.TrimPrefix(parts[2], "v"), nil
	}

	return strings.TrimSpace(output), nil
}

// run executes a Terragrunt command
func (a *Adapter) run(ctx context.Context, args ...string) (string, error) {
	return a.runInDir(ctx, a.workDir, args...)
}

// runInDir executes a Terragrunt command in a specific directory
func (a *Adapter) runInDir(ctx context.Context, dir string, args ...string) (string, error) {
	ctx, cancel := context.WithTimeout(ctx, a.config.Timeout)
	defer cancel()

	cmd := exec.CommandContext(ctx, a.terragruntPath, args...)
	cmd.Dir = dir

	// Set terraform path if specified
	if a.terraformPath != "" {
		cmd.Env = append(os.Environ(), "TERRAGRUNT_TFPATH="+a.terraformPath)
	}

	var stdout, stderr bytes.Buffer
	cmd.Stdout = &stdout
	cmd.Stderr = &stderr

	if err := cmd.Run(); err != nil {
		return "", fmt.Errorf("terragrunt %s failed: %w: %s", strings.Join(args, " "), err, stderr.String())
	}

	return stdout.String(), nil
}

// GetDependencyGraph returns the dependency graph
func (a *Adapter) GetDependencyGraph(ctx context.Context) (map[string][]string, error) {
	output, err := a.run(ctx, "graph-dependencies")
	if err != nil {
		return nil, err
	}

	graph := make(map[string][]string)

	// Parse DOT format for dependencies
	for _, line := range strings.Split(output, "\n") {
		line = strings.TrimSpace(line)
		if strings.Contains(line, "->") {
			parts := strings.Split(line, "->")
			if len(parts) == 2 {
				from := strings.Trim(strings.TrimSpace(parts[0]), "\"")
				to := strings.Trim(strings.TrimSpace(parts[1]), "\" ;")
				graph[from] = append(graph[from], to)
			}
		}
	}

	return graph, nil
}

// GetOrderedModules returns modules in dependency order
func (a *Adapter) GetOrderedModules(ctx context.Context) ([]*Module, error) {
	graph, err := a.GetDependencyGraph(ctx)
	if err != nil {
		return a.FindModules(ctx)
	}

	// Topological sort
	var ordered []string
	visited := make(map[string]bool)
	temp := make(map[string]bool)

	var visit func(node string) error
	visit = func(node string) error {
		if temp[node] {
			return fmt.Errorf("circular dependency detected at %s", node)
		}
		if visited[node] {
			return nil
		}

		temp[node] = true
		for _, dep := range graph[node] {
			if err := visit(dep); err != nil {
				return err
			}
		}
		temp[node] = false
		visited[node] = true
		ordered = append(ordered, node)
		return nil
	}

	for node := range graph {
		if !visited[node] {
			if err := visit(node); err != nil {
				return nil, err
			}
		}
	}

	// Convert to modules
	var modules []*Module
	for _, path := range ordered {
		modules = append(modules, &Module{
			Path:         filepath.Join(a.workDir, path),
			RelativePath: path,
			Dependencies: graph[path],
		})
	}

	return modules, nil
}

################################################################################
# FILE: :\good projects\cost estimation\adapters\webhook\adapter.go
# TYPE: go
# SIZE: 8003 bytes
################################################################################
// Package webhook provides production-grade webhook adapter for integrations.
// Supports GitHub, GitLab, Bitbucket, and custom webhook targets.
package webhook

import (
	"bytes"
	"context"
	"crypto/hmac"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"time"
)

// Provider is a webhook provider type
type Provider string

const (
	ProviderGitHub    Provider = "github"
	ProviderGitLab    Provider = "gitlab"
	ProviderBitbucket Provider = "bitbucket"
	ProviderSlack     Provider = "slack"
	ProviderTeams     Provider = "teams"
	ProviderCustom    Provider = "custom"
)

// Config configures webhook behavior
type Config struct {
	// Provider type
	Provider Provider `json:"provider"`

	// Endpoint URL
	Endpoint string `json:"endpoint"`

	// Secret for signature verification
	Secret string `json:"secret"`

	// Headers to include
	Headers map[string]string `json:"headers"`

	// Timeout for requests
	Timeout time.Duration `json:"timeout"`

	// RetryCount for failed requests
	RetryCount int `json:"retry_count"`

	// RetryDelay between retries
	RetryDelay time.Duration `json:"retry_delay"`
}

// DefaultConfig returns sensible defaults
func DefaultConfig(provider Provider) *Config {
	return &Config{
		Provider:   provider,
		Timeout:    30 * time.Second,
		RetryCount: 3,
		RetryDelay: 1 * time.Second,
		Headers:    make(map[string]string),
	}
}

// Adapter is the webhook adapter
type Adapter struct {
	config     *Config
	httpClient *http.Client
}

// New creates a new webhook adapter
func New(config *Config) *Adapter {
	return &Adapter{
		config: config,
		httpClient: &http.Client{
			Timeout: config.Timeout,
		},
	}
}

// Payload is the webhook payload
type Payload struct {
	// Event type
	Event string `json:"event"`

	// TotalCost monthly
	TotalCost float64 `json:"total_cost"`

	// Confidence (0-1)
	Confidence float64 `json:"confidence"`

	// Coverage breakdown
	Coverage CoveragePayload `json:"coverage"`

	// Delta if diff
	Delta *float64 `json:"delta,omitempty"`

	// Resources count
	ResourceCount int `json:"resource_count"`

	// PolicyViolations
	PolicyViolations []PolicyViolationPayload `json:"policy_violations,omitempty"`

	// Repository info
	Repository RepositoryPayload `json:"repository"`

	// Pull request info
	PullRequest *PullRequestPayload `json:"pull_request,omitempty"`

	// Snapshot
	Snapshot SnapshotPayload `json:"snapshot"`

	// Timestamp
	Timestamp time.Time `json:"timestamp"`
}

// CoveragePayload is coverage info
type CoveragePayload struct {
	NumericPercent     float64 `json:"numeric_percent"`
	SymbolicPercent    float64 `json:"symbolic_percent"`
	UnsupportedPercent float64 `json:"unsupported_percent"`
}

// PolicyViolationPayload is policy violation
type PolicyViolationPayload struct {
	Rule     string `json:"rule"`
	Message  string `json:"message"`
	Severity string `json:"severity"`
}

// RepositoryPayload is repo info
type RepositoryPayload struct {
	Owner    string `json:"owner"`
	Name     string `json:"name"`
	FullName string `json:"full_name"`
	URL      string `json:"url"`
}

// PullRequestPayload is PR info
type PullRequestPayload struct {
	Number int    `json:"number"`
	Title  string `json:"title"`
	SHA    string `json:"sha"`
	Branch string `json:"branch"`
	Author string `json:"author"`
}

// SnapshotPayload is snapshot info
type SnapshotPayload struct {
	ID       string `json:"id"`
	Provider string `json:"provider"`
	Region   string `json:"region"`
}

// Send sends the webhook
func (a *Adapter) Send(ctx context.Context, payload *Payload) error {
	var lastErr error

	for attempt := 0; attempt <= a.config.RetryCount; attempt++ {
		if attempt > 0 {
			select {
			case <-ctx.Done():
				return ctx.Err()
			case <-time.After(a.config.RetryDelay):
			}
		}

		if err := a.sendOnce(ctx, payload); err != nil {
			lastErr = err
			continue
		}
		return nil
	}

	return fmt.Errorf("webhook failed after %d attempts: %w", a.config.RetryCount+1, lastErr)
}

func (a *Adapter) sendOnce(ctx context.Context, payload *Payload) error {
	// Format payload for provider
	body, err := a.formatPayload(payload)
	if err != nil {
		return fmt.Errorf("failed to format payload: %w", err)
	}

	// Create request
	req, err := http.NewRequestWithContext(ctx, "POST", a.config.Endpoint, bytes.NewReader(body))
	if err != nil {
		return fmt.Errorf("failed to create request: %w", err)
	}

	// Set headers
	req.Header.Set("Content-Type", "application/json")
	for k, v := range a.config.Headers {
		req.Header.Set(k, v)
	}

	// Sign if secret provided
	if a.config.Secret != "" {
		sig := a.sign(body)
		switch a.config.Provider {
		case ProviderGitHub:
			req.Header.Set("X-Hub-Signature-256", "sha256="+sig)
		case ProviderGitLab:
			req.Header.Set("X-Gitlab-Token", a.config.Secret)
		default:
			req.Header.Set("X-Signature", sig)
		}
	}

	// Send
	resp, err := a.httpClient.Do(req)
	if err != nil {
		return fmt.Errorf("request failed: %w", err)
	}
	defer resp.Body.Close()

	// Check response
	if resp.StatusCode >= 400 {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("webhook returned %d: %s", resp.StatusCode, string(body))
	}

	return nil
}

func (a *Adapter) formatPayload(payload *Payload) ([]byte, error) {
	switch a.config.Provider {
	case ProviderSlack:
		return a.formatSlack(payload)
	case ProviderTeams:
		return a.formatTeams(payload)
	default:
		return json.Marshal(payload)
	}
}

func (a *Adapter) formatSlack(payload *Payload) ([]byte, error) {
	// Slack block kit format
	color := "good"
	if len(payload.PolicyViolations) > 0 {
		color = "danger"
	}

	slack := map[string]interface{}{
		"attachments": []map[string]interface{}{
			{
				"color": color,
				"title": fmt.Sprintf("ðŸ’° Cost Estimate: $%.2f/month", payload.TotalCost),
				"fields": []map[string]interface{}{
					{
						"title": "Confidence",
						"value": fmt.Sprintf("%.0f%%", payload.Confidence*100),
						"short": true,
					},
					{
						"title": "Resources",
						"value": fmt.Sprintf("%d", payload.ResourceCount),
						"short": true,
					},
					{
						"title": "Coverage",
						"value": fmt.Sprintf("%.0f%% numeric", payload.Coverage.NumericPercent),
						"short": true,
					},
				},
				"footer": fmt.Sprintf("Snapshot: %s/%s", payload.Snapshot.Provider, payload.Snapshot.Region),
				"ts":     payload.Timestamp.Unix(),
			},
		},
	}

	return json.Marshal(slack)
}

func (a *Adapter) formatTeams(payload *Payload) ([]byte, error) {
	// Microsoft Teams adaptive card format
	themeColor := "00FF00"
	if len(payload.PolicyViolations) > 0 {
		themeColor = "FF0000"
	}

	teams := map[string]interface{}{
		"@type":      "MessageCard",
		"@context":   "http://schema.org/extensions",
		"themeColor": themeColor,
		"summary":    fmt.Sprintf("Cost Estimate: $%.2f/month", payload.TotalCost),
		"sections": []map[string]interface{}{
			{
				"activityTitle": "ðŸ’° Terraform Cost Estimate",
				"facts": []map[string]interface{}{
					{"name": "Total Cost", "value": fmt.Sprintf("$%.2f/month", payload.TotalCost)},
					{"name": "Confidence", "value": fmt.Sprintf("%.0f%%", payload.Confidence*100)},
					{"name": "Resources", "value": fmt.Sprintf("%d", payload.ResourceCount)},
				},
			},
		},
	}

	return json.Marshal(teams)
}

func (a *Adapter) sign(payload []byte) string {
	mac := hmac.New(sha256.New, []byte(a.config.Secret))
	mac.Write(payload)
	return hex.EncodeToString(mac.Sum(nil))
}

// VerifySignature verifies an incoming webhook signature
func VerifySignature(payload []byte, signature, secret string) bool {
	mac := hmac.New(sha256.New, []byte(secret))
	mac.Write(payload)
	expected := hex.EncodeToString(mac.Sum(nil))
	return hmac.Equal([]byte(signature), []byte(expected))
}

################################################################################
# FILE: :\good projects\cost estimation\api\diff.go
# TYPE: go
# SIZE: 2972 bytes
################################################################################
// Package api - Additional API types for diff and metadata
package api

import "fmt"

// ResponseMetadata contains audit/reproducibility metadata
type ResponseMetadata struct {
	InputHash       string `json:"input_hash"`
	EngineVersion   string `json:"engine_version"`
	PricingSnapshot string `json:"pricing_snapshot"`
	Mode            string `json:"mode"`
	DurationMs      int64  `json:"duration_ms"`
}

// DiffRequest is the request for POST /diff
type DiffRequest struct {
	Base DiffRef        `json:"base"`
	Head DiffRef        `json:"head"`
	Mode EstimationMode `json:"mode"`
}

// DiffRef identifies a ref for comparison
type DiffRef struct {
	Ref  string `json:"ref"`
	Path string `json:"path,omitempty"`
}

// DiffResponse is the response for POST /diff
type DiffResponse struct {
	Base          DiffSummary    `json:"base"`
	Head          DiffSummary    `json:"head"`
	Delta         DiffDelta      `json:"delta"`
	Changes       []DiffChange   `json:"changes"`
	Explanations  []string       `json:"explanations,omitempty"`
	PolicyResults []PolicyResult `json:"policy_results,omitempty"`
	DurationMs    int64          `json:"duration_ms"`
}

// DiffSummary summarizes one side of a diff
type DiffSummary struct {
	Ref        string     `json:"ref"`
	TotalCost  *CostValue `json:"total_cost"`
	Confidence float64    `json:"confidence"`
}

// DiffDelta represents the change between base and head
type DiffDelta struct {
	MonthlyCost     string  `json:"monthly_cost"`
	ConfidenceDelta float64 `json:"confidence_delta"`
}

// DiffChange represents a single change
type DiffChange struct {
	Type           string   `json:"type"` // "added", "removed", "changed"
	ResourceAddr   string   `json:"resource_address"`
	CostBefore     string   `json:"cost_before,omitempty"`
	CostAfter      string   `json:"cost_after,omitempty"`
	CostDelta      string   `json:"cost_delta"`
	DependencyPath []string `json:"dependency_path,omitempty"`
	Explanation    string   `json:"explanation,omitempty"`
}

// PRCommentData contains data for rendering PR comments
type PRCommentData struct {
	DeltaCost     string       `json:"delta_cost"`
	Confidence    float64      `json:"confidence"`
	Changes       []DiffChange `json:"changes"`
	Unknowns      []string     `json:"unknowns"`
	PolicyBlocked bool         `json:"policy_blocked"`
}

// RenderMarkdown renders the PR comment as markdown
func (p *PRCommentData) RenderMarkdown() string {
	md := "### Terraform Cost Impact\n\n"
	md += p.DeltaCost + " / month\n"
	md += fmt.Sprintf("Confidence: %.0f%%\n\n", p.Confidence*100)

	if len(p.Changes) > 0 {
		md += "#### Why?\n"
		for _, c := range p.Changes {
			md += fmt.Sprintf("- %s %s\n", c.Type, c.ResourceAddr)
		}
		md += "\n"
	}

	if len(p.Unknowns) > 0 {
		md += "âš ï¸ Unknown cost components present\n"
	}

	if p.PolicyBlocked {
		md += "\nâŒ **Blocked by policy**\n"
	}

	return md
}

################################################################################
# FILE: :\good projects\cost estimation\api\handler.go
# TYPE: go
# SIZE: 5844 bytes
################################################################################
// Package api - HTTP handler for cost estimation
// This handler wraps the engine - it contains NO estimation logic.
// All logic is delegated to core packages.
package api

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"time"

	"terraform-cost/core/confidence"
	"terraform-cost/core/graph"
	"terraform-cost/core/pricing"
)

// Handler handles estimation requests
type Handler struct {
	// Dependencies
	pricingGate *pricing.PricingGate

	// Configuration
	defaultMode EstimationMode
}

// NewHandler creates a new handler
func NewHandler() *Handler {
	return &Handler{
		pricingGate: pricing.NewPricingGate(),
		defaultMode: ModePermissive,
	}
}

// HandleEstimate handles POST /estimate
func (h *Handler) HandleEstimate(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()
	requestID := generateRequestID()

	// Parse request
	var req EstimateRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		h.writeError(w, requestID, "INVALID_REQUEST", err.Error(), http.StatusBadRequest)
		return
	}

	// Validate request
	if err := validateRequest(&req); err != nil {
		h.writeError(w, requestID, "VALIDATION_ERROR", err.Error(), http.StatusBadRequest)
		return
	}

	// Execute estimation
	resp, err := h.execute(ctx, requestID, &req)
	if err != nil {
		h.writeError(w, requestID, "EXECUTION_ERROR", err.Error(), http.StatusInternalServerError)
		return
	}

	// Write response
	h.writeJSON(w, resp, http.StatusOK)
}

func (h *Handler) execute(ctx context.Context, requestID string, req *EstimateRequest) (*EstimateResponse, error) {
	resp := &EstimateResponse{
		RequestID:   requestID,
		Timestamp:   time.Now().UTC(),
		Status:      "success",
		Resources:   []ResourceCost{},
		Unknowns:    []UnknownCost{},
		Assumptions: []Assumption{},
	}

	isStrict := req.Mode == ModeStrict

	// Step 1: Build canonical dependency graph
	depGraph := graph.NewCanonicalDependencyGraph()
	// ... parsing and building would go here
	depGraph.Seal()
	depGraph.MustBeClosed() // INVARIANT: graph must be closed

	// Step 2: Create expansion guard
	expansionGuard := graph.NewExpansionGuard(isStrict)

	// Step 3: Create asset graph
	assetGraph, err := graph.NewEnforcedAssetGraph(depGraph)
	if err != nil {
		return nil, fmt.Errorf("failed to create asset graph: %w", err)
	}

	// Step 4: Create cost graph (ONLY from asset graph with dep graph)
	costGraph, err := graph.NewEnforcedCostGraph(assetGraph)
	if err != nil {
		return nil, fmt.Errorf("failed to create cost graph: %w", err)
	}

	// Step 5: Run invariant checks
	checker := graph.NewInvariantChecker(isStrict)
	if err := checker.RunFullCheck(costGraph); err != nil {
		return nil, fmt.Errorf("invariant check failed: %w", err)
	}

	// Step 6: Collect results
	confidences := []float64{}
	for _, unit := range costGraph.AllCostUnits() {
		confidences = append(confidences, unit.Confidence)

		if unit.IsSymbolic {
			// Add to unknowns
			resp.Unknowns = append(resp.Unknowns, UnknownCost{
				Address:     unit.AssetID,
				Reason:      unit.SymbolicInfo.Reason,
				IsUnbounded: unit.SymbolicInfo.IsUnbounded,
			})
		} else {
			// Add to resources
			resp.Resources = append(resp.Resources, ResourceCost{
				Address:        unit.AssetID,
				MonthlyCost:    &CostValue{Amount: unit.MonthlyCost.String(), Currency: "USD"},
				Confidence:     unit.Confidence,
				DependencyPath: unit.DependencyPath,
			})
		}
	}

	// Step 7: Aggregate confidence (PESSIMISTIC)
	resp.Confidence = confidence.AggregateConfidence(confidences)
	resp.ConfidenceLevel = confidence.ConfidenceLevel(resp.Confidence)

	// Step 8: Add blocked expansions as unknowns
	for _, blocked := range expansionGuard.GetBlocked() {
		resp.Unknowns = append(resp.Unknowns, UnknownCost{
			Address:     blocked.Address,
			Reason:      blocked.Reason,
			IsUnbounded: true,
		})
	}

	// Set status based on unknowns
	if len(resp.Unknowns) > 0 {
		resp.Status = "partial"
		resp.Message = fmt.Sprintf("%d resources have unknown cardinality", len(resp.Unknowns))
	}

	return resp, nil
}

func validateRequest(req *EstimateRequest) error {
	if req.Source.Type == "" {
		return fmt.Errorf("source.type is required")
	}
	switch req.Source.Type {
	case "directory":
		if req.Source.Path == "" {
			return fmt.Errorf("source.path is required for directory type")
		}
	case "git":
		if req.Source.URL == "" {
			return fmt.Errorf("source.url is required for git type")
		}
	case "inline":
		if len(req.Source.InlineHCL) == 0 {
			return fmt.Errorf("source.inline_hcl is required for inline type")
		}
	default:
		return fmt.Errorf("invalid source.type: %s", req.Source.Type)
	}
	return nil
}

func (h *Handler) writeError(w http.ResponseWriter, requestID, code, message string, status int) {
	resp := &EstimateResponse{
		RequestID: requestID,
		Timestamp: time.Now().UTC(),
		Status:    "error",
		Message:   message,
		Errors: []ErrorDetail{
			{Code: code, Message: message},
		},
	}
	h.writeJSON(w, resp, status)
}

func (h *Handler) writeJSON(w http.ResponseWriter, data interface{}, status int) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(status)
	json.NewEncoder(w).Encode(data)
}

func generateRequestID() string {
	return fmt.Sprintf("est-%d", time.Now().UnixNano())
}

// RegisterRoutes registers API routes
func RegisterRoutes(mux *http.ServeMux, h *Handler) {
	mux.HandleFunc("POST /estimate", h.HandleEstimate)
	mux.HandleFunc("GET /health", handleHealth)
}

func handleHealth(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(http.StatusOK)
	json.NewEncoder(w).Encode(map[string]string{"status": "ok"})
}

################################################################################
# FILE: :\good projects\cost estimation\api\server.go
# TYPE: go
# SIZE: 6788 bytes
################################################################################
// Package api - Thin, deterministic API layer
// The API is ONLY responsible for: input ingestion, engine orchestration, output serialization.
// The API NEVER performs cost logic.
package api

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"net/http"
	"time"
)

// Server is the API server
type Server struct {
	handler *Handler
	mux     *http.ServeMux
	version string
}

// NewServer creates a new API server
func NewServer(version string) *Server {
	handler := NewHandler()
	mux := http.NewServeMux()

	s := &Server{
		handler: handler,
		mux:     mux,
		version: version,
	}

	s.registerRoutes()
	return s
}

// registerRoutes registers all API routes
func (s *Server) registerRoutes() {
	// Core endpoints
	s.mux.HandleFunc("POST /estimate", s.handleEstimate)
	s.mux.HandleFunc("POST /diff", s.handleDiff)
	s.mux.HandleFunc("GET /health", s.handleHealth)

	// Supporting endpoints
	s.mux.HandleFunc("GET /version", s.handleVersion)
	s.mux.HandleFunc("GET /pricing-snapshots", s.handleListSnapshots)
}

// handleEstimate handles POST /estimate
func (s *Server) handleEstimate(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()
	start := time.Now()

	// Parse request
	var req EstimateRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		s.writeError(w, "INVALID_JSON", err.Error(), http.StatusBadRequest)
		return
	}

	// Validate
	if err := validateEstimateRequest(&req); err != nil {
		s.writeError(w, "VALIDATION_ERROR", err.Error(), http.StatusBadRequest)
		return
	}

	// Compute deterministic input hash
	inputHash := computeInputHash(&req)

	// Execute engine (NO COST LOGIC HERE)
	result, err := s.handler.execute(ctx, generateRequestID(), &req)
	if err != nil {
		s.writeError(w, "ENGINE_ERROR", err.Error(), http.StatusInternalServerError)
		return
	}

	// Add metadata
	result.Metadata = &ResponseMetadata{
		InputHash:       inputHash,
		EngineVersion:   s.version,
		PricingSnapshot: getCurrentPricingSnapshot(),
		Mode:            string(req.Mode),
		DurationMs:      time.Since(start).Milliseconds(),
	}

	s.writeJSON(w, result, http.StatusOK)
}

// handleDiff handles POST /diff
func (s *Server) handleDiff(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()
	start := time.Now()

	var req DiffRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		s.writeError(w, "INVALID_JSON", err.Error(), http.StatusBadRequest)
		return
	}

	// Execute diff (NO COST LOGIC HERE)
	result, err := s.executeDiff(ctx, &req)
	if err != nil {
		s.writeError(w, "DIFF_ERROR", err.Error(), http.StatusInternalServerError)
		return
	}

	result.DurationMs = time.Since(start).Milliseconds()
	s.writeJSON(w, result, http.StatusOK)
}

// handleHealth handles GET /health
func (s *Server) handleHealth(w http.ResponseWriter, r *http.Request) {
	s.writeJSON(w, map[string]interface{}{
		"status":  "healthy",
		"version": s.version,
		"time":    time.Now().UTC().Format(time.RFC3339),
	}, http.StatusOK)
}

// handleVersion handles GET /version
func (s *Server) handleVersion(w http.ResponseWriter, r *http.Request) {
	s.writeJSON(w, map[string]string{
		"version":    s.version,
		"engine":     "terraform-cost",
		"api_version": "v1",
	}, http.StatusOK)
}

// handleListSnapshots handles GET /pricing-snapshots
func (s *Server) handleListSnapshots(w http.ResponseWriter, r *http.Request) {
	// Return available pricing snapshots
	s.writeJSON(w, map[string]interface{}{
		"snapshots": []map[string]string{
			{"id": "aws-us-east-1-2026-01-15", "region": "us-east-1", "provider": "aws"},
			{"id": "aws-us-west-2-2026-01-15", "region": "us-west-2", "provider": "aws"},
		},
	}, http.StatusOK)
}

// executeDiff executes a diff between two estimates
func (s *Server) executeDiff(ctx context.Context, req *DiffRequest) (*DiffResponse, error) {
	// Get base estimate
	baseReq := &EstimateRequest{
		Source: SourceConfig{Type: "git", Ref: req.Base.Ref},
		Mode:   req.Mode,
	}
	baseResult, err := s.handler.execute(ctx, generateRequestID(), baseReq)
	if err != nil {
		return nil, fmt.Errorf("base estimate failed: %w", err)
	}

	// Get head estimate
	headReq := &EstimateRequest{
		Source: SourceConfig{Type: "git", Ref: req.Head.Ref},
		Mode:   req.Mode,
	}
	headResult, err := s.handler.execute(ctx, generateRequestID(), headReq)
	if err != nil {
		return nil, fmt.Errorf("head estimate failed: %w", err)
	}

	// Compute diff (using engine diff, NOT computing here)
	return computeDiff(baseResult, headResult), nil
}

func (s *Server) writeJSON(w http.ResponseWriter, data interface{}, status int) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(status)
	json.NewEncoder(w).Encode(data)
}

func (s *Server) writeError(w http.ResponseWriter, code, message string, status int) {
	s.writeJSON(w, map[string]interface{}{
		"error": map[string]string{
			"code":    code,
			"message": message,
		},
	}, status)
}

// ServeHTTP implements http.Handler
func (s *Server) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	s.mux.ServeHTTP(w, r)
}

// ListenAndServe starts the server
func (s *Server) ListenAndServe(addr string) error {
	return http.ListenAndServe(addr, s)
}

// Helper functions

func computeInputHash(req *EstimateRequest) string {
	data, _ := json.Marshal(req)
	hash := sha256.Sum256(data)
	return hex.EncodeToString(hash[:])
}

func getCurrentPricingSnapshot() string {
	return fmt.Sprintf("aws-us-east-1-%s", time.Now().Format("2006-01-02"))
}

func validateEstimateRequest(req *EstimateRequest) error {
	if req.Source.Type == "" {
		return fmt.Errorf("source.type is required")
	}
	return nil
}

func computeDiff(base, head *EstimateResponse) *DiffResponse {
	// Parse costs
	baseCost := parseCost(base.TotalMonthlyCost)
	headCost := parseCost(head.TotalMonthlyCost)

	delta := headCost - baseCost
	var deltaStr string
	if delta >= 0 {
		deltaStr = fmt.Sprintf("+$%.2f", delta)
	} else {
		deltaStr = fmt.Sprintf("-$%.2f", -delta)
	}

	return &DiffResponse{
		Base: DiffSummary{
			Ref:         "",
			TotalCost:   base.TotalMonthlyCost,
			Confidence:  base.Confidence,
		},
		Head: DiffSummary{
			Ref:         "",
			TotalCost:   head.TotalMonthlyCost,
			Confidence:  head.Confidence,
		},
		Delta: DiffDelta{
			MonthlyCost:      deltaStr,
			ConfidenceDelta:  head.Confidence - base.Confidence,
		},
		Changes:       []DiffChange{},
		PolicyResults: []PolicyResult{},
	}
}

func parseCost(cost *CostValue) float64 {
	if cost == nil {
		return 0
	}
	var f float64
	fmt.Sscanf(cost.Amount, "%f", &f)
	return f
}

################################################################################
# FILE: :\good projects\cost estimation\api\types.go
# TYPE: go
# SIZE: 6337 bytes
################################################################################
// Package api - API types for cost estimation
// These types define the contract for /estimate endpoint.
// API is stateless, idempotent, and deterministic.
package api

import (
	"time"

	"terraform-cost/core/graph"
)

// EstimateRequest is the input to POST /estimate
type EstimateRequest struct {
	// Source configuration
	Source SourceConfig `json:"source"`

	// Estimation mode
	Mode EstimationMode `json:"mode"`

	// Usage overrides (optional)
	UsageOverrides map[string]UsageOverride `json:"usage_overrides,omitempty"`

	// Pricing snapshot ID (optional, uses latest if empty)
	PricingSnapshotID string `json:"pricing_snapshot_id,omitempty"`

	// Policy configuration (optional)
	PolicyConfig *PolicyConfig `json:"policy_config,omitempty"`
}

// SourceConfig defines the Terraform source
type SourceConfig struct {
	// Type of source: "directory", "git", "inline"
	Type string `json:"type"`

	// Path or URL
	Path string `json:"path,omitempty"`
	URL  string `json:"url,omitempty"`
	Ref  string `json:"ref,omitempty"` // git ref

	// Inline HCL (for type="inline")
	InlineHCL map[string]string `json:"inline_hcl,omitempty"`

	// Variables
	Variables map[string]interface{} `json:"variables,omitempty"`

	// Workspace
	Workspace string `json:"workspace,omitempty"`
}

// EstimationMode controls strictness
type EstimationMode string

const (
	ModeStrict     EstimationMode = "strict"
	ModePermissive EstimationMode = "permissive"
)

// UsageOverride overrides default usage assumptions
type UsageOverride struct {
	ResourceAddress string                 `json:"resource_address"`
	Values          map[string]interface{} `json:"values"`
}

// PolicyConfig configures policy evaluation
type PolicyConfig struct {
	// Policies to evaluate
	Policies []PolicyRule `json:"policies"`

	// Baseline for diff (optional)
	BaselineID string `json:"baseline_id,omitempty"`
}

// PolicyRule defines a policy
type PolicyRule struct {
	Name      string                 `json:"name"`
	Type      string                 `json:"type"` // "budget", "change", "unknown"
	Threshold interface{}            `json:"threshold,omitempty"`
	Scope     string                 `json:"scope,omitempty"` // "all", "new", "changed"
	Config    map[string]interface{} `json:"config,omitempty"`
}

// EstimateResponse is the output of POST /estimate
type EstimateResponse struct {
	// Request tracking
	RequestID string    `json:"request_id"`
	Timestamp time.Time `json:"timestamp"`

	// Metadata for reproducibility
	Metadata *ResponseMetadata `json:"metadata,omitempty"`

	// Status
	Status  string `json:"status"` // "success", "partial", "error"
	Message string `json:"message,omitempty"`

	// Cost summary
	TotalMonthlyCost  *CostValue `json:"total_monthly_cost,omitempty"`
	TotalHourlyCost   *CostValue `json:"total_hourly_cost,omitempty"`

	// Confidence (pessimistic)
	Confidence       float64  `json:"confidence"`
	ConfidenceLevel  string   `json:"confidence_level"` // "high", "medium", "low", "unknown"
	ConfidenceReason string   `json:"confidence_reason,omitempty"`

	// Cost breakdown
	Resources []ResourceCost `json:"resources,omitempty"`

	// Unknowns (symbolic costs)
	Unknowns []UnknownCost `json:"unknowns,omitempty"`

	// Assumptions made
	Assumptions []Assumption `json:"assumptions,omitempty"`

	// Policy results
	PolicyResults []PolicyResult `json:"policy_results,omitempty"`

	// Pricing reference
	PricingSnapshot *PricingReference `json:"pricing_snapshot,omitempty"`

	// Errors (for partial results)
	Errors []ErrorDetail `json:"errors,omitempty"`
}

// CostValue represents a cost with currency
type CostValue struct {
	Amount   string `json:"amount"` // Decimal string for precision
	Currency string `json:"currency"`
}

// ResourceCost is the cost of a single resource
type ResourceCost struct {
	Address        string                      `json:"address"`
	ResourceType   string                      `json:"resource_type"`
	MonthlyCost    *CostValue                  `json:"monthly_cost"`
	HourlyCost     *CostValue                  `json:"hourly_cost"`
	Confidence     float64                     `json:"confidence"`
	DependsOn      []string                    `json:"depends_on,omitempty"`
	Components     []CostComponent             `json:"components,omitempty"`
	DependencyPath []graph.DependencyNodeID    `json:"dependency_path,omitempty"`
}

// CostComponent is a component of resource cost
type CostComponent struct {
	Name        string     `json:"name"`
	MonthlyCost *CostValue `json:"monthly_cost"`
	Unit        string     `json:"unit,omitempty"`
	Quantity    float64    `json:"quantity,omitempty"`
}

// UnknownCost represents a symbolic cost bucket
type UnknownCost struct {
	Address     string     `json:"address"`
	Reason      string     `json:"reason"`
	Expression  string     `json:"expression,omitempty"`
	MinCost     *CostValue `json:"min_cost,omitempty"`
	MaxCost     *CostValue `json:"max_cost,omitempty"`
	IsUnbounded bool       `json:"is_unbounded"`
}

// Assumption is a usage assumption made
type Assumption struct {
	ResourceAddress string  `json:"resource_address"`
	Attribute       string  `json:"attribute"`
	Value           string  `json:"value"`
	Unit            string  `json:"unit,omitempty"`
	Reason          string  `json:"reason"`
	Impact          float64 `json:"impact"` // Confidence impact
	Overrideable    bool    `json:"overrideable"`
	OverrideKey     string  `json:"override_key,omitempty"`
}

// PolicyResult is the result of a policy evaluation
type PolicyResult struct {
	PolicyName string `json:"policy_name"`
	Passed     bool   `json:"passed"`
	Message    string `json:"message,omitempty"`
	Severity   string `json:"severity,omitempty"` // "error", "warning", "info"
}

// PricingReference identifies the pricing snapshot used
type PricingReference struct {
	ID          string    `json:"id"`
	Version     string    `json:"version"`
	EffectiveAt time.Time `json:"effective_at"`
	ContentHash string    `json:"content_hash"`
}

// ErrorDetail provides error information
type ErrorDetail struct {
	Code    string `json:"code"`
	Message string `json:"message"`
	Path    string `json:"path,omitempty"`
}

################################################################################
# FILE: :\good projects\cost estimation\api\envelope\audit.go
# TYPE: go
# SIZE: 1705 bytes
################################################################################
// Package envelope - Envelope logging and audit
package envelope

import (
	"encoding/json"
	"fmt"
	"time"
)

// AuditEntry is a log entry for an envelope
type AuditEntry struct {
	Timestamp  time.Time `json:"timestamp"`
	InputHash  string    `json:"input_hash"`
	Envelope   string    `json:"envelope_json"`
	RequestID  string    `json:"request_id,omitempty"`
	ClientIP   string    `json:"client_ip,omitempty"`
	UserAgent  string    `json:"user_agent,omitempty"`
	DurationMs int64     `json:"duration_ms,omitempty"`
	Success    bool      `json:"success"`
	Error      string    `json:"error,omitempty"`
}

// AuditLogger logs envelopes for audit and replay
type AuditLogger interface {
	Log(entry AuditEntry) error
}

// StdoutAuditLogger logs to stdout (for development)
type StdoutAuditLogger struct{}

// Log logs an audit entry to stdout
func (l *StdoutAuditLogger) Log(entry AuditEntry) error {
	data, _ := json.Marshal(entry)
	fmt.Printf("[AUDIT] %s\n", data)
	return nil
}

// CreateAuditEntry creates an audit entry from an envelope
func CreateAuditEntry(envelope *InputEnvelope, requestID, clientIP, userAgent string) AuditEntry {
	envJSON, _ := json.Marshal(envelope)
	return AuditEntry{
		Timestamp: time.Now().UTC(),
		InputHash: envelope.InputHash,
		Envelope:  string(envJSON),
		RequestID: requestID,
		ClientIP:  clientIP,
		UserAgent: userAgent,
		Success:   true,
	}
}

// MarkFailed marks the audit entry as failed
func (e *AuditEntry) MarkFailed(err error) {
	e.Success = false
	e.Error = err.Error()
}

// SetDuration sets the duration
func (e *AuditEntry) SetDuration(d time.Duration) {
	e.DurationMs = d.Milliseconds()
}

################################################################################
# FILE: :\good projects\cost estimation\api\envelope\convert.go
# TYPE: go
# SIZE: 1202 bytes
################################################################################
// Package envelope - API request to envelope conversion
package envelope

// FromRequest converts API request types to RawInput
// This is the bridge between API DTOs and normalization

import (
	"terraform-cost/api/v1/types"
)

// FromEstimateRequest converts EstimateRequest to RawInput
func FromEstimateRequest(req *types.EstimateRequest) RawInput {
	return RawInput{
		SourceType:   req.Source.Type,
		Repo:         req.Source.Repo,
		Ref:          req.Source.Ref,
		Path:         req.Source.Path,
		Mode:         req.Mode,
		UsageProfile: req.UsageProfile,
		Options: RawOptions{
			IncludeDependencyGraph: req.Options.IncludeDependencyGraph,
			IncludeCostLineage:     req.Options.IncludeCostLineage,
			IncludeComponents:      req.Options.IncludeComponents,
		},
	}
}

// FromDiffRequest converts DiffRequest to two RawInputs
func FromDiffRequest(req *types.DiffRequest) (base, head RawInput) {
	base = RawInput{
		SourceType: "git",
		Ref:        req.Base.Ref,
		Path:       req.Base.Path,
		Mode:       req.Mode,
	}
	head = RawInput{
		SourceType: "git",
		Ref:        req.Head.Ref,
		Path:       req.Head.Path,
		Mode:       req.Mode,
	}
	return
}

################################################################################
# FILE: :\good projects\cost estimation\api\envelope\envelope.go
# TYPE: go
# SIZE: 5962 bytes
################################################################################
// Package envelope - Input normalization and envelope creation
// The engine NEVER sees raw input - only normalized envelopes.
// This ensures determinism and auditability.
package envelope

import (
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"path/filepath"
	"strings"
	"time"
)

// InputEnvelope is the normalized, hashed representation of an API request.
// The engine receives ONLY this - never raw input.
type InputEnvelope struct {
	// Source identification
	SourceType string `json:"source_type"` // "git", "upload", "local"
	Repo       string `json:"repo,omitempty"`
	Ref        string `json:"ref,omitempty"`
	Path       string `json:"path"`

	// Normalized fields
	CanonicalPath string `json:"canonical_path"`
	ResolvedRef   string `json:"resolved_ref,omitempty"`

	// Identity
	InputHash string `json:"input_hash"`

	// Execution context
	Mode         string `json:"mode"`
	UsageProfile string `json:"usage_profile,omitempty"`

	// Timing
	NormalizedAt time.Time `json:"normalized_at"`

	// Options
	Options EnvelopeOptions `json:"options"`
}

// EnvelopeOptions are normalized options
type EnvelopeOptions struct {
	IncludeDependencyGraph bool `json:"include_dependency_graph"`
	IncludeCostLineage     bool `json:"include_cost_lineage"`
	IncludeComponents      bool `json:"include_components"`
}

// RawInput represents unnormalized API input
type RawInput struct {
	SourceType   string
	Repo         string
	Ref          string
	Path         string
	Mode         string
	UsageProfile string
	Options      RawOptions
}

// RawOptions are unnormalized options
type RawOptions struct {
	IncludeDependencyGraph bool
	IncludeCostLineage     bool
	IncludeComponents      bool
}

// Normalizer normalizes raw input into envelopes
type Normalizer struct {
	// RefResolver resolves git refs to commit hashes (optional)
	RefResolver RefResolver
}

// RefResolver resolves git refs
type RefResolver interface {
	Resolve(repo, ref string) (string, error)
}

// NewNormalizer creates a normalizer
func NewNormalizer() *Normalizer {
	return &Normalizer{}
}

// WithRefResolver sets the ref resolver
func (n *Normalizer) WithRefResolver(r RefResolver) *Normalizer {
	n.RefResolver = r
	return n
}

// Normalize transforms raw input to a deterministic envelope
func (n *Normalizer) Normalize(raw RawInput) (*InputEnvelope, error) {
	now := time.Now().UTC()

	envelope := &InputEnvelope{
		SourceType:   normalizeSourceType(raw.SourceType),
		Repo:         normalizeRepo(raw.Repo),
		Ref:          raw.Ref,
		Path:         raw.Path,
		Mode:         normalizeMode(raw.Mode),
		UsageProfile: raw.UsageProfile,
		NormalizedAt: now,
		Options: EnvelopeOptions{
			IncludeDependencyGraph: raw.Options.IncludeDependencyGraph,
			IncludeCostLineage:     raw.Options.IncludeCostLineage,
			IncludeComponents:      raw.Options.IncludeComponents,
		},
	}

	// Canonicalize path
	envelope.CanonicalPath = canonicalizePath(raw.SourceType, raw.Repo, raw.Ref, raw.Path)

	// Resolve ref if possible
	if n.RefResolver != nil && raw.Repo != "" && raw.Ref != "" {
		resolved, err := n.RefResolver.Resolve(raw.Repo, raw.Ref)
		if err == nil {
			envelope.ResolvedRef = resolved
		}
	}

	// Compute deterministic hash
	envelope.InputHash = computeInputHash(envelope)

	return envelope, nil
}

func normalizeSourceType(t string) string {
	switch strings.ToLower(t) {
	case "git", "github", "gitlab", "bitbucket":
		return "git"
	case "upload", "uploaded":
		return "upload"
	case "local", "file", "path":
		return "local"
	default:
		return "local"
	}
}

func normalizeRepo(repo string) string {
	// Remove trailing .git
	repo = strings.TrimSuffix(repo, ".git")
	// Normalize to HTTPS if SSH
	if strings.HasPrefix(repo, "git@") {
		repo = strings.Replace(repo, ":", "/", 1)
		repo = strings.Replace(repo, "git@", "https://", 1)
	}
	return repo
}

func normalizeMode(mode string) string {
	switch strings.ToLower(mode) {
	case "strict":
		return "strict"
	default:
		return "permissive"
	}
}

func canonicalizePath(sourceType, repo, ref, path string) string {
	switch sourceType {
	case "git":
		// git:repo@ref:path
		return fmt.Sprintf("git:%s@%s:%s", repo, ref, normalizePath(path))
	case "upload":
		return fmt.Sprintf("upload:%s", path)
	default:
		return normalizePath(path)
	}
}

func normalizePath(path string) string {
	// Clean the path
	path = filepath.Clean(path)
	// Convert to forward slashes
	path = filepath.ToSlash(path)
	// Remove leading ./
	path = strings.TrimPrefix(path, "./")
	return path
}

func computeInputHash(envelope *InputEnvelope) string {
	// Hash only the fields that affect estimation
	hashData := struct {
		CanonicalPath string
		ResolvedRef   string
		Mode          string
		UsageProfile  string
	}{
		CanonicalPath: envelope.CanonicalPath,
		ResolvedRef:   envelope.ResolvedRef,
		Mode:          envelope.Mode,
		UsageProfile:  envelope.UsageProfile,
	}

	data, _ := json.Marshal(hashData)
	hash := sha256.Sum256(data)
	return hex.EncodeToString(hash[:])
}

// Validate validates the envelope
func (e *InputEnvelope) Validate() error {
	if e.CanonicalPath == "" {
		return fmt.Errorf("canonical path is required")
	}
	if e.InputHash == "" {
		return fmt.Errorf("input hash is required")
	}
	if e.Mode != "strict" && e.Mode != "permissive" {
		return fmt.Errorf("invalid mode: %s", e.Mode)
	}
	return nil
}

// ShortHash returns first 12 characters of hash
func (e *InputEnvelope) ShortHash() string {
	if len(e.InputHash) >= 12 {
		return e.InputHash[:12]
	}
	return e.InputHash
}

// IsGit returns true if source is git
func (e *InputEnvelope) IsGit() bool {
	return e.SourceType == "git"
}

// IsStrict returns true if strict mode
func (e *InputEnvelope) IsStrict() bool {
	return e.Mode == "strict"
}

################################################################################
# FILE: :\good projects\cost estimation\api\v1\diff.go
# TYPE: go
# SIZE: 5004 bytes
################################################################################
// Package v1 - Diff types for POST /api/v1/diff
package v1

// DiffRequest is the stable request contract for POST /api/v1/diff
type DiffRequest struct {
	// Base ref for comparison
	Base RefSpec `json:"base"`

	// Head ref for comparison
	Head RefSpec `json:"head"`

	// Mode for estimation
	Mode Mode `json:"mode"`

	// Options
	Options DiffOptions `json:"options,omitempty"`
}

// RefSpec identifies a git ref or source
type RefSpec struct {
	// Ref is the git ref (branch, tag, commit)
	Ref string `json:"ref"`

	// Path within the ref
	Path string `json:"path,omitempty"`
}

// DiffOptions are optional diff parameters
type DiffOptions struct {
	// IncludeUnchanged includes unchanged resources
	IncludeUnchanged bool `json:"include_unchanged,omitempty"`

	// IncludeExplanations includes dependency explanations
	IncludeExplanations bool `json:"include_explanations,omitempty"`
}

// DiffResponse is the stable response contract for POST /api/v1/diff
type DiffResponse struct {
	// Metadata for reproducibility
	Metadata ResponseMetadata `json:"metadata"`

	// Base summary
	Base DiffSummary `json:"base"`

	// Head summary
	Head DiffSummary `json:"head"`

	// Delta between base and head
	Delta DiffDelta `json:"delta"`

	// Changes are individual resource changes
	Changes []DiffChange `json:"changes"`

	// Explanations explain why costs changed
	Explanations []DiffExplanation `json:"explanations,omitempty"`

	// PolicyResults are policy evaluation results
	PolicyResults []PolicyResult `json:"policy_results,omitempty"`
}

// DiffSummary summarizes one side of the diff
type DiffSummary struct {
	// Ref that was estimated
	Ref string `json:"ref"`

	// TotalMonthlyCost
	TotalMonthlyCost string `json:"total_monthly_cost"`

	// Confidence
	Confidence float64 `json:"confidence"`

	// ResourceCount
	ResourceCount int `json:"resource_count"`

	// SymbolicCount
	SymbolicCount int `json:"symbolic_count"`
}

// DiffDelta represents the change between base and head
type DiffDelta struct {
	// MonthlyCostDelta as signed decimal string (e.g., "+123.45", "-67.89")
	MonthlyCostDelta string `json:"monthly_cost_delta"`

	// PercentChange if calculable
	PercentChange string `json:"percent_change,omitempty"`

	// ConfidenceDelta
	ConfidenceDelta float64 `json:"confidence_delta"`

	// AddedCount
	AddedCount int `json:"added_count"`

	// RemovedCount
	RemovedCount int `json:"removed_count"`

	// ChangedCount
	ChangedCount int `json:"changed_count"`
}

// DiffChange represents a single resource change
type DiffChange struct {
	// Type: "added", "removed", "changed"
	Type string `json:"type"`

	// ResourceAddress
	ResourceAddress string `json:"resource_address"`

	// ResourceType
	ResourceType string `json:"resource_type"`

	// CostBefore (empty for added)
	CostBefore string `json:"cost_before,omitempty"`

	// CostAfter (empty for removed)
	CostAfter string `json:"cost_after,omitempty"`

	// CostDelta as signed string
	CostDelta string `json:"cost_delta"`

	// ConfidenceBefore
	ConfidenceBefore float64 `json:"confidence_before,omitempty"`

	// ConfidenceAfter
	ConfidenceAfter float64 `json:"confidence_after,omitempty"`

	// IsSymbolic
	IsSymbolic bool `json:"is_symbolic,omitempty"`

	// DependencyPath shows lineage
	DependencyPath []string `json:"dependency_path,omitempty"`
}

// DiffExplanation explains why cost changed
type DiffExplanation struct {
	// ResourceAddress
	ResourceAddress string `json:"resource_address"`

	// Explanation is human-readable
	Explanation string `json:"explanation"`

	// CausalChain shows dependency causation
	CausalChain []string `json:"causal_chain,omitempty"`
}

// PRComment is the data for rendering a PR comment
type PRComment struct {
	// DeltaCost formatted with sign
	DeltaCost string `json:"delta_cost"`

	// Confidence percentage
	Confidence float64 `json:"confidence"`

	// ChangeSummary
	ChangeSummary string `json:"change_summary"`

	// Unknowns list
	Unknowns []string `json:"unknowns,omitempty"`

	// PolicyBlocked
	PolicyBlocked bool `json:"policy_blocked"`

	// PolicyMessages
	PolicyMessages []string `json:"policy_messages,omitempty"`
}

// RenderMarkdown renders the PR comment
func (p *PRComment) RenderMarkdown() string {
	md := "### Terraform Cost Impact\n\n"
	md += p.DeltaCost + " / month\n"
	md += "Confidence: " + formatPercent(p.Confidence) + "\n\n"

	if p.ChangeSummary != "" {
		md += "#### Summary\n"
		md += p.ChangeSummary + "\n\n"
	}

	if len(p.Unknowns) > 0 {
		md += "âš ï¸ **Unknown cost components:**\n"
		for _, u := range p.Unknowns {
			md += "- " + u + "\n"
		}
		md += "\n"
	}

	if p.PolicyBlocked {
		md += "âŒ **Blocked by policy**\n"
		for _, m := range p.PolicyMessages {
			md += "- " + m + "\n"
		}
	}

	return md
}

func formatPercent(f float64) string {
	return string(rune(int(f*100))) + "%"
}

################################################################################
# FILE: :\good projects\cost estimation\api\v1\handler.go
# TYPE: go
# SIZE: 5547 bytes
################################################################################
// Package v1 - Versioned API handler
// Routes: POST /api/v1/estimate, POST /api/v1/diff
package v1

import (
	"encoding/json"
	"net/http"
	"time"
)

// Handler handles v1 API requests
type Handler struct {
	mapper *Mapper
}

// NewHandler creates a v1 handler
func NewHandler(engineVersion, pricingSnapshot string) *Handler {
	return &Handler{
		mapper: NewMapper(engineVersion, pricingSnapshot),
	}
}

// RegisterRoutes registers v1 routes on the mux
func (h *Handler) RegisterRoutes(mux *http.ServeMux) {
	mux.HandleFunc("POST /api/v1/estimate", h.handleEstimate)
	mux.HandleFunc("POST /api/v1/diff", h.handleDiff)
	mux.HandleFunc("GET /api/v1/health", h.handleHealth)
}

// handleEstimate handles POST /api/v1/estimate
func (h *Handler) handleEstimate(w http.ResponseWriter, r *http.Request) {
	start := time.Now()

	// Parse request
	var req EstimateRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		h.writeError(w, "INVALID_JSON", err.Error(), http.StatusBadRequest)
		return
	}

	// Normalize input
	input, err := NormalizeInput(&req)
	if err != nil {
		h.writeError(w, "NORMALIZATION_ERROR", err.Error(), http.StatusBadRequest)
		return
	}

	// Execute engine (placeholder - would call actual engine)
	result := h.executeEngine(input)

	// Map to response
	resp := h.mapper.MapEstimateResponse(input, result, time.Since(start).Milliseconds())

	h.writeJSON(w, resp, http.StatusOK)
}

// handleDiff handles POST /api/v1/diff
func (h *Handler) handleDiff(w http.ResponseWriter, r *http.Request) {
	start := time.Now()

	var req DiffRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		h.writeError(w, "INVALID_JSON", err.Error(), http.StatusBadRequest)
		return
	}

	// Execute base and head
	baseInput := &NormalizedInput{
		ResolvedPath: "git:@" + req.Base.Ref,
		Mode:         req.Mode,
	}
	headInput := &NormalizedInput{
		ResolvedPath: "git:@" + req.Head.Ref,
		Mode:         req.Mode,
	}

	baseResult := h.executeEngine(baseInput)
	headResult := h.executeEngine(headInput)

	// Build diff response
	resp := h.buildDiffResponse(req, baseResult, headResult, time.Since(start).Milliseconds())

	h.writeJSON(w, resp, http.StatusOK)
}

// handleHealth handles GET /api/v1/health
func (h *Handler) handleHealth(w http.ResponseWriter, r *http.Request) {
	h.writeJSON(w, map[string]interface{}{
		"status":      "healthy",
		"api_version": "v1",
		"engine":      h.mapper.engineVersion,
		"time":        time.Now().UTC().Format(time.RFC3339),
	}, http.StatusOK)
}

// executeEngine is a placeholder for actual engine execution
func (h *Handler) executeEngine(input *NormalizedInput) *EngineResult {
	// This would call the actual engine
	// For now, return mock data
	return &EngineResult{
		TotalMonthlyCost: "1234.56",
		TotalHourlyCost:  "1.69",
		Currency:         "USD",
		Confidence:       0.72,
		ConfidenceReason: "Unknown usage for aws_lambda_function.api",
		Resources: []EngineResourceCost{
			{
				Address:        "module.compute.aws_instance.web",
				ResourceType:   "aws_instance",
				ProviderAlias:  "aws.prod",
				MonthlyCost:    "730.00",
				Confidence:     0.95,
				DependencyPath: []string{"module.compute", "aws_instance.web"},
			},
			{
				Address:        "module.database.aws_db_instance.main",
				ResourceType:   "aws_db_instance",
				ProviderAlias:  "aws.prod",
				MonthlyCost:    "504.56",
				Confidence:     0.72,
				DependencyPath: []string{"module.database", "aws_db_instance.main"},
			},
		},
		SymbolicCosts: []EngineSymbolicCost{
			{
				Address:     "module.workers.aws_instance.worker",
				Reason:      "for_each derived from module output",
				Expression:  "for_each = module.config.worker_names",
				IsUnbounded: true,
			},
		},
		Warnings: []string{
			"Unknown usage for aws_lambda_function.api - using default",
		},
	}
}

func (h *Handler) buildDiffResponse(req DiffRequest, base, head *EngineResult, durationMs int64) *DiffResponse {
	return &DiffResponse{
		Metadata: ResponseMetadata{
			InputHash:       "diff-" + req.Base.Ref + "-" + req.Head.Ref,
			EngineVersion:   h.mapper.engineVersion,
			PricingSnapshot: h.mapper.pricingSnapshot,
			Mode:            string(req.Mode),
			Timestamp:       time.Now().UTC(),
			DurationMs:      durationMs,
		},
		Base: DiffSummary{
			Ref:              req.Base.Ref,
			TotalMonthlyCost: base.TotalMonthlyCost,
			Confidence:       base.Confidence,
			ResourceCount:    len(base.Resources),
			SymbolicCount:    len(base.SymbolicCosts),
		},
		Head: DiffSummary{
			Ref:              req.Head.Ref,
			TotalMonthlyCost: head.TotalMonthlyCost,
			Confidence:       head.Confidence,
			ResourceCount:    len(head.Resources),
			SymbolicCount:    len(head.SymbolicCosts),
		},
		Delta: DiffDelta{
			MonthlyCostDelta: "+$0.00",
			ConfidenceDelta:  0,
			AddedCount:       0,
			RemovedCount:     0,
			ChangedCount:     0,
		},
		Changes: []DiffChange{},
	}
}

func (h *Handler) writeJSON(w http.ResponseWriter, data interface{}, status int) {
	w.Header().Set("Content-Type", "application/json")
	w.Header().Set("X-API-Version", "v1")
	w.WriteHeader(status)
	json.NewEncoder(w).Encode(data)
}

func (h *Handler) writeError(w http.ResponseWriter, code, message string, status int) {
	h.writeJSON(w, map[string]interface{}{
		"error": map[string]string{
			"code":    code,
			"message": message,
		},
	}, status)
}

################################################################################
# FILE: :\good projects\cost estimation\api\v1\mapper.go
# TYPE: go
# SIZE: 6684 bytes
################################################################################
// Package v1 - Mapping layer from engine to API types
// This is the ONLY place where engine types are converted to API types
package v1

import (
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"time"
)

// Mapper converts engine results to API responses
type Mapper struct {
	engineVersion   string
	pricingSnapshot string
}

// NewMapper creates a mapper
func NewMapper(engineVersion, pricingSnapshot string) *Mapper {
	return &Mapper{
		engineVersion:   engineVersion,
		pricingSnapshot: pricingSnapshot,
	}
}

// NormalizedInput is the normalized form of an estimate request
type NormalizedInput struct {
	// ResolvedPath is the absolute path to Terraform files
	ResolvedPath string

	// InputHash is the SHA256 of the normalized request
	InputHash string

	// Mode
	Mode Mode

	// UsageProfile
	UsageProfile string

	// Options
	Options EstimateOptions

	// ResolvedAt is when normalization occurred
	ResolvedAt time.Time
}

// NormalizeInput normalizes an estimate request
func NormalizeInput(req *EstimateRequest) (*NormalizedInput, error) {
	// Resolve source to path
	resolvedPath, err := resolveSource(&req.Source)
	if err != nil {
		return nil, fmt.Errorf("failed to resolve source: %w", err)
	}

	// Compute input hash
	hashData, _ := json.Marshal(struct {
		Path    string
		Mode    Mode
		Profile string
	}{
		Path:    resolvedPath,
		Mode:    req.Mode,
		Profile: req.UsageProfile,
	})
	hash := sha256.Sum256(hashData)

	return &NormalizedInput{
		ResolvedPath: resolvedPath,
		InputHash:    hex.EncodeToString(hash[:]),
		Mode:         req.Mode,
		UsageProfile: req.UsageProfile,
		Options:      req.Options,
		ResolvedAt:   time.Now().UTC(),
	}, nil
}

func resolveSource(src *SourceConfig) (string, error) {
	switch src.Type {
	case "local":
		return src.Path, nil
	case "git":
		// Would clone/checkout here
		return fmt.Sprintf("git:%s@%s:%s", src.Repo, src.Ref, src.Path), nil
	case "upload":
		return fmt.Sprintf("upload:%s", src.UploadID), nil
	default:
		return "", fmt.Errorf("unknown source type: %s", src.Type)
	}
}

// EngineResult is a placeholder for engine output
// In real implementation, this would import from core/engine
type EngineResult struct {
	TotalMonthlyCost string
	TotalHourlyCost  string
	Currency         string
	Confidence       float64
	ConfidenceReason string
	Resources        []EngineResourceCost
	SymbolicCosts    []EngineSymbolicCost
	Warnings         []string
}

// EngineResourceCost is a placeholder for engine resource cost
type EngineResourceCost struct {
	Address        string
	ResourceType   string
	ProviderAlias  string
	MonthlyCost    string
	HourlyCost     string
	Confidence     float64
	IsSymbolic     bool
	DependencyPath []string
}

// EngineSymbolicCost is a placeholder for engine symbolic cost
type EngineSymbolicCost struct {
	Address     string
	Reason      string
	Expression  string
	IsUnbounded bool
}

// MapEstimateResponse maps engine result to API response
func (m *Mapper) MapEstimateResponse(
	input *NormalizedInput,
	result *EngineResult,
	durationMs int64,
) *EstimateResponse {
	resp := &EstimateResponse{
		Metadata: ResponseMetadata{
			InputHash:       input.InputHash,
			EngineVersion:   m.engineVersion,
			PricingSnapshot: m.pricingSnapshot,
			Mode:            string(input.Mode),
			Timestamp:       time.Now().UTC(),
			DurationMs:      durationMs,
		},
		Summary: CostSummary{
			TotalMonthlyCost: result.TotalMonthlyCost,
			TotalHourlyCost:  result.TotalHourlyCost,
			Currency:         result.Currency,
			Confidence:       result.Confidence,
			ConfidenceLevel:  getConfidenceLevel(result.Confidence),
			ConfidenceReason: result.ConfidenceReason,
			ResourceCount:    len(result.Resources),
			SymbolicCount:    len(result.SymbolicCosts),
		},
	}

	// Map cost graph if requested
	if input.Options.IncludeDependencyGraph {
		resp.CostGraph = m.mapCostGraph(result.Resources)
	}

	// Map symbolic costs
	for _, sc := range result.SymbolicCosts {
		resp.SymbolicCosts = append(resp.SymbolicCosts, SymbolicCost{
			Address:     sc.Address,
			Reason:      sc.Reason,
			Expression:  sc.Expression,
			IsUnbounded: sc.IsUnbounded,
		})
	}

	// Map warnings
	for _, w := range result.Warnings {
		resp.Warnings = append(resp.Warnings, Warning{
			Code:    "WARN",
			Message: w,
		})
	}

	return resp
}

func (m *Mapper) mapCostGraph(resources []EngineResourceCost) *CostGraph {
	// Group by module
	moduleMap := make(map[string][]EngineResourceCost)
	for _, r := range resources {
		module := extractModule(r.Address)
		moduleMap[module] = append(moduleMap[module], r)
	}

	graph := &CostGraph{Modules: []ModuleCost{}}
	for modAddr, modResources := range moduleMap {
		modCost := ModuleCost{
			Address:   modAddr,
			Resources: []ResourceCost{},
		}

		totalCost := 0.0
		minConf := 1.0
		for _, r := range modResources {
			var cost float64
			fmt.Sscanf(r.MonthlyCost, "%f", &cost)
			totalCost += cost
			if r.Confidence < minConf {
				minConf = r.Confidence
			}

			rc := ResourceCost{
				Address:       r.Address,
				ResourceType:  r.ResourceType,
				ProviderAlias: r.ProviderAlias,
				MonthlyCost:   r.MonthlyCost,
				HourlyCost:    r.HourlyCost,
				Confidence:    r.Confidence,
				IsSymbolic:    r.IsSymbolic,
			}

			if len(r.DependencyPath) > 0 {
				rc.Lineage = &CostLineage{
					DependencyPath: r.DependencyPath,
					Explanation:    fmt.Sprintf("This cost exists because of: %v", r.DependencyPath),
				}
			}

			modCost.Resources = append(modCost.Resources, rc)
		}

		modCost.MonthlyCost = fmt.Sprintf("%.2f", totalCost)
		modCost.Confidence = minConf
		graph.Modules = append(graph.Modules, modCost)
	}

	return graph
}

func extractModule(address string) string {
	// Simple extraction - would be more sophisticated in real impl
	parts := splitAddress(address)
	if len(parts) > 2 {
		return parts[0] + "." + parts[1]
	}
	return "root"
}

func splitAddress(addr string) []string {
	var parts []string
	current := ""
	for _, c := range addr {
		if c == '.' {
			if current != "" {
				parts = append(parts, current)
				current = ""
			}
		} else {
			current += string(c)
		}
	}
	if current != "" {
		parts = append(parts, current)
	}
	return parts
}

func getConfidenceLevel(confidence float64) string {
	switch {
	case confidence >= 0.9:
		return "high"
	case confidence >= 0.7:
		return "medium"
	case confidence >= 0.5:
		return "low"
	default:
		return "unknown"
	}
}

################################################################################
# FILE: :\good projects\cost estimation\api\v1\types.go
# TYPE: go
# SIZE: 6661 bytes
################################################################################
// Package v1 - Versioned API types
// These DTOs are the STABLE contract - no engine imports allowed
// Changes to these types are breaking changes
package v1

import "time"

// EstimateRequest is the stable request contract for POST /api/v1/estimate
type EstimateRequest struct {
	// Source configuration
	Source SourceConfig `json:"source"`

	// Estimation mode
	Mode Mode `json:"mode"`

	// Usage profile (optional)
	UsageProfile string `json:"usage_profile,omitempty"`

	// Options
	Options EstimateOptions `json:"options,omitempty"`
}

// SourceConfig defines the Terraform source
type SourceConfig struct {
	// Type: "git", "upload", "local"
	Type string `json:"type"`

	// For git sources
	Repo string `json:"repo,omitempty"`
	Ref  string `json:"ref,omitempty"`

	// Path within source
	Path string `json:"path,omitempty"`

	// For upload sources
	UploadID string `json:"upload_id,omitempty"`
}

// Mode is the estimation mode
type Mode string

const (
	ModeStrict     Mode = "strict"
	ModePermissive Mode = "permissive"
)

// EstimateOptions are optional request parameters
type EstimateOptions struct {
	IncludeDependencyGraph bool `json:"include_dependency_graph,omitempty"`
	IncludeCostLineage     bool `json:"include_cost_lineage,omitempty"`
	IncludeAssumptions     bool `json:"include_assumptions,omitempty"`
}

// EstimateResponse is the stable response contract for POST /api/v1/estimate
type EstimateResponse struct {
	// Metadata for reproducibility
	Metadata ResponseMetadata `json:"metadata"`

	// Summary
	Summary CostSummary `json:"summary"`

	// Cost graph (if requested)
	CostGraph *CostGraph `json:"cost_graph,omitempty"`

	// Symbolic costs (unknown cardinality)
	SymbolicCosts []SymbolicCost `json:"symbolic_costs,omitempty"`

	// Warnings
	Warnings []Warning `json:"warnings,omitempty"`

	// Policy results
	PolicyResults []PolicyResult `json:"policy_results,omitempty"`
}

// ResponseMetadata provides audit/reproducibility information
type ResponseMetadata struct {
	// InputHash is SHA256 of normalized input
	InputHash string `json:"input_hash"`

	// EngineVersion is the engine version
	EngineVersion string `json:"engine_version"`

	// PricingSnapshot identifies the pricing data used
	PricingSnapshot string `json:"pricing_snapshot"`

	// Mode used for estimation
	Mode string `json:"mode"`

	// Timestamp of estimation
	Timestamp time.Time `json:"timestamp"`

	// DurationMs is the processing time
	DurationMs int64 `json:"duration_ms"`
}

// CostSummary is the top-level cost summary
type CostSummary struct {
	// TotalMonthlyCost in decimal string format
	TotalMonthlyCost string `json:"total_monthly_cost"`

	// TotalHourlyCost in decimal string format
	TotalHourlyCost string `json:"total_hourly_cost,omitempty"`

	// Currency code
	Currency string `json:"currency"`

	// Confidence score (0.0 to 1.0)
	Confidence float64 `json:"confidence"`

	// ConfidenceLevel is human-readable
	ConfidenceLevel string `json:"confidence_level"`

	// ConfidenceReason explains the confidence
	ConfidenceReason string `json:"confidence_reason,omitempty"`

	// ResourceCount is the number of resources
	ResourceCount int `json:"resource_count"`

	// SymbolicCount is resources with unknown cost
	SymbolicCount int `json:"symbolic_count"`
}

// CostGraph is the hierarchical cost structure
type CostGraph struct {
	// Modules in the graph
	Modules []ModuleCost `json:"modules"`
}

// ModuleCost is the cost of a module
type ModuleCost struct {
	// Address is the module address
	Address string `json:"address"`

	// MonthlyCost in decimal string
	MonthlyCost string `json:"monthly_cost"`

	// Confidence for this module
	Confidence float64 `json:"confidence"`

	// Resources in this module
	Resources []ResourceCost `json:"resources"`
}

// ResourceCost is the cost of a single resource
type ResourceCost struct {
	// Address is the resource address
	Address string `json:"address"`

	// ResourceType is the Terraform type
	ResourceType string `json:"resource_type"`

	// ProviderAlias is the provider identity
	ProviderAlias string `json:"provider_alias"`

	// MonthlyCost in decimal string
	MonthlyCost string `json:"monthly_cost"`

	// HourlyCost in decimal string
	HourlyCost string `json:"hourly_cost,omitempty"`

	// Confidence for this resource
	Confidence float64 `json:"confidence"`

	// IsSymbolic indicates unknown cardinality
	IsSymbolic bool `json:"is_symbolic,omitempty"`

	// Components are cost sub-components
	Components []CostComponent `json:"components,omitempty"`

	// Lineage shows dependency path
	Lineage *CostLineage `json:"lineage,omitempty"`
}

// CostComponent is a sub-component of resource cost
type CostComponent struct {
	// Name of the component
	Name string `json:"name"`

	// MonthlyCost in decimal string
	MonthlyCost string `json:"monthly_cost"`

	// Unit of measurement
	Unit string `json:"unit,omitempty"`

	// Quantity used
	Quantity string `json:"quantity,omitempty"`

	// UnitPrice
	UnitPrice string `json:"unit_price,omitempty"`
}

// CostLineage explains why a cost exists
type CostLineage struct {
	// DependencyPath from root to this resource
	DependencyPath []string `json:"dependency_path"`

	// Explanation is human-readable
	Explanation string `json:"explanation"`
}

// SymbolicCost represents a cost that cannot be computed
type SymbolicCost struct {
	// Address of the resource
	Address string `json:"address"`

	// Reason why cost is unknown
	Reason string `json:"reason"`

	// Expression that caused unknowability
	Expression string `json:"expression,omitempty"`

	// LowerBound if estimable
	LowerBound string `json:"lower_bound,omitempty"`

	// UpperBound if estimable
	UpperBound string `json:"upper_bound,omitempty"`

	// IsUnbounded if no upper limit
	IsUnbounded bool `json:"is_unbounded,omitempty"`
}

// Warning is a non-fatal warning
type Warning struct {
	// Code is machine-readable
	Code string `json:"code"`

	// Message is human-readable
	Message string `json:"message"`

	// ResourceAddress if applicable
	ResourceAddress string `json:"resource_address,omitempty"`
}

// PolicyResult is the result of policy evaluation
type PolicyResult struct {
	// PolicyName
	PolicyName string `json:"policy_name"`

	// Passed indicates if policy passed
	Passed bool `json:"passed"`

	// Severity: "info", "warning", "error", "block"
	Severity string `json:"severity"`

	// Message explains the result
	Message string `json:"message"`
}

################################################################################
# FILE: :\good projects\cost estimation\api\v1\mapping\diff.go
# TYPE: go
# SIZE: 4415 bytes
################################################################################
// Package mapping - Diff mapping
package mapping

import (
	"fmt"
	"time"

	"terraform-cost/api/v1/types"
)

// EngineDiffResult is an interface for engine diff results
type EngineDiffResult interface {
	GetBaseTotal() string
	GetHeadTotal() string
	GetBaseConfidence() float64
	GetHeadConfidence() float64
	GetBaseResourceCount() int
	GetHeadResourceCount() int
	GetBaseSymbolicCount() int
	GetHeadSymbolicCount() int
	GetChanges() []EngineChange
	GetExplanations() []EngineExplanation
}

// EngineChange is an interface for a single change
type EngineChange interface {
	GetType() string
	GetAddress() string
	GetResourceType() string
	GetCostBefore() string
	GetCostAfter() string
	GetDependencyPath() []string
}

// EngineExplanation is an interface for an explanation
type EngineExplanation interface {
	GetAddress() string
	GetExplanation() string
	GetCausalChain() []string
}

// MapDiffResponse maps engine diff result to API response
func MapDiffResponse(
	result EngineDiffResult,
	baseRef, headRef string,
	inputHash string,
	mode string,
	startTime time.Time,
	config MapperConfig,
) types.DiffResponse {
	durationMs := time.Since(startTime).Milliseconds()

	resp := types.DiffResponse{
		Metadata: types.MetadataDTO{
			InputHash:       inputHash,
			EngineVersion:   config.EngineVersion,
			PricingSnapshot: config.PricingSnapshot,
			Mode:            mode,
			Timestamp:       time.Now().UTC(),
			DurationMs:      durationMs,
			APIVersion:      config.APIVersion,
		},
		Base: types.DiffSideDTO{
			Ref:              baseRef,
			TotalMonthlyCost: result.GetBaseTotal(),
			Confidence:       result.GetBaseConfidence(),
			ResourceCount:    result.GetBaseResourceCount(),
			SymbolicCount:    result.GetBaseSymbolicCount(),
		},
		Head: types.DiffSideDTO{
			Ref:              headRef,
			TotalMonthlyCost: result.GetHeadTotal(),
			Confidence:       result.GetHeadConfidence(),
			ResourceCount:    result.GetHeadResourceCount(),
			SymbolicCount:    result.GetHeadSymbolicCount(),
		},
		Delta:        computeDelta(result),
		Changes:      mapChanges(result.GetChanges()),
		Explanations: mapExplanations(result.GetExplanations()),
	}

	return resp
}

func computeDelta(result EngineDiffResult) types.DeltaDTO {
	var baseVal, headVal float64
	fmt.Sscanf(result.GetBaseTotal(), "%f", &baseVal)
	fmt.Sscanf(result.GetHeadTotal(), "%f", &headVal)

	delta := headVal - baseVal
	var deltaStr string
	if delta >= 0 {
		deltaStr = fmt.Sprintf("+%.2f", delta)
	} else {
		deltaStr = fmt.Sprintf("%.2f", delta)
	}

	var percentStr string
	if baseVal > 0 {
		percent := (delta / baseVal) * 100
		if percent >= 0 {
			percentStr = fmt.Sprintf("+%.1f%%", percent)
		} else {
			percentStr = fmt.Sprintf("%.1f%%", percent)
		}
	}

	changes := result.GetChanges()
	var added, removed, changed int
	for _, c := range changes {
		switch c.GetType() {
		case "added":
			added++
		case "removed":
			removed++
		case "changed":
			changed++
		}
	}

	return types.DeltaDTO{
		MonthlyCostDelta: deltaStr,
		PercentChange:    percentStr,
		ConfidenceDelta:  result.GetHeadConfidence() - result.GetBaseConfidence(),
		AddedCount:       added,
		RemovedCount:     removed,
		ChangedCount:     changed,
	}
}

func mapChanges(changes []EngineChange) []types.ChangeDTO {
	result := make([]types.ChangeDTO, len(changes))
	for i, c := range changes {
		var delta string
		var before, after float64
		fmt.Sscanf(c.GetCostBefore(), "%f", &before)
		fmt.Sscanf(c.GetCostAfter(), "%f", &after)
		d := after - before
		if d >= 0 {
			delta = fmt.Sprintf("+%.2f", d)
		} else {
			delta = fmt.Sprintf("%.2f", d)
		}

		result[i] = types.ChangeDTO{
			Type:           c.GetType(),
			Address:        c.GetAddress(),
			ResourceType:   c.GetResourceType(),
			CostBefore:     c.GetCostBefore(),
			CostAfter:      c.GetCostAfter(),
			CostDelta:      delta,
			DependencyPath: c.GetDependencyPath(),
		}
	}
	return result
}

func mapExplanations(explanations []EngineExplanation) []types.ExplanationDTO {
	result := make([]types.ExplanationDTO, len(explanations))
	for i, e := range explanations {
		result[i] = types.ExplanationDTO{
			Address:     e.GetAddress(),
			Explanation: e.GetExplanation(),
			CausalChain: e.GetCausalChain(),
		}
	}
	return result
}

################################################################################
# FILE: :\good projects\cost estimation\api\v1\mapping\estimate.go
# TYPE: go
# SIZE: 3988 bytes
################################################################################
// Package mapping - Explicit mapping from engine to API DTOs
// This is the ONLY place where engine types touch API types.
// Rules:
// - One-way mapping only (engine â†’ API)
// - No mutation of engine results
// - No inference or aggregation
// - No business logic
package mapping

import (
	"fmt"
	"time"

	"terraform-cost/api/v1/types"
)

// EngineEstimateResult is an interface for engine results
// We use an interface to avoid importing engine package directly
type EngineEstimateResult interface {
	GetTotalMonthlyCost() string
	GetTotalHourlyCost() string
	GetCurrency() string
	GetConfidence() float64
	GetConfidenceReason() string
	GetResources() []EngineResource
	GetSymbolicCosts() []EngineSymbolicCost
	GetWarnings() []string
}

// EngineResource is an interface for engine resource
type EngineResource interface {
	GetAddress() string
	GetType() string
	GetProviderAlias() string
	GetMonthlyCost() string
	GetHourlyCost() string
	GetConfidence() float64
	IsSymbolic() bool
	GetDependencyPath() []string
}

// EngineSymbolicCost is an interface for symbolic costs
type EngineSymbolicCost interface {
	GetAddress() string
	GetReason() string
	GetExpression() string
	IsUnbounded() bool
}

// MapperConfig configures the mapping
type MapperConfig struct {
	EngineVersion   string
	PricingSnapshot string
	APIVersion      string
}

// MapEstimateResponse maps engine result to API response
// This is a PURE function - no side effects, no state
func MapEstimateResponse(
	result EngineEstimateResult,
	inputHash string,
	mode string,
	startTime time.Time,
	config MapperConfig,
) types.EstimateResponse {
	durationMs := time.Since(startTime).Milliseconds()

	resp := types.EstimateResponse{
		Metadata: types.MetadataDTO{
			InputHash:       inputHash,
			EngineVersion:   config.EngineVersion,
			PricingSnapshot: config.PricingSnapshot,
			Mode:            mode,
			Timestamp:       time.Now().UTC(),
			DurationMs:      durationMs,
			APIVersion:      config.APIVersion,
		},
		Summary: types.SummaryDTO{
			TotalMonthlyCost: result.GetTotalMonthlyCost(),
			TotalHourlyCost:  result.GetTotalHourlyCost(),
			Currency:         result.GetCurrency(),
			Confidence:       result.GetConfidence(),
			ConfidenceLevel:  mapConfidenceLevel(result.GetConfidence()),
			ConfidenceReason: result.GetConfidenceReason(),
			ResourceCount:    len(result.GetResources()),
			SymbolicCount:    len(result.GetSymbolicCosts()),
		},
		Costs:    mapCosts(result.GetResources()),
		Symbolic: mapSymbolicCosts(result.GetSymbolicCosts()),
		Warnings: result.GetWarnings(),
	}

	return resp
}

func mapCosts(resources []EngineResource) []types.CostNodeDTO {
	costs := make([]types.CostNodeDTO, len(resources))
	for i, r := range resources {
		costs[i] = types.CostNodeDTO{
			Address:       r.GetAddress(),
			Type:          r.GetType(),
			ProviderAlias: r.GetProviderAlias(),
			MonthlyCost:   r.GetMonthlyCost(),
			HourlyCost:    r.GetHourlyCost(),
			Confidence:    r.GetConfidence(),
			IsSymbolic:    r.IsSymbolic(),
		}

		if len(r.GetDependencyPath()) > 0 {
			costs[i].Lineage = &types.LineageDTO{
				DependencyPath: r.GetDependencyPath(),
				Explanation:    fmt.Sprintf("Cost derived from dependency: %v", r.GetDependencyPath()),
			}
		}
	}
	return costs
}

func mapSymbolicCosts(symbolics []EngineSymbolicCost) []types.SymbolicCostDTO {
	costs := make([]types.SymbolicCostDTO, len(symbolics))
	for i, s := range symbolics {
		costs[i] = types.SymbolicCostDTO{
			Address:     s.GetAddress(),
			Reason:      s.GetReason(),
			Expression:  s.GetExpression(),
			IsUnbounded: s.IsUnbounded(),
		}
	}
	return costs
}

func mapConfidenceLevel(confidence float64) string {
	switch {
	case confidence >= 0.9:
		return "high"
	case confidence >= 0.7:
		return "medium"
	case confidence >= 0.5:
		return "low"
	default:
		return "unknown"
	}
}

################################################################################
# FILE: :\good projects\cost estimation\api\v1\types\diff.go
# TYPE: go
# SIZE: 3783 bytes
################################################################################
// Package types - Diff DTOs for POST /api/v1/diff
package types

// DiffRequest is the public request for POST /api/v1/diff
type DiffRequest struct {
	// Base ref for comparison
	Base RefSpecDTO `json:"base"`

	// Head ref for comparison
	Head RefSpecDTO `json:"head"`

	// Mode for estimation
	Mode string `json:"mode"`

	// Options
	Options DiffOptionsDTO `json:"options,omitempty"`
}

// RefSpecDTO identifies a git ref or source
type RefSpecDTO struct {
	// Ref is the git ref (branch, tag, commit)
	Ref string `json:"ref"`

	// Path within the ref (optional)
	Path string `json:"path,omitempty"`
}

// DiffOptionsDTO are optional diff parameters
type DiffOptionsDTO struct {
	// IncludeUnchanged includes unchanged resources
	IncludeUnchanged bool `json:"include_unchanged,omitempty"`

	// IncludeExplanations includes dependency explanations
	IncludeExplanations bool `json:"include_explanations,omitempty"`
}

// DiffResponse is the public response for POST /api/v1/diff
type DiffResponse struct {
	// Metadata for reproducibility
	Metadata MetadataDTO `json:"metadata"`

	// Base summary
	Base DiffSideDTO `json:"base"`

	// Head summary
	Head DiffSideDTO `json:"head"`

	// Delta between base and head
	Delta DeltaDTO `json:"delta"`

	// Changes are individual resource changes
	Changes []ChangeDTO `json:"changes"`

	// Explanations explain why costs changed
	Explanations []ExplanationDTO `json:"explanations,omitempty"`

	// Policies are policy evaluation results
	Policies []PolicyResultDTO `json:"policy_results,omitempty"`
}

// DiffSideDTO summarizes one side of the diff
type DiffSideDTO struct {
	// Ref that was estimated
	Ref string `json:"ref"`

	// TotalMonthlyCost as decimal string
	TotalMonthlyCost string `json:"total_monthly_cost"`

	// Confidence
	Confidence float64 `json:"confidence"`

	// ResourceCount
	ResourceCount int `json:"resource_count"`

	// SymbolicCount
	SymbolicCount int `json:"symbolic_count"`
}

// DeltaDTO represents the change between base and head
type DeltaDTO struct {
	// MonthlyCostDelta as signed decimal string (e.g., "+123.45", "-67.89")
	MonthlyCostDelta string `json:"monthly_cost_delta"`

	// PercentChange if calculable (e.g., "+15.2%")
	PercentChange string `json:"percent_change,omitempty"`

	// ConfidenceDelta
	ConfidenceDelta float64 `json:"confidence_delta"`

	// AddedCount
	AddedCount int `json:"added_count"`

	// RemovedCount
	RemovedCount int `json:"removed_count"`

	// ChangedCount
	ChangedCount int `json:"changed_count"`
}

// ChangeDTO represents a single resource change
type ChangeDTO struct {
	// Type: "added", "removed", "changed"
	Type string `json:"type"`

	// Address of the resource
	Address string `json:"address"`

	// ResourceType
	ResourceType string `json:"resource_type"`

	// CostBefore (empty for added)
	CostBefore string `json:"cost_before,omitempty"`

	// CostAfter (empty for removed)
	CostAfter string `json:"cost_after,omitempty"`

	// CostDelta as signed string
	CostDelta string `json:"cost_delta"`

	// ConfidenceBefore
	ConfidenceBefore float64 `json:"confidence_before,omitempty"`

	// ConfidenceAfter
	ConfidenceAfter float64 `json:"confidence_after,omitempty"`

	// IsSymbolic
	IsSymbolic bool `json:"is_symbolic,omitempty"`

	// DependencyPath shows lineage
	DependencyPath []string `json:"dependency_path,omitempty"`
}

// ExplanationDTO explains why cost changed
type ExplanationDTO struct {
	// Address of the resource
	Address string `json:"address"`

	// Explanation is human-readable
	Explanation string `json:"explanation"`

	// CausalChain shows dependency causation
	CausalChain []string `json:"causal_chain,omitempty"`
}

################################################################################
# FILE: :\good projects\cost estimation\api\v1\types\estimate.go
# TYPE: go
# SIZE: 5150 bytes
################################################################################
// Package types - Public API DTOs
// This package contains ONLY data transfer objects for the public API.
// NO ENGINE IMPORTS ALLOWED - this is the stable API contract.
package types

import "time"

// EstimateResponse is the public response for POST /api/v1/estimate
// This struct is the API contract - changes are breaking changes.
type EstimateResponse struct {
	Metadata MetadataDTO       `json:"metadata"`
	Summary  SummaryDTO        `json:"summary"`
	Costs    []CostNodeDTO     `json:"costs"`
	Symbolic []SymbolicCostDTO `json:"symbolic_costs,omitempty"`
	Warnings []string          `json:"warnings,omitempty"`
	Policies []PolicyResultDTO `json:"policy_results,omitempty"`
}

// MetadataDTO provides audit and reproducibility information
type MetadataDTO struct {
	// InputHash is SHA256 of normalized input - enables reproducibility
	InputHash string `json:"input_hash"`

	// EngineVersion identifies the engine that produced this result
	EngineVersion string `json:"engine_version"`

	// PricingSnapshot identifies the pricing data used
	PricingSnapshot string `json:"pricing_snapshot"`

	// Mode is "strict" or "permissive"
	Mode string `json:"mode"`

	// Timestamp is when the estimation was performed
	Timestamp time.Time `json:"timestamp"`

	// DurationMs is processing time in milliseconds
	DurationMs int64 `json:"duration_ms"`

	// APIVersion is the API version (e.g., "v1")
	APIVersion string `json:"api_version"`
}

// SummaryDTO is the top-level cost summary
type SummaryDTO struct {
	// TotalMonthlyCost as decimal string (e.g., "1234.56")
	TotalMonthlyCost string `json:"total_monthly_cost"`

	// TotalHourlyCost as decimal string
	TotalHourlyCost string `json:"total_hourly_cost,omitempty"`

	// Currency is the currency code (e.g., "USD")
	Currency string `json:"currency"`

	// Confidence is 0.0 to 1.0
	Confidence float64 `json:"confidence"`

	// ConfidenceLevel is human-readable: "high", "medium", "low", "unknown"
	ConfidenceLevel string `json:"confidence_level"`

	// ConfidenceReason explains why confidence is not 100%
	ConfidenceReason string `json:"confidence_reason,omitempty"`

	// ResourceCount is total resources estimated
	ResourceCount int `json:"resource_count"`

	// SymbolicCount is resources with unknown cardinality
	SymbolicCount int `json:"symbolic_count"`
}

// CostNodeDTO represents a cost node in the graph
type CostNodeDTO struct {
	// Address is the Terraform resource address
	Address string `json:"address"`

	// Type is the resource type (e.g., "aws_instance")
	Type string `json:"type"`

	// ProviderAlias is the provider identity (e.g., "aws.prod")
	ProviderAlias string `json:"provider_alias"`

	// MonthlyCost as decimal string
	MonthlyCost string `json:"monthly_cost"`

	// HourlyCost as decimal string
	HourlyCost string `json:"hourly_cost,omitempty"`

	// Confidence for this specific resource
	Confidence float64 `json:"confidence"`

	// IsSymbolic indicates this resource has unknown cardinality
	IsSymbolic bool `json:"is_symbolic,omitempty"`

	// Components are cost sub-components
	Components []CostComponentDTO `json:"components,omitempty"`

	// Lineage explains dependency chain
	Lineage *LineageDTO `json:"lineage,omitempty"`

	// Children are nested resources (for modules)
	Children []CostNodeDTO `json:"children,omitempty"`
}

// CostComponentDTO is a sub-component of resource cost
type CostComponentDTO struct {
	// Name of the component (e.g., "compute", "storage")
	Name string `json:"name"`

	// MonthlyCost as decimal string
	MonthlyCost string `json:"monthly_cost"`

	// Unit of measurement (e.g., "hours", "GB-month")
	Unit string `json:"unit,omitempty"`

	// Quantity used
	Quantity string `json:"quantity,omitempty"`

	// UnitPrice per unit
	UnitPrice string `json:"unit_price,omitempty"`
}

// LineageDTO explains why a cost exists
type LineageDTO struct {
	// DependencyPath from root to this node
	DependencyPath []string `json:"dependency_path"`

	// Explanation is human-readable
	Explanation string `json:"explanation"`
}

// SymbolicCostDTO represents a cost that cannot be computed numerically
type SymbolicCostDTO struct {
	// Address of the resource
	Address string `json:"address"`

	// Reason why cost cannot be computed
	Reason string `json:"reason"`

	// Expression that caused unknowability
	Expression string `json:"expression,omitempty"`

	// LowerBound if estimable
	LowerBound string `json:"lower_bound,omitempty"`

	// UpperBound if estimable (omit for unbounded)
	UpperBound string `json:"upper_bound,omitempty"`

	// IsUnbounded if no upper limit can be estimated
	IsUnbounded bool `json:"is_unbounded,omitempty"`
}

// PolicyResultDTO is the result of a policy evaluation
type PolicyResultDTO struct {
	// Name of the policy
	Name string `json:"name"`

	// Passed indicates if the policy passed
	Passed bool `json:"passed"`

	// Severity: "info", "warning", "error", "block"
	Severity string `json:"severity"`

	// Message explains the result
	Message string `json:"message"`
}

################################################################################
# FILE: :\good projects\cost estimation\api\v1\types\request.go
# TYPE: go
# SIZE: 1430 bytes
################################################################################
// Package types - Request DTOs
package types

// EstimateRequest is the public request for POST /api/v1/estimate
type EstimateRequest struct {
	// Source configuration
	Source SourceDTO `json:"source"`

	// Mode for estimation: "strict" or "permissive"
	Mode string `json:"mode"`

	// UsageProfile: "prod", "staging", "dev" (optional)
	UsageProfile string `json:"usage_profile,omitempty"`

	// Options
	Options EstimateOptionsDTO `json:"options,omitempty"`
}

// SourceDTO defines the Terraform source
type SourceDTO struct {
	// Type: "git", "upload", "local"
	Type string `json:"type"`

	// Repo is the git repository URL (for git sources)
	Repo string `json:"repo,omitempty"`

	// Ref is the git ref: branch, tag, or commit (for git sources)
	Ref string `json:"ref,omitempty"`

	// Path within source
	Path string `json:"path,omitempty"`

	// UploadID for upload sources
	UploadID string `json:"upload_id,omitempty"`
}

// EstimateOptionsDTO are optional request parameters
type EstimateOptionsDTO struct {
	// IncludeDependencyGraph includes the full graph in response
	IncludeDependencyGraph bool `json:"include_dependency_graph,omitempty"`

	// IncludeCostLineage includes lineage for each cost
	IncludeCostLineage bool `json:"include_cost_lineage,omitempty"`

	// IncludeComponents includes cost sub-components
	IncludeComponents bool `json:"include_components,omitempty"`
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\registry.go
# TYPE: go
# SIZE: 4155 bytes
################################################################################
// Package clouds provides the cloud plugin system.
// Cloud providers are modular plugins that can be added without modifying core.
package clouds

import (
	"fmt"
	"sync"

	"terraform-cost/core/asset"
	"terraform-cost/core/pricing"
	"terraform-cost/core/types"
	"terraform-cost/core/usage"
)

// Plugin defines the interface for a cloud provider plugin
type Plugin interface {
	// Provider returns the cloud provider identifier
	Provider() types.Provider

	// Name returns a human-readable name
	Name() string

	// Description returns a description of the plugin
	Description() string

	// Initialize sets up the plugin
	Initialize() error

	// AssetBuilders returns asset builders for this provider
	AssetBuilders() []asset.Builder

	// UsageEstimators returns usage estimators for this provider
	UsageEstimators() []usage.Estimator

	// PricingSource returns the pricing source for this provider
	PricingSource() pricing.Source

	// SupportedResourceTypes returns all supported resource types
	SupportedResourceTypes() []string

	// SupportedRegions returns all supported regions
	SupportedRegions() []string
}

// Registry manages cloud plugin registration
type Registry struct {
	mu      sync.RWMutex
	plugins map[types.Provider]Plugin
}

// NewRegistry creates a new plugin registry
func NewRegistry() *Registry {
	return &Registry{
		plugins: make(map[types.Provider]Plugin),
	}
}

// Register adds a plugin to the registry
func (r *Registry) Register(plugin Plugin) error {
	r.mu.Lock()
	defer r.mu.Unlock()

	if _, exists := r.plugins[plugin.Provider()]; exists {
		return fmt.Errorf("plugin already registered: %s", plugin.Provider())
	}

	// Initialize the plugin
	if err := plugin.Initialize(); err != nil {
		return fmt.Errorf("failed to initialize plugin %s: %w", plugin.Provider(), err)
	}

	r.plugins[plugin.Provider()] = plugin
	return nil
}

// GetPlugin returns a plugin by provider
func (r *Registry) GetPlugin(provider types.Provider) (Plugin, bool) {
	r.mu.RLock()
	defer r.mu.RUnlock()

	plugin, ok := r.plugins[provider]
	return plugin, ok
}

// GetAll returns all registered plugins
func (r *Registry) GetAll() []Plugin {
	r.mu.RLock()
	defer r.mu.RUnlock()

	plugins := make([]Plugin, 0, len(r.plugins))
	for _, plugin := range r.plugins {
		plugins = append(plugins, plugin)
	}
	return plugins
}

// Providers returns all registered provider IDs
func (r *Registry) Providers() []types.Provider {
	r.mu.RLock()
	defer r.mu.RUnlock()

	providers := make([]types.Provider, 0, len(r.plugins))
	for p := range r.plugins {
		providers = append(providers, p)
	}
	return providers
}

// RegisterAll registers all components from a plugin to the core registries
func (r *Registry) RegisterAll(
	assetRegistry asset.BuilderRegistry,
	usageRegistry usage.EstimatorRegistry,
	pricingRegistry pricing.SourceRegistry,
) error {
	r.mu.RLock()
	defer r.mu.RUnlock()

	for _, plugin := range r.plugins {
		// Register asset builders
		for _, builder := range plugin.AssetBuilders() {
			if err := assetRegistry.Register(builder); err != nil {
				return fmt.Errorf("failed to register asset builder from %s: %w", plugin.Provider(), err)
			}
		}

		// Register usage estimators
		for _, estimator := range plugin.UsageEstimators() {
			if err := usageRegistry.Register(estimator); err != nil {
				return fmt.Errorf("failed to register usage estimator from %s: %w", plugin.Provider(), err)
			}
		}

		// Register pricing source
		if source := plugin.PricingSource(); source != nil {
			if err := pricingRegistry.Register(source); err != nil {
				return fmt.Errorf("failed to register pricing source from %s: %w", plugin.Provider(), err)
			}
		}
	}

	return nil
}

// Global default registry
var defaultRegistry = NewRegistry()

// RegisterPlugin adds a plugin to the default registry
func RegisterPlugin(plugin Plugin) error {
	return defaultRegistry.Register(plugin)
}

// GetDefaultRegistry returns the default registry
func GetDefaultRegistry() *Registry {
	return defaultRegistry
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\types.go
# TYPE: go
# SIZE: 7131 bytes
################################################################################
// Package clouds - Common mapper interfaces and types
// This package defines the contract that all cloud mappers must implement.
// Mappers emit UsageVectors and CostUnits - they NEVER resolve prices.
package clouds

import (
	"fmt"
)

// CloudProvider identifies a cloud provider
type CloudProvider string

const (
	AWS   CloudProvider = "aws"
	Azure CloudProvider = "azure"
	GCP   CloudProvider = "gcp"
)

// AssetCostMapper is the interface all cloud resource mappers must implement
type AssetCostMapper interface {
	// Cloud returns the cloud provider
	Cloud() CloudProvider

	// ResourceType returns the Terraform resource type (e.g., "aws_instance")
	ResourceType() string

	// BuildUsage extracts usage from an asset
	// Returns symbolic usage if cardinality is unknown
	BuildUsage(asset AssetNode, ctx UsageContext) ([]UsageVector, error)

	// BuildCostUnits creates cost units from asset and usage
	// Returns symbolic cost if usage is symbolic
	BuildCostUnits(asset AssetNode, usage []UsageVector) ([]CostUnit, error)
}

// AssetNode represents a Terraform resource in the asset graph
type AssetNode struct {
	// Address is the Terraform address (e.g., "aws_instance.web")
	Address string

	// Type is the resource type (e.g., "aws_instance")
	Type string

	// Attributes are the resolved Terraform attributes
	Attributes map[string]interface{}

	// ProviderContext contains provider-level information
	ProviderContext ProviderContext

	// Cardinality indicates whether the instance count is known
	Cardinality Cardinality

	// InstanceKey for expanded resources (count/for_each)
	InstanceKey string
}

// Attr returns an attribute value as string
func (a AssetNode) Attr(key string) string {
	if v, ok := a.Attributes[key].(string); ok {
		return v
	}
	return ""
}

// AttrFloat returns an attribute value as float64
func (a AssetNode) AttrFloat(key string, defaultVal float64) float64 {
	if v, ok := a.Attributes[key].(float64); ok {
		return v
	}
	if v, ok := a.Attributes[key].(int); ok {
		return float64(v)
	}
	return defaultVal
}

// AttrInt returns an attribute value as int
func (a AssetNode) AttrInt(key string, defaultVal int) int {
	if v, ok := a.Attributes[key].(int); ok {
		return v
	}
	if v, ok := a.Attributes[key].(float64); ok {
		return int(v)
	}
	return defaultVal
}

// AttrBool returns an attribute value as bool
func (a AssetNode) AttrBool(key string, defaultVal bool) bool {
	if v, ok := a.Attributes[key].(bool); ok {
		return v
	}
	return defaultVal
}

// ProviderContext contains provider-level information
type ProviderContext struct {
	// ProviderID is the finalized provider identity
	ProviderID string

	// Alias is the provider alias (e.g., "aws.prod")
	Alias string

	// Region is the cloud region
	Region string

	// Account/Project/Subscription ID
	AccountID string
}

// Cardinality represents whether instance count is known
type Cardinality struct {
	IsKnown bool
	Count   int
	Reason  string
}

// IsUnknown returns true if cardinality is not deterministic
func (c Cardinality) IsUnknown() bool {
	return !c.IsKnown
}

// UsageContext provides context for usage resolution
type UsageContext struct {
	// Profile is the usage profile (prod, staging, dev)
	Profile string

	// Overrides are explicit usage overrides
	Overrides map[string]interface{}

	// Confidence is the confidence in the usage values
	Confidence float64
}

// ResolveOrDefault returns an override value or default
func (ctx UsageContext) ResolveOrDefault(key string, defaultVal float64) float64 {
	if v, ok := ctx.Overrides[key].(float64); ok {
		return v
	}
	return defaultVal
}

// Metric is a usage metric type
type Metric string

const (
	MetricMonthlyHours    Metric = "monthly_hours"
	MetricMonthlyRequests Metric = "monthly_requests"
	MetricStorageGB       Metric = "storage_gb"
	MetricDataTransferGB  Metric = "data_transfer_gb"
	MetricIOPS            Metric = "iops"
	MetricThroughputMBps  Metric = "throughput_mbps"
)

// UsageVector represents a usage measurement
type UsageVector struct {
	// Metric is the type of usage
	Metric Metric

	// Value is the numeric value (nil if symbolic)
	Value *float64

	// IsSymbolic indicates this usage cannot be numerically resolved
	IsSymbolic bool

	// SymbolicReason explains why usage is symbolic
	SymbolicReason string

	// Confidence in this usage value (0.0 to 1.0)
	Confidence float64
}

// NewUsageVector creates a concrete usage vector
func NewUsageVector(metric Metric, value float64, confidence float64) UsageVector {
	return UsageVector{
		Metric:     metric,
		Value:      &value,
		Confidence: confidence,
	}
}

// SymbolicUsage creates a symbolic usage vector
func SymbolicUsage(metric Metric, reason string) UsageVector {
	return UsageVector{
		Metric:         metric,
		IsSymbolic:     true,
		SymbolicReason: reason,
		Confidence:     0,
	}
}

// UsageVectors is a collection of usage vectors
type UsageVectors []UsageVector

// IsSymbolic returns true if any usage is symbolic
func (vs UsageVectors) IsSymbolic() bool {
	for _, v := range vs {
		if v.IsSymbolic {
			return true
		}
	}
	return false
}

// Get returns the value for a metric
func (vs UsageVectors) Get(metric Metric) (float64, bool) {
	for _, v := range vs {
		if v.Metric == metric && v.Value != nil {
			return *v.Value, true
		}
	}
	return 0, false
}

// CostUnit represents a billable cost component
type CostUnit struct {
	// Name of the cost component (e.g., "compute", "storage")
	Name string

	// Measure is the billing unit (e.g., "hours", "GB-months")
	Measure string

	// Quantity is the usage quantity (nil if symbolic)
	Quantity *float64

	// RateKey identifies the pricing rate
	RateKey RateKey

	// IsSymbolic indicates this cost cannot be numerically resolved
	IsSymbolic bool

	// SymbolicReason explains why cost is symbolic
	SymbolicReason string

	// Confidence in this cost (0.0 to 1.0)
	Confidence float64
}

// NewCostUnit creates a concrete cost unit
func NewCostUnit(name, measure string, quantity float64, rateKey RateKey, confidence float64) CostUnit {
	return CostUnit{
		Name:       name,
		Measure:    measure,
		Quantity:   &quantity,
		RateKey:    rateKey,
		Confidence: confidence,
	}
}

// SymbolicCost creates a symbolic cost unit
func SymbolicCost(name, reason string) CostUnit {
	return CostUnit{
		Name:           name,
		IsSymbolic:     true,
		SymbolicReason: reason,
		Confidence:     0,
	}
}

// RateKey identifies a pricing rate
type RateKey struct {
	// Provider is the finalized provider ID
	Provider string

	// Service is the cloud service (e.g., "EC2", "S3")
	Service string

	// Region is the cloud region
	Region string

	// Attributes are pricing dimensions
	Attributes map[string]string
}

// String returns a unique key string
func (k RateKey) String() string {
	return fmt.Sprintf("%s/%s/%s/%v", k.Provider, k.Service, k.Region, k.Attributes)
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\plugin.go
# TYPE: go
# SIZE: 3925 bytes
################################################################################
// Package aws provides the AWS cloud plugin.
package aws

import (
	"terraform-cost/clouds/aws/assets"
	"terraform-cost/clouds/aws/pricing"
	"terraform-cost/clouds/aws/usage"
	"terraform-cost/core/asset"
	corePricing "terraform-cost/core/pricing"
	coreUsage "terraform-cost/core/usage"
	"terraform-cost/core/types"
)

// Plugin implements the AWS cloud plugin
type Plugin struct {
	initialized bool
	region      string
}

// New creates a new AWS plugin
func New() *Plugin {
	return &Plugin{
		region: "us-east-1",
	}
}

// NewWithRegion creates a new AWS plugin with a specific default region
func NewWithRegion(region string) *Plugin {
	return &Plugin{
		region: region,
	}
}

// Provider returns the cloud provider identifier
func (p *Plugin) Provider() types.Provider {
	return types.ProviderAWS
}

// Name returns a human-readable name
func (p *Plugin) Name() string {
	return "Amazon Web Services"
}

// Description returns a description of the plugin
func (p *Plugin) Description() string {
	return "Cost estimation for AWS infrastructure including EC2, RDS, S3, Lambda, and more"
}

// Initialize sets up the plugin
func (p *Plugin) Initialize() error {
	p.initialized = true
	return nil
}

// AssetBuilders returns asset builders for AWS resources
func (p *Plugin) AssetBuilders() []asset.Builder {
	return []asset.Builder{
		// Compute
		assets.NewEC2InstanceBuilder(),
		assets.NewEC2AutoScalingGroupBuilder(),
		assets.NewLambdaFunctionBuilder(),
		assets.NewECSServiceBuilder(),
		assets.NewEKSClusterBuilder(),

		// Storage
		assets.NewS3BucketBuilder(),
		assets.NewEBSVolumeBuilder(),
		assets.NewEFSFileSystemBuilder(),

		// Database
		assets.NewRDSInstanceBuilder(),
		assets.NewRDSClusterBuilder(),
		assets.NewDynamoDBTableBuilder(),
		assets.NewElastiCacheClusterBuilder(),

		// Network
		assets.NewNATGatewayBuilder(),
		assets.NewVPCEndpointBuilder(),
		assets.NewELBBuilder(),
		assets.NewALBBuilder(),
		assets.NewNLBBuilder(),

		// Other
		assets.NewCloudWatchLogGroupBuilder(),
		assets.NewKMSKeyBuilder(),
		assets.NewSecretsManagerSecretBuilder(),
	}
}

// UsageEstimators returns usage estimators for AWS resources
func (p *Plugin) UsageEstimators() []coreUsage.Estimator {
	return []coreUsage.Estimator{
		usage.NewEC2InstanceEstimator(),
		usage.NewS3BucketEstimator(),
		usage.NewRDSInstanceEstimator(),
		usage.NewLambdaFunctionEstimator(),
		usage.NewDynamoDBTableEstimator(),
		usage.NewNATGatewayEstimator(),
		usage.NewEBSVolumeEstimator(),
	}
}

// PricingSource returns the pricing source for AWS
func (p *Plugin) PricingSource() corePricing.Source {
	return pricing.NewAWSPricingSource(p.region)
}

// SupportedResourceTypes returns all supported AWS resource types
func (p *Plugin) SupportedResourceTypes() []string {
	return []string{
		// Compute
		"aws_instance",
		"aws_autoscaling_group",
		"aws_lambda_function",
		"aws_ecs_service",
		"aws_eks_cluster",
		"aws_eks_node_group",

		// Storage
		"aws_s3_bucket",
		"aws_ebs_volume",
		"aws_efs_file_system",

		// Database
		"aws_db_instance",
		"aws_rds_cluster",
		"aws_dynamodb_table",
		"aws_elasticache_cluster",
		"aws_elasticache_replication_group",

		// Network
		"aws_nat_gateway",
		"aws_vpc_endpoint",
		"aws_lb", // ALB/NLB
		"aws_elb",

		// Other
		"aws_cloudwatch_log_group",
		"aws_kms_key",
		"aws_secretsmanager_secret",
	}
}

// SupportedRegions returns all supported AWS regions
func (p *Plugin) SupportedRegions() []string {
	return []string{
		"us-east-1",
		"us-east-2",
		"us-west-1",
		"us-west-2",
		"eu-west-1",
		"eu-west-2",
		"eu-west-3",
		"eu-central-1",
		"eu-north-1",
		"ap-northeast-1",
		"ap-northeast-2",
		"ap-northeast-3",
		"ap-southeast-1",
		"ap-southeast-2",
		"ap-south-1",
		"sa-east-1",
		"ca-central-1",
	}
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\register.go
# TYPE: go
# SIZE: 482 bytes
################################################################################
// Package aws - AWS cloud provider registration
package aws

// SupportedResourceTypes returns all supported AWS resource types
func SupportedResourceTypes() []string {
	return []string{
		// Compute
		"aws_instance",
		"aws_autoscaling_group",
		"aws_spot_instance_request",

		// Storage
		"aws_s3_bucket",
		"aws_ebs_volume",

		// Database
		"aws_db_instance",
		"aws_rds_cluster",
		"aws_dynamodb_table",

		// Serverless
		"aws_lambda_function",
	}
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\analytics\opensearch.go
# TYPE: go
# SIZE: 4582 bytes
################################################################################
// Package analytics - AWS OpenSearch cost mapper
// Pricing model:
// - Instance hours (by instance type)
// - Storage (EBS or instance-based)
// - UltraWarm storage (per GB-month)
// - Cold storage (per GB-month)
// - Serverless (OCU-hours for compute + indexing)
package analytics

import (
	"terraform-cost/clouds"
)

// OpenSearchMapper maps aws_opensearch_domain to cost units
type OpenSearchMapper struct{}

// NewOpenSearchMapper creates an OpenSearch mapper
func NewOpenSearchMapper() *OpenSearchMapper {
	return &OpenSearchMapper{}
}

// Cloud returns the cloud provider
func (m *OpenSearchMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *OpenSearchMapper) ResourceType() string {
	return "aws_opensearch_domain"
}

// BuildUsage extracts usage vectors
func (m *OpenSearchMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown OpenSearch domain count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
	}, nil
}

// BuildCostUnits creates cost units
func (m *OpenSearchMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("opensearch", "OpenSearch cost unknown due to cardinality"),
		}, nil
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	// Get instance configuration
	instanceType := asset.Attr("cluster_config.0.instance_type")
	if instanceType == "" {
		instanceType = "t3.small.search"
	}
	instanceCount := asset.AttrInt("cluster_config.0.instance_count", 1)

	// Dedicated master nodes
	masterType := asset.Attr("cluster_config.0.dedicated_master_type")
	masterCount := asset.AttrInt("cluster_config.0.dedicated_master_count", 0)
	masterEnabled := asset.AttrBool("cluster_config.0.dedicated_master_enabled", false)

	// EBS storage
	ebsEnabled := asset.AttrBool("ebs_options.0.ebs_enabled", true)
	volumeSize := asset.AttrFloat("ebs_options.0.volume_size", 10)
	volumeType := asset.Attr("ebs_options.0.volume_type")
	if volumeType == "" {
		volumeType = "gp3"
	}

	var units []clouds.CostUnit

	// Data nodes
	units = append(units, clouds.NewCostUnit(
		"data_nodes",
		"instance-hours",
		float64(instanceCount)*monthlyHours,
		clouds.RateKey{
			Provider: providerID,
			Service:  "AmazonES",
			Region:   region,
			Attributes: map[string]string{
				"instanceType": instanceType,
				"usageType":    "ESInstance:" + instanceType,
			},
		},
		0.95,
	))

	// Master nodes (if enabled)
	if masterEnabled && masterCount > 0 && masterType != "" {
		units = append(units, clouds.NewCostUnit(
			"master_nodes",
			"instance-hours",
			float64(masterCount)*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonES",
				Region:   region,
				Attributes: map[string]string{
					"instanceType": masterType,
					"usageType":    "ESInstance:" + masterType,
				},
			},
			0.95,
		))
	}

	// EBS storage
	if ebsEnabled && volumeSize > 0 {
		totalStorage := volumeSize * float64(instanceCount)
		units = append(units, clouds.NewCostUnit(
			"ebs_storage",
			"GB-months",
			totalStorage,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonES",
				Region:   region,
				Attributes: map[string]string{
					"volumeType": volumeType,
					"usageType":  "ES:VolumeUsage." + volumeType,
				},
			},
			0.95,
		))
	}

	// UltraWarm nodes (if configured)
	warmType := asset.Attr("cluster_config.0.warm_type")
	warmCount := asset.AttrInt("cluster_config.0.warm_count", 0)
	if warmCount > 0 && warmType != "" {
		units = append(units, clouds.NewCostUnit(
			"ultrawarm_nodes",
			"instance-hours",
			float64(warmCount)*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonES",
				Region:   region,
				Attributes: map[string]string{
					"instanceType": warmType,
					"usageType":    "ESInstance:" + warmType,
				},
			},
			0.95,
		))
	}

	return units, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\analytics\redshift.go
# TYPE: go
# SIZE: 2944 bytes
################################################################################
// Package analytics - AWS Redshift cost mapper
// Pricing model:
// - Node hours (by node type)
// - Managed storage (RA3 nodes only)
// - Spectrum queries (per TB scanned)
// - Concurrency scaling (per second)
// - Snapshots (beyond free storage)
package analytics

import (
	"terraform-cost/clouds"
)

// RedshiftMapper maps aws_redshift_cluster to cost units
type RedshiftMapper struct{}

// NewRedshiftMapper creates a Redshift mapper
func NewRedshiftMapper() *RedshiftMapper {
	return &RedshiftMapper{}
}

// Cloud returns the cloud provider
func (m *RedshiftMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *RedshiftMapper) ResourceType() string {
	return "aws_redshift_cluster"
}

// BuildUsage extracts usage vectors
func (m *RedshiftMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown Redshift cluster count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
	}, nil
}

// BuildCostUnits creates cost units
func (m *RedshiftMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("redshift", "Redshift cost unknown due to cardinality"),
		}, nil
	}

	nodeType := asset.Attr("node_type")
	if nodeType == "" {
		nodeType = "dc2.large"
	}

	numberOfNodes := asset.AttrInt("number_of_nodes", 1)
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	units := []clouds.CostUnit{
		// Node hours
		clouds.NewCostUnit(
			"nodes",
			"node-hours",
			float64(numberOfNodes)*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRedshift",
				Region:   region,
				Attributes: map[string]string{
					"nodeType":  nodeType,
					"usageType": "Node:" + nodeType,
				},
			},
			0.95,
		),
	}

	// RA3 nodes have separate managed storage cost
	if isRA3Node(nodeType) {
		// RA3 storage is usage-based
		units = append(units, clouds.SymbolicCost(
			"managed_storage",
			"RA3 managed storage depends on data volume",
		))
	}

	// Concurrency scaling (if enabled)
	// This is highly usage-dependent
	units = append(units, clouds.SymbolicCost(
		"concurrency_scaling",
		"concurrency scaling cost depends on query load",
	))

	return units, nil
}

func isRA3Node(nodeType string) bool {
	return len(nodeType) >= 3 && nodeType[:3] == "ra3"
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\apigateway\api_gateway.go
# TYPE: go
# SIZE: 5587 bytes
################################################################################
// Package apigateway - AWS API Gateway cost mapper
// Pricing model:
// - REST API: per million requests + cache (if enabled)
// - HTTP API: per million requests (cheaper)
// - WebSocket API: per million messages + connection minutes
// - Data transfer: standard AWS rates
package apigateway

import (
	"terraform-cost/clouds"
)

// RESTAPIMapper maps aws_api_gateway_rest_api to cost units
type RESTAPIMapper struct{}

// NewRESTAPIMapper creates an API Gateway REST API mapper
func NewRESTAPIMapper() *RESTAPIMapper {
	return &RESTAPIMapper{}
}

// Cloud returns the cloud provider
func (m *RESTAPIMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *RESTAPIMapper) ResourceType() string {
	return "aws_api_gateway_rest_api"
}

// BuildUsage extracts usage vectors
func (m *RESTAPIMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyRequests, "unknown API count: "+asset.Cardinality.Reason),
		}, nil
	}

	// API Gateway is HIGHLY usage-dependent
	monthlyRequests := ctx.ResolveOrDefault("monthly_requests", -1)

	if monthlyRequests < 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyRequests, "monthly API requests not provided"),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyRequests, monthlyRequests, 0.5),
	}, nil
}

// BuildCostUnits creates cost units
func (m *RESTAPIMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("api_requests", "API Gateway cost requires request volume"),
		}, nil
	}

	monthlyRequests, _ := usageVecs.Get(clouds.MetricMonthlyRequests)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"requests",
			"million-requests",
			monthlyRequests/1000000,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonApiGateway",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "ApiGatewayRequest",
					"apiType":   "REST",
				},
			},
			0.5,
		),
	}, nil
}

// HTTPAPIMapper maps aws_apigatewayv2_api (HTTP) to cost units
type HTTPAPIMapper struct{}

// NewHTTPAPIMapper creates an HTTP API mapper
func NewHTTPAPIMapper() *HTTPAPIMapper {
	return &HTTPAPIMapper{}
}

// Cloud returns the cloud provider
func (m *HTTPAPIMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *HTTPAPIMapper) ResourceType() string {
	return "aws_apigatewayv2_api"
}

// BuildUsage extracts usage vectors
func (m *HTTPAPIMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyRequests, "unknown API count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyRequests := ctx.ResolveOrDefault("monthly_requests", -1)
	monthlyMessages := ctx.ResolveOrDefault("monthly_messages", -1)

	protocolType := asset.Attr("protocol_type")

	if protocolType == "WEBSOCKET" {
		if monthlyMessages < 0 {
			return []clouds.UsageVector{
				clouds.SymbolicUsage("monthly_messages", "WebSocket messages not provided"),
			}, nil
		}
		return []clouds.UsageVector{
			clouds.NewUsageVector("monthly_messages", monthlyMessages, 0.5),
		}, nil
	}

	// HTTP API
	if monthlyRequests < 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyRequests, "monthly API requests not provided"),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyRequests, monthlyRequests, 0.5),
	}, nil
}

// BuildCostUnits creates cost units
func (m *HTTPAPIMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("api", "API Gateway v2 cost requires usage data"),
		}, nil
	}

	protocolType := asset.Attr("protocol_type")
	if protocolType == "" {
		protocolType = "HTTP"
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	if protocolType == "WEBSOCKET" {
		messages, _ := usageVecs.Get("monthly_messages")
		return []clouds.CostUnit{
			clouds.NewCostUnit(
				"messages",
				"million-messages",
				messages/1000000,
				clouds.RateKey{
					Provider: providerID,
					Service:  "AmazonApiGateway",
					Region:   region,
					Attributes: map[string]string{
						"usageType": "WebSocketMessage",
						"apiType":   "WEBSOCKET",
					},
				},
				0.5,
			),
		}, nil
	}

	// HTTP API (cheaper than REST)
	monthlyRequests, _ := usageVecs.Get(clouds.MetricMonthlyRequests)
	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"requests",
			"million-requests",
			monthlyRequests/1000000,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonApiGateway",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "ApiGatewayHttpRequest",
					"apiType":   "HTTP",
				},
			},
			0.5,
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\assets\compute.go
# TYPE: go
# SIZE: 5050 bytes
################################################################################
// Package assets - AWS compute asset builders
package assets

import (
	"context"
	"fmt"

	"terraform-cost/core/asset"
	"terraform-cost/core/types"
)

// EC2AutoScalingGroupBuilder builds assets for aws_autoscaling_group
type EC2AutoScalingGroupBuilder struct {
	baseBuilder
}

// NewEC2AutoScalingGroupBuilder creates a new ASG builder
func NewEC2AutoScalingGroupBuilder() asset.Builder {
	return &EC2AutoScalingGroupBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_autoscaling_group",
			category:     types.CategoryCompute,
		},
	}
}

// Build converts a raw ASG into an asset
func (b *EC2AutoScalingGroupBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	return &types.Asset{
		ID:       fmt.Sprintf("aws_autoscaling_group.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryCompute,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"min_size":              raw.Attributes["min_size"],
			"max_size":              raw.Attributes["max_size"],
			"desired_capacity":      raw.Attributes["desired_capacity"],
			"launch_configuration":  raw.Attributes["launch_configuration"],
			"launch_template":       raw.Attributes["launch_template"],
			"mixed_instances_policy": raw.Attributes["mixed_instances_policy"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
	}, nil
}

// LambdaFunctionBuilder builds assets for aws_lambda_function
type LambdaFunctionBuilder struct {
	baseBuilder
}

// NewLambdaFunctionBuilder creates a new Lambda builder
func NewLambdaFunctionBuilder() asset.Builder {
	return &LambdaFunctionBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_lambda_function",
			category:     types.CategoryServerless,
		},
	}
}

// Build converts a raw Lambda function into an asset
func (b *LambdaFunctionBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	memorySize := raw.Attributes.GetInt("memory_size")
	if memorySize == 0 {
		memorySize = 128 // Default
	}

	timeout := raw.Attributes.GetInt("timeout")
	if timeout == 0 {
		timeout = 3 // Default
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_lambda_function.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryServerless,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"memory_size":       {Value: memorySize},
			"timeout":           {Value: timeout},
			"runtime":           raw.Attributes["runtime"],
			"architectures":     raw.Attributes["architectures"],
			"ephemeral_storage": raw.Attributes["ephemeral_storage"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
	}, nil
}

// ECSServiceBuilder builds assets for aws_ecs_service
type ECSServiceBuilder struct {
	baseBuilder
}

// NewECSServiceBuilder creates a new ECS service builder
func NewECSServiceBuilder() asset.Builder {
	return &ECSServiceBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_ecs_service",
			category:     types.CategoryContainer,
		},
	}
}

// Build converts a raw ECS service into an asset
func (b *ECSServiceBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	desiredCount := raw.Attributes.GetInt("desired_count")
	if desiredCount == 0 {
		desiredCount = 1
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_ecs_service.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryContainer,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"desired_count":   {Value: desiredCount},
			"task_definition": raw.Attributes["task_definition"],
			"launch_type":     raw.Attributes["launch_type"],
			"capacity_provider_strategy": raw.Attributes["capacity_provider_strategy"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
	}, nil
}

// EKSClusterBuilder builds assets for aws_eks_cluster
type EKSClusterBuilder struct {
	baseBuilder
}

// NewEKSClusterBuilder creates a new EKS cluster builder
func NewEKSClusterBuilder() asset.Builder {
	return &EKSClusterBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_eks_cluster",
			category:     types.CategoryContainer,
		},
	}
}

// Build converts a raw EKS cluster into an asset
func (b *EKSClusterBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	return &types.Asset{
		ID:       fmt.Sprintf("aws_eks_cluster.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryContainer,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"version": raw.Attributes["version"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\assets\database.go
# TYPE: go
# SIZE: 6530 bytes
################################################################################
// Package assets - AWS database asset builders
package assets

import (
	"context"
	"fmt"

	"terraform-cost/core/asset"
	"terraform-cost/core/types"
)

// RDSInstanceBuilder builds assets for aws_db_instance
type RDSInstanceBuilder struct {
	baseBuilder
}

// NewRDSInstanceBuilder creates a new RDS instance builder
func NewRDSInstanceBuilder() asset.Builder {
	return &RDSInstanceBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_db_instance",
			category:     types.CategoryDatabase,
		},
	}
}

// Build converts a raw RDS instance into an asset
func (b *RDSInstanceBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	instanceClass := raw.Attributes.GetString("instance_class")
	if instanceClass == "" {
		instanceClass = "db.t3.micro"
	}

	engine := raw.Attributes.GetString("engine")
	storageType := raw.Attributes.GetString("storage_type")
	if storageType == "" {
		storageType = "gp2"
	}

	allocatedStorage := raw.Attributes.GetInt("allocated_storage")
	if allocatedStorage == 0 {
		allocatedStorage = 20
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_db_instance.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryDatabase,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"instance_class":              {Value: instanceClass},
			"engine":                      {Value: engine},
			"engine_version":              raw.Attributes["engine_version"],
			"storage_type":                {Value: storageType},
			"allocated_storage":           {Value: allocatedStorage},
			"max_allocated_storage":       raw.Attributes["max_allocated_storage"],
			"iops":                        raw.Attributes["iops"],
			"storage_throughput":          raw.Attributes["storage_throughput"],
			"multi_az":                    raw.Attributes["multi_az"],
			"storage_encrypted":           raw.Attributes["storage_encrypted"],
			"performance_insights_enabled": raw.Attributes["performance_insights_enabled"],
			"backup_retention_period":     raw.Attributes["backup_retention_period"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// RDSClusterBuilder builds assets for aws_rds_cluster
type RDSClusterBuilder struct {
	baseBuilder
}

// NewRDSClusterBuilder creates a new RDS cluster builder
func NewRDSClusterBuilder() asset.Builder {
	return &RDSClusterBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_rds_cluster",
			category:     types.CategoryDatabase,
		},
	}
}

// Build converts a raw RDS cluster into an asset
func (b *RDSClusterBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	return &types.Asset{
		ID:       fmt.Sprintf("aws_rds_cluster.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryDatabase,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"engine":                  raw.Attributes["engine"],
			"engine_mode":             raw.Attributes["engine_mode"],
			"engine_version":          raw.Attributes["engine_version"],
			"serverlessv2_scaling_configuration": raw.Attributes["serverlessv2_scaling_configuration"],
			"backup_retention_period": raw.Attributes["backup_retention_period"],
			"storage_encrypted":       raw.Attributes["storage_encrypted"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// DynamoDBTableBuilder builds assets for aws_dynamodb_table
type DynamoDBTableBuilder struct {
	baseBuilder
}

// NewDynamoDBTableBuilder creates a new DynamoDB builder
func NewDynamoDBTableBuilder() asset.Builder {
	return &DynamoDBTableBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_dynamodb_table",
			category:     types.CategoryDatabase,
		},
	}
}

// Build converts a raw DynamoDB table into an asset
func (b *DynamoDBTableBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	billingMode := raw.Attributes.GetString("billing_mode")
	if billingMode == "" {
		billingMode = "PROVISIONED"
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_dynamodb_table.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryDatabase,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"billing_mode":           {Value: billingMode},
			"read_capacity":          raw.Attributes["read_capacity"],
			"write_capacity":         raw.Attributes["write_capacity"],
			"global_secondary_index": raw.Attributes["global_secondary_index"],
			"stream_enabled":         raw.Attributes["stream_enabled"],
			"table_class":            raw.Attributes["table_class"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// ElastiCacheClusterBuilder builds assets for aws_elasticache_cluster
type ElastiCacheClusterBuilder struct {
	baseBuilder
}

// NewElastiCacheClusterBuilder creates a new ElastiCache builder
func NewElastiCacheClusterBuilder() asset.Builder {
	return &ElastiCacheClusterBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_elasticache_cluster",
			category:     types.CategoryDatabase,
		},
	}
}

// Build converts a raw ElastiCache cluster into an asset
func (b *ElastiCacheClusterBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	nodeType := raw.Attributes.GetString("node_type")
	if nodeType == "" {
		nodeType = "cache.t3.micro"
	}

	numCacheNodes := raw.Attributes.GetInt("num_cache_nodes")
	if numCacheNodes == 0 {
		numCacheNodes = 1
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_elasticache_cluster.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryDatabase,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"node_type":       {Value: nodeType},
			"num_cache_nodes": {Value: numCacheNodes},
			"engine":          raw.Attributes["engine"],
			"engine_version":  raw.Attributes["engine_version"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\assets\ec2.go
# TYPE: go
# SIZE: 5341 bytes
################################################################################
// Package assets provides AWS asset builders.
package assets

import (
	"context"
	"fmt"

	"terraform-cost/core/asset"
	"terraform-cost/core/types"
)

// baseBuilder provides common functionality for AWS builders
type baseBuilder struct {
	resourceType string
	category     types.AssetCategory
}

func (b *baseBuilder) Provider() types.Provider {
	return types.ProviderAWS
}

func (b *baseBuilder) ResourceType() string {
	return b.resourceType
}

func (b *baseBuilder) Category() types.AssetCategory {
	return b.category
}

// EC2InstanceBuilder builds assets for aws_instance resources
type EC2InstanceBuilder struct {
	baseBuilder
}

// NewEC2InstanceBuilder creates a new EC2 instance builder
func NewEC2InstanceBuilder() asset.Builder {
	return &EC2InstanceBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_instance",
			category:     types.CategoryCompute,
		},
	}
}

// Build converts a raw EC2 instance into an asset
func (b *EC2InstanceBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	instanceType := raw.Attributes.GetString("instance_type")
	if instanceType == "" {
		instanceType = "t3.micro" // Default
	}

	ami := raw.Attributes.GetString("ami")
	az := raw.Attributes.GetString("availability_zone")

	// Extract region from AZ
	region := ""
	if len(az) > 0 {
		region = az[:len(az)-1]
	}

	asset := &types.Asset{
		ID:       fmt.Sprintf("aws_instance.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryCompute,
		Type:     raw.Type,
		Name:     raw.Name,
		Region:   types.Region(region),
		Attributes: types.Attributes{
			"instance_type": {Value: instanceType},
			"ami":           {Value: ami},
			"tenancy":       raw.Attributes["tenancy"],
			"ebs_optimized": raw.Attributes["ebs_optimized"],
			"monitoring":    raw.Attributes["monitoring"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}

	// Add root block device as child
	if rootBlock := raw.Attributes.Get("root_block_device"); rootBlock != nil {
		if rbdList, ok := rootBlock.([]interface{}); ok && len(rbdList) > 0 {
			if rbd, ok := rbdList[0].(map[string]interface{}); ok {
				child := &types.Asset{
					ID:       fmt.Sprintf("%s.root_block_device", asset.ID),
					Address:  types.ResourceAddress(fmt.Sprintf("%s.root_block_device", raw.Address)),
					Provider: types.ProviderAWS,
					Category: types.CategoryStorage,
					Type:     "aws_ebs_volume",
					Name:     "root",
					Parent:   asset,
					Attributes: types.Attributes{
						"volume_type": {Value: getMapString(rbd, "volume_type", "gp3")},
						"volume_size": {Value: getMapInt(rbd, "volume_size", 8)},
						"iops":        {Value: getMapInt(rbd, "iops", 0)},
						"throughput":  {Value: getMapInt(rbd, "throughput", 0)},
						"encrypted":   {Value: getMapBool(rbd, "encrypted", false)},
					},
				}
				asset.Children = append(asset.Children, child)
			}
		}
	}

	// Add additional EBS volumes as children
	if ebsBlocks := raw.Attributes.Get("ebs_block_device"); ebsBlocks != nil {
		if ebsList, ok := ebsBlocks.([]interface{}); ok {
			for i, ebs := range ebsList {
				if ebsMap, ok := ebs.(map[string]interface{}); ok {
					deviceName := getMapString(ebsMap, "device_name", fmt.Sprintf("/dev/sd%c", 'b'+i))
					child := &types.Asset{
						ID:       fmt.Sprintf("%s.ebs_block_device.%d", asset.ID, i),
						Address:  types.ResourceAddress(fmt.Sprintf("%s.ebs_block_device[%d]", raw.Address, i)),
						Provider: types.ProviderAWS,
						Category: types.CategoryStorage,
						Type:     "aws_ebs_volume",
						Name:     deviceName,
						Parent:   asset,
						Attributes: types.Attributes{
							"device_name": {Value: deviceName},
							"volume_type": {Value: getMapString(ebsMap, "volume_type", "gp3")},
							"volume_size": {Value: getMapInt(ebsMap, "volume_size", 8)},
							"iops":        {Value: getMapInt(ebsMap, "iops", 0)},
							"throughput":  {Value: getMapInt(ebsMap, "throughput", 0)},
							"encrypted":   {Value: getMapBool(ebsMap, "encrypted", false)},
						},
					}
					asset.Children = append(asset.Children, child)
				}
			}
		}
	}

	return asset, nil
}

// Helper functions
func extractTags(attrs types.Attributes) map[string]string {
	tags := make(map[string]string)
	if tagsAttr := attrs.Get("tags"); tagsAttr != nil {
		if tagsMap, ok := tagsAttr.(map[string]interface{}); ok {
			for k, v := range tagsMap {
				if s, ok := v.(string); ok {
					tags[k] = s
				}
			}
		}
	}
	return tags
}

func getMapString(m map[string]interface{}, key, defaultVal string) string {
	if v, ok := m[key]; ok {
		if s, ok := v.(string); ok {
			return s
		}
	}
	return defaultVal
}

func getMapInt(m map[string]interface{}, key string, defaultVal int) int {
	if v, ok := m[key]; ok {
		switch n := v.(type) {
		case int:
			return n
		case int64:
			return int(n)
		case float64:
			return int(n)
		}
	}
	return defaultVal
}

func getMapBool(m map[string]interface{}, key string, defaultVal bool) bool {
	if v, ok := m[key]; ok {
		if b, ok := v.(bool); ok {
			return b
		}
	}
	return defaultVal
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\assets\network.go
# TYPE: go
# SIZE: 4609 bytes
################################################################################
// Package assets - AWS network asset builders
package assets

import (
	"context"
	"fmt"

	"terraform-cost/core/asset"
	"terraform-cost/core/types"
)

// NATGatewayBuilder builds assets for aws_nat_gateway
type NATGatewayBuilder struct {
	baseBuilder
}

// NewNATGatewayBuilder creates a new NAT Gateway builder
func NewNATGatewayBuilder() asset.Builder {
	return &NATGatewayBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_nat_gateway",
			category:     types.CategoryNetwork,
		},
	}
}

// Build converts a raw NAT Gateway into an asset
func (b *NATGatewayBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	return &types.Asset{
		ID:       fmt.Sprintf("aws_nat_gateway.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryNetwork,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"connectivity_type": raw.Attributes["connectivity_type"],
			"subnet_id":         raw.Attributes["subnet_id"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// VPCEndpointBuilder builds assets for aws_vpc_endpoint
type VPCEndpointBuilder struct {
	baseBuilder
}

// NewVPCEndpointBuilder creates a new VPC Endpoint builder
func NewVPCEndpointBuilder() asset.Builder {
	return &VPCEndpointBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_vpc_endpoint",
			category:     types.CategoryNetwork,
		},
	}
}

// Build converts a raw VPC Endpoint into an asset
func (b *VPCEndpointBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	vpcEndpointType := raw.Attributes.GetString("vpc_endpoint_type")
	if vpcEndpointType == "" {
		vpcEndpointType = "Gateway"
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_vpc_endpoint.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryNetwork,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"vpc_endpoint_type": {Value: vpcEndpointType},
			"service_name":      raw.Attributes["service_name"],
			"vpc_id":            raw.Attributes["vpc_id"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// ELBBuilder builds assets for aws_elb (Classic)
type ELBBuilder struct {
	baseBuilder
}

// NewELBBuilder creates a new ELB builder
func NewELBBuilder() asset.Builder {
	return &ELBBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_elb",
			category:     types.CategoryNetwork,
		},
	}
}

// Build converts a raw ELB into an asset
func (b *ELBBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	return &types.Asset{
		ID:       fmt.Sprintf("aws_elb.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryNetwork,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"internal": raw.Attributes["internal"],
			"listener": raw.Attributes["listener"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// ALBBuilder builds assets for aws_lb (Application)
type ALBBuilder struct {
	baseBuilder
}

// NewALBBuilder creates a new ALB builder
func NewALBBuilder() asset.Builder {
	return &ALBBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_lb",
			category:     types.CategoryNetwork,
		},
	}
}

// Build converts a raw ALB/NLB into an asset
func (b *ALBBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	loadBalancerType := raw.Attributes.GetString("load_balancer_type")
	if loadBalancerType == "" {
		loadBalancerType = "application"
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_lb.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryNetwork,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"load_balancer_type": {Value: loadBalancerType},
			"internal":           raw.Attributes["internal"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// NLBBuilder builds assets for aws_lb (Network) - alias to ALBBuilder
func NewNLBBuilder() asset.Builder {
	return NewALBBuilder()
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\assets\other.go
# TYPE: go
# SIZE: 3785 bytes
################################################################################
// Package assets - AWS other asset builders
package assets

import (
	"context"
	"fmt"

	"terraform-cost/core/asset"
	"terraform-cost/core/types"
)

// CloudWatchLogGroupBuilder builds assets for aws_cloudwatch_log_group
type CloudWatchLogGroupBuilder struct {
	baseBuilder
}

// NewCloudWatchLogGroupBuilder creates a new CloudWatch Log Group builder
func NewCloudWatchLogGroupBuilder() asset.Builder {
	return &CloudWatchLogGroupBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_cloudwatch_log_group",
			category:     types.CategoryMonitoring,
		},
	}
}

// Build converts a raw CloudWatch Log Group into an asset
func (b *CloudWatchLogGroupBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	retentionDays := raw.Attributes.GetInt("retention_in_days")
	// 0 means never expire

	return &types.Asset{
		ID:       fmt.Sprintf("aws_cloudwatch_log_group.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryMonitoring,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"retention_in_days": {Value: retentionDays},
			"kms_key_id":        raw.Attributes["kms_key_id"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// KMSKeyBuilder builds assets for aws_kms_key
type KMSKeyBuilder struct {
	baseBuilder
}

// NewKMSKeyBuilder creates a new KMS Key builder
func NewKMSKeyBuilder() asset.Builder {
	return &KMSKeyBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_kms_key",
			category:     types.CategorySecurity,
		},
	}
}

// Build converts a raw KMS Key into an asset
func (b *KMSKeyBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	keySpec := raw.Attributes.GetString("customer_master_key_spec")
	if keySpec == "" {
		keySpec = "SYMMETRIC_DEFAULT"
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_kms_key.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategorySecurity,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"customer_master_key_spec": {Value: keySpec},
			"key_usage":                raw.Attributes["key_usage"],
			"is_enabled":               raw.Attributes["is_enabled"],
			"multi_region":              raw.Attributes["multi_region"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// SecretsManagerSecretBuilder builds assets for aws_secretsmanager_secret
type SecretsManagerSecretBuilder struct {
	baseBuilder
}

// NewSecretsManagerSecretBuilder creates a new Secrets Manager builder
func NewSecretsManagerSecretBuilder() asset.Builder {
	return &SecretsManagerSecretBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_secretsmanager_secret",
			category:     types.CategorySecurity,
		},
	}
}

// Build converts a raw Secrets Manager Secret into an asset
func (b *SecretsManagerSecretBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	return &types.Asset{
		ID:       fmt.Sprintf("aws_secretsmanager_secret.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategorySecurity,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"recovery_window_in_days": raw.Attributes["recovery_window_in_days"],
			"kms_key_id":              raw.Attributes["kms_key_id"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\assets\storage.go
# TYPE: go
# SIZE: 4249 bytes
################################################################################
// Package assets - AWS storage asset builders
package assets

import (
	"context"
	"fmt"

	"terraform-cost/core/asset"
	"terraform-cost/core/types"
)

// S3BucketBuilder builds assets for aws_s3_bucket
type S3BucketBuilder struct {
	baseBuilder
}

// NewS3BucketBuilder creates a new S3 bucket builder
func NewS3BucketBuilder() asset.Builder {
	return &S3BucketBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_s3_bucket",
			category:     types.CategoryStorage,
		},
	}
}

// Build converts a raw S3 bucket into an asset
func (b *S3BucketBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	return &types.Asset{
		ID:       fmt.Sprintf("aws_s3_bucket.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryStorage,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"bucket": raw.Attributes["bucket"],
			"acl":    raw.Attributes["acl"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// EBSVolumeBuilder builds assets for aws_ebs_volume
type EBSVolumeBuilder struct {
	baseBuilder
}

// NewEBSVolumeBuilder creates a new EBS volume builder
func NewEBSVolumeBuilder() asset.Builder {
	return &EBSVolumeBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_ebs_volume",
			category:     types.CategoryStorage,
		},
	}
}

// Build converts a raw EBS volume into an asset
func (b *EBSVolumeBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	volumeType := raw.Attributes.GetString("type")
	if volumeType == "" {
		volumeType = "gp3"
	}

	size := raw.Attributes.GetInt("size")
	if size == 0 {
		size = 8
	}

	az := raw.Attributes.GetString("availability_zone")
	region := ""
	if len(az) > 0 {
		region = az[:len(az)-1]
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_ebs_volume.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryStorage,
		Type:     raw.Type,
		Name:     raw.Name,
		Region:   types.Region(region),
		Attributes: types.Attributes{
			"type":              {Value: volumeType},
			"size":              {Value: size},
			"iops":              raw.Attributes["iops"],
			"throughput":        raw.Attributes["throughput"],
			"encrypted":         raw.Attributes["encrypted"],
			"availability_zone": {Value: az},
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

// EFSFileSystemBuilder builds assets for aws_efs_file_system
type EFSFileSystemBuilder struct {
	baseBuilder
}

// NewEFSFileSystemBuilder creates a new EFS builder
func NewEFSFileSystemBuilder() asset.Builder {
	return &EFSFileSystemBuilder{
		baseBuilder: baseBuilder{
			resourceType: "aws_efs_file_system",
			category:     types.CategoryStorage,
		},
	}
}

// Build converts a raw EFS file system into an asset
func (b *EFSFileSystemBuilder) Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error) {
	throughputMode := raw.Attributes.GetString("throughput_mode")
	if throughputMode == "" {
		throughputMode = "bursting"
	}

	performanceMode := raw.Attributes.GetString("performance_mode")
	if performanceMode == "" {
		performanceMode = "generalPurpose"
	}

	return &types.Asset{
		ID:       fmt.Sprintf("aws_efs_file_system.%s", raw.Name),
		Address:  raw.Address,
		Provider: types.ProviderAWS,
		Category: types.CategoryStorage,
		Type:     raw.Type,
		Name:     raw.Name,
		Attributes: types.Attributes{
			"throughput_mode":                  {Value: throughputMode},
			"performance_mode":                 {Value: performanceMode},
			"provisioned_throughput_in_mibps":  raw.Attributes["provisioned_throughput_in_mibps"],
			"encrypted":                        raw.Attributes["encrypted"],
			"lifecycle_policy":                 raw.Attributes["lifecycle_policy"],
		},
		Metadata: types.AssetMetadata{
			Source: raw.SourceFile,
			Line:   raw.SourceLine,
		},
		Tags: extractTags(raw.Attributes),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\backup\backup.go
# TYPE: go
# SIZE: 1750 bytes
################################################################################
// Package backup - AWS Backup Vault mapper
package backup

import (
	"terraform-cost/clouds"
)

// BackupVaultMapper maps aws_backup_vault to cost units
type BackupVaultMapper struct{}

func NewBackupVaultMapper() *BackupVaultMapper { return &BackupVaultMapper{} }

func (m *BackupVaultMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *BackupVaultMapper) ResourceType() string        { return "aws_backup_vault" }

func (m *BackupVaultMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage("vaults", "unknown vault count")}, nil
	}

	storageGB := ctx.ResolveOrDefault("storage_gb", -1)
	if storageGB < 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricStorageGB, "backup storage size depends on backup schedule and retention"),
		}, nil
	}

	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricStorageGB, storageGB, 0.5)}, nil
}

func (m *BackupVaultMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("backup", "Backup vault cost depends on stored backup data"),
		}, nil
	}

	storageGB, _ := usageVecs.Get(clouds.MetricStorageGB)

	return []clouds.CostUnit{
		clouds.NewCostUnit("storage", "GB-months", storageGB, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSBackup",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "StorageUsage",
			},
		}, 0.5),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\cdn\cloudfront.go
# TYPE: go
# SIZE: 4592 bytes
################################################################################
// Package cdn - AWS CloudFront and Global Accelerator mappers
package cdn

import (
	"terraform-cost/clouds"
)

// CloudFrontMapper maps aws_cloudfront_distribution to cost units
type CloudFrontMapper struct{}

func NewCloudFrontMapper() *CloudFrontMapper { return &CloudFrontMapper{} }

func (m *CloudFrontMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *CloudFrontMapper) ResourceType() string        { return "aws_cloudfront_distribution" }

func (m *CloudFrontMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage("distributions", "unknown distribution count")}, nil
	}

	// CloudFront is entirely usage-based
	dataTransferGB := ctx.ResolveOrDefault("data_transfer_gb", -1)
	requests := ctx.ResolveOrDefault("monthly_requests", -1)

	if dataTransferGB < 0 || requests < 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricDataTransferGB, "CloudFront usage not provided"),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricDataTransferGB, dataTransferGB, 0.5),
		clouds.NewUsageVector(clouds.MetricMonthlyRequests, requests, 0.5),
	}, nil
}

func (m *CloudFrontMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("cloudfront", "CloudFront cost depends on data transfer and requests"),
		}, nil
	}

	dataTransferGB, _ := usageVecs.Get(clouds.MetricDataTransferGB)
	requests, _ := usageVecs.Get(clouds.MetricMonthlyRequests)

	priceClass := asset.Attr("price_class")
	if priceClass == "" {
		priceClass = "PriceClass_All"
	}

	return []clouds.CostUnit{
		clouds.NewCostUnit("data_transfer", "GB", dataTransferGB, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonCloudFront",
			Region:   "global",
			Attributes: map[string]string{
				"priceClass": priceClass,
				"usageType":  "DataTransfer-Out-Bytes",
			},
		}, 0.5),
		clouds.NewCostUnit("requests", "10k-requests", requests/10000, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonCloudFront",
			Region:   "global",
			Attributes: map[string]string{
				"usageType": "Requests-Tier1",
			},
		}, 0.5),
	}, nil
}

// GlobalAcceleratorMapper maps aws_global_accelerator to cost units
type GlobalAcceleratorMapper struct{}

func NewGlobalAcceleratorMapper() *GlobalAcceleratorMapper { return &GlobalAcceleratorMapper{} }

func (m *GlobalAcceleratorMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *GlobalAcceleratorMapper) ResourceType() string        { return "aws_globalaccelerator_accelerator" }

func (m *GlobalAcceleratorMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown accelerator count")}, nil
	}
	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, 730, 0.95),
		clouds.NewUsageVector(clouds.MetricDataTransferGB, ctx.ResolveOrDefault("data_transfer_gb", 0), 0.5),
	}, nil
}

func (m *GlobalAcceleratorMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("global_accelerator", "accelerator count unknown")}, nil
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)
	dataTransferGB, _ := usageVecs.Get(clouds.MetricDataTransferGB)

	units := []clouds.CostUnit{
		// Fixed hourly cost per accelerator
		clouds.NewCostUnit("accelerator_hours", "hours", monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSGlobalAccelerator",
			Region:   "global",
			Attributes: map[string]string{
				"usageType": "Accelerator-Hours",
			},
		}, 0.95),
	}

	// Data transfer (DT-Premium)
	if dataTransferGB > 0 {
		units = append(units, clouds.NewCostUnit("data_transfer", "GB", dataTransferGB, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSGlobalAccelerator",
			Region:   "global",
			Attributes: map[string]string{
				"usageType": "DataTransfer-Premium",
			},
		}, 0.5))
	}

	return units, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\compute\autoscaling.go
# TYPE: go
# SIZE: 4245 bytes
################################################################################
// Package compute - AWS Auto Scaling cost mapper
// Clean-room implementation based on ASG pricing model:
// - No direct ASG cost (it's free)
// - Costs come from launched instances (tracked separately)
// - This mapper handles capacity estimation for cost projection
package compute

import (
	"terraform-cost/clouds"
)

// AutoscalingMapper maps aws_autoscaling_group to cost units
type AutoscalingMapper struct{}

// NewAutoscalingMapper creates an ASG mapper
func NewAutoscalingMapper() *AutoscalingMapper {
	return &AutoscalingMapper{}
}

// Cloud returns the cloud provider
func (m *AutoscalingMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *AutoscalingMapper) ResourceType() string {
	return "aws_autoscaling_group"
}

// BuildUsage extracts usage vectors from an ASG
func (m *AutoscalingMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	// Check for unknown cardinality
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown ASG capacity: "+asset.Cardinality.Reason),
		}, nil
	}

	// Get capacity configuration
	minSize := asset.AttrInt("min_size", 0)
	maxSize := asset.AttrInt("max_size", 0)
	desiredCapacity := asset.AttrInt("desired_capacity", minSize)

	// If desired capacity depends on dynamic scaling, it's unknown
	if desiredCapacity == 0 && minSize == 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "dynamic scaling with min_size=0"),
		}, nil
	}

	// Use desired capacity or min_size for estimation
	instanceCount := float64(desiredCapacity)
	if instanceCount == 0 {
		instanceCount = float64(minSize)
	}

	// Calculate instance hours (instances * hours/month)
	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)
	totalInstanceHours := instanceCount * monthlyHours

	// Confidence is lower for ASG because actual capacity varies
	confidence := 0.7
	if minSize == maxSize {
		// Fixed capacity = higher confidence
		confidence = 0.9
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, totalInstanceHours, confidence),
	}, nil
}

// BuildCostUnits creates cost units for an ASG
func (m *AutoscalingMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	// Check for symbolic usage
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("instances", "ASG cost unknown: capacity is dynamic"),
		}, nil
	}

	// ASG itself is free - costs come from instances
	// We estimate the aggregate instance cost here

	// Get launch template or launch configuration
	instanceType := m.getInstanceType(asset)

	// Get total instance hours
	totalHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	// Infer OS from launch template/config
	os := "Linux" // Default

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"instances",
			"instance-hours",
			totalHours,
			clouds.RateKey{
				Provider: asset.ProviderContext.ProviderID,
				Service:  "AmazonEC2",
				Region:   asset.ProviderContext.Region,
				Attributes: map[string]string{
					"instanceType":    instanceType,
					"operatingSystem": os,
					"tenancy":         "default",
					"capacityStatus":  "Used",
				},
			},
			0.7, // Lower confidence for ASG
		),
	}, nil
}

// getInstanceType extracts instance type from launch template or config
func (m *AutoscalingMapper) getInstanceType(asset clouds.AssetNode) string {
	// Check launch template
	if lt := asset.Attr("launch_template.0.instance_type"); lt != "" {
		return lt
	}

	// Check launch configuration (legacy)
	if lc := asset.Attr("launch_configuration"); lc != "" {
		// Would need to resolve launch configuration
		// For now, use a default
		return "t3.medium"
	}

	// Check mixed instances policy
	if override := asset.Attr("mixed_instances_policy.0.launch_template.0.override.0.instance_type"); override != "" {
		return override
	}

	return "t3.medium" // Default fallback
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\compute\ec2.go
# TYPE: go
# SIZE: 5116 bytes
################################################################################
// Package compute - AWS EC2 cost mapper
// Clean-room implementation based on EC2 pricing model:
// - Instance hours (by instance type, region, OS, tenancy)
// - EBS storage for root/additional volumes
// - Data transfer
// - EBS-optimized surcharge (some instance types)
package compute

import (
	"terraform-cost/clouds"
)

// EC2Mapper maps aws_instance to cost units
type EC2Mapper struct{}

// NewEC2Mapper creates an EC2 mapper
func NewEC2Mapper() *EC2Mapper {
	return &EC2Mapper{}
}

// Cloud returns the cloud provider
func (m *EC2Mapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *EC2Mapper) ResourceType() string {
	return "aws_instance"
}

// BuildUsage extracts usage vectors from an EC2 instance
func (m *EC2Mapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	// Check for unknown cardinality
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown instance count: "+asset.Cardinality.Reason),
		}, nil
	}

	// Default: 730 hours/month (24*365/12)
	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, ctx.Confidence),
	}, nil
}

// BuildCostUnits creates cost units for an EC2 instance
func (m *EC2Mapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	// Check for symbolic usage
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("compute", "EC2 cost unknown due to cardinality"),
		}, nil
	}

	// Extract attributes
	instanceType := asset.Attr("instance_type")
	if instanceType == "" {
		instanceType = "t3.micro"
	}

	// Determine OS (affects pricing)
	ami := asset.Attr("ami")
	os := inferOS(ami, asset.Attributes)

	// Tenancy
	tenancy := asset.Attr("tenancy")
	if tenancy == "" {
		tenancy = "default"
	}

	// Get monthly hours
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	// Build rate key
	rateKey := clouds.RateKey{
		Provider: asset.ProviderContext.ProviderID,
		Service:  "AmazonEC2",
		Region:   asset.ProviderContext.Region,
		Attributes: map[string]string{
			"instanceType": instanceType,
			"operatingSystem": os,
			"tenancy":      tenancy,
			"capacityStatus": "Used",
		},
	}

	units := []clouds.CostUnit{
		clouds.NewCostUnit("compute", "hours", monthlyHours, rateKey, 0.95),
	}

	// Root block device storage
	if rootVolumeSize := asset.AttrFloat("root_block_device.0.volume_size", 0); rootVolumeSize > 0 {
		volumeType := asset.Attr("root_block_device.0.volume_type")
		if volumeType == "" {
			volumeType = "gp3"
		}

		units = append(units, clouds.NewCostUnit(
			"root_storage",
			"GB-months",
			rootVolumeSize,
			clouds.RateKey{
				Provider: asset.ProviderContext.ProviderID,
				Service:  "AmazonEC2",
				Region:   asset.ProviderContext.Region,
				Attributes: map[string]string{
					"volumeType": volumeType,
					"usageType":  "EBS:VolumeUsage." + volumeType,
				},
			},
			0.95,
		))
	}

	// EBS optimized (if applicable and not included)
	if asset.AttrBool("ebs_optimized", false) {
		// Some newer instance types include EBS optimization for free
		if !isEBSOptimizedFree(instanceType) {
			units = append(units, clouds.NewCostUnit(
				"ebs_optimized",
				"hours",
				monthlyHours,
				clouds.RateKey{
					Provider: asset.ProviderContext.ProviderID,
					Service:  "AmazonEC2",
					Region:   asset.ProviderContext.Region,
					Attributes: map[string]string{
						"instanceType": instanceType,
						"usageType":    "EBSOptimized:" + instanceType,
					},
				},
				0.90,
			))
		}
	}

	return units, nil
}

// inferOS infers the operating system from AMI or attributes
func inferOS(ami string, attrs map[string]interface{}) string {
	// Check for Windows in AMI name or tags
	if amiName, ok := attrs["ami_name"].(string); ok {
		if containsWindows(amiName) {
			return "Windows"
		}
	}

	// Default to Linux
	return "Linux"
}

func containsWindows(s string) bool {
	// Simple check - would be more sophisticated in production
	for i := 0; i < len(s)-6; i++ {
		if s[i:i+7] == "windows" || s[i:i+7] == "Windows" {
			return true
		}
	}
	return false
}

// isEBSOptimizedFree checks if EBS optimization is free for instance type
func isEBSOptimizedFree(instanceType string) bool {
	// Most newer instance types include EBS optimization
	// This is a simplified check
	freeTypes := map[string]bool{
		"t3": true, "t3a": true, "m5": true, "m5a": true, "m5d": true,
		"c5": true, "c5d": true, "c5n": true, "r5": true, "r5a": true,
	}

	// Extract family from instance type (e.g., "m5" from "m5.large")
	family := ""
	for i, c := range instanceType {
		if c == '.' {
			family = instanceType[:i]
			break
		}
	}

	return freeTypes[family]
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\compute\ec2_host.go
# TYPE: go
# SIZE: 1682 bytes
################################################################################
// Package compute - AWS EC2 dedicated host mapper
package compute

import (
	"terraform-cost/clouds"
)

// EC2HostMapper maps aws_ec2_host to cost units
type EC2HostMapper struct{}

func NewEC2HostMapper() *EC2HostMapper { return &EC2HostMapper{} }

func (m *EC2HostMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *EC2HostMapper) ResourceType() string        { return "aws_ec2_host" }

func (m *EC2HostMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown dedicated host count")}, nil
	}
	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricMonthlyHours, ctx.ResolveOrDefault("monthly_hours", 730), 0.95)}, nil
}

func (m *EC2HostMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("dedicated_host", "host count unknown")}, nil
	}

	instanceFamily := asset.Attr("instance_family")
	if instanceFamily == "" {
		instanceFamily = "m5"
	}
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	return []clouds.CostUnit{
		clouds.NewCostUnit("dedicated_host", "host-hours", monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonEC2",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"instanceFamily": instanceFamily,
				"usageType":      "DedicatedHostUsage",
			},
		}, 0.95),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\containers\ecr.go
# TYPE: go
# SIZE: 1734 bytes
################################################################################
// Package containers - AWS ECR Repository mapper
package containers

import (
	"terraform-cost/clouds"
)

// ECRRepositoryMapper maps aws_ecr_repository to cost units
type ECRRepositoryMapper struct{}

func NewECRRepositoryMapper() *ECRRepositoryMapper { return &ECRRepositoryMapper{} }

func (m *ECRRepositoryMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *ECRRepositoryMapper) ResourceType() string        { return "aws_ecr_repository" }

func (m *ECRRepositoryMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage("repositories", "unknown repository count")}, nil
	}

	storageGB := ctx.ResolveOrDefault("storage_gb", -1)
	if storageGB < 0 {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricStorageGB, "ECR storage size unknown")}, nil
	}

	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricStorageGB, storageGB, 0.5)}, nil
}

func (m *ECRRepositoryMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("ecr", "ECR cost depends on stored image size"),
		}, nil
	}

	storageGB, _ := usageVecs.Get(clouds.MetricStorageGB)

	return []clouds.CostUnit{
		clouds.NewCostUnit("storage", "GB-months", storageGB, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonECR",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "StorageUsage",
			},
		}, 0.5),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\containers\ecs.go
# TYPE: go
# SIZE: 3722 bytes
################################################################################
// Package containers - AWS ECS Service and Task Definition mappers
package containers

import (
	"terraform-cost/clouds"
)

// ECSServiceMapper maps aws_ecs_service to cost units
type ECSServiceMapper struct{}

func NewECSServiceMapper() *ECSServiceMapper { return &ECSServiceMapper{} }

func (m *ECSServiceMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *ECSServiceMapper) ResourceType() string        { return "aws_ecs_service" }

func (m *ECSServiceMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown service count")}, nil
	}
	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricMonthlyHours, ctx.ResolveOrDefault("monthly_hours", 730), 0.95)}, nil
}

func (m *ECSServiceMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("ecs_service", "service count unknown")}, nil
	}

	launchType := asset.Attr("launch_type")
	if launchType == "" {
		launchType = "EC2"
	}

	desiredCount := asset.AttrInt("desired_count", 1)
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	// For Fargate, cost is vCPU + memory hours
	if launchType == "FARGATE" {
		return []clouds.CostUnit{
			clouds.SymbolicCost("fargate_tasks", "Fargate cost depends on task definition CPU/memory"),
		}, nil
	}

	// For EC2 launch type, tasks run on EC2 instances (no additional service cost)
	return []clouds.CostUnit{
		clouds.NewCostUnit("service_tasks", "task-hours", float64(desiredCount)*monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonECS",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"launchType": launchType,
			},
		}, 0.7),
	}, nil
}

// ECSTaskDefinitionMapper maps aws_ecs_task_definition to cost units
type ECSTaskDefinitionMapper struct{}

func NewECSTaskDefinitionMapper() *ECSTaskDefinitionMapper { return &ECSTaskDefinitionMapper{} }

func (m *ECSTaskDefinitionMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *ECSTaskDefinitionMapper) ResourceType() string        { return "aws_ecs_task_definition" }

func (m *ECSTaskDefinitionMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	// Task definitions don't have direct cost - cost is per running task
	return []clouds.UsageVector{clouds.NewUsageVector("task_definitions", 1, 1.0)}, nil
}

func (m *ECSTaskDefinitionMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	requiresCompatibilities := asset.Attr("requires_compatibilities.0")

	if requiresCompatibilities == "FARGATE" {
		cpu := asset.AttrFloat("cpu", 256)
		memory := asset.AttrFloat("memory", 512)

		// Convert to vCPU (256 CPU units = 0.25 vCPU)
		vcpu := cpu / 1024
		memoryGB := memory / 1024

		return []clouds.CostUnit{
			clouds.SymbolicCost("fargate", 
				"Fargate task definition: "+
				"vCPU="+formatFloat(vcpu)+
				", Memory="+formatFloat(memoryGB)+"GB. "+
				"Cost depends on number of running tasks"),
		}, nil
	}

	// EC2 launch type - no additional cost from task definition
	return []clouds.CostUnit{
		clouds.SymbolicCost("ec2_task", "Task runs on EC2 instances, no additional ECS cost"),
	}, nil
}

func formatFloat(f float64) string {
	if f == float64(int(f)) {
		return string(rune('0' + int(f)))
	}
	return "~"
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\containers\eks.go
# TYPE: go
# SIZE: 4776 bytes
################################################################################
// Package containers - AWS EKS cost mapper
// Pricing model:
// - Control plane: $0.10/hour per cluster
// - Nodes: EC2 instance costs (tracked separately)
// - Fargate: vCPU-hour + GB-hour
package containers

import (
	"terraform-cost/clouds"
)

// EKSClusterMapper maps aws_eks_cluster to cost units
type EKSClusterMapper struct{}

// NewEKSClusterMapper creates an EKS Cluster mapper
func NewEKSClusterMapper() *EKSClusterMapper {
	return &EKSClusterMapper{}
}

// Cloud returns the cloud provider
func (m *EKSClusterMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *EKSClusterMapper) ResourceType() string {
	return "aws_eks_cluster"
}

// BuildUsage extracts usage vectors
func (m *EKSClusterMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown EKS cluster count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
	}, nil
}

// BuildCostUnits creates cost units for EKS control plane
func (m *EKSClusterMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("control_plane", "EKS cost unknown due to cardinality"),
		}, nil
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	// EKS control plane is fixed at $0.10/hour
	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"control_plane",
			"hours",
			monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEKS",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "AmazonEKS-Hours:perkubernetes",
				},
			},
			0.95,
		),
	}, nil
}

// EKSNodeGroupMapper maps aws_eks_node_group to cost units
type EKSNodeGroupMapper struct{}

// NewEKSNodeGroupMapper creates an EKS Node Group mapper
func NewEKSNodeGroupMapper() *EKSNodeGroupMapper {
	return &EKSNodeGroupMapper{}
}

// Cloud returns the cloud provider
func (m *EKSNodeGroupMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *EKSNodeGroupMapper) ResourceType() string {
	return "aws_eks_node_group"
}

// BuildUsage extracts usage vectors
func (m *EKSNodeGroupMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown node group: "+asset.Cardinality.Reason),
		}, nil
	}

	// Get scaling config
	desiredSize := asset.AttrInt("scaling_config.0.desired_size", 2)
	minSize := asset.AttrInt("scaling_config.0.min_size", 1)

	// Use desired or min for estimation
	nodeCount := float64(desiredSize)
	if nodeCount == 0 {
		nodeCount = float64(minSize)
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	// Confidence depends on whether it's fixed or auto-scaling
	confidence := 0.7
	maxSize := asset.AttrInt("scaling_config.0.max_size", desiredSize)
	if minSize == maxSize {
		confidence = 0.95
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, nodeCount*monthlyHours, confidence),
	}, nil
}

// BuildCostUnits creates cost units for EKS nodes
func (m *EKSNodeGroupMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("nodes", "EKS node cost unknown"),
		}, nil
	}

	// Get instance types
	instanceTypes := asset.Attr("instance_types.0")
	if instanceTypes == "" {
		instanceTypes = "t3.medium"
	}

	totalHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"nodes",
			"instance-hours",
			totalHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEC2",
				Region:   region,
				Attributes: map[string]string{
					"instanceType":    instanceTypes,
					"operatingSystem": "Linux",
					"tenancy":         "default",
				},
			},
			0.7,
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\database\aurora.go
# TYPE: go
# SIZE: 5185 bytes
################################################################################
// Package database - AWS Aurora (RDS Cluster) cost mapper
// Pricing model:
// - Aurora Provisioned: instance hours + storage + I/O
// - Aurora Serverless v1: ACU-hours
// - Aurora Serverless v2: ACU-hours (more granular)
// - Storage: per GB-month (grows automatically)
// - I/O: per million requests (unless I/O-Optimized)
// - Backtrack: per million change records
package database

import (
	"terraform-cost/clouds"
)

// AuroraMapper maps aws_rds_cluster to cost units
type AuroraMapper struct{}

// NewAuroraMapper creates an Aurora mapper
func NewAuroraMapper() *AuroraMapper {
	return &AuroraMapper{}
}

// Cloud returns the cloud provider
func (m *AuroraMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *AuroraMapper) ResourceType() string {
	return "aws_rds_cluster"
}

// BuildUsage extracts usage vectors
func (m *AuroraMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown Aurora cluster count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)
	storageGB := ctx.ResolveOrDefault("storage_gb", 10)
	ioRequestsMillions := ctx.ResolveOrDefault("io_requests_millions", 10)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
		clouds.NewUsageVector(clouds.MetricStorageGB, storageGB, 0.5),
		clouds.NewUsageVector("io_requests_millions", ioRequestsMillions, 0.5),
	}, nil
}

// BuildCostUnits creates cost units
func (m *AuroraMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("aurora", "Aurora cost unknown due to cardinality"),
		}, nil
	}

	engine := asset.Attr("engine")
	if engine == "" {
		engine = "aurora-mysql"
	}

	engineMode := asset.Attr("engine_mode")
	if engineMode == "" {
		engineMode = "provisioned"
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)
	storageGB, _ := usageVecs.Get(clouds.MetricStorageGB)
	ioRequests, _ := usageVecs.Get("io_requests_millions")

	var units []clouds.CostUnit

	// Engine mode determines compute pricing
	switch engineMode {
	case "serverless":
		// Aurora Serverless v1
		minCapacity := asset.AttrFloat("scaling_configuration.0.min_capacity", 2)
		units = append(units, clouds.NewCostUnit(
			"serverless_acu",
			"ACU-hours",
			minCapacity*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRDS",
				Region:   region,
				Attributes: map[string]string{
					"databaseEngine": normalizeAuroraEngine(engine),
					"usageType":      "Aurora:ServerlessUsage",
				},
			},
			0.7, // Lower confidence - actual ACU usage varies
		))

	case "serverlessv2":
		// Aurora Serverless v2
		minCapacity := asset.AttrFloat("serverlessv2_scaling_configuration.0.min_capacity", 0.5)
		units = append(units, clouds.NewCostUnit(
			"serverlessv2_acu",
			"ACU-hours",
			minCapacity*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRDS",
				Region:   region,
				Attributes: map[string]string{
					"databaseEngine": normalizeAuroraEngine(engine),
					"usageType":      "Aurora:ServerlessV2Usage",
				},
			},
			0.7,
		))

	default:
		// Provisioned - instances are separate aws_rds_cluster_instance resources
		// Cluster itself has no compute cost
	}

	// Storage (always charged)
	units = append(units, clouds.NewCostUnit(
		"storage",
		"GB-months",
		storageGB,
		clouds.RateKey{
			Provider: providerID,
			Service:  "AmazonRDS",
			Region:   region,
			Attributes: map[string]string{
				"databaseEngine": normalizeAuroraEngine(engine),
				"usageType":      "Aurora:StorageUsage",
			},
		},
		0.5,
	))

	// I/O (unless I/O-Optimized storage type)
	storageType := asset.Attr("storage_type")
	if storageType != "aurora-iopt1" && ioRequests > 0 {
		units = append(units, clouds.NewCostUnit(
			"io_requests",
			"million-requests",
			ioRequests,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRDS",
				Region:   region,
				Attributes: map[string]string{
					"databaseEngine": normalizeAuroraEngine(engine),
					"usageType":      "Aurora:IOUsage",
				},
			},
			0.5,
		))
	}

	// Backtrack (if enabled)
	if backtrackWindow := asset.AttrInt("backtrack_window", 0); backtrackWindow > 0 {
		units = append(units, clouds.SymbolicCost(
			"backtrack",
			"backtrack cost depends on change rate",
		))
	}

	return units, nil
}

func normalizeAuroraEngine(engine string) string {
	switch engine {
	case "aurora", "aurora-mysql":
		return "Aurora MySQL"
	case "aurora-postgresql":
		return "Aurora PostgreSQL"
	default:
		return engine
	}
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\database\dynamodb.go
# TYPE: go
# SIZE: 4801 bytes
################################################################################
// Package database - AWS DynamoDB cost mapper
// Clean-room implementation based on DynamoDB pricing model:
// - On-demand: Read/Write Request Units
// - Provisioned: Read/Write Capacity Units
// - Storage (per GB-month)
// - Global tables (additional per-replicated write)
// - Backups (per GB-month)
// - Streams (per 100K read requests)
package database

import (
	"terraform-cost/clouds"
)

// DynamoDBMapper maps aws_dynamodb_table to cost units
type DynamoDBMapper struct{}

// NewDynamoDBMapper creates a DynamoDB mapper
func NewDynamoDBMapper() *DynamoDBMapper {
	return &DynamoDBMapper{}
}

// Cloud returns the cloud provider
func (m *DynamoDBMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *DynamoDBMapper) ResourceType() string {
	return "aws_dynamodb_table"
}

// BuildUsage extracts usage vectors from a DynamoDB table
func (m *DynamoDBMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	// Check for unknown cardinality
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricStorageGB, "unknown table count: "+asset.Cardinality.Reason),
		}, nil
	}

	// DynamoDB usage is highly dependent on application patterns
	// Storage grows with data
	storageGB := ctx.ResolveOrDefault("storage_gb", 10)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricStorageGB, storageGB, 0.5),
	}, nil
}

// BuildCostUnits creates cost units for a DynamoDB table
func (m *DynamoDBMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	// Check for symbolic usage
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("capacity", "DynamoDB cost unknown due to cardinality"),
		}, nil
	}

	// Determine billing mode
	billingMode := asset.Attr("billing_mode")
	if billingMode == "" {
		billingMode = "PROVISIONED" // Default
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	var units []clouds.CostUnit

	if billingMode == "PAY_PER_REQUEST" {
		// On-demand mode - charged per request
		// Need usage data for accurate estimation
		units = []clouds.CostUnit{
			clouds.SymbolicCost("read_requests", "on-demand read usage unknown"),
			clouds.SymbolicCost("write_requests", "on-demand write usage unknown"),
		}
	} else {
		// Provisioned mode
		readCapacity := asset.AttrFloat("read_capacity", 5)
		writeCapacity := asset.AttrFloat("write_capacity", 5)

		units = []clouds.CostUnit{
			// Read Capacity Units
			clouds.NewCostUnit(
				"read_capacity",
				"RCU-hours",
				readCapacity*730, // RCUs * hours/month
				clouds.RateKey{
					Provider: providerID,
					Service:  "AmazonDynamoDB",
					Region:   region,
					Attributes: map[string]string{
						"usageType": "ReadCapacityUnit-Hrs",
					},
				},
				0.9,
			),

			// Write Capacity Units
			clouds.NewCostUnit(
				"write_capacity",
				"WCU-hours",
				writeCapacity*730,
				clouds.RateKey{
					Provider: providerID,
					Service:  "AmazonDynamoDB",
					Region:   region,
					Attributes: map[string]string{
						"usageType": "WriteCapacityUnit-Hrs",
					},
				},
				0.9,
			),
		}
	}

	// Storage (always charged)
	storageGB, _ := usageVecs.Get(clouds.MetricStorageGB)
	units = append(units, clouds.NewCostUnit(
		"storage",
		"GB-months",
		storageGB,
		clouds.RateKey{
			Provider: providerID,
			Service:  "AmazonDynamoDB",
			Region:   region,
			Attributes: map[string]string{
				"usageType": "TimedStorage-ByteHrs",
			},
		},
		0.5, // Lower confidence - storage is usage-dependent
	))

	// Global tables (if replicas exist)
	if replicas := asset.AttrInt("replica.#", 0); replicas > 0 {
		// Each replica incurs additional write costs
		if billingMode != "PAY_PER_REQUEST" {
			writeCapacity := asset.AttrFloat("write_capacity", 5)
			for i := 0; i < replicas; i++ {
				units = append(units, clouds.NewCostUnit(
					"replica_write_capacity",
					"rWCU-hours",
					writeCapacity*730,
					clouds.RateKey{
						Provider: providerID,
						Service:  "AmazonDynamoDB",
						Region:   region, // Would be replica region
						Attributes: map[string]string{
							"usageType": "ReplicatedWriteCapacityUnit-Hrs",
						},
					},
					0.8,
				))
			}
		}
	}

	// Streams (if enabled)
	if streamEnabled := asset.Attr("stream_enabled"); streamEnabled == "true" {
		units = append(units, clouds.SymbolicCost(
			"streams",
			"stream read requests depend on consumer patterns",
		))
	}

	return units, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\database\elasticache.go
# TYPE: go
# SIZE: 4879 bytes
################################################################################
// Package database - AWS ElastiCache cost mapper
// Pricing model:
// - Node hours (by node type, engine)
// - Data transfer
// - Backup storage (beyond free tier)
package database

import (
	"terraform-cost/clouds"
)

// ElastiCacheMapper maps aws_elasticache_cluster to cost units
type ElastiCacheMapper struct{}

// NewElastiCacheMapper creates an ElastiCache mapper
func NewElastiCacheMapper() *ElastiCacheMapper {
	return &ElastiCacheMapper{}
}

// Cloud returns the cloud provider
func (m *ElastiCacheMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *ElastiCacheMapper) ResourceType() string {
	return "aws_elasticache_cluster"
}

// BuildUsage extracts usage vectors
func (m *ElastiCacheMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown cluster count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
	}, nil
}

// BuildCostUnits creates cost units
func (m *ElastiCacheMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("cache_nodes", "ElastiCache cost unknown"),
		}, nil
	}

	nodeType := asset.Attr("node_type")
	if nodeType == "" {
		nodeType = "cache.t3.micro"
	}

	engine := asset.Attr("engine")
	if engine == "" {
		engine = "redis"
	}

	numCacheNodes := asset.AttrInt("num_cache_nodes", 1)
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"cache_nodes",
			"node-hours",
			float64(numCacheNodes)*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonElastiCache",
				Region:   region,
				Attributes: map[string]string{
					"nodeType":   nodeType,
					"cacheEngine": engine,
					"usageType":  "NodeUsage:" + nodeType,
				},
			},
			0.95,
		),
	}, nil
}

// ElastiCacheReplicationGroupMapper maps aws_elasticache_replication_group
type ElastiCacheReplicationGroupMapper struct{}

// NewElastiCacheReplicationGroupMapper creates mapper
func NewElastiCacheReplicationGroupMapper() *ElastiCacheReplicationGroupMapper {
	return &ElastiCacheReplicationGroupMapper{}
}

// Cloud returns the cloud provider
func (m *ElastiCacheReplicationGroupMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *ElastiCacheReplicationGroupMapper) ResourceType() string {
	return "aws_elasticache_replication_group"
}

// BuildUsage extracts usage vectors
func (m *ElastiCacheReplicationGroupMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown replication group: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
	}, nil
}

// BuildCostUnits creates cost units
func (m *ElastiCacheReplicationGroupMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("cache_nodes", "ElastiCache Replication Group cost unknown"),
		}, nil
	}

	nodeType := asset.Attr("node_type")
	if nodeType == "" {
		nodeType = "cache.t3.micro"
	}

	// Calculate total nodes
	numNodeGroups := asset.AttrInt("num_node_groups", 1)
	replicasPerGroup := asset.AttrInt("replicas_per_node_group", 1)
	totalNodes := numNodeGroups * (replicasPerGroup + 1) // +1 for primary

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"cache_nodes",
			"node-hours",
			float64(totalNodes)*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonElastiCache",
				Region:   region,
				Attributes: map[string]string{
					"nodeType":   nodeType,
					"cacheEngine": "redis",
					"usageType":  "NodeUsage:" + nodeType,
				},
			},
			0.95,
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\database\rds.go
# TYPE: go
# SIZE: 4953 bytes
################################################################################
// Package database - AWS RDS cost mapper
// Clean-room implementation based on RDS pricing model:
// - Instance hours (by instance class, engine, deployment type)
// - Storage (by storage type and size)
// - Provisioned IOPS (for io1)
// - Backup storage (beyond allocated)
// - Data transfer
package database

import (
	"terraform-cost/clouds"
)

// RDSMapper maps aws_db_instance to cost units
type RDSMapper struct{}

// NewRDSMapper creates an RDS mapper
func NewRDSMapper() *RDSMapper {
	return &RDSMapper{}
}

// Cloud returns the cloud provider
func (m *RDSMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *RDSMapper) ResourceType() string {
	return "aws_db_instance"
}

// BuildUsage extracts usage vectors from an RDS instance
func (m *RDSMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	// Check for unknown cardinality
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown RDS instance count: "+asset.Cardinality.Reason),
		}, nil
	}

	// RDS instances run 24/7 by default
	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
	}, nil
}

// BuildCostUnits creates cost units for an RDS instance
func (m *RDSMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	// Check for symbolic usage
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("instance", "RDS cost unknown due to cardinality"),
		}, nil
	}

	// Extract attributes
	instanceClass := asset.Attr("instance_class")
	if instanceClass == "" {
		instanceClass = "db.t3.micro"
	}

	engine := asset.Attr("engine")
	if engine == "" {
		engine = "mysql"
	}

	storageType := asset.Attr("storage_type")
	if storageType == "" {
		storageType = "gp2"
	}

	allocatedStorage := asset.AttrFloat("allocated_storage", 20)
	iops := asset.AttrFloat("iops", 0)
	multiAZ := asset.AttrBool("multi_az", false)

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	// Normalize engine for pricing
	engineFamily := normalizeEngine(engine)

	// Deployment option affects pricing
	deploymentOption := "Single-AZ"
	if multiAZ {
		deploymentOption = "Multi-AZ"
	}

	units := []clouds.CostUnit{
		// Instance
		clouds.NewCostUnit(
			"instance",
			"hours",
			monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRDS",
				Region:   region,
				Attributes: map[string]string{
					"instanceType":     instanceClass,
					"databaseEngine":   engineFamily,
					"deploymentOption": deploymentOption,
				},
			},
			0.95,
		),

		// Storage
		clouds.NewCostUnit(
			"storage",
			"GB-months",
			allocatedStorage,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRDS",
				Region:   region,
				Attributes: map[string]string{
					"volumeType":       storageType,
					"deploymentOption": deploymentOption,
					"usageType":        "RDS:GP2-Storage",
				},
			},
			0.95,
		),
	}

	// Provisioned IOPS for io1
	if storageType == "io1" && iops > 0 {
		units = append(units, clouds.NewCostUnit(
			"provisioned_iops",
			"IOPS-months",
			iops,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRDS",
				Region:   region,
				Attributes: map[string]string{
					"deploymentOption": deploymentOption,
					"usageType":        "RDS:PIOPS",
				},
			},
			0.95,
		))
	}

	// Backup storage (simplified: assume equal to allocated)
	backupRetention := asset.AttrInt("backup_retention_period", 1)
	if backupRetention > 0 {
		units = append(units, clouds.NewCostUnit(
			"backup_storage",
			"GB-months",
			allocatedStorage,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRDS",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "RDS:ChargedBackupUsage",
				},
			},
			0.7, // Lower confidence - actual backup size varies
		))
	}

	return units, nil
}

// normalizeEngine normalizes engine name for pricing
func normalizeEngine(engine string) string {
	switch engine {
	case "mysql":
		return "MySQL"
	case "postgres":
		return "PostgreSQL"
	case "mariadb":
		return "MariaDB"
	case "oracle-se", "oracle-se1", "oracle-se2", "oracle-ee":
		return "Oracle"
	case "sqlserver-ee", "sqlserver-se", "sqlserver-ex", "sqlserver-web":
		return "SQL Server"
	case "aurora", "aurora-mysql":
		return "Aurora MySQL"
	case "aurora-postgresql":
		return "Aurora PostgreSQL"
	default:
		return engine
	}
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\database\rds_cluster_instance.go
# TYPE: go
# SIZE: 1898 bytes
################################################################################
// Package database - AWS RDS Cluster Instance mapper
package database

import (
	"terraform-cost/clouds"
)

// RDSClusterInstanceMapper maps aws_rds_cluster_instance to cost units
type RDSClusterInstanceMapper struct{}

func NewRDSClusterInstanceMapper() *RDSClusterInstanceMapper { return &RDSClusterInstanceMapper{} }

func (m *RDSClusterInstanceMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *RDSClusterInstanceMapper) ResourceType() string        { return "aws_rds_cluster_instance" }

func (m *RDSClusterInstanceMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown instance count")}, nil
	}
	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricMonthlyHours, ctx.ResolveOrDefault("monthly_hours", 730), 0.95)}, nil
}

func (m *RDSClusterInstanceMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("aurora_instance", "instance count unknown")}, nil
	}

	instanceClass := asset.Attr("instance_class")
	if instanceClass == "" {
		instanceClass = "db.r5.large"
	}

	engine := asset.Attr("engine")
	if engine == "" {
		engine = "aurora-mysql"
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	return []clouds.CostUnit{
		clouds.NewCostUnit("instance", "hours", monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonRDS",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"instanceType":   instanceClass,
				"databaseEngine": normalizeAuroraEngine(engine),
			},
		}, 0.95),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\dns\route53.go
# TYPE: go
# SIZE: 4702 bytes
################################################################################
// Package dns - AWS Route53 cost mapper
// Pricing model:
// - Hosted zones: per zone per month
// - Queries: per million queries (varies by type)
// - Health checks: per endpoint per month
// - Traffic policies: per policy record
// - Resolver endpoints: per ENI per hour
package dns

import (
	"terraform-cost/clouds"
)

// HostedZoneMapper maps aws_route53_zone to cost units
type HostedZoneMapper struct{}

// NewHostedZoneMapper creates a Route53 Hosted Zone mapper
func NewHostedZoneMapper() *HostedZoneMapper {
	return &HostedZoneMapper{}
}

// Cloud returns the cloud provider
func (m *HostedZoneMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *HostedZoneMapper) ResourceType() string {
	return "aws_route53_zone"
}

// BuildUsage extracts usage vectors
func (m *HostedZoneMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage("zones", "unknown zone count: "+asset.Cardinality.Reason),
		}, nil
	}

	// Queries are usage-dependent
	queriesMillions := ctx.ResolveOrDefault("monthly_queries_millions", -1)

	vectors := []clouds.UsageVector{
		clouds.NewUsageVector("zones", 1, 1.0),
	}

	if queriesMillions >= 0 {
		vectors = append(vectors, clouds.NewUsageVector("queries_millions", queriesMillions, 0.5))
	} else {
		vectors = append(vectors, clouds.SymbolicUsage("queries_millions", "query volume not provided"))
	}

	return vectors, nil
}

// BuildCostUnits creates cost units
func (m *HostedZoneMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	providerID := asset.ProviderContext.ProviderID
	region := "global" // Route53 is global

	units := []clouds.CostUnit{
		// Hosted zone - $0.50/month (first 25 free)
		clouds.NewCostUnit(
			"hosted_zone",
			"zones",
			1,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRoute53",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "HostedZone",
				},
			},
			0.95,
		),
	}

	// Queries
	if queriesMillions, ok := usageVecs.Get("queries_millions"); ok {
		units = append(units, clouds.NewCostUnit(
			"queries",
			"million-queries",
			queriesMillions,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRoute53",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "DNS-Queries",
				},
			},
			0.5,
		))
	}

	return units, nil
}

// HealthCheckMapper maps aws_route53_health_check to cost units
type HealthCheckMapper struct{}

// NewHealthCheckMapper creates a Route53 Health Check mapper
func NewHealthCheckMapper() *HealthCheckMapper {
	return &HealthCheckMapper{}
}

// Cloud returns the cloud provider
func (m *HealthCheckMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *HealthCheckMapper) ResourceType() string {
	return "aws_route53_health_check"
}

// BuildUsage extracts usage vectors
func (m *HealthCheckMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage("health_checks", "unknown health check count"),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector("health_checks", 1, 1.0),
	}, nil
}

// BuildCostUnits creates cost units
func (m *HealthCheckMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("health_check", "health check cost unknown"),
		}, nil
	}

	providerID := asset.ProviderContext.ProviderID

	// Determine health check type
	healthCheckType := asset.Attr("type")
	if healthCheckType == "" {
		healthCheckType = "HTTP"
	}

	// HTTPS and string matching cost more
	usageType := "Health-Check-AWS"
	if healthCheckType == "HTTPS" || healthCheckType == "HTTPS_STR_MATCH" {
		usageType = "Health-Check-AWS-HTTPS"
	}

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"health_check",
			"endpoints",
			1,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonRoute53",
				Region:   "global",
				Attributes: map[string]string{
					"usageType":       usageType,
					"healthCheckType": healthCheckType,
				},
			},
			0.95,
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\messaging\sqs_sns.go
# TYPE: go
# SIZE: 4774 bytes
################################################################################
// Package messaging - AWS SQS/SNS cost mapper
// SQS Pricing:
// - Requests: per million requests (Standard vs FIFO)
// - Data transfer: outbound
// SNS Pricing:
// - Publishes: per million
// - Deliveries: per protocol (HTTP, Email, SMS, Lambda)
// - Data transfer: outbound
package messaging

import (
	"terraform-cost/clouds"
)

// SQSMapper maps aws_sqs_queue to cost units
type SQSMapper struct{}

// NewSQSMapper creates an SQS mapper
func NewSQSMapper() *SQSMapper {
	return &SQSMapper{}
}

// Cloud returns the cloud provider
func (m *SQSMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *SQSMapper) ResourceType() string {
	return "aws_sqs_queue"
}

// BuildUsage extracts usage vectors
func (m *SQSMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyRequests, "unknown queue count: "+asset.Cardinality.Reason),
		}, nil
	}

	// SQS is HIGHLY usage-dependent
	monthlyRequests := ctx.ResolveOrDefault("monthly_requests", -1)

	if monthlyRequests < 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyRequests, "monthly SQS requests not provided"),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyRequests, monthlyRequests, 0.5),
	}, nil
}

// BuildCostUnits creates cost units
func (m *SQSMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("sqs_requests", "SQS cost requires request volume"),
		}, nil
	}

	monthlyRequests, _ := usageVecs.Get(clouds.MetricMonthlyRequests)

	// FIFO queues cost more
	isFIFO := asset.AttrBool("fifo_queue", false)
	queueType := "Standard"
	if isFIFO {
		queueType = "FIFO"
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"requests",
			"million-requests",
			monthlyRequests/1000000,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonSQS",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "Requests",
					"queueType": queueType,
				},
			},
			0.5,
		),
	}, nil
}

// SNSMapper maps aws_sns_topic to cost units
type SNSMapper struct{}

// NewSNSMapper creates an SNS mapper
func NewSNSMapper() *SNSMapper {
	return &SNSMapper{}
}

// Cloud returns the cloud provider
func (m *SNSMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *SNSMapper) ResourceType() string {
	return "aws_sns_topic"
}

// BuildUsage extracts usage vectors
func (m *SNSMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage("publishes", "unknown topic count: "+asset.Cardinality.Reason),
		}, nil
	}

	// SNS is HIGHLY usage-dependent
	monthlyPublishes := ctx.ResolveOrDefault("monthly_publishes", -1)

	if monthlyPublishes < 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage("publishes", "monthly SNS publishes not provided"),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector("publishes", monthlyPublishes, 0.5),
	}, nil
}

// BuildCostUnits creates cost units
func (m *SNSMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("sns_publishes", "SNS cost requires publish volume"),
		}, nil
	}

	monthlyPublishes, _ := usageVecs.Get("publishes")

	// FIFO topics cost more
	isFIFO := asset.AttrBool("fifo_topic", false)
	topicType := "Standard"
	if isFIFO {
		topicType = "FIFO"
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"publishes",
			"million-publishes",
			monthlyPublishes/1000000,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonSNS",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "PublishAPI-Requests",
					"topicType": topicType,
				},
			},
			0.5,
		),
		// Deliveries depend on subscriber types - symbolic
		clouds.SymbolicCost("deliveries", "delivery cost depends on subscriber protocols"),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\monitoring\cloudtrail.go
# TYPE: go
# SIZE: 1989 bytes
################################################################################
// Package monitoring - AWS CloudTrail mapper
package monitoring

import (
	"terraform-cost/clouds"
)

// CloudTrailMapper maps aws_cloudtrail to cost units
type CloudTrailMapper struct{}

func NewCloudTrailMapper() *CloudTrailMapper { return &CloudTrailMapper{} }

func (m *CloudTrailMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *CloudTrailMapper) ResourceType() string        { return "aws_cloudtrail" }

func (m *CloudTrailMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage("trails", "unknown trail count")}, nil
	}

	eventsPerMonth := ctx.ResolveOrDefault("events_per_month", -1)
	if eventsPerMonth < 0 {
		return []clouds.UsageVector{clouds.SymbolicUsage("events", "event volume not provided")}, nil
	}

	return []clouds.UsageVector{clouds.NewUsageVector("events", eventsPerMonth, 0.5)}, nil
}

func (m *CloudTrailMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("cloudtrail", "CloudTrail cost depends on event volume"),
		}, nil
	}

	events, _ := usageVecs.Get("events")

	isMultiRegion := asset.AttrBool("is_multi_region_trail", false)
	includeDataEvents := asset.AttrBool("include_global_service_events", false)

	var notes string
	if isMultiRegion {
		notes = "multi-region"
	}
	if includeDataEvents {
		notes += " with data events"
	}

	return []clouds.CostUnit{
		clouds.NewCostUnit("events", "100k-events", events/100000, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSCloudTrail",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "DataEventsRecorded",
				"notes":     notes,
			},
		}, 0.5),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\networking\endpoints.go
# TYPE: go
# SIZE: 8684 bytes
################################################################################
// Package networking - AWS EIP, VPC Endpoint, VPN mappers
package networking

import (
	"terraform-cost/clouds"
)

// EIPMapper maps aws_eip to cost units
type EIPMapper struct{}

func NewEIPMapper() *EIPMapper { return &EIPMapper{} }

func (m *EIPMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *EIPMapper) ResourceType() string        { return "aws_eip" }

func (m *EIPMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown EIP count")}, nil
	}
	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricMonthlyHours, 730, 0.95)}, nil
}

func (m *EIPMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("eip", "EIP count unknown")}, nil
	}

	// Unattached EIPs cost money, attached ones are free (pre-2024)
	// Post Feb 2024, all EIPs cost $0.005/hour
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	return []clouds.CostUnit{
		clouds.NewCostUnit("eip", "hours", monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonEC2",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "ElasticIP:IdleAddress",
			},
		}, 0.95),
	}, nil
}

// VPCEndpointMapper maps aws_vpc_endpoint to cost units
type VPCEndpointMapper struct{}

func NewVPCEndpointMapper() *VPCEndpointMapper { return &VPCEndpointMapper{} }

func (m *VPCEndpointMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *VPCEndpointMapper) ResourceType() string        { return "aws_vpc_endpoint" }

func (m *VPCEndpointMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown endpoint count")}, nil
	}
	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, 730, 0.95),
		clouds.NewUsageVector("data_processed_gb", ctx.ResolveOrDefault("data_processed_gb", 0), 0.5),
	}, nil
}

func (m *VPCEndpointMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("vpc_endpoint", "endpoint count unknown")}, nil
	}

	vpcEndpointType := asset.Attr("vpc_endpoint_type")
	if vpcEndpointType == "" {
		vpcEndpointType = "Gateway"
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)
	dataProcessed, _ := usageVecs.Get("data_processed_gb")

	var units []clouds.CostUnit

	// Gateway endpoints are free, Interface endpoints cost per hour + data
	if vpcEndpointType == "Interface" {
		units = append(units, clouds.NewCostUnit("endpoint_hours", "hours", monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonVPC",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "VpcEndpoint-Hours",
			},
		}, 0.95))

		if dataProcessed > 0 {
			units = append(units, clouds.NewCostUnit("data_processed", "GB", dataProcessed, clouds.RateKey{
				Provider: asset.ProviderContext.ProviderID,
				Service:  "AmazonVPC",
				Region:   asset.ProviderContext.Region,
				Attributes: map[string]string{
					"usageType": "VpcEndpoint-Bytes",
				},
			}, 0.5))
		}
	}

	if len(units) == 0 {
		return []clouds.CostUnit{clouds.SymbolicCost("gateway_endpoint", "Gateway endpoints are free")}, nil
	}

	return units, nil
}

// VPNConnectionMapper maps aws_vpn_connection to cost units
type VPNConnectionMapper struct{}

func NewVPNConnectionMapper() *VPNConnectionMapper { return &VPNConnectionMapper{} }

func (m *VPNConnectionMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *VPNConnectionMapper) ResourceType() string        { return "aws_vpn_connection" }

func (m *VPNConnectionMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown VPN count")}, nil
	}
	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricMonthlyHours, 730, 0.95)}, nil
}

func (m *VPNConnectionMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("vpn", "VPN count unknown")}, nil
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	return []clouds.CostUnit{
		clouds.NewCostUnit("vpn_connection", "hours", monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonVPC",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "VPN-Connection-Hours",
			},
		}, 0.95),
	}, nil
}

// DXConnectionMapper maps aws_dx_connection to cost units
type DXConnectionMapper struct{}

func NewDXConnectionMapper() *DXConnectionMapper { return &DXConnectionMapper{} }

func (m *DXConnectionMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *DXConnectionMapper) ResourceType() string        { return "aws_dx_connection" }

func (m *DXConnectionMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown DX count")}, nil
	}
	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricMonthlyHours, 730, 0.95)}, nil
}

func (m *DXConnectionMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("direct_connect", "DX count unknown")}, nil
	}

	bandwidth := asset.Attr("bandwidth")
	if bandwidth == "" {
		bandwidth = "1Gbps"
	}
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	return []clouds.CostUnit{
		clouds.NewCostUnit("port_hours", "hours", monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSDirectConnect",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"bandwidth": bandwidth,
				"usageType": "PortUsage:" + bandwidth,
			},
		}, 0.95),
	}, nil
}

// CLBMapper maps aws_elb (Classic Load Balancer) to cost units
type CLBMapper struct{}

func NewCLBMapper() *CLBMapper { return &CLBMapper{} }

func (m *CLBMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *CLBMapper) ResourceType() string        { return "aws_elb" }

func (m *CLBMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown ELB count")}, nil
	}
	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, 730, 0.95),
		clouds.NewUsageVector("data_processed_gb", ctx.ResolveOrDefault("data_processed_gb", 0), 0.5),
	}, nil
}

func (m *CLBMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("clb", "ELB count unknown")}, nil
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)
	dataProcessed, _ := usageVecs.Get("data_processed_gb")

	units := []clouds.CostUnit{
		clouds.NewCostUnit("clb_hours", "hours", monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSELB",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "LoadBalancerUsage",
			},
		}, 0.95),
	}

	if dataProcessed > 0 {
		units = append(units, clouds.NewCostUnit("data_processed", "GB", dataProcessed, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSELB",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "DataProcessing-Bytes",
			},
		}, 0.5))
	}

	return units, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\networking\lb.go
# TYPE: go
# SIZE: 3063 bytes
################################################################################
// Package networking - AWS Load Balancer cost mapper
// Pricing model:
// - Hourly charge
// - LCU charge (ALB/NLB) or data processed (Classic)
// Types: ALB, NLB, GLB, Classic ELB
package networking

import (
	"terraform-cost/clouds"
)

// LBMapper maps aws_lb to cost units
type LBMapper struct{}

// NewLBMapper creates a Load Balancer mapper
func NewLBMapper() *LBMapper {
	return &LBMapper{}
}

// Cloud returns the cloud provider
func (m *LBMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *LBMapper) ResourceType() string {
	return "aws_lb"
}

// BuildUsage extracts usage vectors
func (m *LBMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown LB count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	// LCU usage is highly variable
	lcuCount := ctx.ResolveOrDefault("lcu_count", 1)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
		clouds.NewUsageVector("lcu_count", lcuCount, 0.5),
	}, nil
}

// BuildCostUnits creates cost units
func (m *LBMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("load_balancer", "LB cost unknown due to cardinality"),
		}, nil
	}

	lbType := asset.Attr("load_balancer_type")
	if lbType == "" {
		lbType = "application"
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)
	lcuCount, _ := usageVecs.Get("lcu_count")

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	// Determine rate key based on LB type
	var usageTypeHourly, usageTypeLCU string
	switch lbType {
	case "network":
		usageTypeHourly = "LoadBalancerUsage"
		usageTypeLCU = "LCUUsage"
	case "gateway":
		usageTypeHourly = "LoadBalancerUsage"
		usageTypeLCU = "LCUUsage"
	default: // application
		usageTypeHourly = "LoadBalancerUsage"
		usageTypeLCU = "LCUUsage"
	}

	return []clouds.CostUnit{
		// Hourly charge
		clouds.NewCostUnit(
			"hourly",
			"hours",
			monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AWSELB",
				Region:   region,
				Attributes: map[string]string{
					"usageType":        usageTypeHourly,
					"loadBalancerType": lbType,
				},
			},
			0.95,
		),
		// LCU charge
		clouds.NewCostUnit(
			"lcu",
			"LCU-hours",
			lcuCount*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AWSELB",
				Region:   region,
				Attributes: map[string]string{
					"usageType":        usageTypeLCU,
					"loadBalancerType": lbType,
				},
			},
			0.5, // LCU is usage-dependent
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\networking\nat_gateway.go
# TYPE: go
# SIZE: 2592 bytes
################################################################################
// Package networking - AWS NAT Gateway cost mapper
// Pricing model:
// - Hourly charge per NAT Gateway
// - Data processing charge per GB
package networking

import (
	"terraform-cost/clouds"
)

// NATGatewayMapper maps aws_nat_gateway to cost units
type NATGatewayMapper struct{}

// NewNATGatewayMapper creates a NAT Gateway mapper
func NewNATGatewayMapper() *NATGatewayMapper {
	return &NATGatewayMapper{}
}

// Cloud returns the cloud provider
func (m *NATGatewayMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *NATGatewayMapper) ResourceType() string {
	return "aws_nat_gateway"
}

// BuildUsage extracts usage vectors
func (m *NATGatewayMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown NAT Gateway count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)
	dataProcessedGB := ctx.ResolveOrDefault("data_processed_gb", 100)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
		clouds.NewUsageVector(clouds.MetricDataTransferGB, dataProcessedGB, 0.5),
	}, nil
}

// BuildCostUnits creates cost units
func (m *NATGatewayMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("nat_gateway", "NAT Gateway cost unknown due to cardinality"),
		}, nil
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)
	dataProcessedGB, _ := usageVecs.Get(clouds.MetricDataTransferGB)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		// Hourly charge
		clouds.NewCostUnit(
			"hourly",
			"hours",
			monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEC2",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "NatGateway-Hours",
				},
			},
			0.95,
		),
		// Data processing
		clouds.NewCostUnit(
			"data_processed",
			"GB",
			dataProcessedGB,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEC2",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "NatGateway-Bytes",
				},
			},
			0.5,
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\observability\cloudwatch.go
# TYPE: go
# SIZE: 4832 bytes
################################################################################
// Package observability - AWS CloudWatch cost mapper
// Pricing model:
// - Log ingestion per GB
// - Log storage per GB-month
// - Metrics (custom metrics, high-res)
// - Alarms per metric
// - Dashboards
package observability

import (
	"terraform-cost/clouds"
)

// CloudWatchLogGroupMapper maps aws_cloudwatch_log_group to cost units
type CloudWatchLogGroupMapper struct{}

// NewCloudWatchLogGroupMapper creates a CloudWatch Log Group mapper
func NewCloudWatchLogGroupMapper() *CloudWatchLogGroupMapper {
	return &CloudWatchLogGroupMapper{}
}

// Cloud returns the cloud provider
func (m *CloudWatchLogGroupMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *CloudWatchLogGroupMapper) ResourceType() string {
	return "aws_cloudwatch_log_group"
}

// BuildUsage extracts usage vectors
func (m *CloudWatchLogGroupMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	// Log groups are HIGHLY usage-dependent
	// Without explicit usage data, we return symbolic
	ingestionGB := ctx.ResolveOrDefault("monthly_ingestion_gb", -1)
	storageGB := ctx.ResolveOrDefault("storage_gb", -1)

	if ingestionGB < 0 || storageGB < 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricStorageGB, "log ingestion/storage usage not provided"),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector("ingestion_gb", ingestionGB, 0.5),
		clouds.NewUsageVector(clouds.MetricStorageGB, storageGB, 0.5),
	}, nil
}

// BuildCostUnits creates cost units
func (m *CloudWatchLogGroupMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("logs", "CloudWatch Logs cost requires usage data"),
		}, nil
	}

	ingestionGB, _ := usageVecs.Get("ingestion_gb")
	storageGB, _ := usageVecs.Get(clouds.MetricStorageGB)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		// Log ingestion
		clouds.NewCostUnit(
			"ingestion",
			"GB",
			ingestionGB,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonCloudWatch",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "DataProcessing-Bytes",
				},
			},
			0.5,
		),
		// Log storage
		clouds.NewCostUnit(
			"storage",
			"GB-months",
			storageGB,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonCloudWatch",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "TimedStorage-ByteHrs",
				},
			},
			0.5,
		),
	}, nil
}

// CloudWatchMetricAlarmMapper maps aws_cloudwatch_metric_alarm to cost units
type CloudWatchMetricAlarmMapper struct{}

// NewCloudWatchMetricAlarmMapper creates a CloudWatch Alarm mapper
func NewCloudWatchMetricAlarmMapper() *CloudWatchMetricAlarmMapper {
	return &CloudWatchMetricAlarmMapper{}
}

// Cloud returns the cloud provider
func (m *CloudWatchMetricAlarmMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *CloudWatchMetricAlarmMapper) ResourceType() string {
	return "aws_cloudwatch_metric_alarm"
}

// BuildUsage extracts usage vectors
func (m *CloudWatchMetricAlarmMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage("alarm_count", "unknown alarm count: "+asset.Cardinality.Reason),
		}, nil
	}

	// One alarm per resource
	return []clouds.UsageVector{
		clouds.NewUsageVector("alarm_count", 1, 1.0),
	}, nil
}

// BuildCostUnits creates cost units
func (m *CloudWatchMetricAlarmMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("alarm", "CloudWatch Alarm cost unknown"),
		}, nil
	}

	// Determine alarm type (standard vs high-res)
	period := asset.AttrInt("period", 60)
	alarmType := "standard"
	if period < 60 {
		alarmType = "high_resolution"
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"alarm",
			"alarms",
			1,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonCloudWatch",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "AlarmMonitorUsage",
					"alarmType": alarmType,
				},
			},
			0.95,
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\pricing\source.go
# TYPE: go
# SIZE: 7230 bytes
################################################################################
// Package pricing provides AWS pricing source.
package pricing

import (
	"context"
	"fmt"
	"time"

	"github.com/shopspring/decimal"

	corePricing "terraform-cost/core/pricing"
	"terraform-cost/core/types"
)

// AWSPricingSource fetches pricing from AWS Pricing API
type AWSPricingSource struct {
	defaultRegion string
	// In production, this would use the AWS SDK
	// client *pricing.Client
}

// NewAWSPricingSource creates a new AWS pricing source
func NewAWSPricingSource(region string) corePricing.Source {
	return &AWSPricingSource{
		defaultRegion: region,
	}
}

// Provider returns AWS
func (s *AWSPricingSource) Provider() types.Provider {
	return types.ProviderAWS
}

// FetchRates retrieves rates for the given keys
func (s *AWSPricingSource) FetchRates(ctx context.Context, keys []types.RateKey) ([]types.Rate, error) {
	rates := make([]types.Rate, 0, len(keys))

	for _, key := range keys {
		rate, err := s.fetchRate(ctx, key)
		if err != nil {
			continue // Skip missing rates
		}
		rates = append(rates, rate)
	}

	return rates, nil
}

// FetchAll retrieves all rates for a region
func (s *AWSPricingSource) FetchAll(ctx context.Context, region string) ([]types.Rate, error) {
	// In production, this would call the AWS Pricing API
	// For now, return common defaults
	return s.getDefaultRates(region), nil
}

// SupportedRegions returns the list of supported AWS regions
func (s *AWSPricingSource) SupportedRegions() []string {
	return []string{
		"us-east-1", "us-east-2", "us-west-1", "us-west-2",
		"eu-west-1", "eu-west-2", "eu-west-3", "eu-central-1",
		"ap-northeast-1", "ap-northeast-2", "ap-southeast-1", "ap-southeast-2",
		"ap-south-1", "sa-east-1", "ca-central-1",
	}
}

func (s *AWSPricingSource) fetchRate(ctx context.Context, key types.RateKey) (types.Rate, error) {
	// In production, this would call the AWS Pricing API
	// For now, return hardcoded defaults for common resources

	switch key.Service {
	case "EC2":
		return s.getEC2Rate(key)
	case "RDS":
		return s.getRDSRate(key)
	case "S3":
		return s.getS3Rate(key)
	case "Lambda":
		return s.getLambdaRate(key)
	case "NAT Gateway":
		return s.getNATGatewayRate(key)
	case "EBS":
		return s.getEBSRate(key)
	default:
		return types.Rate{}, fmt.Errorf("unknown service: %s", key.Service)
	}
}

func (s *AWSPricingSource) getEC2Rate(key types.RateKey) (types.Rate, error) {
	// Instance type pricing (On-Demand, us-east-1)
	instancePricing := map[string]float64{
		"t3.micro":    0.0104,
		"t3.small":    0.0208,
		"t3.medium":   0.0416,
		"t3.large":    0.0832,
		"t3.xlarge":   0.1664,
		"t3.2xlarge":  0.3328,
		"m5.large":    0.096,
		"m5.xlarge":   0.192,
		"m5.2xlarge":  0.384,
		"m5.4xlarge":  0.768,
		"c5.large":    0.085,
		"c5.xlarge":   0.17,
		"c5.2xlarge":  0.34,
		"r5.large":    0.126,
		"r5.xlarge":   0.252,
		"r5.2xlarge":  0.504,
	}

	instanceType := key.Attributes["instance_type"]
	price, ok := instancePricing[instanceType]
	if !ok {
		price = 0.10 // Default
	}

	return types.Rate{
		Key:           key,
		Price:         decimal.NewFromFloat(price),
		Unit:          "hour",
		Currency:      types.CurrencyUSD,
		EffectiveFrom: time.Now().AddDate(0, -1, 0),
	}, nil
}

func (s *AWSPricingSource) getRDSRate(key types.RateKey) (types.Rate, error) {
	// RDS instance pricing (Single-AZ, us-east-1)
	instancePricing := map[string]float64{
		"db.t3.micro":   0.017,
		"db.t3.small":   0.034,
		"db.t3.medium":  0.068,
		"db.t3.large":   0.136,
		"db.m5.large":   0.171,
		"db.m5.xlarge":  0.342,
		"db.m5.2xlarge": 0.684,
		"db.r5.large":   0.24,
		"db.r5.xlarge":  0.48,
		"db.r5.2xlarge": 0.96,
	}

	instanceClass := key.Attributes["instance_class"]
	price, ok := instancePricing[instanceClass]
	if !ok {
		price = 0.10 // Default
	}

	return types.Rate{
		Key:           key,
		Price:         decimal.NewFromFloat(price),
		Unit:          "hour",
		Currency:      types.CurrencyUSD,
		EffectiveFrom: time.Now().AddDate(0, -1, 0),
	}, nil
}

func (s *AWSPricingSource) getS3Rate(key types.RateKey) (types.Rate, error) {
	// S3 pricing (Standard, us-east-1)
	storageClass := key.Attributes["storage_class"]
	if storageClass == "" {
		storageClass = "STANDARD"
	}

	prices := map[string]float64{
		"STANDARD":            0.023,  // per GB-month
		"STANDARD_IA":         0.0125,
		"ONEZONE_IA":          0.01,
		"GLACIER":             0.004,
		"GLACIER_DEEP_ARCHIVE": 0.00099,
	}

	price, ok := prices[storageClass]
	if !ok {
		price = 0.023
	}

	return types.Rate{
		Key:           key,
		Price:         decimal.NewFromFloat(price),
		Unit:          "GB-month",
		Currency:      types.CurrencyUSD,
		EffectiveFrom: time.Now().AddDate(0, -1, 0),
	}, nil
}

func (s *AWSPricingSource) getLambdaRate(key types.RateKey) (types.Rate, error) {
	// Lambda is priced per GB-second and per request
	rateType := key.Attributes["rate_type"]

	switch rateType {
	case "requests":
		return types.Rate{
			Key:           key,
			Price:         decimal.NewFromFloat(0.0000002), // $0.20 per 1M requests
			Unit:          "request",
			Currency:      types.CurrencyUSD,
			EffectiveFrom: time.Now().AddDate(0, -1, 0),
		}, nil
	case "duration":
		return types.Rate{
			Key:           key,
			Price:         decimal.NewFromFloat(0.0000166667), // per GB-second
			Unit:          "GB-second",
			Currency:      types.CurrencyUSD,
			EffectiveFrom: time.Now().AddDate(0, -1, 0),
		}, nil
	default:
		return types.Rate{}, fmt.Errorf("unknown Lambda rate type")
	}
}

func (s *AWSPricingSource) getNATGatewayRate(key types.RateKey) (types.Rate, error) {
	rateType := key.Attributes["rate_type"]

	switch rateType {
	case "hourly":
		return types.Rate{
			Key:           key,
			Price:         decimal.NewFromFloat(0.045), // per hour
			Unit:          "hour",
			Currency:      types.CurrencyUSD,
			EffectiveFrom: time.Now().AddDate(0, -1, 0),
		}, nil
	case "data":
		return types.Rate{
			Key:           key,
			Price:         decimal.NewFromFloat(0.045), // per GB processed
			Unit:          "GB",
			Currency:      types.CurrencyUSD,
			EffectiveFrom: time.Now().AddDate(0, -1, 0),
		}, nil
	default:
		return types.Rate{}, fmt.Errorf("unknown NAT Gateway rate type")
	}
}

func (s *AWSPricingSource) getEBSRate(key types.RateKey) (types.Rate, error) {
	// EBS pricing per GB-month
	volumeType := key.Attributes["volume_type"]

	prices := map[string]float64{
		"gp3":      0.08,
		"gp2":      0.10,
		"io1":      0.125,
		"io2":      0.125,
		"st1":      0.045,
		"sc1":      0.015,
		"standard": 0.05,
	}

	price, ok := prices[volumeType]
	if !ok {
		price = 0.10
	}

	return types.Rate{
		Key:           key,
		Price:         decimal.NewFromFloat(price),
		Unit:          "GB-month",
		Currency:      types.CurrencyUSD,
		EffectiveFrom: time.Now().AddDate(0, -1, 0),
	}, nil
}

func (s *AWSPricingSource) getDefaultRates(region string) []types.Rate {
	// Return a set of common default rates
	// In production, this would be fetched from AWS
	return []types.Rate{}
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\secrets\secrets_manager.go
# TYPE: go
# SIZE: 2632 bytes
################################################################################
// Package secrets - AWS Secrets Manager cost mapper
// Pricing model:
// - Secret storage: per secret per month
// - API calls: per 10,000 API calls
package secrets

import (
	"terraform-cost/clouds"
)

// SecretsManagerMapper maps aws_secretsmanager_secret to cost units
type SecretsManagerMapper struct{}

// NewSecretsManagerMapper creates a Secrets Manager mapper
func NewSecretsManagerMapper() *SecretsManagerMapper {
	return &SecretsManagerMapper{}
}

// Cloud returns the cloud provider
func (m *SecretsManagerMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *SecretsManagerMapper) ResourceType() string {
	return "aws_secretsmanager_secret"
}

// BuildUsage extracts usage vectors
func (m *SecretsManagerMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage("secrets", "unknown secret count: "+asset.Cardinality.Reason),
		}, nil
	}

	// API calls are usage-dependent
	monthlyAPICalls := ctx.ResolveOrDefault("monthly_api_calls", -1)

	vectors := []clouds.UsageVector{
		clouds.NewUsageVector("secrets", 1, 1.0),
	}

	if monthlyAPICalls >= 0 {
		vectors = append(vectors, clouds.NewUsageVector("api_calls", monthlyAPICalls, 0.5))
	} else {
		vectors = append(vectors, clouds.SymbolicUsage("api_calls", "API call volume not provided"))
	}

	return vectors, nil
}

// BuildCostUnits creates cost units
func (m *SecretsManagerMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	units := []clouds.CostUnit{
		// Per secret per month ($0.40/secret/month)
		clouds.NewCostUnit(
			"secret_storage",
			"secrets",
			1,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AWSSecretsManager",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "SecretsManager-Secret",
				},
			},
			0.95,
		),
	}

	// API calls ($0.05 per 10,000)
	if apiCalls, ok := usageVecs.Get("api_calls"); ok {
		units = append(units, clouds.NewCostUnit(
			"api_calls",
			"10k-calls",
			apiCalls/10000,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AWSSecretsManager",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "SecretsManager-API",
				},
			},
			0.5,
		))
	}

	return units, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\security\waf.go
# TYPE: go
# SIZE: 2843 bytes
################################################################################
// Package security - AWS WAF mappers
package security

import (
	"terraform-cost/clouds"
)

// WAFWebACLMapper maps aws_waf_web_acl to cost units
type WAFWebACLMapper struct{}

func NewWAFWebACLMapper() *WAFWebACLMapper { return &WAFWebACLMapper{} }

func (m *WAFWebACLMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *WAFWebACLMapper) ResourceType() string        { return "aws_waf_web_acl" }

func (m *WAFWebACLMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage("web_acls", "unknown ACL count")}, nil
	}

	requestsMillions := ctx.ResolveOrDefault("requests_millions", -1)
	if requestsMillions < 0 {
		return []clouds.UsageVector{
			clouds.NewUsageVector("web_acls", 1, 1.0),
			clouds.SymbolicUsage(clouds.MetricMonthlyRequests, "WAF request volume not provided"),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector("web_acls", 1, 1.0),
		clouds.NewUsageVector("requests_millions", requestsMillions, 0.5),
	}, nil
}

func (m *WAFWebACLMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	units := []clouds.CostUnit{
		// Web ACL monthly cost
		clouds.NewCostUnit("web_acl", "ACLs", 1, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSWAF",
			Region:   "global",
			Attributes: map[string]string{
				"usageType": "WebACL",
			},
		}, 0.95),
	}

	// Request cost if available
	if requestsMillions, ok := usageVecs.Get("requests_millions"); ok {
		units = append(units, clouds.NewCostUnit("requests", "million-requests", requestsMillions, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSWAF",
			Region:   "global",
			Attributes: map[string]string{
				"usageType": "Request",
			},
		}, 0.5))
	} else {
		units = append(units, clouds.SymbolicCost("requests", "WAF request cost depends on traffic volume"))
	}

	return units, nil
}

// WAFv2WebACLMapper maps aws_wafv2_web_acl to cost units
type WAFv2WebACLMapper struct{}

func NewWAFv2WebACLMapper() *WAFv2WebACLMapper { return &WAFv2WebACLMapper{} }

func (m *WAFv2WebACLMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *WAFv2WebACLMapper) ResourceType() string        { return "aws_wafv2_web_acl" }

func (m *WAFv2WebACLMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	return (&WAFWebACLMapper{}).BuildUsage(asset, ctx)
}

func (m *WAFv2WebACLMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	return (&WAFWebACLMapper{}).BuildCostUnits(asset, usage)
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\serverless\lambda.go
# TYPE: go
# SIZE: 4447 bytes
################################################################################
// Package serverless - AWS Lambda cost mapper
// Clean-room implementation based on Lambda pricing model:
// - Requests (per 1M requests)
// - Duration (per GB-second)
// - Provisioned concurrency (per GB-hour)
// - Ephemeral storage (above 512MB baseline)
// - Architecture affects pricing (x86 vs ARM)
package serverless

import (
	"terraform-cost/clouds"
)

// LambdaMapper maps aws_lambda_function to cost units
type LambdaMapper struct{}

// NewLambdaMapper creates a Lambda mapper
func NewLambdaMapper() *LambdaMapper {
	return &LambdaMapper{}
}

// Cloud returns the cloud provider
func (m *LambdaMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *LambdaMapper) ResourceType() string {
	return "aws_lambda_function"
}

// BuildUsage extracts usage vectors from a Lambda function
func (m *LambdaMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	// Check for unknown cardinality
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyRequests, "unknown function count: "+asset.Cardinality.Reason),
		}, nil
	}

	// Lambda costs are highly usage-dependent
	// Request count and duration are not in Terraform config
	monthlyRequests := ctx.ResolveOrDefault("monthly_requests", 1000000)
	avgDurationMs := ctx.ResolveOrDefault("average_duration_ms", 100)

	// Lower confidence because these are estimates
	confidence := ctx.Confidence
	if confidence == 0 {
		confidence = 0.5
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyRequests, monthlyRequests, confidence),
		clouds.NewUsageVector("average_duration_ms", avgDurationMs, confidence),
	}, nil
}

// BuildCostUnits creates cost units for a Lambda function
func (m *LambdaMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	// Check for symbolic usage
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("requests", "Lambda cost unknown due to cardinality"),
		}, nil
	}

	// Extract attributes
	memorySize := asset.AttrFloat("memory_size", 128)

	// Architecture affects pricing (ARM is ~20% cheaper)
	architecture := asset.Attr("architectures.0")
	if architecture == "" {
		architecture = "x86_64"
	}

	// Get usage values
	monthlyRequests, _ := usageVecs.Get(clouds.MetricMonthlyRequests)
	avgDurationMs, _ := usageVecs.Get("average_duration_ms")

	// Calculate GB-seconds
	// GB-seconds = requests * (duration in seconds) * (memory in GB)
	gbSeconds := monthlyRequests * (avgDurationMs / 1000) * (memorySize / 1024)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	// Determine pricing tier based on architecture
	durationUsageType := "Lambda-GB-Second"
	if architecture == "arm64" {
		durationUsageType = "Lambda-GB-Second-ARM"
	}

	units := []clouds.CostUnit{
		// Requests (first 1M free, then $0.20 per 1M)
		clouds.NewCostUnit(
			"requests",
			"requests",
			monthlyRequests,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AWSLambda",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "Request",
				},
			},
			0.5,
		),

		// Duration (first 400K GB-seconds free)
		clouds.NewCostUnit(
			"duration",
			"GB-seconds",
			gbSeconds,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AWSLambda",
				Region:   region,
				Attributes: map[string]string{
					"usageType":    durationUsageType,
					"architecture": architecture,
				},
			},
			0.5,
		),
	}

	// Ephemeral storage (above 512MB baseline)
	ephemeralStorage := asset.AttrFloat("ephemeral_storage.0.size", 512)
	if ephemeralStorage > 512 {
		extraStorageMB := ephemeralStorage - 512
		// Storage-duration in GB-seconds
		storageGBSeconds := monthlyRequests * (avgDurationMs / 1000) * (extraStorageMB / 1024)

		units = append(units, clouds.NewCostUnit(
			"ephemeral_storage",
			"GB-seconds",
			storageGBSeconds,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AWSLambda",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "Lambda-Provisioned-GB-Second",
				},
			},
			0.5,
		))
	}

	return units, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\serverless\lambda_provisioned.go
# TYPE: go
# SIZE: 2166 bytes
################################################################################
// Package serverless - AWS Lambda Provisioned Concurrency mapper
package serverless

import (
	"terraform-cost/clouds"
)

// LambdaProvisionedConcurrencyMapper maps aws_lambda_provisioned_concurrency_config
type LambdaProvisionedConcurrencyMapper struct{}

func NewLambdaProvisionedConcurrencyMapper() *LambdaProvisionedConcurrencyMapper {
	return &LambdaProvisionedConcurrencyMapper{}
}

func (m *LambdaProvisionedConcurrencyMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *LambdaProvisionedConcurrencyMapper) ResourceType() string {
	return "aws_lambda_provisioned_concurrency_config"
}

func (m *LambdaProvisionedConcurrencyMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown concurrency config count")}, nil
	}
	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricMonthlyHours, 730, 0.95)}, nil
}

func (m *LambdaProvisionedConcurrencyMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("provisioned_concurrency", "concurrency count unknown")}, nil
	}

	provisionedCount := asset.AttrInt("provisioned_concurrent_executions", 1)
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	// Need memory size from referenced function (cross-resource)
	// For now, emit symbolic with count info
	return []clouds.CostUnit{
		clouds.SymbolicCost("provisioned_concurrency",
			"Provisioned concurrency cost requires function memory size. Provisioned: "+
				string(rune('0'+provisionedCount))),
		clouds.NewCostUnit("provisioned_hours", "concurrency-hours", float64(provisionedCount)*monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSLambda",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "Lambda-Provisioned-Concurrency",
			},
		}, 0.7),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\serverless\step_functions.go
# TYPE: go
# SIZE: 2100 bytes
################################################################################
// Package serverless - AWS Step Functions mapper
package serverless

import (
	"terraform-cost/clouds"
)

// StepFunctionsMapper maps aws_sfn_state_machine to cost units
type StepFunctionsMapper struct{}

func NewStepFunctionsMapper() *StepFunctionsMapper { return &StepFunctionsMapper{} }

func (m *StepFunctionsMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *StepFunctionsMapper) ResourceType() string        { return "aws_sfn_state_machine" }

func (m *StepFunctionsMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage("state_machines", "unknown state machine count")}, nil
	}

	transitions := ctx.ResolveOrDefault("monthly_transitions", -1)
	if transitions < 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage("transitions", "Step Functions transitions not provided"),
		}, nil
	}

	return []clouds.UsageVector{clouds.NewUsageVector("transitions", transitions, 0.5)}, nil
}

func (m *StepFunctionsMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		smType := asset.Attr("type")
		if smType == "" {
			smType = "STANDARD"
		}
		return []clouds.CostUnit{
			clouds.SymbolicCost("step_functions", "Step Functions ("+smType+") cost depends on state transitions"),
		}, nil
	}

	transitions, _ := usageVecs.Get("transitions")
	smType := asset.Attr("type")
	if smType == "" {
		smType = "STANDARD"
	}

	usageType := "StateTransition"
	if smType == "EXPRESS" {
		usageType = "ExpressTransition"
	}

	return []clouds.CostUnit{
		clouds.NewCostUnit("transitions", "1k-transitions", transitions/1000, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AWSStepFunctions",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": usageType,
				"type":      smType,
			},
		}, 0.5),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\storage\ebs.go
# TYPE: go
# SIZE: 3891 bytes
################################################################################
// Package storage - AWS EBS cost mapper
// Clean-room implementation based on EBS pricing model:
// - Storage (per GB-month, varies by volume type)
// - Provisioned IOPS (for io1, io2)
// - Provisioned throughput (for gp3)
// - Snapshots
package storage

import (
	"terraform-cost/clouds"
)

// EBSMapper maps aws_ebs_volume to cost units
type EBSMapper struct{}

// NewEBSMapper creates an EBS mapper
func NewEBSMapper() *EBSMapper {
	return &EBSMapper{}
}

// Cloud returns the cloud provider
func (m *EBSMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *EBSMapper) ResourceType() string {
	return "aws_ebs_volume"
}

// BuildUsage extracts usage vectors from an EBS volume
func (m *EBSMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	// Check for unknown cardinality
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricStorageGB, "unknown volume count: "+asset.Cardinality.Reason),
		}, nil
	}

	// EBS volumes have deterministic attributes
	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricStorageGB, 1, 1.0), // Placeholder, actual from attrs
	}, nil
}

// BuildCostUnits creates cost units for an EBS volume
func (m *EBSMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	// Check for symbolic usage
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("storage", "EBS cost unknown due to cardinality"),
		}, nil
	}

	// Extract volume attributes
	volumeType := asset.Attr("type")
	if volumeType == "" {
		volumeType = "gp3" // Default in newer AWS
	}

	size := asset.AttrFloat("size", 8) // Default 8 GB
	iops := asset.AttrFloat("iops", 0)
	throughput := asset.AttrFloat("throughput", 0)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	units := []clouds.CostUnit{
		// Storage
		clouds.NewCostUnit(
			"storage",
			"GB-months",
			size,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEC2",
				Region:   region,
				Attributes: map[string]string{
					"volumeType": volumeType,
					"usageType":  "EBS:VolumeUsage." + volumeType,
				},
			},
			0.95,
		),
	}

	// Provisioned IOPS for io1/io2
	if (volumeType == "io1" || volumeType == "io2") && iops > 0 {
		units = append(units, clouds.NewCostUnit(
			"provisioned_iops",
			"IOPS-months",
			iops,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEC2",
				Region:   region,
				Attributes: map[string]string{
					"volumeType": volumeType,
					"usageType":  "EBS:VolumeP-IOPS." + volumeType,
				},
			},
			0.95,
		))
	}

	// Provisioned IOPS for gp3 (above 3000 baseline)
	if volumeType == "gp3" && iops > 3000 {
		extraIOPS := iops - 3000
		units = append(units, clouds.NewCostUnit(
			"provisioned_iops",
			"IOPS-months",
			extraIOPS,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEC2",
				Region:   region,
				Attributes: map[string]string{
					"volumeType": "gp3",
					"usageType":  "EBS:VolumeP-IOPS.gp3",
				},
			},
			0.95,
		))
	}

	// Provisioned throughput for gp3 (above 125 MiB/s baseline)
	if volumeType == "gp3" && throughput > 125 {
		extraThroughput := throughput - 125
		units = append(units, clouds.NewCostUnit(
			"provisioned_throughput",
			"MiBps-months",
			extraThroughput,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEC2",
				Region:   region,
				Attributes: map[string]string{
					"volumeType": "gp3",
					"usageType":  "EBS:VolumeP-Throughput.gp3",
				},
			},
			0.95,
		))
	}

	return units, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\storage\ebs_snapshot.go
# TYPE: go
# SIZE: 1803 bytes
################################################################################
// Package storage - AWS EBS Snapshot mapper
package storage

import (
	"terraform-cost/clouds"
)

// EBSSnapshotMapper maps aws_ebs_snapshot to cost units
type EBSSnapshotMapper struct{}

func NewEBSSnapshotMapper() *EBSSnapshotMapper { return &EBSSnapshotMapper{} }

func (m *EBSSnapshotMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *EBSSnapshotMapper) ResourceType() string        { return "aws_ebs_snapshot" }

func (m *EBSSnapshotMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricStorageGB, "unknown snapshot count")}, nil
	}

	// Snapshot size is typically a fraction of volume size due to incremental
	storageGB := ctx.ResolveOrDefault("storage_gb", -1)
	if storageGB < 0 {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricStorageGB, "snapshot size unknown")}, nil
	}

	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricStorageGB, storageGB, 0.5)}, nil
}

func (m *EBSSnapshotMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("snapshot", "snapshot size unknown - depends on changed data")}, nil
	}

	storageGB, _ := usageVecs.Get(clouds.MetricStorageGB)

	return []clouds.CostUnit{
		clouds.NewCostUnit("snapshot_storage", "GB-months", storageGB, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonEC2",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "EBS:SnapshotUsage",
			},
		}, 0.5),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\storage\efs_fsx.go
# TYPE: go
# SIZE: 7748 bytes
################################################################################
// Package storage - AWS EFS/FSx cost mapper
// EFS Pricing:
// - Storage: per GB-month (Standard, IA, One Zone)
// - Throughput: provisioned or bursting
// - Data transfer: infrequent access reads
// FSx Pricing:
// - Capacity: per GB-month
// - Throughput: per MBps-month (FSx for Lustre, Windows)
// - Backups: per GB-month
package storage

import (
	"terraform-cost/clouds"
)

// EFSMapper maps aws_efs_file_system to cost units
type EFSMapper struct{}

// NewEFSMapper creates an EFS mapper
func NewEFSMapper() *EFSMapper {
	return &EFSMapper{}
}

// Cloud returns the cloud provider
func (m *EFSMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *EFSMapper) ResourceType() string {
	return "aws_efs_file_system"
}

// BuildUsage extracts usage vectors
func (m *EFSMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricStorageGB, "unknown EFS count: "+asset.Cardinality.Reason),
		}, nil
	}

	// EFS storage is usage-dependent
	storageGB := ctx.ResolveOrDefault("storage_gb", -1)

	if storageGB < 0 {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricStorageGB, "EFS storage size unknown (grows dynamically)"),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricStorageGB, storageGB, 0.5),
	}, nil
}

// BuildCostUnits creates cost units
func (m *EFSMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("efs_storage", "EFS cost depends on actual storage used"),
		}, nil
	}

	storageGB, _ := usageVecs.Get(clouds.MetricStorageGB)

	// Determine storage class
	performanceMode := asset.Attr("performance_mode")
	if performanceMode == "" {
		performanceMode = "generalPurpose"
	}

	// One Zone vs Standard
	availabilityZoneName := asset.Attr("availability_zone_name")
	storageClass := "Standard"
	if availabilityZoneName != "" {
		storageClass = "One Zone"
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	units := []clouds.CostUnit{
		clouds.NewCostUnit(
			"storage",
			"GB-months",
			storageGB,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEFS",
				Region:   region,
				Attributes: map[string]string{
					"storageClass":    storageClass,
					"performanceMode": performanceMode,
					"usageType":       "TimedStorage-ByteHrs",
				},
			},
			0.5,
		),
	}

	// Provisioned throughput (if specified)
	provisionedThroughput := asset.AttrFloat("provisioned_throughput_in_mibps", 0)
	if provisionedThroughput > 0 {
		units = append(units, clouds.NewCostUnit(
			"provisioned_throughput",
			"MiBps-months",
			provisionedThroughput,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonEFS",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "ProvisionedTP-MiBpsHrs",
				},
			},
			0.95,
		))
	}

	return units, nil
}

// FSxMapper maps aws_fsx_lustre_file_system to cost units
type FSxLustreMapper struct{}

// NewFSxLustreMapper creates an FSx for Lustre mapper
func NewFSxLustreMapper() *FSxLustreMapper {
	return &FSxLustreMapper{}
}

// Cloud returns the cloud provider
func (m *FSxLustreMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *FSxLustreMapper) ResourceType() string {
	return "aws_fsx_lustre_file_system"
}

// BuildUsage extracts usage vectors
func (m *FSxLustreMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricStorageGB, "unknown FSx count: "+asset.Cardinality.Reason),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricStorageGB, 1, 1.0), // Placeholder
	}, nil
}

// BuildCostUnits creates cost units
func (m *FSxLustreMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("fsx_lustre", "FSx cost unknown"),
		}, nil
	}

	storageCapacity := asset.AttrFloat("storage_capacity", 1200) // Minimum 1.2 TB
	deploymentType := asset.Attr("deployment_type")
	if deploymentType == "" {
		deploymentType = "SCRATCH_1"
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"storage",
			"GB-months",
			storageCapacity,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonFSx",
				Region:   region,
				Attributes: map[string]string{
					"fileSystemType": "Lustre",
					"deploymentType": deploymentType,
					"usageType":      "Storage-SDD",
				},
			},
			0.95,
		),
	}, nil
}

// FSxWindowsMapper maps aws_fsx_windows_file_system to cost units
type FSxWindowsMapper struct{}

// NewFSxWindowsMapper creates an FSx for Windows mapper
func NewFSxWindowsMapper() *FSxWindowsMapper {
	return &FSxWindowsMapper{}
}

// Cloud returns the cloud provider
func (m *FSxWindowsMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *FSxWindowsMapper) ResourceType() string {
	return "aws_fsx_windows_file_system"
}

// BuildUsage extracts usage vectors
func (m *FSxWindowsMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricStorageGB, "unknown FSx count: "+asset.Cardinality.Reason),
		}, nil
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricStorageGB, 1, 1.0),
	}, nil
}

// BuildCostUnits creates cost units
func (m *FSxWindowsMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("fsx_windows", "FSx cost unknown"),
		}, nil
	}

	storageCapacity := asset.AttrFloat("storage_capacity", 32) // Minimum 32 GB
	storageType := asset.Attr("storage_type")
	if storageType == "" {
		storageType = "SSD"
	}
	throughputCapacity := asset.AttrFloat("throughput_capacity", 8) // MBps
	deploymentType := asset.Attr("deployment_type")
	if deploymentType == "" {
		deploymentType = "SINGLE_AZ_1"
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"storage",
			"GB-months",
			storageCapacity,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonFSx",
				Region:   region,
				Attributes: map[string]string{
					"fileSystemType": "Windows",
					"storageType":    storageType,
					"deploymentType": deploymentType,
				},
			},
			0.95,
		),
		clouds.NewCostUnit(
			"throughput",
			"MBps-months",
			throughputCapacity,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonFSx",
				Region:   region,
				Attributes: map[string]string{
					"fileSystemType": "Windows",
					"usageType":      "Throughput-MBps",
				},
			},
			0.95,
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\storage\s3.go
# TYPE: go
# SIZE: 4099 bytes
################################################################################
// Package storage - AWS S3 cost mapper
// Clean-room implementation based on S3 pricing model:
// - Storage (per GB-month, varies by storage class)
// - Requests (PUT, GET, LIST, etc.)
// - Data transfer (out to internet, cross-region)
// - Management features (analytics, inventory, replication)
package storage

import (
	"terraform-cost/clouds"
)

// S3Mapper maps aws_s3_bucket to cost units
type S3Mapper struct{}

// NewS3Mapper creates an S3 mapper
func NewS3Mapper() *S3Mapper {
	return &S3Mapper{}
}

// Cloud returns the cloud provider
func (m *S3Mapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *S3Mapper) ResourceType() string {
	return "aws_s3_bucket"
}

// BuildUsage extracts usage vectors from an S3 bucket
func (m *S3Mapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	// S3 buckets always have known cardinality (1 bucket)
	// But storage size and request volume are usage-dependent

	// Storage (usage-based, needs override or default)
	storageGB := ctx.ResolveOrDefault("storage_gb", 100)

	// Requests (usage-based)
	putRequests := ctx.ResolveOrDefault("put_requests", 10000)
	getRequests := ctx.ResolveOrDefault("get_requests", 100000)

	// Data transfer out
	dataTransferGB := ctx.ResolveOrDefault("data_transfer_out_gb", 10)

	// Lower confidence because these are estimates
	confidence := ctx.Confidence
	if confidence == 0 {
		confidence = 0.5 // Usage-based = moderate confidence
	}

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricStorageGB, storageGB, confidence),
		clouds.NewUsageVector("put_requests", putRequests, confidence),
		clouds.NewUsageVector("get_requests", getRequests, confidence),
		clouds.NewUsageVector(clouds.MetricDataTransferGB, dataTransferGB, confidence),
	}, nil
}

// BuildCostUnits creates cost units for an S3 bucket
func (m *S3Mapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	// Determine storage class
	storageClass := "STANDARD"
	if sc := asset.Attr("storage_class"); sc != "" {
		storageClass = sc
	}

	// Get usage values
	storageGB, _ := usageVecs.Get(clouds.MetricStorageGB)
	putRequests, _ := usageVecs.Get("put_requests")
	getRequests, _ := usageVecs.Get("get_requests")
	dataTransferGB, _ := usageVecs.Get(clouds.MetricDataTransferGB)

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region

	units := []clouds.CostUnit{
		// Storage
		clouds.NewCostUnit(
			"storage",
			"GB-months",
			storageGB,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonS3",
				Region:   region,
				Attributes: map[string]string{
					"storageClass": storageClass,
					"usageType":    "TimedStorage-" + storageClass,
				},
			},
			0.5,
		),

		// PUT requests
		clouds.NewCostUnit(
			"put_requests",
			"requests",
			putRequests,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonS3",
				Region:   region,
				Attributes: map[string]string{
					"storageClass": storageClass,
					"usageType":    "Requests-Tier1",
				},
			},
			0.5,
		),

		// GET requests
		clouds.NewCostUnit(
			"get_requests",
			"requests",
			getRequests,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonS3",
				Region:   region,
				Attributes: map[string]string{
					"storageClass": storageClass,
					"usageType":    "Requests-Tier2",
				},
			},
			0.5,
		),
	}

	// Data transfer (first 1GB free, then tiered)
	if dataTransferGB > 0 {
		units = append(units, clouds.NewCostUnit(
			"data_transfer_out",
			"GB",
			dataTransferGB,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AWSDataTransfer",
				Region:   region,
				Attributes: map[string]string{
					"transferType": "AWS Outbound",
					"toLocation":   "External",
				},
			},
			0.5,
		))
	}

	return units, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\streaming\kinesis.go
# TYPE: go
# SIZE: 4016 bytes
################################################################################
// Package streaming - AWS Kinesis cost mapper
// Pricing model:
// - Shard hours (per shard per hour)
// - PUT payload units (per 25KB chunk)
// - Extended retention (beyond 24 hours)
// - Enhanced fan-out (per consumer shard hour + data retrieval)
package streaming

import (
	"terraform-cost/clouds"
)

// KinesisStreamMapper maps aws_kinesis_stream to cost units
type KinesisStreamMapper struct{}

// NewKinesisStreamMapper creates a Kinesis Stream mapper
func NewKinesisStreamMapper() *KinesisStreamMapper {
	return &KinesisStreamMapper{}
}

// Cloud returns the cloud provider
func (m *KinesisStreamMapper) Cloud() clouds.CloudProvider {
	return clouds.AWS
}

// ResourceType returns the Terraform resource type
func (m *KinesisStreamMapper) ResourceType() string {
	return "aws_kinesis_stream"
}

// BuildUsage extracts usage vectors
func (m *KinesisStreamMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown Kinesis stream count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)
	// PUT units are usage-dependent
	putUnitsMillions := ctx.ResolveOrDefault("put_units_millions", -1)

	vectors := []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
	}

	if putUnitsMillions >= 0 {
		vectors = append(vectors, clouds.NewUsageVector("put_units_millions", putUnitsMillions, 0.5))
	} else {
		vectors = append(vectors, clouds.SymbolicUsage("put_units_millions", "PUT units depend on ingestion volume"))
	}

	return vectors, nil
}

// BuildCostUnits creates cost units
func (m *KinesisStreamMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("kinesis", "Kinesis cost unknown"),
		}, nil
	}

	// Get stream mode
	streamMode := asset.Attr("stream_mode_details.0.stream_mode")
	if streamMode == "" {
		streamMode = "PROVISIONED"
	}

	providerID := asset.ProviderContext.ProviderID
	region := asset.ProviderContext.Region
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	var units []clouds.CostUnit

	if streamMode == "ON_DEMAND" {
		// On-demand pricing
		units = append(units, clouds.SymbolicCost(
			"on_demand",
			"On-demand Kinesis cost depends on throughput",
		))
	} else {
		// Provisioned shards
		shardCount := asset.AttrInt("shard_count", 1)
		units = append(units, clouds.NewCostUnit(
			"shards",
			"shard-hours",
			float64(shardCount)*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonKinesis",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "Kinesis:shardHour",
				},
			},
			0.95,
		))
	}

	// PUT payload units
	if putUnits, ok := usageVecs.Get("put_units_millions"); ok {
		units = append(units, clouds.NewCostUnit(
			"put_payload_units",
			"million-units",
			putUnits,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonKinesis",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "Kinesis:PutRecordPayloadBytes",
				},
			},
			0.5,
		))
	}

	// Extended retention
	retentionPeriod := asset.AttrInt("retention_period", 24)
	if retentionPeriod > 24 {
		// Extended retention per shard-hour
		shardCount := asset.AttrInt("shard_count", 1)
		units = append(units, clouds.NewCostUnit(
			"extended_retention",
			"shard-hours",
			float64(shardCount)*monthlyHours,
			clouds.RateKey{
				Provider: providerID,
				Service:  "AmazonKinesis",
				Region:   region,
				Attributes: map[string]string{
					"usageType": "Kinesis:ExtendedRetention",
				},
			},
			0.95,
		))
	}

	return units, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\streaming\msk_firehose.go
# TYPE: go
# SIZE: 3880 bytes
################################################################################
// Package streaming - AWS MSK and Kinesis Firehose mappers
package streaming

import (
	"terraform-cost/clouds"
)

// MSKClusterMapper maps aws_msk_cluster to cost units
type MSKClusterMapper struct{}

func NewMSKClusterMapper() *MSKClusterMapper { return &MSKClusterMapper{} }

func (m *MSKClusterMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *MSKClusterMapper) ResourceType() string        { return "aws_msk_cluster" }

func (m *MSKClusterMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown MSK cluster count")}, nil
	}
	return []clouds.UsageVector{clouds.NewUsageVector(clouds.MetricMonthlyHours, 730, 0.95)}, nil
}

func (m *MSKClusterMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{clouds.SymbolicCost("msk", "MSK cluster count unknown")}, nil
	}

	instanceType := asset.Attr("broker_node_group_info.0.instance_type")
	if instanceType == "" {
		instanceType = "kafka.m5.large"
	}

	numberOfBrokerNodes := asset.AttrInt("number_of_broker_nodes", 3)
	ebsVolumeSize := asset.AttrFloat("broker_node_group_info.0.ebs_volume_size", 100)
	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	return []clouds.CostUnit{
		clouds.NewCostUnit("broker_hours", "broker-hours", float64(numberOfBrokerNodes)*monthlyHours, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonMSK",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"instanceType": instanceType,
			},
		}, 0.95),
		clouds.NewCostUnit("storage", "GB-months", ebsVolumeSize*float64(numberOfBrokerNodes), clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonMSK",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "Storage",
			},
		}, 0.95),
	}, nil
}

// KinesisFirehoseMapper maps aws_kinesis_firehose_delivery_stream to cost units
type KinesisFirehoseMapper struct{}

func NewKinesisFirehoseMapper() *KinesisFirehoseMapper { return &KinesisFirehoseMapper{} }

func (m *KinesisFirehoseMapper) Cloud() clouds.CloudProvider { return clouds.AWS }
func (m *KinesisFirehoseMapper) ResourceType() string        { return "aws_kinesis_firehose_delivery_stream" }

func (m *KinesisFirehoseMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{clouds.SymbolicUsage("streams", "unknown stream count")}, nil
	}

	dataIngestionGB := ctx.ResolveOrDefault("data_ingestion_gb", -1)
	if dataIngestionGB < 0 {
		return []clouds.UsageVector{clouds.SymbolicUsage("data_ingestion", "data ingestion volume not provided")}, nil
	}

	return []clouds.UsageVector{clouds.NewUsageVector("data_ingestion_gb", dataIngestionGB, 0.5)}, nil
}

func (m *KinesisFirehoseMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)
	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("firehose", "Firehose cost depends on data ingestion volume"),
		}, nil
	}

	dataIngestionGB, _ := usageVecs.Get("data_ingestion_gb")

	return []clouds.CostUnit{
		clouds.NewCostUnit("data_ingestion", "GB", dataIngestionGB, clouds.RateKey{
			Provider: asset.ProviderContext.ProviderID,
			Service:  "AmazonKinesisFirehose",
			Region:   asset.ProviderContext.Region,
			Attributes: map[string]string{
				"usageType": "DataIngested",
			},
		}, 0.5),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\aws\usage\estimators.go
# TYPE: go
# SIZE: 10814 bytes
################################################################################
// Package usage provides AWS usage estimators.
package usage

import (
	"context"

	"terraform-cost/core/types"
	coreUsage "terraform-cost/core/usage"
)

// baseEstimator provides common functionality for AWS estimators
type baseEstimator struct {
	resourceType string
}

func (e *baseEstimator) Provider() types.Provider {
	return types.ProviderAWS
}

func (e *baseEstimator) ResourceType() string {
	return e.resourceType
}

// EC2InstanceEstimator estimates usage for aws_instance
type EC2InstanceEstimator struct {
	baseEstimator
}

// NewEC2InstanceEstimator creates a new EC2 instance estimator
func NewEC2InstanceEstimator() coreUsage.Estimator {
	return &EC2InstanceEstimator{
		baseEstimator: baseEstimator{resourceType: "aws_instance"},
	}
}

// Estimate produces usage vectors for an EC2 instance
func (e *EC2InstanceEstimator) Estimate(ctx context.Context, asset *types.Asset, uctx *coreUsage.Context) ([]types.UsageVector, error) {
	// Default: 24/7 operation = 730 hours/month
	monthlyHours := 730.0
	confidence := 0.8

	// Check for overrides
	if uctx != nil && uctx.Profile != nil {
		if overrides := uctx.Profile.GetOverrides(asset.Address); len(overrides) > 0 {
			return overrides, nil
		}
	}

	// Adjust based on environment
	if uctx != nil && uctx.Environment == "development" {
		// Dev environments typically run 8 hours/day, 5 days/week
		monthlyHours = 8 * 5 * 4 // ~160 hours
		confidence = 0.6
	}

	return []types.UsageVector{
		{
			Metric:      types.MetricMonthlyHours,
			Value:       monthlyHours,
			Confidence:  confidence,
			Source:      types.SourceDefault,
			Description: "Estimated monthly runtime hours",
		},
	}, nil
}

// S3BucketEstimator estimates usage for aws_s3_bucket
type S3BucketEstimator struct {
	baseEstimator
}

// NewS3BucketEstimator creates a new S3 bucket estimator
func NewS3BucketEstimator() coreUsage.Estimator {
	return &S3BucketEstimator{
		baseEstimator: baseEstimator{resourceType: "aws_s3_bucket"},
	}
}

// Estimate produces usage vectors for an S3 bucket
func (e *S3BucketEstimator) Estimate(ctx context.Context, asset *types.Asset, uctx *coreUsage.Context) ([]types.UsageVector, error) {
	// Check for overrides
	if uctx != nil && uctx.Profile != nil {
		if overrides := uctx.Profile.GetOverrides(asset.Address); len(overrides) > 0 {
			return overrides, nil
		}
	}

	// Default estimates - these should be overridden in production
	return []types.UsageVector{
		{
			Metric:      types.MetricMonthlyGBStorage,
			Value:       100, // 100 GB default
			Confidence:  0.3, // Low confidence - highly variable
			Source:      types.SourceDefault,
			Description: "Estimated monthly storage in GB",
		},
		{
			Metric:      types.MetricMonthlyGetOperations,
			Value:       100000, // 100k GET requests
			Confidence:  0.3,
			Source:      types.SourceDefault,
			Description: "Estimated monthly GET requests",
		},
		{
			Metric:      types.MetricMonthlyPutOperations,
			Value:       10000, // 10k PUT requests
			Confidence:  0.3,
			Source:      types.SourceDefault,
			Description: "Estimated monthly PUT requests",
		},
		{
			Metric:      types.MetricMonthlyGBTransferOut,
			Value:       10, // 10 GB transfer out
			Confidence:  0.3,
			Source:      types.SourceDefault,
			Description: "Estimated monthly data transfer out in GB",
		},
	}, nil
}

// RDSInstanceEstimator estimates usage for aws_db_instance
type RDSInstanceEstimator struct {
	baseEstimator
}

// NewRDSInstanceEstimator creates a new RDS instance estimator
func NewRDSInstanceEstimator() coreUsage.Estimator {
	return &RDSInstanceEstimator{
		baseEstimator: baseEstimator{resourceType: "aws_db_instance"},
	}
}

// Estimate produces usage vectors for an RDS instance
func (e *RDSInstanceEstimator) Estimate(ctx context.Context, asset *types.Asset, uctx *coreUsage.Context) ([]types.UsageVector, error) {
	// Check for overrides
	if uctx != nil && uctx.Profile != nil {
		if overrides := uctx.Profile.GetOverrides(asset.Address); len(overrides) > 0 {
			return overrides, nil
		}
	}

	// Get storage from attributes
	storage := asset.Attributes.GetInt("allocated_storage")
	if storage == 0 {
		storage = 20
	}

	return []types.UsageVector{
		{
			Metric:      types.MetricMonthlyHours,
			Value:       730, // 24/7
			Confidence:  0.9,
			Source:      types.SourceDefault,
			Description: "Database typically runs 24/7",
		},
		{
			Metric:      types.MetricMonthlyGBStorage,
			Value:       float64(storage),
			Confidence:  0.95,
			Source:      types.SourceTerraform,
			Description: "Storage from Terraform configuration",
		},
		{
			Metric:      types.MetricMonthlyBackupStorageGB,
			Value:       float64(storage), // Assume backup equals storage
			Confidence:  0.5,
			Source:      types.SourceDefault,
			Description: "Estimated backup storage",
		},
	}, nil
}

// LambdaFunctionEstimator estimates usage for aws_lambda_function
type LambdaFunctionEstimator struct {
	baseEstimator
}

// NewLambdaFunctionEstimator creates a new Lambda function estimator
func NewLambdaFunctionEstimator() coreUsage.Estimator {
	return &LambdaFunctionEstimator{
		baseEstimator: baseEstimator{resourceType: "aws_lambda_function"},
	}
}

// Estimate produces usage vectors for a Lambda function
func (e *LambdaFunctionEstimator) Estimate(ctx context.Context, asset *types.Asset, uctx *coreUsage.Context) ([]types.UsageVector, error) {
	// Check for overrides
	if uctx != nil && uctx.Profile != nil {
		if overrides := uctx.Profile.GetOverrides(asset.Address); len(overrides) > 0 {
			return overrides, nil
		}
	}

	memorySize := asset.Attributes.GetInt("memory_size")
	if memorySize == 0 {
		memorySize = 128
	}

	timeout := asset.Attributes.GetInt("timeout")
	if timeout == 0 {
		timeout = 3
	}

	// Default: 1 million invocations, average 500ms duration
	invocations := 1000000.0
	avgDurationMs := float64(timeout) * 1000 * 0.5 // 50% of timeout

	return []types.UsageVector{
		{
			Metric:      types.MetricMonthlyInvocations,
			Value:       invocations,
			Confidence:  0.3, // Very variable
			Source:      types.SourceDefault,
			Description: "Estimated monthly invocations",
		},
		{
			Metric:      types.MetricMonthlyDurationMs,
			Value:       avgDurationMs,
			Confidence:  0.3,
			Source:      types.SourceDefault,
			Description: "Average execution duration in ms",
		},
		{
			Metric:      types.MetricMonthlyGBSeconds,
			Value:       (float64(memorySize) / 1024) * (avgDurationMs / 1000) * invocations,
			Confidence:  0.3,
			Source:      types.SourceDefault,
			Description: "Compute GB-seconds",
		},
	}, nil
}

// DynamoDBTableEstimator estimates usage for aws_dynamodb_table
type DynamoDBTableEstimator struct {
	baseEstimator
}

// NewDynamoDBTableEstimator creates a new DynamoDB table estimator
func NewDynamoDBTableEstimator() coreUsage.Estimator {
	return &DynamoDBTableEstimator{
		baseEstimator: baseEstimator{resourceType: "aws_dynamodb_table"},
	}
}

// Estimate produces usage vectors for a DynamoDB table
func (e *DynamoDBTableEstimator) Estimate(ctx context.Context, asset *types.Asset, uctx *coreUsage.Context) ([]types.UsageVector, error) {
	// Check for overrides
	if uctx != nil && uctx.Profile != nil {
		if overrides := uctx.Profile.GetOverrides(asset.Address); len(overrides) > 0 {
			return overrides, nil
		}
	}

	billingMode := asset.Attributes.GetString("billing_mode")

	vectors := []types.UsageVector{
		{
			Metric:      types.MetricMonthlyGBStorage,
			Value:       10, // 10 GB default
			Confidence:  0.3,
			Source:      types.SourceDefault,
			Description: "Estimated table storage",
		},
	}

	if billingMode == "PAY_PER_REQUEST" {
		vectors = append(vectors,
			types.UsageVector{
				Metric:      types.MetricMonthlyReadRequests,
				Value:       1000000,
				Confidence:  0.3,
				Source:      types.SourceDefault,
				Description: "Estimated read request units",
			},
			types.UsageVector{
				Metric:      types.MetricMonthlyWriteRequests,
				Value:       100000,
				Confidence:  0.3,
				Source:      types.SourceDefault,
				Description: "Estimated write request units",
			},
		)
	}

	return vectors, nil
}

// NATGatewayEstimator estimates usage for aws_nat_gateway
type NATGatewayEstimator struct {
	baseEstimator
}

// NewNATGatewayEstimator creates a new NAT Gateway estimator
func NewNATGatewayEstimator() coreUsage.Estimator {
	return &NATGatewayEstimator{
		baseEstimator: baseEstimator{resourceType: "aws_nat_gateway"},
	}
}

// Estimate produces usage vectors for a NAT Gateway
func (e *NATGatewayEstimator) Estimate(ctx context.Context, asset *types.Asset, uctx *coreUsage.Context) ([]types.UsageVector, error) {
	// Check for overrides
	if uctx != nil && uctx.Profile != nil {
		if overrides := uctx.Profile.GetOverrides(asset.Address); len(overrides) > 0 {
			return overrides, nil
		}
	}

	return []types.UsageVector{
		{
			Metric:      types.MetricMonthlyHours,
			Value:       730, // 24/7
			Confidence:  0.95,
			Source:      types.SourceDefault,
			Description: "NAT Gateway runs continuously",
		},
		{
			Metric:      types.MetricMonthlyGB,
			Value:       100, // 100 GB data processed
			Confidence:  0.3,
			Source:      types.SourceDefault,
			Description: "Estimated data processed through NAT",
		},
	}, nil
}

// EBSVolumeEstimator estimates usage for aws_ebs_volume
type EBSVolumeEstimator struct {
	baseEstimator
}

// NewEBSVolumeEstimator creates a new EBS volume estimator
func NewEBSVolumeEstimator() coreUsage.Estimator {
	return &EBSVolumeEstimator{
		baseEstimator: baseEstimator{resourceType: "aws_ebs_volume"},
	}
}

// Estimate produces usage vectors for an EBS volume
func (e *EBSVolumeEstimator) Estimate(ctx context.Context, asset *types.Asset, uctx *coreUsage.Context) ([]types.UsageVector, error) {
	// Check for overrides
	if uctx != nil && uctx.Profile != nil {
		if overrides := uctx.Profile.GetOverrides(asset.Address); len(overrides) > 0 {
			return overrides, nil
		}
	}

	size := asset.Attributes.GetInt("size")
	if size == 0 {
		size = 8
	}

	return []types.UsageVector{
		{
			Metric:      types.MetricMonthlyGBStorage,
			Value:       float64(size),
			Confidence:  0.95,
			Source:      types.SourceTerraform,
			Description: "Volume size from Terraform configuration",
		},
		{
			Metric:      types.MetricMonthlySnapshots,
			Value:       1, // One snapshot per month
			Confidence:  0.5,
			Source:      types.SourceDefault,
			Description: "Estimated monthly snapshots",
		},
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\azure\register.go
# TYPE: go
# SIZE: 638 bytes
################################################################################
// Package azure - Azure cloud provider registration
package azure

// SupportedResourceTypes returns all supported Azure resource types
func SupportedResourceTypes() []string {
	return []string{
		// Compute
		"azurerm_virtual_machine",
		"azurerm_linux_virtual_machine",
		"azurerm_windows_virtual_machine",
		"azurerm_virtual_machine_scale_set",

		// Storage
		"azurerm_storage_account",
		"azurerm_managed_disk",

		// Database
		"azurerm_sql_database",
		"azurerm_cosmosdb_account",
		"azurerm_mysql_flexible_server",
		"azurerm_postgresql_flexible_server",

		// Serverless
		"azurerm_function_app",
	}
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\azure\compute\vm.go
# TYPE: go
# SIZE: 2169 bytes
################################################################################
// Package compute - Azure VM cost mapper (placeholder)
// Clean-room implementation based on Azure VM pricing model:
// - Compute hours (by VM size, region, OS)
// - Managed disks (separate resource)
// - Spot VMs
// - Reserved instances
package compute

import (
	"terraform-cost/clouds"
)

// VMMapper maps azurerm_linux_virtual_machine to cost units
type VMMapper struct{}

// NewVMMapper creates a VM mapper
func NewVMMapper() *VMMapper {
	return &VMMapper{}
}

// Cloud returns the cloud provider
func (m *VMMapper) Cloud() clouds.CloudProvider {
	return clouds.Azure
}

// ResourceType returns the Terraform resource type
func (m *VMMapper) ResourceType() string {
	return "azurerm_linux_virtual_machine"
}

// BuildUsage extracts usage vectors from an Azure VM
func (m *VMMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown VM count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
	}, nil
}

// BuildCostUnits creates cost units for an Azure VM
func (m *VMMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("compute", "Azure VM cost unknown due to cardinality"),
		}, nil
	}

	vmSize := asset.Attr("size")
	if vmSize == "" {
		vmSize = "Standard_B1s"
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"compute",
			"hours",
			monthlyHours,
			clouds.RateKey{
				Provider: asset.ProviderContext.ProviderID,
				Service:  "Virtual Machines",
				Region:   asset.ProviderContext.Region,
				Attributes: map[string]string{
					"vmSize": vmSize,
					"os":     "Linux",
				},
			},
			0.95,
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\gcp\register.go
# TYPE: go
# SIZE: 598 bytes
################################################################################
// Package gcp - GCP cloud provider registration
package gcp

// SupportedResourceTypes returns all supported GCP resource types
func SupportedResourceTypes() []string {
	return []string{
		// Compute
		"google_compute_instance",
		"google_compute_instance_template",
		"google_compute_instance_group_manager",

		// Storage
		"google_storage_bucket",
		"google_compute_disk",

		// Database
		"google_sql_database_instance",
		"google_bigtable_instance",
		"google_spanner_instance",

		// Serverless
		"google_cloudfunctions_function",
		"google_cloud_run_service",
	}
}

################################################################################
# FILE: :\good projects\cost estimation\clouds\gcp\compute\instance.go
# TYPE: go
# SIZE: 2354 bytes
################################################################################
// Package compute - GCP Compute Instance cost mapper (placeholder)
// Clean-room implementation based on GCE pricing model:
// - Machine type hours (by machine type, region)
// - Preemptible/Spot VMs
// - Committed use discounts
// - Sustained use discounts
package compute

import (
	"terraform-cost/clouds"
)

// InstanceMapper maps google_compute_instance to cost units
type InstanceMapper struct{}

// NewInstanceMapper creates a GCE instance mapper
func NewInstanceMapper() *InstanceMapper {
	return &InstanceMapper{}
}

// Cloud returns the cloud provider
func (m *InstanceMapper) Cloud() clouds.CloudProvider {
	return clouds.GCP
}

// ResourceType returns the Terraform resource type
func (m *InstanceMapper) ResourceType() string {
	return "google_compute_instance"
}

// BuildUsage extracts usage vectors from a GCE instance
func (m *InstanceMapper) BuildUsage(asset clouds.AssetNode, ctx clouds.UsageContext) ([]clouds.UsageVector, error) {
	if asset.Cardinality.IsUnknown() {
		return []clouds.UsageVector{
			clouds.SymbolicUsage(clouds.MetricMonthlyHours, "unknown instance count: "+asset.Cardinality.Reason),
		}, nil
	}

	monthlyHours := ctx.ResolveOrDefault("monthly_hours", 730)

	return []clouds.UsageVector{
		clouds.NewUsageVector(clouds.MetricMonthlyHours, monthlyHours, 0.95),
	}, nil
}

// BuildCostUnits creates cost units for a GCE instance
func (m *InstanceMapper) BuildCostUnits(asset clouds.AssetNode, usage []clouds.UsageVector) ([]clouds.CostUnit, error) {
	usageVecs := clouds.UsageVectors(usage)

	if usageVecs.IsSymbolic() {
		return []clouds.CostUnit{
			clouds.SymbolicCost("compute", "GCE cost unknown due to cardinality"),
		}, nil
	}

	machineType := asset.Attr("machine_type")
	if machineType == "" {
		machineType = "e2-micro"
	}

	monthlyHours, _ := usageVecs.Get(clouds.MetricMonthlyHours)

	// GCP applies sustained use discounts automatically
	// For estimation, we use full hourly rate
	return []clouds.CostUnit{
		clouds.NewCostUnit(
			"compute",
			"hours",
			monthlyHours,
			clouds.RateKey{
				Provider: asset.ProviderContext.ProviderID,
				Service:  "Compute Engine",
				Region:   asset.ProviderContext.Region,
				Attributes: map[string]string{
					"machineType": machineType,
				},
			},
			0.95,
		),
	}, nil
}

################################################################################
# FILE: :\good projects\cost estimation\cmd\cli\main.go
# TYPE: go
# SIZE: 207 bytes
################################################################################
// Package main is the entry point for terraform-cost CLI.
package main

import (
	"os"

	"terraform-cost/cmd/cli/cmd"
)

func main() {
	if err := cmd.Execute(); err != nil {
		os.Exit(1)
	}
}

################################################################################
# FILE: :\good projects\cost estimation\cmd\cli\cmd\estimate.go
# TYPE: go
# SIZE: 12916 bytes
################################################################################
// Package cmd - estimate command
package cmd

import (
	"context"
	"fmt"
	"os"
	"time"

	"github.com/shopspring/decimal"
	"github.com/spf13/cobra"

	"terraform-cost/clouds"
	"terraform-cost/clouds/aws"
	"terraform-cost/core/asset"
	"terraform-cost/core/output"
	"terraform-cost/core/scanner"
	"terraform-cost/core/types"
	"terraform-cost/internal/logging"
)

var (
	outputFormat string
	usageFile    string
	showDetails  bool
	region       string
)

// estimateCmd represents the estimate command
var estimateCmd = &cobra.Command{
	Use:   "estimate [path]",
	Short: "Estimate costs for a Terraform project",
	Long: `Analyze Terraform configurations and produce cost estimates.

The path can be a directory containing .tf files or a Terraform plan JSON file.

Examples:
  terraform-cost estimate .
  terraform-cost estimate ./infrastructure
  terraform-cost estimate --format json ./my-project
  terraform-cost estimate --usage usage.yml ./my-project`,
	Args: cobra.MaximumNArgs(1),
	RunE: runEstimate,
}

func init() {
	estimateCmd.Flags().StringVarP(&outputFormat, "format", "f", "cli", "output format (cli, json, html, markdown)")
	estimateCmd.Flags().StringVarP(&usageFile, "usage", "u", "", "usage file for custom usage estimates")
	estimateCmd.Flags().BoolVarP(&showDetails, "details", "d", true, "show detailed cost breakdown")
	estimateCmd.Flags().StringVarP(&region, "region", "r", "", "default AWS region")
}

func runEstimate(cmd *cobra.Command, args []string) error {
	ctx := context.Background()
	startTime := time.Now()

	// Determine path
	path := "."
	if len(args) > 0 {
		path = args[0]
	}

	// Validate path exists
	if _, err := os.Stat(path); os.IsNotExist(err) {
		return fmt.Errorf("path does not exist: %s", path)
	}

	logging.Info("Starting cost estimation")

	// Initialize cloud plugins
	if err := initializePlugins(); err != nil {
		return fmt.Errorf("failed to initialize plugins: %w", err)
	}

	// Create project input
	input := &types.ProjectInput{
		ID:     fmt.Sprintf("estimate-%d", time.Now().Unix()),
		Path:   path,
		Source: types.SourceCLI,
		Metadata: types.InputMetadata{
			Timestamp: time.Now(),
		},
	}

	// Scan the project
	fmt.Println("Scanning Terraform files...")
	scanResult, err := scanner.GetDefault().DetectAndScan(ctx, input)
	if err != nil {
		return fmt.Errorf("failed to scan project: %w", err)
	}

	if scanResult.HasErrors() {
		fmt.Printf("Warning: %d errors during scanning\n", len(scanResult.Errors))
		for _, e := range scanResult.Errors {
			fmt.Printf("  %s:%d: %s\n", e.File, e.Line, e.Message)
		}
	}

	if len(scanResult.Assets) == 0 {
		fmt.Println("No resources found in the project.")
		return nil
	}

	fmt.Printf("Found %d resources\n\n", len(scanResult.Assets))

	// Build asset graph
	graph := buildAssetGraph(ctx, scanResult.Assets)

	// Calculate costs (simplified)
	costGraph := calculateCosts(graph)

	// Create estimation result
	result := &output.EstimationResult{
		CostGraph:  costGraph,
		AssetGraph: graph,
		Confidence: 0.7,
		Metadata: output.EstimationMetadata{
			Timestamp: time.Now().Format(time.RFC3339),
			Duration:  time.Since(startTime).String(),
			Version:   "0.1.0",
			Source:    types.SourceCLI,
		},
	}

	// Output results
	printResults(result)

	return nil
}

func initializePlugins() error {
	// Register AWS plugin
	awsPlugin := aws.New()
	if region != "" {
		awsPlugin = aws.NewWithRegion(region)
	}
	
	if err := clouds.RegisterPlugin(awsPlugin); err != nil {
		return err
	}

	return nil
}

func buildAssetGraph(ctx context.Context, rawAssets []types.RawAsset) *types.AssetGraph {
	graph := types.NewAssetGraph()
	builderRegistry := asset.GetDefaultBuilderRegistry()

	// Register AWS builders
	awsPlugin := aws.New()
	for _, builder := range awsPlugin.AssetBuilders() {
		builderRegistry.Register(builder)
	}

	for _, raw := range rawAssets {
		builder, ok := builderRegistry.GetBuilder(raw.Provider, raw.Type)
		if !ok {
			// No builder for this resource type - create a generic asset
			asset := &types.Asset{
				ID:         fmt.Sprintf("%s.%s", raw.Type, raw.Name),
				Address:    raw.Address,
				Provider:   raw.Provider,
				Category:   types.CategoryOther,
				Type:       raw.Type,
				Name:       raw.Name,
				Attributes: raw.Attributes,
				Metadata: types.AssetMetadata{
					Source: raw.SourceFile,
					Line:   raw.SourceLine,
				},
			}
			graph.Add(asset)
			continue
		}

		asset, err := builder.Build(ctx, &raw)
		if err != nil {
			fmt.Printf("Warning: failed to build asset %s: %v\n", raw.Address, err)
			continue
		}

		graph.Add(asset)
	}

	return graph
}

func calculateCosts(graph *types.AssetGraph) *types.CostGraph {
	costGraph := types.NewCostGraph(types.CurrencyUSD)

	graph.Walk(func(asset *types.Asset) error {
		// Calculate cost for this asset
		units := calculateAssetCost(asset)
		for _, unit := range units {
			costGraph.AddCostUnit(unit, asset)
		}
		return nil
	})

	costGraph.Summarize()
	return costGraph
}

func calculateAssetCost(asset *types.Asset) []*types.CostUnit {
	var units []*types.CostUnit

	// Simplified cost calculation based on resource type
	switch asset.Type {
	case "aws_instance":
		instanceType := asset.Attributes.GetString("instance_type")
		if instanceType == "" {
			instanceType = "t3.micro"
		}
		hourlyRate := getEC2HourlyRate(instanceType)
		monthlyHours := decimal.NewFromInt(730)
		monthlyCost := hourlyRate.Mul(monthlyHours)

		units = append(units, &types.CostUnit{
			ID:       fmt.Sprintf("%s-compute", asset.ID),
			Label:    fmt.Sprintf("EC2 Instance (%s)", instanceType),
			Measure:  "hours",
			Quantity: monthlyHours,
			Rate:     hourlyRate,
			Amount:   monthlyCost,
			Currency: types.CurrencyUSD,
			Lineage: types.CostLineage{
				AssetID:      asset.ID,
				AssetAddress: asset.Address,
				Formula:      "hourly_rate * 730 hours/month",
			},
		})

	case "aws_db_instance":
		instanceClass := asset.Attributes.GetString("instance_class")
		if instanceClass == "" {
			instanceClass = "db.t3.micro"
		}
		hourlyRate := getRDSHourlyRate(instanceClass)
		monthlyHours := decimal.NewFromInt(730)
		monthlyCost := hourlyRate.Mul(monthlyHours)

		units = append(units, &types.CostUnit{
			ID:       fmt.Sprintf("%s-compute", asset.ID),
			Label:    fmt.Sprintf("RDS Instance (%s)", instanceClass),
			Measure:  "hours",
			Quantity: monthlyHours,
			Rate:     hourlyRate,
			Amount:   monthlyCost,
			Currency: types.CurrencyUSD,
			Lineage: types.CostLineage{
				AssetID:      asset.ID,
				AssetAddress: asset.Address,
				Formula:      "hourly_rate * 730 hours/month",
			},
		})

		// Add storage cost
		storage := asset.Attributes.GetInt("allocated_storage")
		if storage > 0 {
			storageRate := decimal.NewFromFloat(0.115) // gp2 per GB-month
			storageCost := storageRate.Mul(decimal.NewFromInt(int64(storage)))
			units = append(units, &types.CostUnit{
				ID:       fmt.Sprintf("%s-storage", asset.ID),
				Label:    "RDS Storage (gp2)",
				Measure:  "GB-month",
				Quantity: decimal.NewFromInt(int64(storage)),
				Rate:     storageRate,
				Amount:   storageCost,
				Currency: types.CurrencyUSD,
				Lineage: types.CostLineage{
					AssetID:      asset.ID,
					AssetAddress: asset.Address,
					Formula:      "storage_gb * $0.115/GB-month",
				},
			})
		}

	case "aws_nat_gateway":
		hourlyRate := decimal.NewFromFloat(0.045)
		monthlyHours := decimal.NewFromInt(730)
		monthlyCost := hourlyRate.Mul(monthlyHours)

		units = append(units, &types.CostUnit{
			ID:       fmt.Sprintf("%s-hourly", asset.ID),
			Label:    "NAT Gateway",
			Measure:  "hours",
			Quantity: monthlyHours,
			Rate:     hourlyRate,
			Amount:   monthlyCost,
			Currency: types.CurrencyUSD,
			Lineage: types.CostLineage{
				AssetID:      asset.ID,
				AssetAddress: asset.Address,
				Formula:      "$0.045/hour * 730 hours/month",
			},
		})

	case "aws_ebs_volume":
		volumeType := asset.Attributes.GetString("type")
		if volumeType == "" {
			volumeType = "gp3"
		}
		size := asset.Attributes.GetInt("size")
		if size == 0 {
			size = 8
		}
		rate := getEBSRate(volumeType)
		amount := rate.Mul(decimal.NewFromInt(int64(size)))

		units = append(units, &types.CostUnit{
			ID:       fmt.Sprintf("%s-storage", asset.ID),
			Label:    fmt.Sprintf("EBS Volume (%s)", volumeType),
			Measure:  "GB-month",
			Quantity: decimal.NewFromInt(int64(size)),
			Rate:     rate,
			Amount:   amount,
			Currency: types.CurrencyUSD,
			Lineage: types.CostLineage{
				AssetID:      asset.ID,
				AssetAddress: asset.Address,
				Formula:      fmt.Sprintf("$%.3f/GB-month * %d GB", rate.InexactFloat64(), size),
			},
		})

	case "aws_lambda_function":
		// Lambda free tier: 1M requests, 400K GB-seconds
		// Just show a minimal cost for estimation
		units = append(units, &types.CostUnit{
			ID:       fmt.Sprintf("%s-compute", asset.ID),
			Label:    "Lambda Function (usage-based)",
			Measure:  "invocations",
			Quantity: decimal.NewFromInt(1000000),
			Rate:     decimal.NewFromFloat(0.0000002),
			Amount:   decimal.NewFromFloat(0.20),
			Currency: types.CurrencyUSD,
			Lineage: types.CostLineage{
				AssetID:      asset.ID,
				AssetAddress: asset.Address,
				Formula:      "Usage-based pricing (1M requests estimate)",
				Assumptions:  []string{"Estimated 1M invocations/month"},
			},
		})
	}

	return units
}

func getEC2HourlyRate(instanceType string) decimal.Decimal {
	rates := map[string]float64{
		"t3.micro":   0.0104,
		"t3.small":   0.0208,
		"t3.medium":  0.0416,
		"t3.large":   0.0832,
		"t3.xlarge":  0.1664,
		"m5.large":   0.096,
		"m5.xlarge":  0.192,
		"c5.large":   0.085,
		"r5.large":   0.126,
	}
	if rate, ok := rates[instanceType]; ok {
		return decimal.NewFromFloat(rate)
	}
	return decimal.NewFromFloat(0.10) // Default
}

func getRDSHourlyRate(instanceClass string) decimal.Decimal {
	rates := map[string]float64{
		"db.t3.micro":   0.017,
		"db.t3.small":   0.034,
		"db.t3.medium":  0.068,
		"db.m5.large":   0.171,
		"db.r5.large":   0.24,
	}
	if rate, ok := rates[instanceClass]; ok {
		return decimal.NewFromFloat(rate)
	}
	return decimal.NewFromFloat(0.10) // Default
}

func getEBSRate(volumeType string) decimal.Decimal {
	rates := map[string]float64{
		"gp3": 0.08,
		"gp2": 0.10,
		"io1": 0.125,
		"st1": 0.045,
		"sc1": 0.015,
	}
	if rate, ok := rates[volumeType]; ok {
		return decimal.NewFromFloat(rate)
	}
	return decimal.NewFromFloat(0.10) // Default
}

func printResults(result *output.EstimationResult) {
	fmt.Println("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
	fmt.Println("â”‚                        COST ESTIMATION SUMMARY                         â”‚")
	fmt.Println("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

	// Print by resource
	for assetID, agg := range result.CostGraph.ByAsset {
		if len(agg.Units) == 0 {
			continue
		}
		fmt.Printf("â”‚ %-50s %20s â”‚\n", 
			truncate(assetID, 50), 
			fmt.Sprintf("$%.2f/month", agg.MonthlyCost.InexactFloat64()))
		
		if showDetails {
			for _, unit := range agg.Units {
				fmt.Printf("â”‚   â””â”€ %-46s %20s â”‚\n",
					truncate(unit.Label, 46),
					fmt.Sprintf("$%.2f", unit.Amount.InexactFloat64()))
			}
		}
	}

	fmt.Println("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
	fmt.Printf("â”‚ %-50s %20s â”‚\n", 
		"TOTAL MONTHLY ESTIMATE",
		fmt.Sprintf("$%.2f", result.CostGraph.TotalMonthlyCost.InexactFloat64()))
	fmt.Printf("â”‚ %-50s %20s â”‚\n",
		"TOTAL HOURLY ESTIMATE",
		fmt.Sprintf("$%.4f", result.CostGraph.TotalHourlyCost.InexactFloat64()))
	fmt.Println("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

	fmt.Printf("\nEstimation completed in %s\n", result.Metadata.Duration)
	fmt.Printf("Confidence: %.0f%%\n", result.Confidence*100)
}

func truncate(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen-3] + "..."
}

################################################################################
# FILE: :\good projects\cost estimation\cmd\cli\cmd\pricing_restore.go
# TYPE: go
# SIZE: 4625 bytes
################################################################################
// Package cmd - CLI command: terraform-cost pricing restore
package cmd

import (
	"context"
	"fmt"
	"os"
	"time"

	"terraform-cost/db/ingestion"

	"github.com/spf13/cobra"
)

var pricingRestoreCmd = &cobra.Command{
	Use:   "restore <backup-file>",
	Short: "Restore pricing data from backup",
	Long: `Restore pricing data from a local backup file.

This command:
  1. Reads the backup file (gzipped JSON)
  2. Validates content hash and structure
  3. Runs all governance checks
  4. Creates a NEW snapshot (never overwrites existing)
  5. Atomically commits to database

IMPORTANT: This creates a new snapshot ID, not a rollback.`,
	Args: cobra.ExactArgs(1),
	RunE: runPricingRestore,
}

var (
	restoreDryRun bool
	restoreForce  bool
)

func init() {
	pricingCmd.AddCommand(pricingRestoreCmd)

	pricingRestoreCmd.Flags().BoolVar(&restoreDryRun, "dry-run", false, "Validate only, no database writes")
	pricingRestoreCmd.Flags().BoolVar(&restoreForce, "force", false, "Skip coverage decrease check")
}

func runPricingRestore(cmd *cobra.Command, args []string) error {
	backupPath := args[0]

	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Minute)
	defer cancel()

	// Print header
	fmt.Println("")
	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘           PRICING DATA RESTORE FROM BACKUP                   â•‘")
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println("")
	fmt.Printf("Backup file: %s\n", backupPath)
	fmt.Printf("Dry-run:     %t\n", restoreDryRun)
	fmt.Printf("Force:       %t\n", restoreForce)
	fmt.Println("")

	// Read backup
	fmt.Println("Reading backup file...")
	backupMgr := ingestion.NewBackupManager()
	backup, err := backupMgr.ReadBackup(backupPath)
	if err != nil {
		fmt.Printf("âœ— Failed to read backup: %v\n", err)
		os.Exit(1)
	}

	fmt.Printf("âœ“ Backup read successfully\n")
	fmt.Println("")

	// Print backup info
	fmt.Println("Backup details:")
	fmt.Printf("  Provider:      %s\n", backup.Provider)
	fmt.Printf("  Region:        %s\n", backup.Region)
	fmt.Printf("  Alias:         %s\n", backup.Alias)
	fmt.Printf("  Timestamp:     %s\n", backup.Timestamp.Format(time.RFC3339))
	fmt.Printf("  Rate count:    %d\n", backup.RateCount)
	fmt.Printf("  Content hash:  %s\n", truncateHash(backup.ContentHash))
	fmt.Printf("  Schema:        %s\n", backup.SchemaVersion)
	fmt.Println("")

	// Run validation
	fmt.Println("Running governance validation...")
	validator := ingestion.NewIngestionValidator()
	if restoreForce {
		validator.SetMinCoveragePercent(0) // Skip coverage check
	}

	if err := validator.ValidateAll(backup.Rates, 0); err != nil {
		fmt.Printf("âœ— Validation failed: %v\n", err)
		os.Exit(1)
	}
	fmt.Println("âœ“ Validation passed")
	fmt.Println("")

	// Dry-run check
	if restoreDryRun {
		fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
		fmt.Println("âœ“ DRY-RUN COMPLETED - No database changes made")
		fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
		return nil
	}

	// Get database store
	store, err := getDBStore()
	if err != nil {
		return fmt.Errorf("failed to connect to database: %w", err)
	}

	// Check for existing snapshot with same hash
	existing, _ := store.FindSnapshotByHash(ctx, backup.Provider, backup.Region, backup.Alias, backup.ContentHash)
	if existing != nil {
		fmt.Printf("âš  Snapshot with this content hash already exists: %s\n", existing.ID.String())
		fmt.Println("  No action needed - data is already current")
		return nil
	}

	// Create restore pipeline config
	fmt.Println("Creating new snapshot...")

	// For restore, we need to directly commit the rates
	// This would normally go through the pipeline, but we already have normalized rates
	fmt.Println("âœ— Database commit not yet implemented")
	fmt.Println("  Backup validation successful - would create snapshot from %d rates", backup.RateCount)
	os.Exit(1)

	return nil
}

################################################################################
# FILE: :\good projects\cost estimation\cmd\cli\cmd\pricing_update.go
# TYPE: go
# SIZE: 7114 bytes
################################################################################
// Package cmd - CLI command: terraform-cost pricing update
package cmd

import (
	"context"
	"fmt"
	"os"
	"time"

	"terraform-cost/db"
	"terraform-cost/db/ingestion"

	"github.com/spf13/cobra"
)

var pricingCmd = &cobra.Command{
	Use:   "pricing",
	Short: "Pricing data management commands",
	Long:  "Commands for updating, restoring, and managing pricing data snapshots.",
}

var pricingUpdateCmd = &cobra.Command{
	Use:   "update",
	Short: "Update pricing data from cloud provider",
	Long: `Manually trigger pricing data ingestion from cloud provider APIs.

This command runs a 5-phase pipeline:
  1. FETCH     - Download raw pricing from cloud API (no DB writes)
  2. NORMALIZE - Transform to canonical dimensions
  3. VALIDATE  - Governance checks (abort on failure)
  4. BACKUP    - Write local snapshot dump
  5. COMMIT    - Atomic database transaction

IMPORTANT: This command is for operators only. Never run automatically.`,
	RunE: runPricingUpdate,
}

var (
	updateProvider  string
	updateRegion    string
	updateDryRun    bool
	updateOutputDir string
	updateAlias     string
	updateTimeout   time.Duration
)

func init() {
	// Add pricing command to root
	rootCmd.AddCommand(pricingCmd)
	pricingCmd.AddCommand(pricingUpdateCmd)

	// Flags for update command
	pricingUpdateCmd.Flags().StringVarP(&updateProvider, "provider", "p", "", "Cloud provider (aws, azure, gcp)")
	pricingUpdateCmd.Flags().StringVarP(&updateRegion, "region", "r", "", "Region to ingest (e.g., us-east-1)")
	pricingUpdateCmd.Flags().BoolVar(&updateDryRun, "dry-run", false, "Validate only, no database writes")
	pricingUpdateCmd.Flags().StringVarP(&updateOutputDir, "output-dir", "o", "./pricing-backups", "Directory for backup files")
	pricingUpdateCmd.Flags().StringVar(&updateAlias, "alias", "default", "Provider alias for multi-account")
	pricingUpdateCmd.Flags().DurationVar(&updateTimeout, "timeout", 30*time.Minute, "Timeout for the pipeline")

	pricingUpdateCmd.MarkFlagRequired("provider")
	pricingUpdateCmd.MarkFlagRequired("region")
}

func runPricingUpdate(cmd *cobra.Command, args []string) error {
	ctx, cancel := context.WithTimeout(context.Background(), updateTimeout)
	defer cancel()

	// Parse provider
	var provider db.CloudProvider
	switch updateProvider {
	case "aws":
		provider = db.AWS
	case "azure":
		provider = db.Azure
	case "gcp":
		provider = db.GCP
	default:
		return fmt.Errorf("unsupported provider: %s (use aws, azure, or gcp)", updateProvider)
	}

	// Print header
	fmt.Println("")
	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘           MANUAL PRICING DATA INGESTION PIPELINE             â•‘")
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println("")
	fmt.Printf("Provider:   %s\n", provider)
	fmt.Printf("Region:     %s\n", updateRegion)
	fmt.Printf("Alias:      %s\n", updateAlias)
	fmt.Printf("Dry-run:    %t\n", updateDryRun)
	fmt.Printf("Output:     %s\n", updateOutputDir)
	fmt.Println("")

	// Create fetcher and normalizer based on provider
	var fetcher ingestion.PriceFetcher
	var normalizer ingestion.PriceNormalizer

	switch provider {
	case db.AWS:
		fetcher = ingestion.NewAWSPriceFetcher()
		normalizer = ingestion.NewAWSPriceNormalizer()
	case db.Azure:
		fetcher = ingestion.NewAzurePriceFetcher()
		normalizer = ingestion.NewAzurePriceNormalizer()
	case db.GCP:
		fetcher = ingestion.NewGCPPriceFetcher()
		normalizer = ingestion.NewGCPPriceNormalizer()
	default:
		return fmt.Errorf("provider %s not implemented", provider)
	}

	// Get database store (placeholder - would come from config)
	store, err := getDBStore()
	if err != nil {
		return fmt.Errorf("failed to connect to database: %w", err)
	}

	// Create pipeline
	pipeline := ingestion.NewPipeline(fetcher, normalizer, store)

	// Configure
	config := &ingestion.PipelineConfig{
		Provider:           provider,
		Region:             updateRegion,
		Alias:              updateAlias,
		DryRun:             updateDryRun,
		BackupDir:          updateOutputDir,
		MinCoveragePercent: 95.0,
		Timeout:            updateTimeout,
	}

	// Execute
	fmt.Println("Starting pipeline...")
	fmt.Println("")
	result, err := pipeline.Execute(ctx, config)
	if err != nil {
		return fmt.Errorf("pipeline execution failed: %w", err)
	}

	// Print results
	printPipelineResult(result)

	// Exit with error if failed
	if !result.Success {
		os.Exit(1)
	}

	return nil
}

func printPipelineResult(result *ingestion.PipelineResult) {
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	
	if result.Success {
		fmt.Println("âœ“ PIPELINE COMPLETED SUCCESSFULLY")
	} else {
		fmt.Printf("âœ— PIPELINE FAILED at phase: %s\n", result.FailedPhase)
		fmt.Printf("  Error: %s\n", result.Error)
	}
	
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println("")

	// Phases
	fmt.Println("Phases completed:")
	phases := []ingestion.Phase{
		ingestion.PhaseFetch,
		ingestion.PhaseNormalize,
		ingestion.PhaseValidate,
		ingestion.PhaseBackup,
		ingestion.PhaseCommit,
	}
	for _, phase := range phases {
		status := "â¬œ"
		for _, completed := range result.PhasesCompleted {
			if completed == phase {
				status = "âœ“"
				break
			}
		}
		if phase == result.FailedPhase {
			status = "âœ—"
		}
		fmt.Printf("  %s %s\n", status, phase)
	}
	fmt.Println("")

	// Stats
	fmt.Println("Statistics:")
	fmt.Printf("  Raw prices fetched:     %d\n", result.Stats.RawPricesCount)
	fmt.Printf("  Normalized rates:       %d\n", result.Stats.NormalizedRatesCount)
	fmt.Printf("  Unique services:        %d\n", result.Stats.UniqueServicesCount)
	fmt.Printf("  Content hash:           %s\n", truncateHash(result.Stats.ContentHash))
	fmt.Println("")

	if result.BackupPath != "" {
		fmt.Printf("Backup written to: %s\n", result.BackupPath)
	}

	if result.SnapshotID != nil {
		fmt.Printf("Snapshot ID: %s\n", result.SnapshotID.String())
	}

	fmt.Printf("\nDuration: %s\n", result.Duration)
}

func truncateHash(hash string) string {
	if len(hash) > 16 {
		return hash[:16] + "..."
	}
	return hash
}

// getDBStore returns the database store (placeholder)
func getDBStore() (db.PricingStore, error) {
	// TODO: Load from config
	// For now, return nil to indicate not implemented
	return nil, fmt.Errorf("database connection not configured - set DATABASE_URL environment variable")
}

################################################################################
# FILE: :\good projects\cost estimation\cmd\cli\cmd\root.go
# TYPE: go
# SIZE: 2116 bytes
################################################################################
// Package cmd provides the CLI commands for terraform-cost.
package cmd

import (
	"fmt"
	"os"

	"github.com/spf13/cobra"

	"terraform-cost/internal/config"
	"terraform-cost/internal/logging"
)

var (
	cfgFile string
	verbose bool
)

// rootCmd represents the base command
var rootCmd = &cobra.Command{
	Use:   "terraform-cost",
	Short: "Estimate costs for Terraform infrastructure",
	Long: `terraform-cost is a cloud-agnostic infrastructure cost estimation tool.

It analyzes Terraform configurations and produces accurate, reproducible
cost estimates with full lineage tracking.

Examples:
  terraform-cost estimate ./my-terraform-project
  terraform-cost estimate --format json ./infrastructure
  terraform-cost diff main..feature-branch`,
}

// Execute runs the CLI
func Execute() error {
	return rootCmd.Execute()
}

func init() {
	cobra.OnInitialize(initConfig)

	rootCmd.PersistentFlags().StringVar(&cfgFile, "config", "", "config file (default is $HOME/.terraform-cost.json)")
	rootCmd.PersistentFlags().BoolVarP(&verbose, "verbose", "v", false, "enable verbose output")

	// Add subcommands
	rootCmd.AddCommand(estimateCmd)
	rootCmd.AddCommand(versionCmd)
	rootCmd.AddCommand(configCmd)
}

func initConfig() {
	if cfgFile != "" {
		cfg, err := config.Load(cfgFile)
		if err != nil {
			fmt.Fprintf(os.Stderr, "Error loading config: %v\n", err)
			os.Exit(1)
		}
		config.Set(cfg)
	}

	// Initialize logging
	cfg := config.Get()
	if verbose {
		cfg.Logging.Level = "debug"
	}
	if err := logging.Initialize(cfg.Logging); err != nil {
		fmt.Fprintf(os.Stderr, "Error initializing logging: %v\n", err)
	}
}

// versionCmd prints version information
var versionCmd = &cobra.Command{
	Use:   "version",
	Short: "Print version information",
	Run: func(cmd *cobra.Command, args []string) {
		fmt.Println("terraform-cost version 0.1.0")
	},
}

// configCmd manages configuration
var configCmd = &cobra.Command{
	Use:   "config",
	Short: "Manage configuration",
	Run: func(cmd *cobra.Command, args []string) {
		cmd.Help()
	},
}

################################################################################
# FILE: :\good projects\cost estimation\cmd\server\main.go
# TYPE: go
# SIZE: 882 bytes
################################################################################
// Package main - Entry point for Terraform Cost Estimation server
package main

import (
	"flag"
	"fmt"
	"log"
	"net/http"

	"terraform-cost/api"
)

const version = "1.0.0"

func main() {
	addr := flag.String("addr", ":8080", "Server address")
	uiPath := flag.String("ui", "./ui", "Path to UI files")
	flag.Parse()

	// Create API server
	apiServer := api.NewServer(version)

	// Create main mux
	mux := http.NewServeMux()

	// API routes
	mux.Handle("/api/", http.StripPrefix("/api", apiServer))

	// UI static files
	mux.Handle("/", http.FileServer(http.Dir(*uiPath)))

	fmt.Printf("ðŸš€ Terraform Cost Estimation Server v%s\n", version)
	fmt.Printf("   API: http://localhost%s/api\n", *addr)
	fmt.Printf("   UI:  http://localhost%s\n", *addr)
	fmt.Println()

	if err := http.ListenAndServe(*addr, mux); err != nil {
		log.Fatal(err)
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\asset\builder.go
# TYPE: go
# SIZE: 2788 bytes
################################################################################
// Package asset provides the asset graph builder interface and types.
// This package builds the provider-agnostic infrastructure DAG.
package asset

import (
	"context"

	"terraform-cost/core/types"
)

// Builder constructs Asset nodes from RawAssets
type Builder interface {
	// Provider returns the cloud provider this builder handles
	Provider() types.Provider

	// ResourceType returns the resource type (e.g., "aws_instance")
	ResourceType() string

	// Build converts a RawAsset into an Asset
	Build(ctx context.Context, raw *types.RawAsset) (*types.Asset, error)

	// Category returns the asset category for this resource type
	Category() types.AssetCategory
}

// GraphBuilder builds an AssetGraph from raw assets
type GraphBuilder interface {
	// Build constructs an asset graph from raw assets
	Build(ctx context.Context, raw []types.RawAsset) (*types.AssetGraph, error)
}

// BuilderRegistry manages asset builder registration
type BuilderRegistry interface {
	// Register adds a builder to the registry
	Register(builder Builder) error

	// GetBuilder returns a builder for a specific provider and resource type
	GetBuilder(provider types.Provider, resourceType string) (Builder, bool)

	// GetProviderBuilders returns all builders for a provider
	GetProviderBuilders(provider types.Provider) []Builder

	// GetAllResourceTypes returns all registered resource types
	GetAllResourceTypes() []string
}

// BuildOptions configures asset building behavior
type BuildOptions struct {
	// ExpandCount expands count meta-argument into separate assets
	ExpandCount bool

	// ExpandForEach expands for_each meta-argument into separate assets
	ExpandForEach bool

	// ResolveReferences attempts to resolve resource references
	ResolveReferences bool

	// IncludeDataSources includes data sources in the graph
	IncludeDataSources bool
}

// DefaultBuildOptions returns sensible default build options
func DefaultBuildOptions() BuildOptions {
	return BuildOptions{
		ExpandCount:        true,
		ExpandForEach:      true,
		ResolveReferences:  true,
		IncludeDataSources: false,
	}
}

// BuildContext provides context for asset building
type BuildContext struct {
	// Options are the build options
	Options BuildOptions

	// Variables are resolved Terraform variables
	Variables map[string]interface{}

	// Providers are provider configurations
	Providers map[string]ProviderConfig
}

// ProviderConfig contains provider configuration
type ProviderConfig struct {
	// Name is the provider name
	Name string

	// Alias is the provider alias
	Alias string

	// Region is the provider region
	Region string

	// Config contains provider-specific configuration
	Config map[string]interface{}
}

################################################################################
# FILE: :\good projects\cost estimation\core\asset\registry.go
# TYPE: go
# SIZE: 2613 bytes
################################################################################
// Package asset - Asset builder registry
package asset

import (
	"fmt"
	"sync"

	"terraform-cost/core/types"
)

// DefaultBuilderRegistry is the default implementation of BuilderRegistry
type DefaultBuilderRegistry struct {
	mu       sync.RWMutex
	builders map[string]Builder // key: provider/resource_type
	byType   map[string][]Builder
}

// NewBuilderRegistry creates a new builder registry
func NewBuilderRegistry() *DefaultBuilderRegistry {
	return &DefaultBuilderRegistry{
		builders: make(map[string]Builder),
		byType:   make(map[string][]Builder),
	}
}

// Register adds a builder to the registry
func (r *DefaultBuilderRegistry) Register(builder Builder) error {
	r.mu.Lock()
	defer r.mu.Unlock()

	key := makeKey(builder.Provider(), builder.ResourceType())
	if _, exists := r.builders[key]; exists {
		return fmt.Errorf("builder already registered: %s", key)
	}

	r.builders[key] = builder
	r.byType[builder.ResourceType()] = append(r.byType[builder.ResourceType()], builder)
	return nil
}

// GetBuilder returns a builder for a specific provider and resource type
func (r *DefaultBuilderRegistry) GetBuilder(provider types.Provider, resourceType string) (Builder, bool) {
	r.mu.RLock()
	defer r.mu.RUnlock()

	key := makeKey(provider, resourceType)
	builder, ok := r.builders[key]
	return builder, ok
}

// GetProviderBuilders returns all builders for a provider
func (r *DefaultBuilderRegistry) GetProviderBuilders(provider types.Provider) []Builder {
	r.mu.RLock()
	defer r.mu.RUnlock()

	var builders []Builder
	prefix := string(provider) + "/"
	for key, builder := range r.builders {
		if len(key) > len(prefix) && key[:len(prefix)] == prefix {
			builders = append(builders, builder)
		}
	}
	return builders
}

// GetAllResourceTypes returns all registered resource types
func (r *DefaultBuilderRegistry) GetAllResourceTypes() []string {
	r.mu.RLock()
	defer r.mu.RUnlock()

	types := make([]string, 0, len(r.byType))
	for t := range r.byType {
		types = append(types, t)
	}
	return types
}

func makeKey(provider types.Provider, resourceType string) string {
	return string(provider) + "/" + resourceType
}

// Global default registry
var defaultBuilderRegistry = NewBuilderRegistry()

// RegisterBuilder adds a builder to the default registry
func RegisterBuilder(builder Builder) error {
	return defaultBuilderRegistry.Register(builder)
}

// GetDefaultBuilderRegistry returns the default builder registry
func GetDefaultBuilderRegistry() *DefaultBuilderRegistry {
	return defaultBuilderRegistry
}

################################################################################
# FILE: :\good projects\cost estimation\core\capabilities\checkers.go
# TYPE: go
# SIZE: 4896 bytes
################################################################################
// Package capabilities - Capability checking utilities
// Provides helper functions to safely check and extract capabilities from assets.
package capabilities

// CheckCompute safely extracts compute sizing from an asset
// Returns nil if asset doesn't implement ComputeSized
func CheckCompute(asset interface{}) (ComputeSized, bool) {
	cs, ok := asset.(ComputeSized)
	return cs, ok
}

// CheckStorage safely extracts storage sizing from an asset
func CheckStorage(asset interface{}) (StorageSized, bool) {
	ss, ok := asset.(StorageSized)
	return ss, ok
}

// CheckIOPS safely extracts provisioned IOPS from an asset
func CheckIOPS(asset interface{}) (IOPSProvisioned, bool) {
	ip, ok := asset.(IOPSProvisioned)
	return ip, ok
}

// CheckNetwork safely extracts network throughput from an asset
func CheckNetwork(asset interface{}) (NetworkThroughput, bool) {
	nt, ok := asset.(NetworkThroughput)
	return nt, ok
}

// CheckMemory safely extracts memory sizing from an asset
func CheckMemory(asset interface{}) (MemorySized, bool) {
	ms, ok := asset.(MemorySized)
	return ms, ok
}

// CheckRegion safely extracts region info from an asset
func CheckRegion(asset interface{}) (RegionAware, bool) {
	ra, ok := asset.(RegionAware)
	return ra, ok
}

// CheckMultiAZ safely extracts multi-AZ config from an asset
func CheckMultiAZ(asset interface{}) (MultiAZ, bool) {
	ma, ok := asset.(MultiAZ)
	return ma, ok
}

// CheckScalable safely extracts scaling config from an asset
func CheckScalable(asset interface{}) (Scalable, bool) {
	s, ok := asset.(Scalable)
	return s, ok
}

// CheckDatabase safely extracts database engine info from an asset
func CheckDatabase(asset interface{}) (DatabaseEngine, bool) {
	de, ok := asset.(DatabaseEngine)
	return de, ok
}

// CheckServerless safely extracts serverless capacity from an asset
func CheckServerless(asset interface{}) (ServerlessCapacity, bool) {
	sc, ok := asset.(ServerlessCapacity)
	return sc, ok
}

// CheckContainer safely extracts container config from an asset
func CheckContainer(asset interface{}) (Containerized, bool) {
	c, ok := asset.(Containerized)
	return c, ok
}

// CheckCache safely extracts cache config from an asset  
func CheckCache(asset interface{}) (Cacheable, bool) {
	c, ok := asset.(Cacheable)
	return c, ok
}

// CheckStream safely extracts streaming config from an asset
func CheckStream(asset interface{}) (Streamable, bool) {
	s, ok := asset.(Streamable)
	return s, ok
}

// CapabilitySet represents the capabilities an asset has
type CapabilitySet struct {
	HasCompute    bool
	HasStorage    bool
	HasIOPS       bool
	HasNetwork    bool
	HasMemory     bool
	HasRegion     bool
	HasMultiAZ    bool
	HasScaling    bool
	HasDatabase   bool
	HasServerless bool
	HasContainer  bool
	HasCache      bool
	HasStream     bool
}

// Analyze determines which capabilities an asset implements
func Analyze(asset interface{}) CapabilitySet {
	return CapabilitySet{
		HasCompute:    implementsCompute(asset),
		HasStorage:    implementsStorage(asset),
		HasIOPS:       implementsIOPS(asset),
		HasNetwork:    implementsNetwork(asset),
		HasMemory:     implementsMemory(asset),
		HasRegion:     implementsRegion(asset),
		HasMultiAZ:    implementsMultiAZ(asset),
		HasScaling:    implementsScaling(asset),
		HasDatabase:   implementsDatabase(asset),
		HasServerless: implementsServerless(asset),
		HasContainer:  implementsContainer(asset),
		HasCache:      implementsCache(asset),
		HasStream:     implementsStream(asset),
	}
}

func implementsCompute(asset interface{}) bool {
	_, ok := asset.(ComputeSized)
	return ok
}

func implementsStorage(asset interface{}) bool {
	_, ok := asset.(StorageSized)
	return ok
}

func implementsIOPS(asset interface{}) bool {
	_, ok := asset.(IOPSProvisioned)
	return ok
}

func implementsNetwork(asset interface{}) bool {
	_, ok := asset.(NetworkThroughput)
	return ok
}

func implementsMemory(asset interface{}) bool {
	_, ok := asset.(MemorySized)
	return ok
}

func implementsRegion(asset interface{}) bool {
	_, ok := asset.(RegionAware)
	return ok
}

func implementsMultiAZ(asset interface{}) bool {
	_, ok := asset.(MultiAZ)
	return ok
}

func implementsScaling(asset interface{}) bool {
	_, ok := asset.(Scalable)
	return ok
}

func implementsDatabase(asset interface{}) bool {
	_, ok := asset.(DatabaseEngine)
	return ok
}

func implementsServerless(asset interface{}) bool {
	_, ok := asset.(ServerlessCapacity)
	return ok
}

func implementsContainer(asset interface{}) bool {
	_, ok := asset.(Containerized)
	return ok
}

func implementsCache(asset interface{}) bool {
	_, ok := asset.(Cacheable)
	return ok
}

func implementsStream(asset interface{}) bool {
	_, ok := asset.(Streamable)
	return ok
}

################################################################################
# FILE: :\good projects\cost estimation\core\capabilities\examples.go
# TYPE: go
# SIZE: 3799 bytes
################################################################################
// Package capabilities - Example asset implementations
// Shows how assets implement capability interfaces
package capabilities

// EC2Asset is an example asset implementing compute capabilities
type EC2Asset struct {
	address      string
	instanceType string
	region       string
	provider     string
}

// NewEC2Asset creates an EC2 asset
func NewEC2Asset(address, instanceType, region string) *EC2Asset {
	return &EC2Asset{
		address:      address,
		instanceType: instanceType,
		region:       region,
		provider:     "aws",
	}
}

// InstanceType implements ComputeSized
func (a *EC2Asset) InstanceType() string {
	return a.instanceType
}

// InstanceCount implements ComputeSized
func (a *EC2Asset) InstanceCount() int {
	return 1
}

// Region implements RegionAware
func (a *EC2Asset) Region() string {
	return a.region
}

// Provider implements RegionAware
func (a *EC2Asset) Provider() string {
	return a.provider
}

// EBSAsset is an example asset implementing storage capabilities
type EBSAsset struct {
	address     string
	volumeType  string
	sizeGB      float64
	iops        int
	throughput  float64
	region      string
}

// NewEBSAsset creates an EBS volume asset
func NewEBSAsset(address, volumeType string, sizeGB float64, iops int, throughput float64, region string) *EBSAsset {
	return &EBSAsset{
		address:    address,
		volumeType: volumeType,
		sizeGB:     sizeGB,
		iops:       iops,
		throughput: throughput,
		region:     region,
	}
}

// StorageGB implements StorageSized
func (a *EBSAsset) StorageGB() float64 {
	return a.sizeGB
}

// StorageType implements StorageSized
func (a *EBSAsset) StorageType() string {
	return a.volumeType
}

// ProvisionedIOPS implements IOPSProvisioned
func (a *EBSAsset) ProvisionedIOPS() int {
	return a.iops
}

// ProvisionedThroughputMBps implements IOPSProvisioned
func (a *EBSAsset) ProvisionedThroughputMBps() float64 {
	return a.throughput
}

// Region implements RegionAware
func (a *EBSAsset) Region() string {
	return a.region
}

// Provider implements RegionAware
func (a *EBSAsset) Provider() string {
	return "aws"
}

// RDSAsset is an example asset implementing database capabilities
type RDSAsset struct {
	address       string
	engine        string
	engineVersion string
	instanceClass string
	storageGB     float64
	storageType   string
	iops          int
	multiAZ       bool
	region        string
}

// NewRDSAsset creates an RDS asset
func NewRDSAsset(address, engine, instanceClass string, storageGB float64, multiAZ bool, region string) *RDSAsset {
	return &RDSAsset{
		address:       address,
		engine:        engine,
		instanceClass: instanceClass,
		storageGB:     storageGB,
		multiAZ:       multiAZ,
		region:        region,
	}
}

// Engine implements DatabaseEngine
func (a *RDSAsset) Engine() string {
	return a.engine
}

// EngineVersion implements DatabaseEngine
func (a *RDSAsset) EngineVersion() string {
	return a.engineVersion
}

// InstanceClass implements DatabaseEngine
func (a *RDSAsset) InstanceClass() string {
	return a.instanceClass
}

// StorageGB implements StorageSized
func (a *RDSAsset) StorageGB() float64 {
	return a.storageGB
}

// StorageType implements StorageSized
func (a *RDSAsset) StorageType() string {
	return a.storageType
}

// IsMultiAZ implements MultiAZ
func (a *RDSAsset) IsMultiAZ() bool {
	return a.multiAZ
}

// ReplicaCount implements MultiAZ
func (a *RDSAsset) ReplicaCount() int {
	if a.multiAZ {
		return 2
	}
	return 1
}

// Region implements RegionAware
func (a *RDSAsset) Region() string {
	return a.region
}

// Provider implements RegionAware
func (a *RDSAsset) Provider() string {
	return "aws"
}

################################################################################
# FILE: :\good projects\cost estimation\core\capabilities\interfaces.go
# TYPE: go
# SIZE: 4122 bytes
################################################################################
// Package capabilities - Asset capability interfaces
// Formalizes what assets can provide, eliminating fragile attribute assumptions.
// No interface â†’ mapper cannot consume it.
package capabilities

// ComputeSized indicates the asset has compute sizing information
type ComputeSized interface {
	// InstanceType returns the instance/VM type (e.g., "t3.micro", "Standard_B1s")
	InstanceType() string

	// InstanceCount returns the number of instances (1 for single, N for autoscaling)
	InstanceCount() int
}

// StorageSized indicates the asset has storage capacity
type StorageSized interface {
	// StorageGB returns the storage capacity in GB
	StorageGB() float64

	// StorageType returns the storage type (e.g., "gp3", "io1", "Standard_LRS")
	StorageType() string
}

// IOPSProvisioned indicates the asset has provisioned IOPS
type IOPSProvisioned interface {
	// ProvisionedIOPS returns the provisioned IOPS count
	ProvisionedIOPS() int

	// ProvisionedThroughputMBps returns provisioned throughput in MB/s (0 if not applicable)
	ProvisionedThroughputMBps() float64
}

// NetworkThroughput indicates the asset has network usage
type NetworkThroughput interface {
	// MonthlyDataTransferGB returns estimated monthly data transfer in GB
	MonthlyDataTransferGB() float64

	// TransferDirection returns the primary transfer direction
	TransferDirection() string
}

// MemorySized indicates the asset has memory sizing
type MemorySized interface {
	// MemoryMB returns the memory in MB
	MemoryMB() int
}

// RegionAware indicates the asset knows its region
type RegionAware interface {
	// Region returns the deployment region
	Region() string

	// Provider returns the cloud provider
	Provider() string
}

// MultiAZ indicates the asset has multi-AZ configuration
type MultiAZ interface {
	// IsMultiAZ returns true if multi-AZ is enabled
	IsMultiAZ() bool

	// ReplicaCount returns the number of replicas
	ReplicaCount() int
}

// Scalable indicates the asset can scale
type Scalable interface {
	// MinCapacity returns minimum capacity
	MinCapacity() int

	// MaxCapacity returns maximum capacity
	MaxCapacity() int

	// DesiredCapacity returns desired/current capacity
	DesiredCapacity() int

	// IsFixedSize returns true if min == max
	IsFixedSize() bool
}

// UsageDependent indicates the asset requires usage data
type UsageDependent interface {
	// RequiredUsageMetrics returns the list of required usage metrics
	RequiredUsageMetrics() []string

	// OptionalUsageMetrics returns the list of optional metrics
	OptionalUsageMetrics() []string
}

// DatabaseEngine indicates the asset is a database
type DatabaseEngine interface {
	// Engine returns the database engine (mysql, postgres, etc.)
	Engine() string

	// EngineVersion returns the engine version
	EngineVersion() string

	// InstanceClass returns the database instance class
	InstanceClass() string
}

// ServerlessCapacity indicates serverless scaling configuration
type ServerlessCapacity interface {
	// MinACU returns minimum capacity units
	MinACU() float64

	// MaxACU returns maximum capacity units
	MaxACU() float64

	// IsServerless returns true if running in serverless mode
	IsServerless() bool
}

// Containerized indicates the asset runs containers
type Containerized interface {
	// VCPU returns the vCPU allocation
	VCPU() float64

	// MemoryGB returns the memory allocation in GB
	MemoryGB() float64

	// ContainerCount returns number of containers/tasks
	ContainerCount() int
}

// Cacheable indicates the asset is a caching layer
type Cacheable interface {
	// CacheEngine returns the cache engine (redis, memcached)
	CacheEngine() string

	// NodeType returns the cache node type
	NodeType() string

	// NodeCount returns the number of cache nodes
	NodeCount() int
}

// Streamable indicates the asset handles streaming data
type Streamable interface {
	// ShardCount returns number of shards
	ShardCount() int

	// RetentionHours returns data retention in hours
	RetentionHours() int
}

################################################################################
# FILE: :\good projects\cost estimation\core\catalog\aws.go
# TYPE: go
# SIZE: 11569 bytes
################################################################################
// Package catalog - AWS authoritative catalog
// This is the source of truth for AWS resource coverage.
package catalog

// RegisterAWS populates the catalog with all AWS resources
func RegisterAWS(c *Catalog) {
	// ============================================
	// TIER 1 - NUMERIC COST DRIVERS (~90-95% spend)
	// ============================================

	// Compute
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_instance", Tier: Tier1Numeric, Behavior: CostDirect, Category: "compute", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_launch_template", Tier: Tier1Numeric, Behavior: CostDirect, Category: "compute", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_autoscaling_group", Tier: Tier1Numeric, Behavior: CostDirect, Category: "compute", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_ec2_host", Tier: Tier1Numeric, Behavior: CostDirect, Category: "compute", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_eks_cluster", Tier: Tier1Numeric, Behavior: CostDirect, Category: "containers", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_eks_node_group", Tier: Tier1Numeric, Behavior: CostDirect, Category: "containers", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_ecs_service", Tier: Tier1Numeric, Behavior: CostDirect, Category: "containers", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_ecs_task_definition", Tier: Tier1Numeric, Behavior: CostDirect, Category: "containers", MapperExists: false})

	// Storage
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_ebs_volume", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_ebs_snapshot", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_s3_bucket", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "storage", RequiresUsage: true, MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_efs_file_system", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "storage", RequiresUsage: true, MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_fsx_windows_file_system", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_fsx_openzfs_file_system", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_fsx_lustre_file_system", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: true})

	// Database
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_db_instance", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_rds_cluster", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_rds_cluster_instance", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_dynamodb_table", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_elasticache_cluster", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_elasticache_replication_group", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_redshift_cluster", Tier: Tier1Numeric, Behavior: CostDirect, Category: "analytics", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_opensearch_domain", Tier: Tier1Numeric, Behavior: CostDirect, Category: "analytics", MapperExists: true})

	// Networking
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_nat_gateway", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_eip", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_vpc_endpoint", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_dx_connection", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_vpn_connection", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})

	// Load Balancing
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_lb", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_elb", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})

	// Serverless
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_lambda_function", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "serverless", RequiresUsage: true, MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_lambda_provisioned_concurrency_config", Tier: Tier1Numeric, Behavior: CostDirect, Category: "serverless", MapperExists: false})

	// Monitoring
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_cloudwatch_log_group", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "monitoring", RequiresUsage: true, MapperExists: true})

	// Data Transfer / CDN
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_global_accelerator", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_cloudfront_distribution", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "cdn", RequiresUsage: true, MapperExists: false})

	// ============================================
	// TIER 2 - SYMBOLIC/USAGE-DEPENDENT
	// ============================================

	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_api_gateway_rest_api", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "apigateway", RequiresUsage: true, MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_api_gateway_stage", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "apigateway", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_apigatewayv2_api", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "apigateway", RequiresUsage: true, MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_sfn_state_machine", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "serverless", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_kinesis_stream", Tier: Tier2Symbolic, Behavior: CostDirect, Category: "streaming", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_kinesis_firehose_delivery_stream", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "streaming", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_msk_cluster", Tier: Tier2Symbolic, Behavior: CostDirect, Category: "streaming", MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_sqs_queue", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "messaging", RequiresUsage: true, MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_sns_topic", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "messaging", RequiresUsage: true, MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_cloudtrail", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "monitoring", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_backup_vault", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "backup", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_ecr_repository", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "containers", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_route53_zone", Tier: Tier2Symbolic, Behavior: CostDirect, Category: "dns", MapperExists: true})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_route53_record", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "dns", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_waf_web_acl", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "security", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_wafv2_web_acl", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "security", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_secretsmanager_secret", Tier: Tier2Symbolic, Behavior: CostDirect, Category: "security", MapperExists: true})

	// ============================================
	// TIER 3 - INDIRECT / ZERO-COST
	// ============================================

	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_vpc", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost, enables other resources"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_subnet", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_route_table", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_security_group", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_iam_role", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "iam", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_iam_policy", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "iam", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_network_interface", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_appautoscaling_target", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "compute", Notes: "Affects capacity, no direct cost"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_cloudformation_stack", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "infra", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_cloudformation_stack_set", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "infra", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: AWS, ResourceType: "aws_ssm_parameter", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "config", Notes: "Free for standard tier"})
}

################################################################################
# FILE: :\good projects\cost estimation\core\catalog\azure.go
# TYPE: go
# SIZE: 7282 bytes
################################################################################
// Package catalog - Azure authoritative catalog
// This is the source of truth for Azure resource coverage.
package catalog

// RegisterAzure populates the catalog with all Azure resources
func RegisterAzure(c *Catalog) {
	// ============================================
	// TIER 1 - NUMERIC COST DRIVERS
	// ============================================

	// Compute
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_linux_virtual_machine", Tier: Tier1Numeric, Behavior: CostDirect, Category: "compute", MapperExists: true})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_windows_virtual_machine", Tier: Tier1Numeric, Behavior: CostDirect, Category: "compute", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_virtual_machine_scale_set", Tier: Tier1Numeric, Behavior: CostDirect, Category: "compute", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_managed_disk", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: false})

	// Kubernetes
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_kubernetes_cluster", Tier: Tier1Numeric, Behavior: CostDirect, Category: "containers", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_kubernetes_cluster_node_pool", Tier: Tier1Numeric, Behavior: CostDirect, Category: "containers", MapperExists: false})

	// Storage
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_storage_account", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "storage", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_storage_share", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: false})

	// Database
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_sql_database", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_sql_managed_instance", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_postgresql_flexible_server", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_mysql_flexible_server", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_cosmosdb_account", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "database", RequiresUsage: true, MapperExists: false})

	// Networking
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_lb", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_application_gateway", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_vpn_gateway", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_express_route_gateway", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_frontdoor", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "cdn", RequiresUsage: true, MapperExists: false})

	// App / Serverless
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_app_service_plan", Tier: Tier1Numeric, Behavior: CostDirect, Category: "app", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_function_app", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "serverless", RequiresUsage: true, MapperExists: false})

	// Monitoring
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_log_analytics_workspace", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "monitoring", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_application_insights", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "monitoring", RequiresUsage: true, MapperExists: false})

	// ============================================
	// TIER 2 - SYMBOLIC/USAGE-DEPENDENT
	// ============================================

	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_api_management", Tier: Tier2Symbolic, Behavior: CostDirect, Category: "apigateway", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_servicebus_namespace", Tier: Tier2Symbolic, Behavior: CostDirect, Category: "messaging", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_eventgrid_topic", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "messaging", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_data_factory", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "data", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_signalr_service", Tier: Tier2Symbolic, Behavior: CostDirect, Category: "app", MapperExists: false})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_powerbi_embedded", Tier: Tier2Symbolic, Behavior: CostDirect, Category: "analytics", MapperExists: false})

	// ============================================
	// TIER 3 - INDIRECT / ZERO-COST
	// ============================================

	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_virtual_network", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_subnet", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_network_security_group", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_route_table", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_dns_zone", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "dns", Notes: "Minimal cost"})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_dns_record_set", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "dns", Notes: "Query-based"})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_private_dns_zone", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "dns", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_user_assigned_identity", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "iam", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: Azure, ResourceType: "azurerm_role_assignment", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "iam", Notes: "No direct cost"})
}

################################################################################
# FILE: :\good projects\cost estimation\core\catalog\catalog.go
# TYPE: go
# SIZE: 4034 bytes
################################################################################
// Package catalog - Authoritative cloud resource catalog
// Defines the canonical list of resources with tier classification.
// This is the source of truth for coverage.
package catalog

// CoverageTier classifies resources by cost behavior
type CoverageTier int

const (
	// Tier1Numeric - must have numeric cost mapper
	Tier1Numeric CoverageTier = iota
	// Tier2Symbolic - numeric only with usage data
	Tier2Symbolic
	// Tier3Indirect - never numeric, zero-cost graph node
	Tier3Indirect
)

// String returns string representation
func (t CoverageTier) String() string {
	switch t {
	case Tier1Numeric:
		return "tier1_numeric"
	case Tier2Symbolic:
		return "tier2_symbolic"
	case Tier3Indirect:
		return "tier3_indirect"
	default:
		return "unknown"
	}
}

// CostBehavior classifies how a resource affects cost
type CostBehavior int

const (
	// CostDirect - always billable
	CostDirect CostBehavior = iota
	// CostUsageBased - billable with usage
	CostUsageBased
	// CostIndirect - enables other costs, no direct billing
	CostIndirect
	// CostUnsupported - not yet modeled
	CostUnsupported
)

// String returns string representation
func (b CostBehavior) String() string {
	switch b {
	case CostDirect:
		return "direct"
	case CostUsageBased:
		return "usage_based"
	case CostIndirect:
		return "indirect"
	case CostUnsupported:
		return "unsupported"
	default:
		return "unknown"
	}
}

// CloudProvider identifies a cloud
type CloudProvider string

const (
	AWS   CloudProvider = "aws"
	Azure CloudProvider = "azure"
	GCP   CloudProvider = "gcp"
)

// ResourceEntry is a catalog entry for a resource type
type ResourceEntry struct {
	Cloud         CloudProvider
	ResourceType  string
	Tier          CoverageTier
	Behavior      CostBehavior
	Category      string
	RequiresUsage bool
	MapperExists  bool
	Notes         string
}

// Catalog is the authoritative resource catalog
type Catalog struct {
	entries map[string]*ResourceEntry
}

// NewCatalog creates a new catalog
func NewCatalog() *Catalog {
	return &Catalog{
		entries: make(map[string]*ResourceEntry),
	}
}

// Register adds a resource to the catalog
func (c *Catalog) Register(entry ResourceEntry) {
	key := string(entry.Cloud) + ":" + entry.ResourceType
	c.entries[key] = &entry
}

// Get returns a resource entry
func (c *Catalog) Get(cloud CloudProvider, resourceType string) (*ResourceEntry, bool) {
	key := string(cloud) + ":" + resourceType
	entry, ok := c.entries[key]
	return entry, ok
}

// GetTier returns the tier for a resource
func (c *Catalog) GetTier(cloud CloudProvider, resourceType string) CoverageTier {
	if entry, ok := c.Get(cloud, resourceType); ok {
		return entry.Tier
	}
	return Tier2Symbolic // Default to symbolic for unknown
}

// ListByTier returns all resources in a tier
func (c *Catalog) ListByTier(cloud CloudProvider, tier CoverageTier) []string {
	var result []string
	for _, entry := range c.entries {
		if entry.Cloud == cloud && entry.Tier == tier {
			result = append(result, entry.ResourceType)
		}
	}
	return result
}

// Stats returns catalog statistics
func (c *Catalog) Stats() CatalogStats {
	stats := CatalogStats{
		ByCloud: make(map[CloudProvider]CloudStats),
	}
	
	for _, entry := range c.entries {
		stats.Total++
		
		cloudStats := stats.ByCloud[entry.Cloud]
		cloudStats.Total++
		
		switch entry.Tier {
		case Tier1Numeric:
			cloudStats.Tier1++
		case Tier2Symbolic:
			cloudStats.Tier2++
		case Tier3Indirect:
			cloudStats.Tier3++
		}
		
		if entry.MapperExists {
			cloudStats.WithMappers++
		}
		
		stats.ByCloud[entry.Cloud] = cloudStats
	}
	
	return stats
}

// CatalogStats holds catalog statistics
type CatalogStats struct {
	Total   int
	ByCloud map[CloudProvider]CloudStats
}

// CloudStats holds per-cloud statistics
type CloudStats struct {
	Total       int
	Tier1       int
	Tier2       int
	Tier3       int
	WithMappers int
}

################################################################################
# FILE: :\good projects\cost estimation\core\catalog\gcp.go
# TYPE: go
# SIZE: 5874 bytes
################################################################################
// Package catalog - GCP authoritative catalog
// This is the source of truth for GCP resource coverage.
package catalog

// RegisterGCP populates the catalog with all GCP resources
func RegisterGCP(c *Catalog) {
	// ============================================
	// TIER 1 - NUMERIC COST DRIVERS
	// ============================================

	// Compute
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_compute_instance", Tier: Tier1Numeric, Behavior: CostDirect, Category: "compute", MapperExists: true})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_compute_disk", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_compute_snapshot", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_compute_image", Tier: Tier1Numeric, Behavior: CostDirect, Category: "storage", MapperExists: false})

	// Kubernetes
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_container_cluster", Tier: Tier1Numeric, Behavior: CostDirect, Category: "containers", MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_container_node_pool", Tier: Tier1Numeric, Behavior: CostDirect, Category: "containers", MapperExists: false})

	// Storage
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_storage_bucket", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "storage", RequiresUsage: true, MapperExists: false})

	// Database
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_sql_database_instance", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_spanner_instance", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_bigtable_instance", Tier: Tier1Numeric, Behavior: CostDirect, Category: "database", MapperExists: false})

	// Big Data
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_bigquery_dataset", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "analytics", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_bigquery_table", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "analytics", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_dataflow_job", Tier: Tier1Numeric, Behavior: CostDirect, Category: "analytics", MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_dataproc_cluster", Tier: Tier1Numeric, Behavior: CostDirect, Category: "analytics", MapperExists: false})

	// Serverless
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_cloudfunctions_function", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "serverless", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_cloud_run_service", Tier: Tier1Numeric, Behavior: CostUsageBased, Category: "serverless", RequiresUsage: true, MapperExists: false})

	// Networking
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_compute_router_nat", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_compute_forwarding_rule", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_compute_vpn_gateway", Tier: Tier1Numeric, Behavior: CostDirect, Category: "networking", MapperExists: false})

	// ============================================
	// TIER 2 - SYMBOLIC/USAGE-DEPENDENT
	// ============================================

	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_pubsub_topic", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "messaging", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_pubsub_subscription", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "messaging", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_monitoring_metric_descriptor", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "monitoring", RequiresUsage: true, MapperExists: false})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_logging_project_sink", Tier: Tier2Symbolic, Behavior: CostUsageBased, Category: "monitoring", RequiresUsage: true, MapperExists: false})

	// ============================================
	// TIER 3 - INDIRECT / ZERO-COST
	// ============================================

	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_compute_network", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_compute_subnetwork", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "networking", Notes: "No direct cost"})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_dns_managed_zone", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "dns", Notes: "Query-based"})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_dns_record_set", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "dns", Notes: "Query-based"})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_kms_crypto_key", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "security", Notes: "Minimal cost"})
	c.Register(ResourceEntry{Cloud: GCP, ResourceType: "google_secret_manager_secret", Tier: Tier3Indirect, Behavior: CostIndirect, Category: "security", Notes: "Minimal cost"})
}

################################################################################
# FILE: :\good projects\cost estimation\core\catalog\validation.go
# TYPE: go
# SIZE: 2466 bytes
################################################################################
// Package catalog - Catalog validation
// Ensures catalog integrity and enforces invariants.
package catalog

import (
	"fmt"
)

// ValidationRule is a catalog validation rule
type ValidationRule func(*ResourceEntry) error

// DefaultValidationRules returns the standard validation rules
func DefaultValidationRules() []ValidationRule {
	return []ValidationRule{
		validateTierBehaviorConsistency,
		validateUsageRequirement,
		validateMapperRequirement,
	}
}

// Validate checks a catalog against validation rules
func (c *Catalog) Validate(rules []ValidationRule) []error {
	var errors []error
	
	for _, entry := range c.entries {
		for _, rule := range rules {
			if err := rule(entry); err != nil {
				errors = append(errors, fmt.Errorf("%s:%s: %w", entry.Cloud, entry.ResourceType, err))
			}
		}
	}
	
	return errors
}

// validateTierBehaviorConsistency ensures tier and behavior are consistent
func validateTierBehaviorConsistency(e *ResourceEntry) error {
	switch e.Tier {
	case Tier1Numeric:
		if e.Behavior == CostIndirect {
			return fmt.Errorf("Tier1 cannot have CostIndirect behavior")
		}
	case Tier3Indirect:
		if e.Behavior != CostIndirect {
			return fmt.Errorf("Tier3 must have CostIndirect behavior")
		}
	}
	return nil
}

// validateUsageRequirement ensures usage-based resources are flagged
func validateUsageRequirement(e *ResourceEntry) error {
	if e.Behavior == CostUsageBased && !e.RequiresUsage {
		return fmt.Errorf("CostUsageBased behavior requires RequiresUsage=true")
	}
	return nil
}

// validateMapperRequirement ensures Tier1 with mapper has correct behavior
func validateMapperRequirement(e *ResourceEntry) error {
	if e.MapperExists && e.Tier == Tier3Indirect {
		return fmt.Errorf("Tier3 (indirect) resources should not have numeric mappers")
	}
	return nil
}

// MustValidate panics if validation fails
func (c *Catalog) MustValidate() {
	errors := c.Validate(DefaultValidationRules())
	if len(errors) > 0 {
		for _, err := range errors {
			fmt.Printf("Catalog validation error: %v\n", err)
		}
		panic(fmt.Sprintf("Catalog has %d validation errors", len(errors)))
	}
}

// GlobalCatalog is the default global catalog
var GlobalCatalog = NewCatalog()

// Init initializes the global catalog with all clouds
func Init() {
	RegisterAWS(GlobalCatalog)
	RegisterAzure(GlobalCatalog)
	RegisterGCP(GlobalCatalog)
	GlobalCatalog.MustValidate()
}

################################################################################
# FILE: :\good projects\cost estimation\core\confidence\strict_confidence.go
# TYPE: go
# SIZE: 5822 bytes
################################################################################
// Package confidence - Strictly pessimistic confidence
// Aggregate confidence = MIN(all children)
// No averaging, weighting, or smoothing allowed.
package confidence

import (
	"fmt"
	"sort"
)

// StrictAggregateConfidence returns the minimum confidence
// This is the ONLY valid aggregation function
func StrictAggregateConfidence(values []float64) float64 {
	if len(values) == 0 {
		return 0.0 // No data = no confidence
	}

	min := 1.0
	for _, v := range values {
		if v < min {
			min = v
		}
	}
	return min
}

// BLOCKED: These functions are epistemically dishonest

// AvgConfidence is BLOCKED - averaging hides low confidence
func AvgConfidence(values []float64) float64 {
	panic("BLOCKED: AvgConfidence - use StrictAggregateConfidence instead")
}

// WeightedConfidence is BLOCKED - weighting masks weak assumptions
func WeightedConfidence(values []float64, weights []float64) float64 {
	panic("BLOCKED: WeightedConfidence - use StrictAggregateConfidence instead")
}

// SmoothedConfidence is BLOCKED - smoothing is cosmetic
func SmoothedConfidence(values []float64) float64 {
	panic("BLOCKED: SmoothedConfidence - use StrictAggregateConfidence instead")
}

// ConfidenceWithCause tracks confidence with explanation
type ConfidenceWithCause struct {
	Value  float64
	Cause  string
	Source string // e.g., "aws_instance.web", "module.vpc"
}

// ConfidenceAggregator aggregates confidence pessimistically with cause tracking
type ConfidenceAggregator struct {
	entries []ConfidenceWithCause
	min     float64
	minCause string
	minSource string
}

// NewConfidenceAggregator creates an aggregator
func NewConfidenceAggregator() *ConfidenceAggregator {
	return &ConfidenceAggregator{
		entries:   []ConfidenceWithCause{},
		min:       1.0,
		minCause:  "",
		minSource: "",
	}
}

// Add adds a confidence value with cause
func (a *ConfidenceAggregator) Add(value float64, cause, source string) {
	entry := ConfidenceWithCause{
		Value:  value,
		Cause:  cause,
		Source: source,
	}
	a.entries = append(a.entries, entry)

	if value < a.min {
		a.min = value
		a.minCause = cause
		a.minSource = source
	}
}

// Aggregate returns the minimum confidence (pessimistic)
func (a *ConfidenceAggregator) Aggregate() float64 {
	return a.min
}

// GetLowestCause returns the cause of lowest confidence
func (a *ConfidenceAggregator) GetLowestCause() string {
	return a.minCause
}

// GetLowestSource returns the source of lowest confidence
func (a *ConfidenceAggregator) GetLowestSource() string {
	return a.minSource
}

// GetAllCauses returns all causes sorted by confidence (lowest first)
func (a *ConfidenceAggregator) GetAllCauses() []ConfidenceWithCause {
	sorted := make([]ConfidenceWithCause, len(a.entries))
	copy(sorted, a.entries)
	sort.Slice(sorted, func(i, j int) bool {
		return sorted[i].Value < sorted[j].Value
	})
	return sorted
}

// ConfidenceResult is the result of confidence aggregation
type ConfidenceResult struct {
	FinalConfidence   float64
	LowestConfidence  float64
	LowestCause       string
	LowestSource      string
	Level             string // "high", "medium", "low", "unknown"
	AllContributors   []ConfidenceWithCause
}

// GetResult returns the full confidence result
func (a *ConfidenceAggregator) GetResult() *ConfidenceResult {
	return &ConfidenceResult{
		FinalConfidence:  a.min,
		LowestConfidence: a.min,
		LowestCause:      a.minCause,
		LowestSource:     a.minSource,
		Level:            ConfidenceLevel(a.min),
		AllContributors:  a.GetAllCauses(),
	}
}

// ConfidenceLevel returns human-readable level
func ConfidenceLevel(confidence float64) string {
	switch {
	case confidence >= 0.9:
		return "high"
	case confidence >= 0.7:
		return "medium"
	case confidence >= 0.5:
		return "low"
	default:
		return "unknown"
	}
}

// Common confidence causes
const (
	CauseUnknownUsage       = "unknown usage assumption"
	CauseUnknownCardinality = "unknown cardinality"
	CauseImpureFunction     = "impure function in expression"
	CauseDataSource         = "data source dependency"
	CauseModuleOutput       = "module output dependency"
	CauseDefaultValue       = "default value used"
	CauseMissingPricing     = "pricing data unavailable"
)

// Standard confidence values
const (
	ConfidenceKnown      = 1.0
	ConfidenceHigh       = 0.9
	ConfidenceMedium     = 0.7
	ConfidenceLow        = 0.5
	ConfidenceVeryLow    = 0.3
	ConfidenceUnknown    = 0.0
)

// RollupConfidence rolls up confidence from children to parent
// This MUST be used at every boundary (CostUnitâ†’Assetâ†’Moduleâ†’Project)
func RollupConfidence(children []float64) float64 {
	return StrictAggregateConfidence(children)
}

// AssertPessimistic panics if aggregate exceeds minimum
func AssertPessimistic(aggregate float64, components []float64) {
	if len(components) == 0 {
		return
	}
	min := 1.0
	for _, c := range components {
		if c < min {
			min = c
		}
	}
	if aggregate > min {
		panic(fmt.Sprintf("INVARIANT VIOLATED: aggregate confidence %.2f exceeds minimum component %.2f", aggregate, min))
	}
}

// ConfidenceTracker is an alias for ConfidenceAggregator (backwards compatibility)
type ConfidenceTracker = ConfidenceAggregator

// NewConfidenceTracker creates a new tracker (backwards compatibility)
func NewConfidenceTracker() *ConfidenceTracker {
	return NewConfidenceAggregator()
}

// AggregateConfidence is the public function for MIN aggregation
func AggregateConfidence(values []float64) float64 {
	return StrictAggregateConfidence(values)
}

// Apply applies a degradation (for backwards compatibility)
func (a *ConfidenceAggregator) Apply(factor string, reason string) {
	a.Add(0.9, reason, factor)
}

################################################################################
# FILE: :\good projects\cost estimation\core\cost\confidence.go
# TYPE: go
# SIZE: 8567 bytes
################################################################################
// Package cost - Confidence-degrading cost calculations
// Every cost unit MUST carry confidence and degradation reasons.
package cost

import (
	"fmt"

	"terraform-cost/core/determinism"
	"terraform-cost/core/model"
	"terraform-cost/core/pricing"
)

// ConfidenceBoundCost is a cost value that ALWAYS carries confidence.
// No cost can exist without explicit confidence tracking.
type ConfidenceBoundCost struct {
	// The cost value
	Monthly determinism.Money
	Hourly  determinism.Money

	// Confidence (0.0 - 1.0)
	Confidence float64

	// Why confidence is what it is
	Factors []ConfidenceFactor

	// Is this degraded from full confidence?
	IsDegraded bool

	// Snapshot reference (for traceability)
	SnapshotID pricing.SnapshotID
}

// ConfidenceFactor explains one contribution to confidence
type ConfidenceFactor struct {
	Source     string  // What affected confidence
	Reason     string  // Why
	Impact     float64 // How much (0.0-1.0, where 1.0 removes all confidence)
	IsUnknown  bool    // Is this due to an unknown value?
	Component  string  // Which component?
}

// NewConfidenceBoundCost creates a new cost with full confidence
func NewConfidenceBoundCost(monthly, hourly determinism.Money, snapshotID pricing.SnapshotID) *ConfidenceBoundCost {
	return &ConfidenceBoundCost{
		Monthly:    monthly,
		Hourly:     hourly,
		Confidence: 1.0,
		Factors:    []ConfidenceFactor{},
		IsDegraded: false,
		SnapshotID: snapshotID,
	}
}

// Zero creates a zero cost
func ZeroCost(snapshotID pricing.SnapshotID) *ConfidenceBoundCost {
	return &ConfidenceBoundCost{
		Monthly:    determinism.Zero("USD"),
		Hourly:     determinism.Zero("USD"),
		Confidence: 1.0,
		SnapshotID: snapshotID,
	}
}

// DegradeForUnknown reduces confidence due to an unknown value
func (c *ConfidenceBoundCost) DegradeForUnknown(source, reason string, impact float64, component string) {
	c.Confidence *= (1.0 - impact)
	c.IsDegraded = true
	c.Factors = append(c.Factors, ConfidenceFactor{
		Source:    source,
		Reason:    reason,
		Impact:    impact,
		IsUnknown: true,
		Component: component,
	})
}

// DegradeForMissing reduces confidence due to missing data
func (c *ConfidenceBoundCost) DegradeForMissing(source, reason string, impact float64, component string) {
	c.Confidence *= (1.0 - impact)
	c.IsDegraded = true
	c.Factors = append(c.Factors, ConfidenceFactor{
		Source:    source,
		Reason:    reason,
		Impact:    impact,
		IsUnknown: false,
		Component: component,
	})
}

// Add adds two costs, combining confidence
func (c *ConfidenceBoundCost) Add(other *ConfidenceBoundCost) *ConfidenceBoundCost {
	return &ConfidenceBoundCost{
		Monthly:    c.Monthly.Add(other.Monthly),
		Hourly:     c.Hourly.Add(other.Hourly),
		Confidence: c.Confidence * other.Confidence, // Compound confidence
		Factors:    append(c.Factors, other.Factors...),
		IsDegraded: c.IsDegraded || other.IsDegraded,
		SnapshotID: c.SnapshotID,
	}
}

// ConfidenceLevel returns a human-readable confidence level
func (c *ConfidenceBoundCost) ConfidenceLevel() string {
	switch {
	case c.Confidence >= 0.9:
		return "high"
	case c.Confidence >= 0.7:
		return "medium"
	case c.Confidence >= 0.5:
		return "low"
	default:
		return "very_low"
	}
}

// UnknownDrivenDegradation tracks degradation from unknown values
type UnknownDrivenDegradation struct {
	// Instance affected
	InstanceID model.InstanceID
	Address    model.CanonicalAddress

	// What was unknown
	UnknownAttribute string
	UnknownReason    string

	// Impact on cost
	ConfidenceImpact float64
	CostImpact       *CostImpactEstimate
}

// CostImpactEstimate estimates how much an unknown affects cost
type CostImpactEstimate struct {
	// Range of possible costs
	MinCost determinism.Money
	MaxCost determinism.Money

	// Most likely cost
	LikelyCost determinism.Money

	// How we estimated
	Method string
}

// CostWithProvenance is a cost with full provenance chain
type CostWithProvenance struct {
	// The cost
	Cost *ConfidenceBoundCost

	// Instance identity
	Identity *model.InstanceIdentity

	// Component name
	Component string

	// Rate used
	Rate *RateProvenance

	// Usage applied
	Usage *UsageProvenance

	// Formula
	Formula *FormulaProvenance
}

// RateProvenance tracks which rate was used
type RateProvenance struct {
	RateID       pricing.RateID
	RateKey      pricing.RateKey
	Price        string
	Unit         string
	Currency     string
	WasFound     bool
	MissingReason string
}

// UsageProvenance tracks where usage came from
type UsageProvenance struct {
	Value       float64
	Unit        string
	Source      UsageSource
	Confidence  float64
	WasUnknown  bool
	Assumptions []string
}

// UsageSource indicates usage data origin
type UsageSource int

const (
	UsageSourceDefault UsageSource = iota
	UsageSourceOverride
	UsageSourceProfile
	UsageSourceHistorical
	UsageSourceUnknown
)

// FormulaProvenance tracks how cost was calculated
type FormulaProvenance struct {
	Name       string
	Expression string
	Inputs     map[string]FormulaInput
	Output     string
}

// FormulaInput is a formula input with source
type FormulaInput struct {
	Value      string
	Source     string // "rate", "usage", "constant"
	Confidence float64
}

// InstanceCostResult is the complete result for one instance
type InstanceCostResult struct {
	// Identity
	Identity *model.InstanceIdentity

	// Total cost with confidence
	Total *ConfidenceBoundCost

	// Per-component costs
	Components []*CostWithProvenance

	// All degradation factors
	Degradations []*UnknownDrivenDegradation

	// Summary
	IsFullConfidence bool
	DegradedCount    int
	UnknownCount     int
}

// NewInstanceCostResult creates a new result
func NewInstanceCostResult(identity *model.InstanceIdentity, snapshotID pricing.SnapshotID) *InstanceCostResult {
	return &InstanceCostResult{
		Identity:         identity,
		Total:            ZeroCost(snapshotID),
		Components:       []*CostWithProvenance{},
		Degradations:     []*UnknownDrivenDegradation{},
		IsFullConfidence: true,
	}
}

// AddComponent adds a component cost
func (r *InstanceCostResult) AddComponent(comp *CostWithProvenance) {
	r.Components = append(r.Components, comp)
	r.Total = r.Total.Add(comp.Cost)

	if comp.Cost.IsDegraded {
		r.IsFullConfidence = false
		r.DegradedCount++
	}

	if comp.Usage != nil && comp.Usage.WasUnknown {
		r.UnknownCount++
		r.Degradations = append(r.Degradations, &UnknownDrivenDegradation{
			InstanceID:       r.Identity.ID,
			Address:          r.Identity.Canonical,
			UnknownAttribute: fmt.Sprintf("%s.usage", comp.Component),
			UnknownReason:    "usage value was unknown",
			ConfidenceImpact: 1.0 - comp.Cost.Confidence,
		})
	}
}

// AggregatedCostResult is the complete estimation result
type AggregatedCostResult struct {
	// Instance results
	Instances []*InstanceCostResult

	// Totals with confidence
	TotalMonthly    determinism.Money
	TotalHourly     determinism.Money
	TotalConfidence float64

	// Aggregated degradation info
	TotalDegraded  int
	TotalUnknowns  int
	DegradedCost   determinism.Money // Amount of cost that's degraded

	// Snapshot
	SnapshotID pricing.SnapshotID
}

// NewAggregatedCostResult creates a new aggregated result
func NewAggregatedCostResult(snapshotID pricing.SnapshotID) *AggregatedCostResult {
	return &AggregatedCostResult{
		Instances:       []*InstanceCostResult{},
		TotalMonthly:    determinism.Zero("USD"),
		TotalHourly:     determinism.Zero("USD"),
		TotalConfidence: 1.0,
		DegradedCost:    determinism.Zero("USD"),
		SnapshotID:      snapshotID,
	}
}

// Add adds an instance result
func (r *AggregatedCostResult) Add(inst *InstanceCostResult) {
	r.Instances = append(r.Instances, inst)
	r.TotalMonthly = r.TotalMonthly.Add(inst.Total.Monthly)
	r.TotalHourly = r.TotalHourly.Add(inst.Total.Hourly)
	r.TotalConfidence *= inst.Total.Confidence

	if !inst.IsFullConfidence {
		r.TotalDegraded++
		r.DegradedCost = r.DegradedCost.Add(inst.Total.Monthly)
	}
	r.TotalUnknowns += inst.UnknownCount
}

// ConfidenceLevel returns overall confidence level
func (r *AggregatedCostResult) ConfidenceLevel() string {
	switch {
	case r.TotalConfidence >= 0.9:
		return "high"
	case r.TotalConfidence >= 0.7:
		return "medium"
	case r.TotalConfidence >= 0.5:
		return "low"
	default:
		return "very_low"
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\cost\engine.go
# TYPE: go
# SIZE: 2177 bytes
################################################################################
// Package cost provides the cost graph engine interface.
// This package transforms assets + usage into billable cost units.
package cost

import (
	"context"

	"terraform-cost/core/types"
	"terraform-cost/core/usage"
)

// Engine transforms assets and usage into cost graphs
type Engine interface {
	// Calculate produces a cost graph from an asset graph and usage data
	Calculate(ctx context.Context, assets *types.AssetGraph, usage map[string]*usage.EstimationResult, pricing *types.PricingResult) (*types.CostGraph, error)
}

// Calculator calculates costs for a specific resource type
type Calculator interface {
	// Provider returns the cloud provider
	Provider() types.Provider

	// ResourceType returns the resource type this calculator handles
	ResourceType() string

	// Calculate produces cost units for an asset
	Calculate(ctx context.Context, asset *types.Asset, usage []types.UsageVector, pricing *types.PricingResult) ([]*types.CostUnit, error)
}

// CalculatorRegistry manages cost calculator registration
type CalculatorRegistry interface {
	// Register adds a calculator to the registry
	Register(calculator Calculator) error

	// GetCalculator returns a calculator for a provider and resource type
	GetCalculator(provider types.Provider, resourceType string) (Calculator, bool)

	// GetProviderCalculators returns all calculators for a provider
	GetProviderCalculators(provider types.Provider) []Calculator
}

// FormulaContext provides context for cost formula evaluation
type FormulaContext struct {
	// Asset is the asset being priced
	Asset *types.Asset

	// Usage contains usage vectors for the asset
	Usage []types.UsageVector

	// Pricing contains resolved prices
	Pricing *types.PricingResult

	// Region is the deployment region
	Region types.Region
}

// Formula represents a cost calculation formula
type Formula interface {
	// Name returns the formula name
	Name() string

	// Calculate evaluates the formula
	Calculate(ctx *FormulaContext) ([]*types.CostUnit, error)

	// RateKeys returns the rate keys needed for this formula
	RateKeys(ctx *FormulaContext) []types.RateKey
}

################################################################################
# FILE: :\good projects\cost estimation\core\cost\graph.go
# TYPE: go
# SIZE: 10959 bytes
################################################################################
// Package cost - Normalized cost graph
// CostUnit (atomic) â†’ CostNode (grouped by asset) â†’ CostAggregate (service/provider/project)
// No pricing logic exists above CostUnit.
package cost

import (
	"sort"

	"terraform-cost/core/determinism"
	"terraform-cost/core/model"
)

// CostUnit is the atomic unit of cost
// All pricing logic lives here and ONLY here
type CostUnit struct {
	// Identity
	ID       string
	Category CostCategory

	// What this costs
	Amount   determinism.Money
	Hourly   determinism.Money
	Monthly  determinism.Money

	// Pricing derivation (immutable)
	Rate     *RateDerivation
	Usage    *UsageDerivation
	Formula  *FormulaDerivation

	// Confidence
	Confidence float64
	Factors    []CostConfidenceFactor

	// Is this an assumption?
	IsAssumed    bool
	AssumptionID string
}

// CostCategory classifies cost units
type CostCategory int

const (
	CategoryCompute   CostCategory = iota // EC2, Lambda, ECS
	CategoryStorage                        // S3, EBS, RDS storage
	CategoryNetwork                        // NAT, data transfer
	CategoryDatabase                       // RDS, DynamoDB, ElastiCache
	CategoryCache                          // ElastiCache, DAX
	CategoryMessaging                      // SQS, SNS, Kinesis
	CategoryOther                          // Uncategorized
)

// String returns the category name
func (c CostCategory) String() string {
	switch c {
	case CategoryCompute:
		return "compute"
	case CategoryStorage:
		return "storage"
	case CategoryNetwork:
		return "network"
	case CategoryDatabase:
		return "database"
	case CategoryCache:
		return "cache"
	case CategoryMessaging:
		return "messaging"
	default:
		return "other"
	}
}

// RateDerivation records how the rate was determined
type RateDerivation struct {
	RateID       string
	SKU          string
	Price        determinism.Money
	Unit         string
	Region       string
	SnapshotID   string
	SnapshotHash string
}

// UsageDerivation records how usage was determined
type UsageDerivation struct {
	Value     float64
	Unit      string
	Source    CostUsageSource
	IsDefault bool
	DefaultID string
}

// CostUsageSource indicates where usage came from
type CostUsageSource int

const (
	CostUsageFromConfig     CostUsageSource = iota // From Terraform config
	CostUsageFromDefault                            // From default value
	CostUsageFromOverride                           // From usage file
	CostUsageFromHistorical                         // From historical data
)

// FormulaDerivation records the calculation formula
type FormulaDerivation struct {
	Expression string   // e.g., "rate * usage * hours"
	Variables  []string // Variables used
	Result     string   // Result expression
}

// CostConfidenceFactor records a reason for confidence change
type CostConfidenceFactor struct {
	Rule   string
	Reason string
	Impact float64
}

// CostNode groups CostUnits by asset
type CostNode struct {
	// Identity
	InstanceID      model.InstanceID
	InstanceAddress model.InstanceAddress
	ResourceType    string
	Provider        string
	Region          string

	// Cost units for this asset
	Units []*CostUnit

	// Aggregated costs
	TotalMonthly determinism.Money
	TotalHourly  determinism.Money

	// Category breakdown
	ByCategory map[CostCategory]determinism.Money

	// Aggregated confidence (minimum)
	Confidence float64

	// Assumptions made
	Assumptions []string
}

// NewCostNode creates a new cost node
func NewCostNode(id model.InstanceID, address model.InstanceAddress, resourceType, provider, region string) *CostNode {
	return &CostNode{
		InstanceID:      id,
		InstanceAddress: address,
		ResourceType:    resourceType,
		Provider:        provider,
		Region:          region,
		Units:           []*CostUnit{},
		ByCategory:      make(map[CostCategory]determinism.Money),
		Confidence:      1.0,
		Assumptions:     []string{},
	}
}

// AddUnit adds a cost unit and updates aggregates
func (n *CostNode) AddUnit(unit *CostUnit) {
	n.Units = append(n.Units, unit)
	n.TotalMonthly = n.TotalMonthly.Add(unit.Monthly)
	n.TotalHourly = n.TotalHourly.Add(unit.Hourly)

	// Update category breakdown
	if existing, ok := n.ByCategory[unit.Category]; ok {
		n.ByCategory[unit.Category] = existing.Add(unit.Monthly)
	} else {
		n.ByCategory[unit.Category] = unit.Monthly
	}

	// Update confidence (take minimum)
	if unit.Confidence < n.Confidence {
		n.Confidence = unit.Confidence
	}

	// Track assumptions
	if unit.IsAssumed {
		n.Assumptions = append(n.Assumptions, unit.AssumptionID)
	}
}

// CostAggregate groups CostNodes by service/provider/project
type CostAggregate struct {
	// Identity
	Name  string
	Level AggregateLevel

	// Child nodes
	Nodes []*CostNode

	// Child aggregates (for hierarchy)
	Children []*CostAggregate

	// Aggregated costs
	TotalMonthly determinism.Money
	TotalHourly  determinism.Money

	// Breakdowns
	ByCategory map[CostCategory]determinism.Money
	ByProvider map[string]determinism.Money
	ByRegion   map[string]determinism.Money

	// Aggregated confidence
	Confidence float64

	// Assumptions count
	AssumptionCount int
}

// AggregateLevel indicates the level of aggregation
type AggregateLevel int

const (
	LevelComponent AggregateLevel = iota // Single component
	LevelResource                         // Single resource
	LevelService                          // Service (e.g., all EC2)
	LevelProvider                         // Provider (e.g., all AWS)
	LevelProject                          // Entire project
)

// String returns the level name
func (l AggregateLevel) String() string {
	switch l {
	case LevelComponent:
		return "component"
	case LevelResource:
		return "resource"
	case LevelService:
		return "service"
	case LevelProvider:
		return "provider"
	case LevelProject:
		return "project"
	default:
		return "unknown"
	}
}

// NewCostAggregate creates a new aggregate
func NewCostAggregate(name string, level AggregateLevel) *CostAggregate {
	return &CostAggregate{
		Name:       name,
		Level:      level,
		Nodes:      []*CostNode{},
		Children:   []*CostAggregate{},
		ByCategory: make(map[CostCategory]determinism.Money),
		ByProvider: make(map[string]determinism.Money),
		ByRegion:   make(map[string]determinism.Money),
		Confidence: 1.0,
	}
}

// AddNode adds a node and updates aggregates
func (a *CostAggregate) AddNode(node *CostNode) {
	a.Nodes = append(a.Nodes, node)
	a.TotalMonthly = a.TotalMonthly.Add(node.TotalMonthly)
	a.TotalHourly = a.TotalHourly.Add(node.TotalHourly)

	// Update category breakdown
	for cat, amount := range node.ByCategory {
		if existing, ok := a.ByCategory[cat]; ok {
			a.ByCategory[cat] = existing.Add(amount)
		} else {
			a.ByCategory[cat] = amount
		}
	}

	// Update provider breakdown
	if existing, ok := a.ByProvider[node.Provider]; ok {
		a.ByProvider[node.Provider] = existing.Add(node.TotalMonthly)
	} else {
		a.ByProvider[node.Provider] = node.TotalMonthly
	}

	// Update region breakdown
	if existing, ok := a.ByRegion[node.Region]; ok {
		a.ByRegion[node.Region] = existing.Add(node.TotalMonthly)
	} else {
		a.ByRegion[node.Region] = node.TotalMonthly
	}

	// Update confidence
	if node.Confidence < a.Confidence {
		a.Confidence = node.Confidence
	}

	// Track assumptions
	a.AssumptionCount += len(node.Assumptions)
}

// AddChild adds a child aggregate
func (a *CostAggregate) AddChild(child *CostAggregate) {
	a.Children = append(a.Children, child)
	a.TotalMonthly = a.TotalMonthly.Add(child.TotalMonthly)
	a.TotalHourly = a.TotalHourly.Add(child.TotalHourly)

	// Merge breakdowns
	for cat, amount := range child.ByCategory {
		if existing, ok := a.ByCategory[cat]; ok {
			a.ByCategory[cat] = existing.Add(amount)
		} else {
			a.ByCategory[cat] = amount
		}
	}

	// Update confidence
	if child.Confidence < a.Confidence {
		a.Confidence = child.Confidence
	}

	a.AssumptionCount += child.AssumptionCount
}

// CostGraph is the complete cost graph
type CostGraph struct {
	// Root aggregate (project level)
	Root *CostAggregate

	// All nodes indexed by instance ID
	NodesByID map[model.InstanceID]*CostNode

	// Aggregates by level
	ByLevel map[AggregateLevel][]*CostAggregate
}

// NewCostGraph creates a new cost graph
func NewCostGraph(projectName string) *CostGraph {
	return &CostGraph{
		Root:      NewCostAggregate(projectName, LevelProject),
		NodesByID: make(map[model.InstanceID]*CostNode),
		ByLevel:   make(map[AggregateLevel][]*CostAggregate),
	}
}

// AddNode adds a cost node to the graph
func (g *CostGraph) AddNode(node *CostNode) {
	g.NodesByID[node.InstanceID] = node
	g.Root.AddNode(node)
}

// GetNode returns a node by instance ID
func (g *CostGraph) GetNode(id model.InstanceID) *CostNode {
	return g.NodesByID[id]
}

// TopCostNodes returns the n highest cost nodes
func (g *CostGraph) TopCostNodes(n int) []*CostNode {
	nodes := make([]*CostNode, 0, len(g.NodesByID))
	for _, node := range g.NodesByID {
		nodes = append(nodes, node)
	}
	sort.Slice(nodes, func(i, j int) bool {
		return nodes[i].TotalMonthly.Cmp(nodes[j].TotalMonthly) > 0
	})
	if n > len(nodes) {
		n = len(nodes)
	}
	return nodes[:n]
}

// LowConfidenceNodes returns nodes below a confidence threshold
func (g *CostGraph) LowConfidenceNodes(threshold float64) []*CostNode {
	var result []*CostNode
	for _, node := range g.NodesByID {
		if node.Confidence < threshold {
			result = append(result, node)
		}
	}
	return result
}

// BuildServiceAggregates builds service-level aggregates
func (g *CostGraph) BuildServiceAggregates() {
	byService := make(map[string]*CostAggregate)

	for _, node := range g.NodesByID {
		service := extractService(node.ResourceType)
		agg, ok := byService[service]
		if !ok {
			agg = NewCostAggregate(service, LevelService)
			byService[service] = agg
		}
		agg.AddNode(node)
	}

	for _, agg := range byService {
		g.ByLevel[LevelService] = append(g.ByLevel[LevelService], agg)
		g.Root.AddChild(agg)
	}
}

func extractService(resourceType string) string {
	// aws_instance â†’ ec2
	// aws_s3_bucket â†’ s3
	// aws_db_instance â†’ rds
	serviceMap := map[string]string{
		"aws_instance":           "ec2",
		"aws_launch_template":    "ec2",
		"aws_s3_bucket":          "s3",
		"aws_s3_object":          "s3",
		"aws_db_instance":        "rds",
		"aws_rds_cluster":        "rds",
		"aws_lambda_function":    "lambda",
		"aws_ecs_service":        "ecs",
		"aws_ecs_task_definition":"ecs",
		"aws_elasticache_cluster":"elasticache",
		"aws_nat_gateway":        "vpc",
		"aws_lb":                 "elb",
	}
	if service, ok := serviceMap[resourceType]; ok {
		return service
	}
	return "other"
}

################################################################################
# FILE: :\good projects\cost estimation\core\detection\detector.go
# TYPE: go
# SIZE: 1582 bytes
################################################################################
// Package detection provides project detection interfaces.
// This package determines what type of IaC project is being analyzed.
package detection

import (
	"context"

	"terraform-cost/core/types"
)

// Detector identifies project types
type Detector interface {
	// Name returns the detector identifier
	Name() string

	// Detect determines if the input matches this detector's project type
	Detect(ctx context.Context, path string) (*types.DetectedProject, error)

	// ProjectType returns the project type this detector handles
	ProjectType() types.ProjectType

	// Priority returns the detection priority (higher = checked first)
	Priority() int
}

// Registry manages detector registration
type Registry interface {
	// Register adds a detector to the registry
	Register(detector Detector) error

	// GetDetector returns a detector by name
	GetDetector(name string) (Detector, bool)

	// GetAll returns all registered detectors
	GetAll() []Detector

	// Detect finds the first matching detector and returns its result
	Detect(ctx context.Context, path string) (*types.DetectedProject, error)

	// DetectAll runs all detectors and returns all matches
	DetectAll(ctx context.Context, path string) ([]*types.DetectedProject, error)
}

// DetectionResult contains detection output
type DetectionResult struct {
	// Project is the detected project
	Project *types.DetectedProject

	// Detector is the detector that matched
	Detector string

	// Alternatives are other possible matches
	Alternatives []*types.DetectedProject
}

################################################################################
# FILE: :\good projects\cost estimation\core\determinism\stable.go
# TYPE: go
# SIZE: 7581 bytes
################################################################################
// Package determinism provides primitives for guaranteeing deterministic execution.
// All code must use these primitives instead of Go built-ins for maps, IDs, etc.
package determinism

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"sort"
	"sync"

	"github.com/shopspring/decimal"
)

// StableMap is a map that guarantees iteration order (sorted by key).
// Use this instead of map[K]V for all cases where iteration matters.
type StableMap[K comparable, V any] struct {
	mu      sync.RWMutex
	keys    []K
	values  map[K]V
	keyFunc func(K) string // For custom ordering
}

// NewStableMap creates a new StableMap
func NewStableMap[K comparable, V any]() *StableMap[K, V] {
	return &StableMap[K, V]{
		values: make(map[K]V),
	}
}

// NewStableMapWithKeyFunc creates a StableMap with custom key ordering
func NewStableMapWithKeyFunc[K comparable, V any](keyFunc func(K) string) *StableMap[K, V] {
	return &StableMap[K, V]{
		values:  make(map[K]V),
		keyFunc: keyFunc,
	}
}

// Set adds or updates a key-value pair
func (m *StableMap[K, V]) Set(key K, value V) {
	m.mu.Lock()
	defer m.mu.Unlock()

	if _, exists := m.values[key]; !exists {
		m.keys = append(m.keys, key)
		m.sortKeys()
	}
	m.values[key] = value
}

// Get retrieves a value by key
func (m *StableMap[K, V]) Get(key K) (V, bool) {
	m.mu.RLock()
	defer m.mu.RUnlock()
	val, ok := m.values[key]
	return val, ok
}

// Delete removes a key
func (m *StableMap[K, V]) Delete(key K) {
	m.mu.Lock()
	defer m.mu.Unlock()

	delete(m.values, key)
	// Remove from keys slice
	for i, k := range m.keys {
		if any(k) == any(key) {
			m.keys = append(m.keys[:i], m.keys[i+1:]...)
			break
		}
	}
}

// Range iterates in stable sorted order
func (m *StableMap[K, V]) Range(fn func(K, V) bool) {
	m.mu.RLock()
	defer m.mu.RUnlock()

	for _, k := range m.keys {
		if !fn(k, m.values[k]) {
			break
		}
	}
}

// Keys returns all keys in sorted order
func (m *StableMap[K, V]) Keys() []K {
	m.mu.RLock()
	defer m.mu.RUnlock()
	result := make([]K, len(m.keys))
	copy(result, m.keys)
	return result
}

// Len returns the number of entries
func (m *StableMap[K, V]) Len() int {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return len(m.values)
}

func (m *StableMap[K, V]) sortKeys() {
	sort.Slice(m.keys, func(i, j int) bool {
		if m.keyFunc != nil {
			return m.keyFunc(m.keys[i]) < m.keyFunc(m.keys[j])
		}
		return fmt.Sprint(m.keys[i]) < fmt.Sprint(m.keys[j])
	})
}

// StableID is a hash-based unique identifier that's deterministic
type StableID string

// IDGenerator generates stable, deterministic IDs
type IDGenerator struct {
	namespace string
}

// NewIDGenerator creates an ID generator with a namespace
func NewIDGenerator(namespace string) *IDGenerator {
	return &IDGenerator{namespace: namespace}
}

// Generate creates a stable ID from inputs
func (g *IDGenerator) Generate(parts ...string) StableID {
	h := sha256.New()
	h.Write([]byte(g.namespace))
	h.Write([]byte{0}) // Separator
	for _, part := range parts {
		h.Write([]byte(part))
		h.Write([]byte{0}) // Separator
	}
	return StableID(hex.EncodeToString(h.Sum(nil))[:16])
}

// ContentHash is a SHA-256 hash for content integrity
type ContentHash [32]byte

// ComputeHash computes a content hash from bytes
func ComputeHash(data []byte) ContentHash {
	return sha256.Sum256(data)
}

// Hex returns the hash as a hex string
func (h ContentHash) Hex() string {
	return hex.EncodeToString(h[:])
}

// String implements Stringer
func (h ContentHash) String() string {
	return h.Hex()[:16] + "..."
}

// Money represents a monetary amount with full precision.
// NEVER use float64 for money calculations.
type Money struct {
	amount   decimal.Decimal
	currency string
}

// NewMoney creates a Money from a decimal string
func NewMoney(amount string, currency string) (Money, error) {
	d, err := decimal.NewFromString(amount)
	if err != nil {
		return Money{}, err
	}
	return Money{amount: d, currency: currency}, nil
}

// NewMoneyFromFloat creates Money from float64 (use sparingly)
func NewMoneyFromFloat(amount float64, currency string) Money {
	return Money{amount: decimal.NewFromFloat(amount), currency: currency}
}

// NewMoneyFromDecimal creates Money from decimal
func NewMoneyFromDecimal(amount decimal.Decimal, currency string) Money {
	return Money{amount: amount, currency: currency}
}

// Zero creates zero money
func Zero(currency string) Money {
	return Money{amount: decimal.Zero, currency: currency}
}

// Amount returns the decimal amount
func (m Money) Amount() decimal.Decimal {
	return m.amount
}

// Currency returns the currency code
func (m Money) Currency() string {
	return m.currency
}

// Add adds two monetary amounts
func (m Money) Add(other Money) Money {
	if m.currency != other.currency {
		panic(fmt.Sprintf("cannot add %s and %s", m.currency, other.currency))
	}
	return Money{amount: m.amount.Add(other.amount), currency: m.currency}
}

// Sub subtracts monetary amounts
func (m Money) Sub(other Money) Money {
	if m.currency != other.currency {
		panic(fmt.Sprintf("cannot subtract %s and %s", m.currency, other.currency))
	}
	return Money{amount: m.amount.Sub(other.amount), currency: m.currency}
}

// Mul multiplies by a scalar
func (m Money) Mul(factor decimal.Decimal) Money {
	return Money{amount: m.amount.Mul(factor), currency: m.currency}
}

// MulFloat multiplies by a float64 scalar
func (m Money) MulFloat(factor float64) Money {
	return Money{amount: m.amount.Mul(decimal.NewFromFloat(factor)), currency: m.currency}
}

// Div divides by a scalar
func (m Money) Div(divisor decimal.Decimal) Money {
	return Money{amount: m.amount.Div(divisor), currency: m.currency}
}

// IsZero returns true if amount is zero
func (m Money) IsZero() bool {
	return m.amount.IsZero()
}

// IsNegative returns true if amount is negative
func (m Money) IsNegative() bool {
	return m.amount.IsNegative()
}

// Cmp compares two monetary amounts
func (m Money) Cmp(other Money) int {
	if m.currency != other.currency {
		panic(fmt.Sprintf("cannot compare %s and %s", m.currency, other.currency))
	}
	return m.amount.Cmp(other.amount)
}

// String returns formatted money (2 decimal places)
func (m Money) String() string {
	return fmt.Sprintf("%s %s", m.amount.StringFixed(2), m.currency)
}

// StringRaw returns the raw decimal string (full precision)
func (m Money) StringRaw() string {
	return m.amount.String()
}

// Float64 returns float64 (only for display, never for calculation)
func (m Money) Float64() float64 {
	f, _ := m.amount.Float64()
	return f
}

// SortSlice sorts a slice in a stable, deterministic manner
func SortSlice[T any](slice []T, less func(a, b T) bool) {
	sort.SliceStable(slice, func(i, j int) bool {
		return less(slice[i], slice[j])
	})
}

// SortStrings sorts strings in place
func SortStrings(s []string) {
	sort.Strings(s)
}

// SortedMap returns a sorted copy of map keys
func SortedKeys[K comparable, V any](m map[K]V) []K {
	keys := make([]K, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	sort.Slice(keys, func(i, j int) bool {
		return fmt.Sprint(keys[i]) < fmt.Sprint(keys[j])
	})
	return keys
}

// RangeMapSorted iterates over a map in sorted key order
func RangeMapSorted[K comparable, V any](m map[K]V, fn func(K, V) bool) {
	for _, k := range SortedKeys(m) {
		if !fn(k, m[k]) {
			break
		}
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\diff\dependency_diff.go
# TYPE: go
# SIZE: 7167 bytes
################################################################################
// Package diff - Dependency-closure aware diff engine
// Diff MUST use dependency closure, not just address matching.
package diff

import (
	"terraform-cost/core/determinism"
	"terraform-cost/core/graph"
)

// DependencyClosureDiff computes diffs using dependency closure
type DependencyClosureDiff struct {
	before *graph.EnforcedCostGraph
	after  *graph.EnforcedCostGraph
}

// NewDependencyClosureDiff creates a diff engine
func NewDependencyClosureDiff(before, after *graph.EnforcedCostGraph) *DependencyClosureDiff {
	return &DependencyClosureDiff{
		before: before,
		after:  after,
	}
}

// ComputeDiff computes the diff with full dependency closure awareness
func (d *DependencyClosureDiff) ComputeDiff() *ClosureAwareDiff {
	result := &ClosureAwareDiff{
		ChangedNodes:      []graph.DependencyNodeID{},
		AffectedAssets:    []*graph.EnforcedAsset{},
		AffectedCostUnits: []*graph.EnforcedCostUnit{},
		DirectChanges:     []*CostChange{},
		IndirectChanges:   []*CostChange{},
		SymbolicChanges:   []*SymbolicChange{},
	}

	if d.after == nil {
		return result
	}

	// Find changed nodes by comparing cost units
	changedNodes := d.findChangedNodes()
	result.ChangedNodes = changedNodes

	// Get affected cost units via dependency closure
	result.AffectedCostUnits = d.after.GetAffectedCostUnits(changedNodes)

	// Classify changes
	d.classifyChanges(result)

	// Calculate totals
	result.calculateTotals()

	return result
}

func (d *DependencyClosureDiff) findChangedNodes() []graph.DependencyNodeID {
	changed := make(map[graph.DependencyNodeID]bool)

	afterUnits := d.after.AllCostUnits()
	for _, unit := range afterUnits {
		// Check if this is new or changed
		isNew := d.before == nil
		var beforeCost determinism.Money
		if !isNew {
			// Find corresponding before unit
			// For simplicity, using first node in dependency path
			if len(unit.DependencyPath) > 0 {
				lastNode := unit.DependencyPath[len(unit.DependencyPath)-1]
				changed[lastNode] = true
			}
		}
		_ = beforeCost
	}

	result := make([]graph.DependencyNodeID, 0, len(changed))
	for nodeID := range changed {
		result = append(result, nodeID)
	}
	return result
}

func (d *DependencyClosureDiff) classifyChanges(result *ClosureAwareDiff) {
	for _, unit := range result.AffectedCostUnits {
		if unit.IsSymbolic {
			result.SymbolicChanges = append(result.SymbolicChanges, &SymbolicChange{
				CostUnitID: unit.CostUnitID,
				AssetID:    unit.AssetID,
				Reason:     unit.SymbolicInfo.Reason,
				IsUnbounded: unit.SymbolicInfo.IsUnbounded,
			})
			continue
		}

		// Check if this is a direct or indirect change
		// Direct: last node in path is changed
		// Indirect: upstream node is changed
		isDirect := false
		if len(unit.DependencyPath) > 0 {
			lastNode := unit.DependencyPath[len(unit.DependencyPath)-1]
			for _, changed := range result.ChangedNodes {
				if lastNode == changed {
					isDirect = true
					break
				}
			}
		}

		change := &CostChange{
			CostUnitID:     unit.CostUnitID,
			AssetID:        unit.AssetID,
			DependencyPath: unit.DependencyPath,
			NewCost:        unit.MonthlyCost,
			Confidence:     unit.Confidence,
		}

		if isDirect {
			result.DirectChanges = append(result.DirectChanges, change)
		} else {
			result.IndirectChanges = append(result.IndirectChanges, change)
		}
	}
}

// ClosureAwareDiff is a diff with full dependency closure
type ClosureAwareDiff struct {
	// Changed nodes in dependency graph
	ChangedNodes []graph.DependencyNodeID

	// Affected entities (via dependency closure)
	AffectedAssets    []*graph.EnforcedAsset
	AffectedCostUnits []*graph.EnforcedCostUnit

	// Classified changes
	DirectChanges   []*CostChange   // Node itself changed
	IndirectChanges []*CostChange   // Upstream dependency changed
	SymbolicChanges []*SymbolicChange

	// Totals
	DirectCostDelta   determinism.Money
	IndirectCostDelta determinism.Money
	TotalCostDelta    determinism.Money
	MinConfidence     float64
}

func (d *ClosureAwareDiff) calculateTotals() {
	d.DirectCostDelta = determinism.Zero("USD")
	d.IndirectCostDelta = determinism.Zero("USD")
	d.MinConfidence = 1.0

	for _, change := range d.DirectChanges {
		d.DirectCostDelta = d.DirectCostDelta.Add(change.NewCost)
		if change.Confidence < d.MinConfidence {
			d.MinConfidence = change.Confidence
		}
	}

	for _, change := range d.IndirectChanges {
		d.IndirectCostDelta = d.IndirectCostDelta.Add(change.NewCost)
		if change.Confidence < d.MinConfidence {
			d.MinConfidence = change.Confidence
		}
	}

	// Symbolic changes reduce confidence to 0
	if len(d.SymbolicChanges) > 0 {
		d.MinConfidence = 0
	}

	d.TotalCostDelta = d.DirectCostDelta.Add(d.IndirectCostDelta)
}

// CostChange represents a cost change
type CostChange struct {
	CostUnitID     string
	AssetID        string
	DependencyPath []graph.DependencyNodeID
	OldCost        determinism.Money
	NewCost        determinism.Money
	Confidence     float64
}

// SymbolicChange represents a symbolic (unknown cardinality) change
type SymbolicChange struct {
	CostUnitID  string
	AssetID     string
	Reason      string
	IsUnbounded bool
}

// GetExplanation returns why a cost unit changed
func (d *ClosureAwareDiff) GetExplanation(costUnitID string) string {
	for _, change := range d.DirectChanges {
		if change.CostUnitID == costUnitID {
			return "Direct change to resource"
		}
	}
	for _, change := range d.IndirectChanges {
		if change.CostUnitID == costUnitID {
			if len(change.DependencyPath) > 1 {
				return "Changed because upstream dependency changed"
			}
		}
	}
	for _, change := range d.SymbolicChanges {
		if change.CostUnitID == costUnitID {
			return "Unknown cardinality: " + change.Reason
		}
	}
	return "No change"
}

// PolicyContext is the context passed to policies
// Policies MUST receive dependency-scoped information
type PolicyContext struct {
	// Changed nodes in dependency graph
	ChangedDependencyNodes []graph.DependencyNodeID

	// Affected cost units (via dependency closure)
	AffectedCostUnits []*graph.EnforcedCostUnit

	// The full diff
	Diff *ClosureAwareDiff

	// Mode
	IsStrictMode bool
}

// NewPolicyContext creates a policy context from a diff
func NewPolicyContext(diff *ClosureAwareDiff, isStrict bool) *PolicyContext {
	return &PolicyContext{
		ChangedDependencyNodes: diff.ChangedNodes,
		AffectedCostUnits:      diff.AffectedCostUnits,
		Diff:                   diff,
		IsStrictMode:           isStrict,
	}
}

// HasSymbolicCosts returns true if there are symbolic costs
func (c *PolicyContext) HasSymbolicCosts() bool {
	return len(c.Diff.SymbolicChanges) > 0
}

// NewResourcesOnly returns only new/added resources
func (c *PolicyContext) NewResourcesOnly() []*graph.EnforcedCostUnit {
	// For now, all affected units are considered "changed"
	return c.AffectedCostUnits
}

// GetMinConfidence returns minimum confidence (pessimistic)
func (c *PolicyContext) GetMinConfidence() float64 {
	return c.Diff.MinConfidence
}

################################################################################
# FILE: :\good projects\cost estimation\core\diff\differ.go
# TYPE: go
# SIZE: 11083 bytes
################################################################################
// Package diff provides instance-level cost diffing.
// Compares two cost estimation results at the instance level.
package diff

import (
	"sort"

	"terraform-cost/core/cost"
	"terraform-cost/core/determinism"
	"terraform-cost/core/model"
)

// DiffResult is the complete diff between two estimation results
type DiffResult struct {
	// Overall summary
	TotalBefore    determinism.Money
	TotalAfter     determinism.Money
	TotalDelta     determinism.Money
	DeltaPercent   float64

	// Instance-level changes
	Added      []*InstanceDiff
	Removed    []*InstanceDiff
	Changed    []*InstanceDiff
	Unchanged  []*InstanceDiff

	// Counts
	AddedCount    int
	RemovedCount  int
	ChangedCount  int
	UnchangedCount int

	// Confidence impact
	ConfidenceBefore float64
	ConfidenceAfter  float64
}

// InstanceDiff describes changes to a single instance
type InstanceDiff struct {
	// Identity
	Identity *model.InstanceIdentity
	Address  model.CanonicalAddress

	// Change type
	ChangeType ChangeType

	// Costs
	Before *cost.ConfidenceBoundCost
	After  *cost.ConfidenceBoundCost
	Delta  determinism.Money

	// Component-level changes
	ComponentDiffs []*ComponentDiff

	// What drove the change
	ChangeReasons []ChangeReason
}

// ChangeType indicates the type of change
type ChangeType int

const (
	ChangeAdded    ChangeType = iota // New instance
	ChangeRemoved                     // Instance removed
	ChangeModified                    // Instance cost changed
	ChangeUnchanged                   // No cost change
)

// String returns the change type name
func (c ChangeType) String() string {
	switch c {
	case ChangeAdded:
		return "added"
	case ChangeRemoved:
		return "removed"
	case ChangeModified:
		return "modified"
	case ChangeUnchanged:
		return "unchanged"
	default:
		return "unknown"
	}
}

// ComponentDiff describes changes to a cost component
type ComponentDiff struct {
	ComponentName string
	ChangeType    ChangeType

	Before *cost.CostWithProvenance
	After  *cost.CostWithProvenance
	Delta  determinism.Money

	// What changed
	RateChanged   bool
	UsageChanged  bool
	OldRate       string
	NewRate       string
	OldUsage      float64
	NewUsage      float64
}

// ChangeReason explains why a cost changed
type ChangeReason struct {
	Category string // "rate", "usage", "quantity", "configuration"
	What     string // What changed
	Impact   determinism.Money
}

// Differ computes diffs between estimation results
type Differ struct {
	// Threshold for "unchanged" (e.g., 0.01 = 1%)
	ChangeThreshold float64
}

// NewDiffer creates a new differ
func NewDiffer(changeThreshold float64) *Differ {
	if changeThreshold <= 0 {
		changeThreshold = 0.001 // 0.1% default
	}
	return &Differ{ChangeThreshold: changeThreshold}
}

// Diff computes the diff between before and after
func (d *Differ) Diff(before, after *cost.AggregatedCostResult) *DiffResult {
	result := &DiffResult{
		TotalBefore:      before.TotalMonthly,
		TotalAfter:       after.TotalMonthly,
		ConfidenceBefore: before.TotalConfidence,
		ConfidenceAfter:  after.TotalConfidence,
		Added:            []*InstanceDiff{},
		Removed:          []*InstanceDiff{},
		Changed:          []*InstanceDiff{},
		Unchanged:        []*InstanceDiff{},
	}

	// Calculate delta
	result.TotalDelta = after.TotalMonthly.Sub(before.TotalMonthly)
	if !before.TotalMonthly.IsZero() {
		result.DeltaPercent = (after.TotalMonthly.Float64() - before.TotalMonthly.Float64()) / before.TotalMonthly.Float64() * 100
	}

	// Index before instances
	beforeMap := make(map[model.CanonicalAddress]*cost.InstanceCostResult)
	for _, inst := range before.Instances {
		beforeMap[inst.Identity.Canonical] = inst
	}

	// Index after instances
	afterMap := make(map[model.CanonicalAddress]*cost.InstanceCostResult)
	for _, inst := range after.Instances {
		afterMap[inst.Identity.Canonical] = inst
	}

	// Find added, changed, unchanged
	for addr, afterInst := range afterMap {
		beforeInst, existed := beforeMap[addr]

		if !existed {
			// Added
			diff := d.createInstanceDiff(nil, afterInst, ChangeAdded)
			result.Added = append(result.Added, diff)
			result.AddedCount++
		} else {
			// Existed before - check if changed
			diff := d.compareInstances(beforeInst, afterInst)
			if diff.ChangeType == ChangeModified {
				result.Changed = append(result.Changed, diff)
				result.ChangedCount++
			} else {
				result.Unchanged = append(result.Unchanged, diff)
				result.UnchangedCount++
			}
		}
	}

	// Find removed
	for addr, beforeInst := range beforeMap {
		if _, exists := afterMap[addr]; !exists {
			diff := d.createInstanceDiff(beforeInst, nil, ChangeRemoved)
			result.Removed = append(result.Removed, diff)
			result.RemovedCount++
		}
	}

	// Sort all lists by address for determinism
	d.sortDiffs(result.Added)
	d.sortDiffs(result.Removed)
	d.sortDiffs(result.Changed)
	d.sortDiffs(result.Unchanged)

	return result
}

func (d *Differ) createInstanceDiff(before, after *cost.InstanceCostResult, changeType ChangeType) *InstanceDiff {
	diff := &InstanceDiff{
		ChangeType:     changeType,
		ComponentDiffs: []*ComponentDiff{},
		ChangeReasons:  []ChangeReason{},
	}

	switch changeType {
	case ChangeAdded:
		diff.Identity = after.Identity
		diff.Address = after.Identity.Canonical
		diff.After = after.Total
		diff.Delta = after.Total.Monthly
		diff.ChangeReasons = append(diff.ChangeReasons, ChangeReason{
			Category: "quantity",
			What:     "new instance",
			Impact:   after.Total.Monthly,
		})

	case ChangeRemoved:
		diff.Identity = before.Identity
		diff.Address = before.Identity.Canonical
		diff.Before = before.Total
		diff.Delta = determinism.Zero("USD").Sub(before.Total.Monthly)
		diff.ChangeReasons = append(diff.ChangeReasons, ChangeReason{
			Category: "quantity",
			What:     "instance removed",
			Impact:   diff.Delta,
		})
	}

	return diff
}

func (d *Differ) compareInstances(before, after *cost.InstanceCostResult) *InstanceDiff {
	diff := &InstanceDiff{
		Identity:       after.Identity,
		Address:        after.Identity.Canonical,
		Before:         before.Total,
		After:          after.Total,
		Delta:          after.Total.Monthly.Sub(before.Total.Monthly),
		ComponentDiffs: []*ComponentDiff{},
		ChangeReasons:  []ChangeReason{},
	}

	// Check if cost changed significantly
	beforeCost := before.Total.Monthly.Float64()
	afterCost := after.Total.Monthly.Float64()

	if beforeCost == 0 && afterCost == 0 {
		diff.ChangeType = ChangeUnchanged
		return diff
	}

	var percentChange float64
	if beforeCost > 0 {
		percentChange = (afterCost - beforeCost) / beforeCost
	} else {
		percentChange = 1.0 // Infinite increase from 0
	}

	if abs(percentChange) <= d.ChangeThreshold {
		diff.ChangeType = ChangeUnchanged
		return diff
	}

	diff.ChangeType = ChangeModified

	// Compare components
	beforeComponents := make(map[string]*cost.CostWithProvenance)
	for _, c := range before.Components {
		beforeComponents[c.Component] = c
	}

	for _, afterComp := range after.Components {
		beforeComp, existed := beforeComponents[afterComp.Component]

		compDiff := &ComponentDiff{
			ComponentName: afterComp.Component,
			After:         afterComp,
		}

		if !existed {
			compDiff.ChangeType = ChangeAdded
			compDiff.Delta = afterComp.Cost.Monthly
			diff.ChangeReasons = append(diff.ChangeReasons, ChangeReason{
				Category: "configuration",
				What:     "new component: " + afterComp.Component,
				Impact:   afterComp.Cost.Monthly,
			})
		} else {
			compDiff.Before = beforeComp
			compDiff.Delta = afterComp.Cost.Monthly.Sub(beforeComp.Cost.Monthly)

			if !compDiff.Delta.IsZero() {
				compDiff.ChangeType = ChangeModified

				// What changed?
				if beforeComp.Rate != nil && afterComp.Rate != nil {
					if beforeComp.Rate.Price != afterComp.Rate.Price {
						compDiff.RateChanged = true
						compDiff.OldRate = beforeComp.Rate.Price
						compDiff.NewRate = afterComp.Rate.Price
						diff.ChangeReasons = append(diff.ChangeReasons, ChangeReason{
							Category: "rate",
							What:     afterComp.Component + " rate changed",
							Impact:   compDiff.Delta,
						})
					}
				}

				if beforeComp.Usage != nil && afterComp.Usage != nil {
					if beforeComp.Usage.Value != afterComp.Usage.Value {
						compDiff.UsageChanged = true
						compDiff.OldUsage = beforeComp.Usage.Value
						compDiff.NewUsage = afterComp.Usage.Value
						diff.ChangeReasons = append(diff.ChangeReasons, ChangeReason{
							Category: "usage",
							What:     afterComp.Component + " usage changed",
							Impact:   compDiff.Delta,
						})
					}
				}
			} else {
				compDiff.ChangeType = ChangeUnchanged
			}
		}

		diff.ComponentDiffs = append(diff.ComponentDiffs, compDiff)
	}

	// Check for removed components
	for name, beforeComp := range beforeComponents {
		found := false
		for _, afterComp := range after.Components {
			if afterComp.Component == name {
				found = true
				break
			}
		}
		if !found {
			compDiff := &ComponentDiff{
				ComponentName: name,
				ChangeType:    ChangeRemoved,
				Before:        beforeComp,
				Delta:         determinism.Zero("USD").Sub(beforeComp.Cost.Monthly),
			}
			diff.ComponentDiffs = append(diff.ComponentDiffs, compDiff)
			diff.ChangeReasons = append(diff.ChangeReasons, ChangeReason{
				Category: "configuration",
				What:     "component removed: " + name,
				Impact:   compDiff.Delta,
			})
		}
	}

	return diff
}

func (d *Differ) sortDiffs(diffs []*InstanceDiff) {
	sort.Slice(diffs, func(i, j int) bool {
		return diffs[i].Address < diffs[j].Address
	})
}

func abs(x float64) float64 {
	if x < 0 {
		return -x
	}
	return x
}

// DiffSummary provides a human-readable summary
func (r *DiffResult) Summary() string {
	var summary string

	// Overall change
	if r.TotalDelta.IsZero() {
		summary = "No cost change\n"
	} else if r.TotalDelta.IsNegative() {
		summary = "Cost decreased by " + r.TotalDelta.String() + "\n"
	} else {
		summary = "Cost increased by " + r.TotalDelta.String() + "\n"
	}

	// Instance changes
	if r.AddedCount > 0 {
		summary += "  + " + string(rune('0'+r.AddedCount)) + " instances added\n"
	}
	if r.RemovedCount > 0 {
		summary += "  - " + string(rune('0'+r.RemovedCount)) + " instances removed\n"
	}
	if r.ChangedCount > 0 {
		summary += "  ~ " + string(rune('0'+r.ChangedCount)) + " instances changed\n"
	}

	return summary
}

// TopChanges returns the instances with largest cost impact
func (r *DiffResult) TopChanges(n int) []*InstanceDiff {
	all := append(r.Added, r.Removed...)
	all = append(all, r.Changed...)

	sort.Slice(all, func(i, j int) bool {
		iAbs := abs(all[i].Delta.Float64())
		jAbs := abs(all[j].Delta.Float64())
		return iAbs > jAbs
	})

	if n > len(all) {
		n = len(all)
	}
	return all[:n]
}

################################################################################
# FILE: :\good projects\cost estimation\core\enforcement\pipeline.go
# TYPE: go
# SIZE: 10129 bytes
################################################################################
// Package enforcement - Unified architectural enforcement
// This is the ONLY entry point for estimation.
// All other paths are blocked by package visibility.
package enforcement

import (
	"context"
	"fmt"

	"terraform-cost/core/determinism"
	"terraform-cost/core/graph"
	"terraform-cost/core/guards"
	"terraform-cost/core/pricing"
	"terraform-cost/core/terraform"
)

// EstimationPipeline is the ONLY way to perform estimation.
// It enforces all architectural invariants at each step.
type EstimationPipeline struct {
	enforcer        *guards.InvariantEnforcer
	guardedExpand   *guards.GuardedExpansion
	mode            terraform.EvaluationMode
	
	// State - each becomes non-nil only after its phase
	depGraph        *graph.InfrastructureGraph
	providerFinal   *terraform.ProviderFinalizer
	costGraph       *graph.DerivedCostGraph
	pricingSnapshot *pricing.PricingSnapshot
	
	// Accumulated warnings and errors
	warnings        []string
	symbolicCosts   []*graph.SymbolicCost
}

// NewEstimationPipeline creates the pipeline
func NewEstimationPipeline(mode terraform.EvaluationMode) *EstimationPipeline {
	enforcer := guards.NewInvariantEnforcer()
	return &EstimationPipeline{
		enforcer:      enforcer,
		guardedExpand: guards.NewGuardedExpansion(enforcer),
		mode:          mode,
		warnings:      []string{},
		symbolicCosts: []*graph.SymbolicCost{},
	}
}

// Step1_BuildDependencyGraph builds the authoritative dependency graph
// This MUST be called first.
func (p *EstimationPipeline) Step1_BuildDependencyGraph(ctx context.Context, parsed *graph.ParsedInfra) error {
	builder := graph.NewInfraGraphBuilder()
	depGraph, err := builder.Build(parsed)
	if err != nil {
		return fmt.Errorf("failed to build dependency graph: %w", err)
	}

	p.depGraph = depGraph
	p.enforcer.MarkDependencyGraphBuilt(depGraph)
	return nil
}

// Step2_FreezeProviders freezes all provider configurations
// This MUST be called after Step1.
func (p *EstimationPipeline) Step2_FreezeProviders(ctx context.Context, providers []*terraform.ProviderContext) error {
	p.enforcer.AssertDependencyGraphBuilt()

	p.providerFinal = terraform.NewProviderFinalizer()
	for _, prov := range providers {
		if _, err := p.providerFinal.Freeze(prov); err != nil {
			return fmt.Errorf("failed to freeze provider %s: %w", prov.ProviderKey(), err)
		}
	}
	p.providerFinal.Finalize()
	p.enforcer.MarkProvidersFrozen(p.providerFinal)
	return nil
}

// Step3_ExpandAssets expands assets using guarded expansion
// This MUST be called after Step2.
// Unknown cardinality is NEVER expanded - it becomes a SymbolicCost.
func (p *EstimationPipeline) Step3_ExpandAssets(ctx context.Context, definitions []ResourceDefinition) (*ExpandedAssets, error) {
	p.enforcer.AssertProvidersFrozen()

	expanded := &ExpandedAssets{
		Instances:     []ExpandedInstance{},
		SymbolicCosts: []*graph.SymbolicCost{},
	}

	for _, def := range definitions {
		// Verify resource is in dependency graph
		p.enforcer.AssertNodeInDependencyGraph(def.Address)

		// Get frozen provider
		providerKey := def.ProviderKey
		if providerKey == "" {
			providerKey = extractProvider(def.ResourceType)
		}
		frozenProvider, ok := p.providerFinal.Get(providerKey)
		if !ok && p.mode == terraform.ModeStrict {
			return nil, fmt.Errorf("no provider for %s in strict mode", def.Address)
		}

		// Handle expansion
		if def.Count != nil {
			instances, err := p.guardedExpand.ExpandResource(def.Address, def.Count.Value, def.Count.IsKnown)
			if err != nil {
				// Unknown cardinality - create symbolic cost
				symbolic := &graph.SymbolicCost{
					Address:      def.Address,
					Expression:   def.Count.Expression,
					MinInstances: 0,
					MaxInstances: -1, // Unbounded
					IsUnbounded:  true,
					Confidence:   0.3,
					Warning:      fmt.Sprintf("count at %s is unknown - cost is unbounded", def.Address),
				}
				expanded.SymbolicCosts = append(expanded.SymbolicCosts, symbolic)
				p.symbolicCosts = append(p.symbolicCosts, symbolic)
				continue
			}
			for _, addr := range instances {
				expanded.Instances = append(expanded.Instances, ExpandedInstance{
					Address:        addr,
					DefinitionAddr: def.Address,
					Provider:       frozenProvider,
				})
			}
			continue
		}

		if def.ForEach != nil {
			instances, err := p.guardedExpand.ExpandForEach(def.Address, def.ForEach.Keys, def.ForEach.IsKnown)
			if err != nil {
				// Unknown cardinality - create symbolic cost
				symbolic := &graph.SymbolicCost{
					Address:      def.Address,
					Expression:   def.ForEach.Expression,
					MinInstances: 0,
					MaxInstances: -1,
					IsUnbounded:  true,
					Confidence:   0.3,
					Warning:      fmt.Sprintf("for_each at %s is unknown - cost is unbounded", def.Address),
				}
				expanded.SymbolicCosts = append(expanded.SymbolicCosts, symbolic)
				p.symbolicCosts = append(p.symbolicCosts, symbolic)
				continue
			}
			for _, addr := range instances {
				expanded.Instances = append(expanded.Instances, ExpandedInstance{
					Address:        addr,
					DefinitionAddr: def.Address,
					Provider:       frozenProvider,
				})
			}
			continue
		}

		// Single instance
		expanded.Instances = append(expanded.Instances, ExpandedInstance{
			Address:        def.Address,
			DefinitionAddr: def.Address,
			Provider:       frozenProvider,
		})
	}

	p.enforcer.MarkExpansionComplete()
	p.warnings = append(p.warnings, p.guardedExpand.GetWarnings()...)
	return expanded, nil
}

// Step4_BuildCostGraph builds the cost graph FROM the dependency graph
// This MUST be called after Step3.
// The cost graph MUST derive from the dependency graph.
func (p *EstimationPipeline) Step4_BuildCostGraph(ctx context.Context, expanded *ExpandedAssets) error {
	p.enforcer.AssertExpansionComplete()

	// Cost graph MUST be derived from dependency graph
	costGraph, err := graph.NewDerivedCostGraph(p.depGraph)
	if err != nil {
		return fmt.Errorf("failed to create cost graph: %w", err)
	}

	// Add symbolic costs for unknown cardinality
	for _, symbolic := range expanded.SymbolicCosts {
		costGraph.AddSymbolicCost(
			symbolic.Address,
			determinism.Zero("USD"), // Cost per unit unknown
			symbolic.MinInstances,
			symbolic.MaxInstances,
			symbolic.Expression,
		)
	}

	p.costGraph = costGraph
	p.enforcer.MarkCostGraphBuilt()
	return nil
}

// Step5_ApplyPricing applies pricing to the cost graph
// This MUST be called after Step4.
// Provider alias MUST be in every rate key.
func (p *EstimationPipeline) Step5_ApplyPricing(ctx context.Context, expanded *ExpandedAssets, calculator PricingCalculator) error {
	p.enforcer.AssertCostGraphBuilt()

	if p.pricingSnapshot == nil {
		return fmt.Errorf("pricing snapshot not set")
	}

	resolver := pricing.NewAliasAwareRateResolver()

	for _, inst := range expanded.Instances {
		// Provider alias MUST be in rate key
		rateKey := pricing.NewAliasAwareRateKey(
			inst.Provider.Type,
			inst.Provider.Alias,
			inst.Provider.Region,
			extractResourceType(inst.Address),
			"compute",
		)

		rate, err := resolver.ResolveRate(p.pricingSnapshot, rateKey)
		if err != nil {
			if p.mode == terraform.ModeStrict {
				return fmt.Errorf("rate not found for %s: %w", inst.Address, err)
			}
			p.warnings = append(p.warnings, fmt.Sprintf("rate not found for %s", inst.Address))
			continue
		}

		// Calculate cost
		monthly := determinism.NewMoneyFromDecimal(rate.Price, rate.Currency)
		hourly := monthly.Div(determinism.NewMoneyFromFloat(730, "USD").Amount())

		if err := p.costGraph.SetNodeCost(inst.DefinitionAddr, monthly, hourly, 1.0); err != nil {
			p.warnings = append(p.warnings, fmt.Sprintf("could not set cost for %s: %v", inst.Address, err))
		}
	}

	p.costGraph.CalculateTransitiveCosts()
	p.enforcer.MarkPricingComplete()
	return nil
}

// SetPricingSnapshot sets the pricing snapshot to use
func (p *EstimationPipeline) SetPricingSnapshot(snapshot *pricing.PricingSnapshot) {
	p.pricingSnapshot = snapshot
}

// GetResult returns the estimation result
func (p *EstimationPipeline) GetResult() *EstimationResult {
	costRange := p.costGraph.GetTotalCostRange()

	return &EstimationResult{
		CostGraph:       p.costGraph,
		TotalCostRange:  costRange,
		SymbolicCosts:   p.symbolicCosts,
		HasUnbounded:    p.costGraph.HasUnboundedCosts(),
		Warnings:        p.warnings,
	}
}

// ResourceDefinition is input to expansion
type ResourceDefinition struct {
	Address      string
	ResourceType string
	ProviderKey  string
	Count        *CountValue
	ForEach      *ForEachValue
}

// CountValue represents a count expression
type CountValue struct {
	Value      int
	IsKnown    bool
	Expression string
}

// ForEachValue represents a for_each expression
type ForEachValue struct {
	Keys       []string
	IsKnown    bool
	Expression string
}

// ExpandedAssets is the result of expansion
type ExpandedAssets struct {
	Instances     []ExpandedInstance
	SymbolicCosts []*graph.SymbolicCost
}

// ExpandedInstance is a single expanded instance
type ExpandedInstance struct {
	Address        string
	DefinitionAddr string
	Provider       *terraform.FrozenProviderContext
}

// PricingCalculator calculates pricing
type PricingCalculator interface {
	Calculate(resourceType string, attrs map[string]string) (determinism.Money, error)
}

// EstimationResult is the final result
type EstimationResult struct {
	CostGraph      *graph.DerivedCostGraph
	TotalCostRange *graph.CostBounds
	SymbolicCosts  []*graph.SymbolicCost
	HasUnbounded   bool
	Warnings       []string
}

func extractProvider(resourceType string) string {
	for i, c := range resourceType {
		if c == '_' {
			return resourceType[:i]
		}
	}
	return resourceType
}

func extractResourceType(address string) string {
	// aws_instance.foo[0] â†’ aws_instance
	for i, c := range address {
		if c == '.' {
			return address[:i]
		}
	}
	return address
}

################################################################################
# FILE: :\good projects\cost estimation\core\engine\engine.go
# TYPE: go
# SIZE: 13444 bytes
################################################################################
// Package engine provides the API-primary estimation engine.
// CLI is a thin wrapper around this engine.
package engine

import (
	"context"
	"fmt"
	"time"

	"terraform-cost/core/determinism"
	"terraform-cost/core/model"
	"terraform-cost/core/pricing"
)

// Engine is the primary API for cost estimation.
// All other interfaces (CLI, HTTP, CI) are thin wrappers.
type Engine struct {
	// Required dependencies
	pricingResolver PricingResolver
	usageEstimator  UsageEstimator
	policyEvaluator PolicyEvaluator

	// Plugin registry
	cloudPlugins map[string]CloudPlugin

	// Configuration
	config EngineConfig
}

// EngineConfig configures the estimation engine
type EngineConfig struct {
	// Default region for pricing
	DefaultRegion string

	// Unknown handling
	UnknownCountDefault int
	UnknownBehavior     UnknownBehavior

	// Confidence thresholds
	MinConfidenceForEstimate float64
}

// UnknownBehavior defines how to handle unknown values
type UnknownBehavior int

const (
	// UnknownPropagate marks results as uncertain (correct behavior)
	UnknownPropagate UnknownBehavior = iota
	// UnknownFail returns an error on unknowns
	UnknownFail
)

// PricingResolver resolves pricing - MUST use snapshots
type PricingResolver interface {
	// GetSnapshot returns a pricing snapshot - never "latest" implicitly
	GetSnapshot(ctx context.Context, req SnapshotRequest) (*pricing.PricingSnapshot, error)

	// LookupRate finds a rate within a snapshot
	LookupRate(snapshot *pricing.PricingSnapshot, resourceType, component string, attrs map[string]string) (*pricing.RateEntry, error)
}

// SnapshotRequest specifies which snapshot to retrieve
type SnapshotRequest struct {
	// SnapshotID is preferred if known
	SnapshotID pricing.SnapshotID

	// Otherwise, specify provider and region
	Provider string
	Region   string

	// AsOf specifies point-in-time (nil = latest known)
	AsOf *time.Time
}

// UsageEstimator estimates usage for instances
type UsageEstimator interface {
	Estimate(ctx context.Context, instance *model.AssetInstance) (*UsageResult, error)
}

// UsageResult contains estimated usage with confidence
type UsageResult struct {
	Metrics    map[string]UsageMetric
	Source     pricing.UsageSource
	Confidence float64
}

// UsageMetric is a single usage estimate
type UsageMetric struct {
	Name       string
	Value      float64
	Unit       string
	Confidence float64
	IsUnknown  bool
}

// PolicyEvaluator evaluates cost policies
type PolicyEvaluator interface {
	Evaluate(ctx context.Context, result *EstimationResult) (*PolicyResult, error)
}

// CloudPlugin provides cloud-specific cost mapping
type CloudPlugin interface {
	Provider() string
	MapInstance(instance *model.AssetInstance) ([]CostComponent, error)
}

// CostComponent is a billable component of an instance
type CostComponent struct {
	Name         string
	ResourceType string
	Unit         string
	Attributes   map[string]string
}

// NewEngine creates a new estimation engine
func NewEngine(
	pricingResolver PricingResolver,
	usageEstimator UsageEstimator,
	policyEvaluator PolicyEvaluator,
	config EngineConfig,
) *Engine {
	return &Engine{
		pricingResolver: pricingResolver,
		usageEstimator:  usageEstimator,
		policyEvaluator: policyEvaluator,
		cloudPlugins:    make(map[string]CloudPlugin),
		config:          config,
	}
}

// RegisterPlugin registers a cloud plugin
func (e *Engine) RegisterPlugin(plugin CloudPlugin) {
	e.cloudPlugins[plugin.Provider()] = plugin
}

// EstimateRequest is the input to estimation
type EstimateRequest struct {
	// REQUIRED: Instance graph to estimate
	Graph *model.InstanceGraph

	// REQUIRED: Pricing snapshot to use
	SnapshotRequest SnapshotRequest

	// Optional: Usage overrides per instance
	UsageOverrides map[model.InstanceID]map[string]float64

	// Optional: Policy configuration
	PolicyConfig map[string]any
}

// EstimationResult is the output of estimation
type EstimationResult struct {
	// Pricing snapshot used (for reproducibility)
	Snapshot *SnapshotReference

	// Costs per INSTANCE (not definition)
	InstanceCosts *determinism.StableMap[model.InstanceID, *InstanceCost]

	// Aggregated totals
	TotalMonthlyCost determinism.Money
	TotalHourlyCost  determinism.Money

	// Overall confidence
	Confidence CostConfidence

	// Warnings and degradations
	Warnings []string
	Degraded bool

	// Policy results (if evaluated)
	PolicyResult *PolicyResult

	// Timing
	EstimatedAt time.Time
	Duration    time.Duration
}

// SnapshotReference is an immutable reference to the pricing snapshot used
type SnapshotReference struct {
	ID          pricing.SnapshotID
	ContentHash determinism.ContentHash
	EffectiveAt time.Time
	Provider    string
	Region      string
}

// InstanceCost is the cost for a SINGLE INSTANCE (not definition)
type InstanceCost struct {
	// Instance identity
	InstanceID model.InstanceID
	Address    model.InstanceAddress

	// Link to definition (for grouping)
	DefinitionID model.DefinitionID

	// Cost components
	Components []*ComponentCost

	// Roll-ups
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money

	// Confidence for THIS instance
	Confidence CostConfidence

	// Full lineage for explainability
	Lineage []*pricing.CostLineage
}

// ComponentCost is a single cost component
type ComponentCost struct {
	Name        string
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money

	// Rate used
	RateID  pricing.RateID
	RateKey pricing.RateKey

	// Usage applied
	UsageValue float64
	UsageUnit  string

	// Formula
	Formula pricing.FormulaApplication

	// Confidence
	Confidence float64
}

// CostConfidence tracks estimation confidence
type CostConfidence struct {
	Score   float64 // 0.0 - 1.0
	Factors []ConfidenceFactor
}

// ConfidenceFactor explains why confidence is reduced
type ConfidenceFactor struct {
	Reason      string
	Impact      float64 // How much this reduces confidence
	Component   string  // Which component affected
	IsUnknown   bool    // Is this due to an unknown value?
}

// PolicyResult is the output of policy evaluation
type PolicyResult struct {
	Passed   bool
	Policies []PolicyOutcome
}

// PolicyOutcome is the result of a single policy
type PolicyOutcome struct {
	Name    string
	Passed  bool
	Message string

	// Deep context for explainability
	AffectedInstances []model.InstanceID
	CostImpact        determinism.Money
	LineageRefs       []*pricing.CostLineage
}

// Estimate performs the estimation
func (e *Engine) Estimate(ctx context.Context, req *EstimateRequest) (*EstimationResult, error) {
	start := time.Now()

	// REQUIRED: Validate inputs
	if req.Graph == nil {
		return nil, fmt.Errorf("instance graph is required")
	}

	// REQUIRED: Get pricing snapshot
	snapshot, err := e.pricingResolver.GetSnapshot(ctx, req.SnapshotRequest)
	if err != nil {
		return nil, fmt.Errorf("failed to get pricing snapshot: %w", err)
	}

	// Verify snapshot integrity
	if !snapshot.Verify() {
		return nil, fmt.Errorf("pricing snapshot failed integrity check")
	}

	result := &EstimationResult{
		Snapshot: &SnapshotReference{
			ID:          snapshot.ID,
			ContentHash: snapshot.ContentHash,
			EffectiveAt: snapshot.EffectiveAt,
			Provider:    snapshot.Provider,
			Region:      snapshot.Region,
		},
		InstanceCosts:    determinism.NewStableMap[model.InstanceID, *InstanceCost](),
		TotalMonthlyCost: determinism.Zero("USD"),
		TotalHourlyCost:  determinism.Zero("USD"),
		Confidence:       CostConfidence{Score: 1.0},
		EstimatedAt:      time.Now().UTC(),
	}

	// Process each INSTANCE (not definition)
	for _, inst := range req.Graph.Instances() {
		instanceCost, err := e.estimateInstance(ctx, inst, snapshot, req.UsageOverrides)
		if err != nil {
			result.Warnings = append(result.Warnings,
				fmt.Sprintf("%s: %v", inst.Address, err))
			result.Degraded = true
			continue
		}

		result.InstanceCosts.Set(inst.ID, instanceCost)
		result.TotalMonthlyCost = result.TotalMonthlyCost.Add(instanceCost.MonthlyCost)
		result.TotalHourlyCost = result.TotalHourlyCost.Add(instanceCost.HourlyCost)

		// Compound confidence
		result.Confidence.Score *= instanceCost.Confidence.Score
	}

	// Evaluate policies with full context
	if e.policyEvaluator != nil {
		policyResult, err := e.policyEvaluator.Evaluate(ctx, result)
		if err != nil {
			result.Warnings = append(result.Warnings,
				fmt.Sprintf("policy evaluation failed: %v", err))
		} else {
			result.PolicyResult = policyResult
		}
	}

	result.Duration = time.Since(start)
	return result, nil
}

func (e *Engine) estimateInstance(
	ctx context.Context,
	inst *model.AssetInstance,
	snapshot *pricing.PricingSnapshot,
	overrides map[model.InstanceID]map[string]float64,
) (*InstanceCost, error) {
	result := &InstanceCost{
		InstanceID:   inst.ID,
		Address:      inst.Address,
		DefinitionID: inst.DefinitionID,
		Components:   []*ComponentCost{},
		MonthlyCost:  determinism.Zero("USD"),
		HourlyCost:   determinism.Zero("USD"),
		Confidence:   CostConfidence{Score: 1.0},
		Lineage:      []*pricing.CostLineage{},
	}

	// Get cloud plugin
	plugin, ok := e.cloudPlugins[inst.Provider.Type]
	if !ok {
		return result, fmt.Errorf("no plugin for provider %s", inst.Provider.Type)
	}

	// Map instance to cost components
	components, err := plugin.MapInstance(inst)
	if err != nil {
		return result, err
	}

	// Get usage estimates
	usage, err := e.usageEstimator.Estimate(ctx, inst)
	if err != nil {
		result.Confidence.Factors = append(result.Confidence.Factors, ConfidenceFactor{
			Reason: "usage estimation failed",
			Impact: 0.3,
		})
		usage = &UsageResult{Confidence: 0.5}
	}

	// Apply overrides if present
	instanceOverrides := overrides[inst.ID]

	// Price each component
	for _, comp := range components {
		compCost, lineage := e.priceComponent(comp, inst, snapshot, usage, instanceOverrides)
		result.Components = append(result.Components, compCost)
		result.MonthlyCost = result.MonthlyCost.Add(compCost.MonthlyCost)
		result.HourlyCost = result.HourlyCost.Add(compCost.HourlyCost)
		result.Lineage = append(result.Lineage, lineage)

		// Track confidence factors
		if compCost.Confidence < 1.0 {
			result.Confidence.Factors = append(result.Confidence.Factors, ConfidenceFactor{
				Reason:    "reduced component confidence",
				Impact:    1.0 - compCost.Confidence,
				Component: comp.Name,
			})
		}
	}

	// Calculate overall confidence
	result.Confidence.Score = e.calculateConfidence(result)

	return result, nil
}

func (e *Engine) priceComponent(
	comp CostComponent,
	inst *model.AssetInstance,
	snapshot *pricing.PricingSnapshot,
	usage *UsageResult,
	overrides map[string]float64,
) (*ComponentCost, *pricing.CostLineage) {
	result := &ComponentCost{
		Name:       comp.Name,
		Confidence: 1.0,
	}

	lineage := &pricing.CostLineage{
		InstanceID: string(inst.ID),
		Component:  comp.Name,
		SnapshotID: snapshot.ID,
		Timestamp:  time.Now().UTC(),
	}

	// Look up rate
	rate, ok := snapshot.LookupRate(comp.ResourceType, comp.Name, comp.Attributes)
	if !ok {
		// Rate not found - degraded estimation
		result.Confidence = 0.0
		lineage.Confidence = 0.0
		return result, lineage
	}

	result.RateID = rate.ID
	result.RateKey = rate.Key
	lineage.RateID = rate.ID
	lineage.RateKey = rate.Key

	// Get usage value
	usageValue := 730.0 // Default monthly hours
	usageUnit := "hours"
	usageConfidence := 1.0

	if metric, ok := usage.Metrics[comp.Name]; ok {
		if metric.IsUnknown {
			// UNKNOWN: propagate, don't guess
			result.Confidence *= 0.5
			usageConfidence = 0.5
			lineage.Confidence = 0.5
		} else {
			usageValue = metric.Value
			usageUnit = metric.Unit
			usageConfidence = metric.Confidence
		}
	}

	// Apply override if present
	if override, ok := overrides[comp.Name]; ok {
		usageValue = override
		usageConfidence = 1.0 // User-provided is trusted
	}

	result.UsageValue = usageValue
	result.UsageUnit = usageUnit

	// Calculate cost
	monthlyCost := determinism.NewMoneyFromDecimal(
		rate.Price.Mul(determinism.NewMoneyFromFloat(usageValue, "USD").Amount()),
		rate.Currency,
	)
	hourlyCost := monthlyCost.Div(determinism.NewMoneyFromFloat(730.0, "USD").Amount())

	result.MonthlyCost = monthlyCost
	result.HourlyCost = hourlyCost
	result.Confidence *= usageConfidence

	// Record formula
	result.Formula = pricing.FormulaApplication{
		Name:       "usage_based",
		Expression: fmt.Sprintf("%s * %s", rate.Price.String(), usageUnit),
		Inputs: map[string]string{
			"rate":  rate.Price.String(),
			"usage": fmt.Sprintf("%.2f", usageValue),
			"unit":  usageUnit,
		},
		Output: monthlyCost.StringRaw(),
	}
	lineage.Formula = result.Formula
	lineage.Usage = pricing.UsageLineage{
		Source:     usage.Source,
		Confidence: usageConfidence,
	}
	lineage.Confidence = result.Confidence

	return result, lineage
}

func (e *Engine) calculateConfidence(ic *InstanceCost) float64 {
	if len(ic.Components) == 0 {
		return 0.0
	}

	total := 0.0
	for _, c := range ic.Components {
		total += c.Confidence
	}
	return total / float64(len(ic.Components))
}

################################################################################
# FILE: :\good projects\cost estimation\core\engine\orchestrator.go
# TYPE: go
# SIZE: 14209 bytes
################################################################################
// Package engine - Authoritative estimation orchestrator
// ENFORCES the correct execution flow:
// 1. Terraform Dependency Graph (authoritative)
// 2. Provider Binding (frozen)
// 3. Expanded Asset Graph (instances)
// 4. Cost Graph (derived from asset graph)
// 5. Policy Evaluation (on full context)
package engine

import (
	"context"
	"fmt"
	"time"

	"terraform-cost/core/cost"
	"terraform-cost/core/graph"
	"terraform-cost/core/model"
	"terraform-cost/core/policy"
	"terraform-cost/core/terraform"
)

// AuthoritativeOrchestrator enforces the correct execution order
type AuthoritativeOrchestrator struct {
	// Current phase - can only move forward
	phase OrchestrationPhase

	// Mode
	mode terraform.EvaluationMode

	// Components - each is nil until its phase
	infraGraph       *graph.InfrastructureGraph
	providerFinal    *terraform.ProviderFinalizer
	bindingRegistry  *terraform.BindingRegistry
	assetGraph       *AssetGraph
	costGraph        *graph.DependencyAwareCostGraph
	policyEngine     *policy.DiffPolicyEngine

	// Cardinality warnings
	cardinalityWarns *terraform.CardinalityWarnings

	// Errors
	errors []OrchestrationError
}

// OrchestrationPhase represents execution phases
type OrchestrationPhase int

const (
	PhaseUninitialized OrchestrationPhase = iota
	PhaseParsed                            // Terraform parsed
	PhaseGraphBuilt                        // Dependency graph built
	PhaseProvidersFrozen                   // Providers finalized
	PhaseExpanded                          // Assets expanded
	PhaseCosted                            // Costs calculated
	PhasePolicyEvaluated                   // Policies run
	PhaseComplete
)

// String returns the phase name
func (p OrchestrationPhase) String() string {
	names := []string{
		"uninitialized", "parsed", "graph_built", "providers_frozen",
		"expanded", "costed", "policy_evaluated", "complete",
	}
	if int(p) < len(names) {
		return names[p]
	}
	return "unknown"
}

// OrchestrationError is an error during orchestration
type OrchestrationError struct {
	Phase   OrchestrationPhase
	Message string
	Cause   error
	Fatal   bool
}

// NewAuthoritativeOrchestrator creates an orchestrator
func NewAuthoritativeOrchestrator(mode terraform.EvaluationMode) *AuthoritativeOrchestrator {
	return &AuthoritativeOrchestrator{
		phase:            PhaseUninitialized,
		mode:             mode,
		providerFinal:    terraform.NewProviderFinalizer(),
		bindingRegistry:  terraform.NewBindingRegistry(),
		cardinalityWarns: terraform.NewCardinalityWarnings(),
		policyEngine:     policy.NewDiffPolicyEngine(),
		errors:           []OrchestrationError{},
	}
}

// PhaseGuard ensures a phase has been completed
func (o *AuthoritativeOrchestrator) PhaseGuard(required OrchestrationPhase) error {
	if o.phase < required {
		return &PhaseOrderError{
			Required: required,
			Current:  o.phase,
		}
	}
	return nil
}

// PhaseOrderError indicates phases executed out of order
type PhaseOrderError struct {
	Required OrchestrationPhase
	Current  OrchestrationPhase
}

func (e *PhaseOrderError) Error() string {
	return fmt.Sprintf("phase %s required, but current phase is %s", e.Required, e.Current)
}

// BuildDependencyGraph builds the authoritative dependency graph
func (o *AuthoritativeOrchestrator) BuildDependencyGraph(ctx context.Context, parsed *graph.ParsedInfra) error {
	if o.phase >= PhaseGraphBuilt {
		return fmt.Errorf("dependency graph already built")
	}

	builder := graph.NewInfraGraphBuilder()
	infraGraph, err := builder.Build(parsed)
	if err != nil {
		o.recordError(PhaseGraphBuilt, "failed to build dependency graph", err, true)
		return err
	}

	o.infraGraph = infraGraph
	o.phase = PhaseGraphBuilt
	return nil
}

// FreezeProviders freezes all provider configurations
func (o *AuthoritativeOrchestrator) FreezeProviders(ctx context.Context, providers []*terraform.ProviderContext) error {
	if err := o.PhaseGuard(PhaseGraphBuilt); err != nil {
		return err
	}
	if o.phase >= PhaseProvidersFrozen {
		return fmt.Errorf("providers already frozen")
	}

	for _, p := range providers {
		if _, err := o.providerFinal.Freeze(p); err != nil {
			o.recordError(PhaseProvidersFrozen, "failed to freeze provider", err, true)
			return err
		}
	}

	o.providerFinal.Finalize()
	o.phase = PhaseProvidersFrozen
	return nil
}

// ExpandAssets expands all assets with frozen providers
func (o *AuthoritativeOrchestrator) ExpandAssets(ctx context.Context, definitions []*terraform.ResourceDefinition) error {
	if err := o.PhaseGuard(PhaseProvidersFrozen); err != nil {
		return err
	}
	if o.phase >= PhaseExpanded {
		return fmt.Errorf("assets already expanded")
	}

	// Ensure providers are finalized
	if !o.providerFinal.IsFinalized() {
		return fmt.Errorf("cannot expand assets: providers not finalized")
	}

	o.assetGraph = NewAssetGraph()
	forEachEval := terraform.NewSafeForEachEvaluator(o.mode)
	countEval := terraform.NewSafeCountEvaluator(o.mode)

	for _, def := range definitions {
		// Get frozen provider
		providerKey := def.Provider
		if providerKey == "" {
			providerKey = extractProviderType(def.Type)
		}

		frozenProvider, ok := o.providerFinal.Get(providerKey)
		if !ok {
			if o.mode == terraform.ModeStrict {
				o.recordError(PhaseExpanded, "no frozen provider for "+def.Address, nil, true)
				return fmt.Errorf("no frozen provider for %s", def.Address)
			}
			// Use default in permissive mode
		}

		// Handle for_each
		if def.ForEach != nil {
			result := forEachEval.Evaluate(def.Address, def.ForEach)
			o.cardinalityWarns.AddForEach(def.Address, result)

			if result.BlocksEstimation {
				o.recordError(PhaseExpanded, result.Warning, nil, true)
				return fmt.Errorf("for_each blocked: %s", result.Warning)
			}

			if result.IsKnown {
				// Expand with known keys
				for _, key := range result.Keys {
					o.addAssetInstance(def, key, frozenProvider)
				}
			} else {
				// DO NOT EXPAND - add symbolic placeholder
				o.addSymbolicAsset(def, result.SymbolicRange, frozenProvider)
			}
			continue
		}

		// Handle count
		if def.Count != nil {
			result := countEval.Evaluate(def.Address, def.Count)
			o.cardinalityWarns.AddCount(def.Address, result)

			if result.BlocksEstimation {
				o.recordError(PhaseExpanded, result.Warning, nil, true)
				return fmt.Errorf("count blocked: %s", result.Warning)
			}

			if result.IsKnown {
				for i := 0; i < result.Value; i++ {
					o.addAssetInstance(def, i, frozenProvider)
				}
			} else {
				// DO NOT EXPAND - add symbolic placeholder
				o.addSymbolicAsset(def, result.SymbolicRange, frozenProvider)
			}
			continue
		}

		// Single instance
		o.addAssetInstance(def, nil, frozenProvider)
	}

	o.phase = PhaseExpanded
	return nil
}

func (o *AuthoritativeOrchestrator) addAssetInstance(def *terraform.ResourceDefinition, key interface{}, provider *terraform.FrozenProviderContext) {
	address := def.Address
	if key != nil {
		switch k := key.(type) {
		case int:
			address = fmt.Sprintf("%s[%d]", def.Address, k)
		case string:
			address = fmt.Sprintf("%s[%q]", def.Address, k)
		}
	}

	asset := &AssetInstance{
		ID:           model.InstanceID(address),
		Address:      model.InstanceAddress(address),
		DefinitionID: def.Address,
		ResourceType: def.Type,
		Provider:     provider,
		InstanceKey:  key,
		IsSymbolic:   false,
	}

	o.assetGraph.AddInstance(asset)

	// Bind to provider
	if provider != nil {
		o.bindingRegistry.Bind(address, key, provider)
	}
}

func (o *AuthoritativeOrchestrator) addSymbolicAsset(def *terraform.ResourceDefinition, symRange *terraform.SymbolicRange, provider *terraform.FrozenProviderContext) {
	asset := &AssetInstance{
		ID:            model.InstanceID(def.Address + "[*]"),
		Address:       model.InstanceAddress(def.Address + "[*]"),
		DefinitionID:  def.Address,
		ResourceType:  def.Type,
		Provider:      provider,
		IsSymbolic:    true,
		SymbolicRange: symRange,
	}

	o.assetGraph.AddInstance(asset)
}

// CalculateCosts calculates costs from expanded assets
func (o *AuthoritativeOrchestrator) CalculateCosts(ctx context.Context, calculator CostCalculator) error {
	if err := o.PhaseGuard(PhaseExpanded); err != nil {
		return err
	}
	if o.phase >= PhaseCosted {
		return fmt.Errorf("costs already calculated")
	}

	// Pricing gate enforces provider binding
	gate := terraform.NewProviderPricingGate(o.providerFinal, o.bindingRegistry)

	// Create cost graph
	rawCostGraph := cost.NewCostGraph("project")

	for _, asset := range o.assetGraph.AllInstances() {
		// Skip symbolic assets - they represent unknown cardinality
		if asset.IsSymbolic {
			continue
		}

		// Verify pricing is allowed
		if err := gate.CanPrice(string(asset.Address)); err != nil {
			if o.mode == terraform.ModeStrict {
				return err
			}
			o.recordError(PhaseCosted, err.Error(), err, false)
			continue
		}

		// Calculate cost
		costNode, err := calculator.Calculate(asset)
		if err != nil {
			o.recordError(PhaseCosted, "failed to calculate cost for "+string(asset.Address), err, false)
			continue
		}

		rawCostGraph.AddNode(costNode)
	}

	// Build service aggregates
	rawCostGraph.BuildServiceAggregates()

	// Create dependency-aware cost graph
	o.costGraph = graph.NewDependencyAwareCostGraph(o.infraGraph, rawCostGraph)

	o.phase = PhaseCosted
	return nil
}

// EvaluatePolicies evaluates policies on the cost graph
func (o *AuthoritativeOrchestrator) EvaluatePolicies(ctx context.Context, diffCtx *policy.DiffPolicyContext) (*policy.DiffPolicyEngineResult, error) {
	if err := o.PhaseGuard(PhaseCosted); err != nil {
		return nil, err
	}

	// Policies operate on full context
	result := o.policyEngine.Evaluate(diffCtx)
	o.phase = PhasePolicyEvaluated

	return result, nil
}

// AddPolicy adds a policy to evaluate
func (o *AuthoritativeOrchestrator) AddPolicy(p policy.DiffAwarePolicy) {
	o.policyEngine.AddPolicy(p)
}

func (o *AuthoritativeOrchestrator) recordError(phase OrchestrationPhase, msg string, cause error, fatal bool) {
	o.errors = append(o.errors, OrchestrationError{
		Phase:   phase,
		Message: msg,
		Cause:   cause,
		Fatal:   fatal,
	})
}

// GetErrors returns all errors
func (o *AuthoritativeOrchestrator) GetErrors() []OrchestrationError {
	return o.errors
}

// GetCardinalityWarnings returns cardinality warnings
func (o *AuthoritativeOrchestrator) GetCardinalityWarnings() []terraform.CardinalityWarning {
	return o.cardinalityWarns.All()
}

// GetCostGraph returns the dependency-aware cost graph
func (o *AuthoritativeOrchestrator) GetCostGraph() *graph.DependencyAwareCostGraph {
	return o.costGraph
}

// GetAssetGraph returns the asset graph
func (o *AuthoritativeOrchestrator) GetAssetGraph() *AssetGraph {
	return o.assetGraph
}

// GetPhase returns current phase
func (o *AuthoritativeOrchestrator) GetPhase() OrchestrationPhase {
	return o.phase
}

func extractProviderType(resourceType string) string {
	// aws_instance â†’ aws
	for i, c := range resourceType {
		if c == '_' {
			return resourceType[:i]
		}
	}
	return resourceType
}

// AssetGraph holds expanded asset instances
type AssetGraph struct {
	instances map[model.InstanceID]*AssetInstance
	order     []model.InstanceID
}

// NewAssetGraph creates an asset graph
func NewAssetGraph() *AssetGraph {
	return &AssetGraph{
		instances: make(map[model.InstanceID]*AssetInstance),
		order:     []model.InstanceID{},
	}
}

// AddInstance adds an instance
func (g *AssetGraph) AddInstance(inst *AssetInstance) {
	g.instances[inst.ID] = inst
	g.order = append(g.order, inst.ID)
}

// GetInstance returns an instance
func (g *AssetGraph) GetInstance(id model.InstanceID) *AssetInstance {
	return g.instances[id]
}

// AllInstances returns all instances in order
func (g *AssetGraph) AllInstances() []*AssetInstance {
	result := make([]*AssetInstance, 0, len(g.order))
	for _, id := range g.order {
		result = append(result, g.instances[id])
	}
	return result
}

// Count returns the number of instances
func (g *AssetGraph) Count() int {
	return len(g.instances)
}

// SymbolicCount returns count of symbolic (unknown cardinality) assets
func (g *AssetGraph) SymbolicCount() int {
	count := 0
	for _, inst := range g.instances {
		if inst.IsSymbolic {
			count++
		}
	}
	return count
}

// AssetInstance is an expanded asset
type AssetInstance struct {
	ID            model.InstanceID
	Address       model.InstanceAddress
	DefinitionID  string
	ResourceType  string
	Provider      *terraform.FrozenProviderContext
	InstanceKey   interface{}
	IsSymbolic    bool
	SymbolicRange *terraform.SymbolicRange
}

// CostCalculator calculates cost for an asset
type CostCalculator interface {
	Calculate(asset *AssetInstance) (*cost.CostNode, error)
}

// OrchestrationResult is the final result
type OrchestrationResult struct {
	Phase             OrchestrationPhase
	CostGraph         *graph.DependencyAwareCostGraph
	TotalMonthly      float64
	TotalHourly       float64
	Confidence        float64
	ResourceCount     int
	SymbolicCount     int
	CardinalityWarns  []terraform.CardinalityWarning
	PolicyResult      *policy.DiffPolicyEngineResult
	Errors            []OrchestrationError
	Duration          time.Duration
}

// NewOrchestrationResult creates a result from orchestrator
func NewOrchestrationResult(o *AuthoritativeOrchestrator, duration time.Duration) *OrchestrationResult {
	result := &OrchestrationResult{
		Phase:            o.GetPhase(),
		CostGraph:        o.GetCostGraph(),
		CardinalityWarns: o.GetCardinalityWarnings(),
		Errors:           o.GetErrors(),
		Duration:         duration,
	}

	if o.assetGraph != nil {
		result.ResourceCount = o.assetGraph.Count()
		result.SymbolicCount = o.assetGraph.SymbolicCount()
	}

	// Calculate aggregates from cost graph
	// No field access needed here

	return result
}

################################################################################
# FILE: :\good projects\cost estimation\core\engine\sealed_builder.go
# TYPE: go
# SIZE: 2627 bytes
################################################################################
// Package engine - Sealed cost graph construction
// This file SEALS the cost graph construction path.
// There is ONE way to build a cost graph - no exceptions.
package engine

import (
	"fmt"

	"terraform-cost/core/graph"
)

// SealedCostGraphBuilder is the ONLY way to build a cost graph
// All other paths are BLOCKED at compile time by making this the only export
type SealedCostGraphBuilder struct {
	depGraph   *graph.CanonicalDependencyGraph
	assetGraph *graph.EnforcedAssetGraph
	validated  bool
}

// NewSealedCostGraphBuilder creates a builder with REQUIRED dependency graph
// Panics immediately if dependency graph is not ready
func NewSealedCostGraphBuilder(
	depGraph *graph.CanonicalDependencyGraph,
	assetGraph *graph.EnforcedAssetGraph,
) *SealedCostGraphBuilder {
	// INVARIANT: depGraph is required
	if depGraph == nil {
		panic("SEALED: cannot build cost graph - depGraph is nil")
	}

	// INVARIANT: depGraph must be sealed
	if !depGraph.IsSealed() {
		panic("SEALED: cannot build cost graph - depGraph is not sealed")
	}

	// INVARIANT: depGraph must be transitively closed
	if !depGraph.IsTransitivelyClosed() {
		panic("SEALED: cannot build cost graph - dependency graph not transitively closed")
	}

	// INVARIANT: assetGraph is required
	if assetGraph == nil {
		panic("SEALED: cannot build cost graph - assetGraph is nil")
	}

	return &SealedCostGraphBuilder{
		depGraph:   depGraph,
		assetGraph: assetGraph,
		validated:  true,
	}
}

// Build builds the cost graph - only succeeds if all invariants hold
func (b *SealedCostGraphBuilder) Build() (*graph.AuthoritativeCostGraph, error) {
	if !b.validated {
		return nil, fmt.Errorf("SEALED: builder not properly initialized")
	}

	return graph.BuildAuthoritativeCostGraph(b.depGraph, b.assetGraph)
}

// BLOCKED PATHS - These exist only to provide clear error messages

// BuildCostGraphWithoutDependencies is BLOCKED
func BuildCostGraphWithoutDependencies() {
	panic("SEALED: BuildCostGraphWithoutDependencies - use NewSealedCostGraphBuilder")
}

// BuildCostGraphFromExpandedInstances is BLOCKED
func BuildCostGraphFromExpandedInstances() {
	panic("SEALED: BuildCostGraphFromExpandedInstances - use NewSealedCostGraphBuilder")
}

// BuildCostGraphFromAssetList is BLOCKED
func BuildCostGraphFromAssetList() {
	panic("SEALED: BuildCostGraphFromAssetList - use NewSealedCostGraphBuilder")
}

// AcceptInstancesWithoutDepGraph is BLOCKED
func AcceptInstancesWithoutDepGraph() {
	panic("SEALED: AcceptInstancesWithoutDepGraph - instances require dependency lineage")
}

################################################################################
# FILE: :\good projects\cost estimation\core\expansion\expander.go
# TYPE: go
# SIZE: 10260 bytes
################################################################################
// Package expansion provides instance expansion for count and for_each.
// This is a clean-room implementation based on Terraform semantics.
package expansion

import (
	"fmt"
	"sort"

	"terraform-cost/core/expression"
	"terraform-cost/core/types"
)

// InstanceKey represents the index/key for an expanded instance
type InstanceKey struct {
	// Type indicates whether this is a numeric or string key
	Type KeyType
	// NumValue is set for count-based expansion
	NumValue int
	// StrValue is set for for_each-based expansion
	StrValue string
}

// KeyType indicates the type of instance key
type KeyType int

const (
	KeyTypeNone KeyType = iota
	KeyTypeInt
	KeyTypeString
)

// String returns the key as an address suffix
func (k InstanceKey) String() string {
	switch k.Type {
	case KeyTypeInt:
		return fmt.Sprintf("[%d]", k.NumValue)
	case KeyTypeString:
		return fmt.Sprintf("[%q]", k.StrValue)
	default:
		return ""
	}
}

// Value returns the key as an expression Value
func (k InstanceKey) Value() expression.Value {
	switch k.Type {
	case KeyTypeInt:
		return expression.NumberFromInt(int64(k.NumValue))
	case KeyTypeString:
		return expression.String(k.StrValue)
	default:
		return expression.Null()
	}
}

// AssetInstance represents an expanded instance of an asset
type AssetInstance struct {
	// Base is the original asset definition
	Base *types.Asset

	// Key is the instance index/key (from count or for_each)
	Key InstanceKey

	// Address is the full address including index
	Address types.ResourceAddress

	// EachValue is the element value for for_each (nil for count)
	EachValue expression.Value

	// Attributes are the resolved attributes for this instance
	Attributes types.Attributes

	// Metadata about the expansion
	Metadata InstanceMetadata
}

// InstanceMetadata contains information about how the instance was created
type InstanceMetadata struct {
	// ExpansionType indicates how this instance was created
	ExpansionType ExpansionType

	// OriginalAddress is the address before expansion
	OriginalAddress types.ResourceAddress

	// IsKnown indicates whether the expansion count was deterministic
	IsKnown bool

	// Warning is set if expansion produced a warning
	Warning string
}

// ExpansionType indicates the type of expansion
type ExpansionType int

const (
	ExpansionNone     ExpansionType = iota // No expansion (single instance)
	ExpansionCount                         // count meta-argument
	ExpansionForEach                       // for_each meta-argument
	ExpansionUnknown                       // Expansion couldn't be determined
)

// Expander expands assets with count/for_each into instances
type Expander struct {
	// DefaultCountOnUnknown is the count to assume when count is unknown
	DefaultCountOnUnknown int
}

// NewExpander creates a new instance expander
func NewExpander() *Expander {
	return &Expander{
		DefaultCountOnUnknown: 1,
	}
}

// Expand expands a single asset into instances
func (e *Expander) Expand(asset *types.Asset, ctx *expression.Context) ([]*AssetInstance, error) {
	// Check for count meta-argument
	if countAttr := asset.Attributes.Get("count"); countAttr != nil {
		return e.expandCount(asset, countAttr, ctx)
	}

	// Check for for_each meta-argument
	if forEachAttr := asset.Attributes.Get("for_each"); forEachAttr != nil {
		return e.expandForEach(asset, forEachAttr, ctx)
	}

	// No expansion - return single instance
	return []*AssetInstance{
		{
			Base:       asset,
			Key:        InstanceKey{Type: KeyTypeNone},
			Address:    asset.Address,
			Attributes: asset.Attributes,
			Metadata: InstanceMetadata{
				ExpansionType:   ExpansionNone,
				OriginalAddress: asset.Address,
				IsKnown:         true,
			},
		},
	}, nil
}

// expandCount handles count-based expansion
func (e *Expander) expandCount(asset *types.Asset, countVal interface{}, ctx *expression.Context) ([]*AssetInstance, error) {
	count, isKnown := e.resolveCount(countVal, ctx)

	if count == 0 {
		// count = 0 means no instances
		return []*AssetInstance{}, nil
	}

	instances := make([]*AssetInstance, count)
	for i := 0; i < count; i++ {
		key := InstanceKey{Type: KeyTypeInt, NumValue: i}
		addr := types.ResourceAddress(fmt.Sprintf("%s[%d]", asset.Address, i))

		// Create evaluation context for this instance
		instanceCtx := ctx.Clone()
		instanceCtx.SetCountIndex(i)

		instances[i] = &AssetInstance{
			Base:       asset,
			Key:        key,
			Address:    addr,
			Attributes: asset.Attributes,
			Metadata: InstanceMetadata{
				ExpansionType:   ExpansionCount,
				OriginalAddress: asset.Address,
				IsKnown:         isKnown,
			},
		}

		if !isKnown {
			instances[i].Metadata.Warning = "count could not be determined; assuming 1"
		}
	}

	return instances, nil
}

// resolveCount attempts to resolve a count value to an integer
func (e *Expander) resolveCount(countVal interface{}, ctx *expression.Context) (int, bool) {
	// If it's already an int, use it
	if n, ok := countVal.(int); ok {
		return n, true
	}

	// If it's a float, convert
	if f, ok := countVal.(float64); ok {
		return int(f), true
	}

	// If it's an expression.Value, extract
	if v, ok := countVal.(expression.Value); ok {
		if v.IsUnknown() {
			return e.DefaultCountOnUnknown, false
		}
		if n, err := v.AsInt(); err == nil {
			return int(n), true
		}
	}

	// If it's a string reference, try to resolve
	if s, ok := countVal.(string); ok {
		ref, err := expression.ParseReference(s)
		if err == nil && ctx != nil {
			resolved, err := ctx.Resolve(ref)
			if err == nil && !resolved.IsUnknown() {
				if n, err := resolved.AsInt(); err == nil {
					return int(n), true
				}
			}
		}
	}

	// Cannot determine count
	return e.DefaultCountOnUnknown, false
}

// expandForEach handles for_each-based expansion
func (e *Expander) expandForEach(asset *types.Asset, forEachVal interface{}, ctx *expression.Context) ([]*AssetInstance, error) {
	keys, values, isKnown := e.resolveForEach(forEachVal, ctx)

	if len(keys) == 0 {
		return []*AssetInstance{}, nil
	}

	instances := make([]*AssetInstance, len(keys))
	for i, key := range keys {
		instanceKey := InstanceKey{Type: KeyTypeString, StrValue: key}
		addr := types.ResourceAddress(fmt.Sprintf("%s[%q]", asset.Address, key))

		// Create evaluation context for this instance
		instanceCtx := ctx.Clone()
		instanceCtx.SetEach(key, values[key])

		instances[i] = &AssetInstance{
			Base:       asset,
			Key:        instanceKey,
			Address:    addr,
			EachValue:  values[key],
			Attributes: asset.Attributes,
			Metadata: InstanceMetadata{
				ExpansionType:   ExpansionForEach,
				OriginalAddress: asset.Address,
				IsKnown:         isKnown,
			},
		}

		if !isKnown {
			instances[i].Metadata.Warning = "for_each could not be determined"
		}
	}

	return instances, nil
}

// resolveForEach attempts to resolve a for_each value to keys and values
func (e *Expander) resolveForEach(forEachVal interface{}, ctx *expression.Context) ([]string, map[string]expression.Value, bool) {
	values := make(map[string]expression.Value)

	// If it's already a map
	if m, ok := forEachVal.(map[string]interface{}); ok {
		keys := make([]string, 0, len(m))
		for k, v := range m {
			keys = append(keys, k)
			values[k] = expression.FromGo(v)
		}
		sort.Strings(keys)
		return keys, values, true
	}

	// If it's a set/list of strings
	if list, ok := forEachVal.([]interface{}); ok {
		keys := make([]string, 0, len(list))
		for _, item := range list {
			if s, ok := item.(string); ok {
				keys = append(keys, s)
				values[s] = expression.String(s)
			}
		}
		sort.Strings(keys)
		return keys, values, true
	}

	// If it's an expression.Value
	if v, ok := forEachVal.(expression.Value); ok {
		if v.IsUnknown() {
			return nil, nil, false
		}

		// Try as map
		if m, err := v.AsMap(); err == nil {
			keys := make([]string, 0, len(m))
			for k := range m {
				keys = append(keys, k)
				values[k] = m[k]
			}
			sort.Strings(keys)
			return keys, values, true
		}

		// Try as list
		if list, err := v.AsList(); err == nil {
			keys := make([]string, 0, len(list))
			for _, item := range list {
				if s, err := item.AsString(); err == nil {
					keys = append(keys, s)
					values[s] = expression.String(s)
				}
			}
			sort.Strings(keys)
			return keys, values, true
		}
	}

	// Cannot determine for_each
	return nil, nil, false
}

// ExpandAll expands all assets in a graph
func (e *Expander) ExpandAll(assets []*types.Asset, ctx *expression.Context) ([]*AssetInstance, error) {
	var allInstances []*AssetInstance

	for _, asset := range assets {
		instances, err := e.Expand(asset, ctx)
		if err != nil {
			return nil, fmt.Errorf("failed to expand %s: %w", asset.Address, err)
		}
		allInstances = append(allInstances, instances...)
	}

	return allInstances, nil
}

// ExpandedGraph represents an asset graph with all instances expanded
type ExpandedGraph struct {
	// Instances is the list of all expanded instances
	Instances []*AssetInstance

	// ByAddress indexes instances by their full address
	ByAddress map[types.ResourceAddress]*AssetInstance

	// ByBaseAddress groups instances by their base address (before expansion)
	ByBaseAddress map[types.ResourceAddress][]*AssetInstance

	// Warnings collects expansion warnings
	Warnings []string
}

// NewExpandedGraph creates an expanded graph from instances
func NewExpandedGraph(instances []*AssetInstance) *ExpandedGraph {
	g := &ExpandedGraph{
		Instances:     instances,
		ByAddress:     make(map[types.ResourceAddress]*AssetInstance),
		ByBaseAddress: make(map[types.ResourceAddress][]*AssetInstance),
	}

	for _, inst := range instances {
		g.ByAddress[inst.Address] = inst
		g.ByBaseAddress[inst.Metadata.OriginalAddress] = append(
			g.ByBaseAddress[inst.Metadata.OriginalAddress], inst,
		)

		if inst.Metadata.Warning != "" {
			g.Warnings = append(g.Warnings, fmt.Sprintf("%s: %s", inst.Address, inst.Metadata.Warning))
		}
	}

	return g
}

################################################################################
# FILE: :\good projects\cost estimation\core\expansion\expander_test.go
# TYPE: go
# SIZE: 8167 bytes
################################################################################
package expansion

import (
	"testing"

	"terraform-cost/core/expression"
	"terraform-cost/core/types"
)

// TestCountExpansion tests count-based expansion behavior
func TestCountExpansion(t *testing.T) {
	expander := NewExpander()
	ctx := expression.NewContext()

	tests := []struct {
		name          string
		countValue    interface{}
		expectedCount int
		isKnown       bool
	}{
		{
			name:          "count=0 produces nothing",
			countValue:    0,
			expectedCount: 0,
			isKnown:       true,
		},
		{
			name:          "count=1 produces one instance",
			countValue:    1,
			expectedCount: 1,
			isKnown:       true,
		},
		{
			name:          "count=3 produces three instances",
			countValue:    3,
			expectedCount: 3,
			isKnown:       true,
		},
		{
			name:          "count=5 produces five instances",
			countValue:    5,
			expectedCount: 5,
			isKnown:       true,
		},
		{
			name:          "unknown count produces default with warning",
			countValue:    expression.Unknown(),
			expectedCount: 1,
			isKnown:       false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			asset := &types.Asset{
				Address: "aws_instance.test",
				Type:    "aws_instance",
				Name:    "test",
				Attributes: types.Attributes{
					"count": {Value: tt.countValue},
				},
			}

			instances, err := expander.Expand(asset, ctx)
			if err != nil {
				t.Fatalf("unexpected error: %v", err)
			}

			if len(instances) != tt.expectedCount {
				t.Errorf("expected %d instances, got %d", tt.expectedCount, len(instances))
			}

			// Verify instance addresses
			for i, inst := range instances {
				expectedKey := i
				if inst.Key.NumValue != expectedKey {
					t.Errorf("instance %d: expected key %d, got %d", i, expectedKey, inst.Key.NumValue)
				}

				if inst.Metadata.IsKnown != tt.isKnown {
					t.Errorf("instance %d: expected isKnown=%v, got %v", i, tt.isKnown, inst.Metadata.IsKnown)
				}

				if !tt.isKnown && inst.Metadata.Warning == "" {
					t.Errorf("instance %d: expected warning for unknown count", i)
				}
			}
		})
	}
}

// TestForEachExpansion tests for_each-based expansion behavior
func TestForEachExpansion(t *testing.T) {
	expander := NewExpander()
	ctx := expression.NewContext()

	tests := []struct {
		name         string
		forEachValue interface{}
		expectedKeys []string
		isKnown      bool
	}{
		{
			name:         "empty map produces nothing",
			forEachValue: map[string]interface{}{},
			expectedKeys: []string{},
			isKnown:      true,
		},
		{
			name: "map with one key",
			forEachValue: map[string]interface{}{
				"web": "value1",
			},
			expectedKeys: []string{"web"},
			isKnown:      true,
		},
		{
			name: "map with multiple keys",
			forEachValue: map[string]interface{}{
				"a": 1,
				"b": 2,
				"c": 3,
			},
			expectedKeys: []string{"a", "b", "c"}, // sorted
			isKnown:      true,
		},
		{
			name:         "set as list of strings",
			forEachValue: []interface{}{"alpha", "beta", "gamma"},
			expectedKeys: []string{"alpha", "beta", "gamma"},
			isKnown:      true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			asset := &types.Asset{
				Address: "aws_instance.multi",
				Type:    "aws_instance",
				Name:    "multi",
				Attributes: types.Attributes{
					"for_each": {Value: tt.forEachValue},
				},
			}

			instances, err := expander.Expand(asset, ctx)
			if err != nil {
				t.Fatalf("unexpected error: %v", err)
			}

			if len(instances) != len(tt.expectedKeys) {
				t.Errorf("expected %d instances, got %d", len(tt.expectedKeys), len(instances))
			}

			// Verify instance keys (they should be sorted)
			for i, inst := range instances {
				if i >= len(tt.expectedKeys) {
					break
				}
				expectedKey := tt.expectedKeys[i]
				if inst.Key.StrValue != expectedKey {
					t.Errorf("instance %d: expected key %q, got %q", i, expectedKey, inst.Key.StrValue)
				}

				if inst.Key.Type != KeyTypeString {
					t.Errorf("instance %d: expected string key type, got %v", i, inst.Key.Type)
				}
			}
		})
	}
}

// TestNoExpansion tests that assets without count/for_each produce single instance
func TestNoExpansion(t *testing.T) {
	expander := NewExpander()
	ctx := expression.NewContext()

	asset := &types.Asset{
		Address: "aws_instance.single",
		Type:    "aws_instance",
		Name:    "single",
		Attributes: types.Attributes{
			"instance_type": {Value: "t3.micro"},
		},
	}

	instances, err := expander.Expand(asset, ctx)
	if err != nil {
		t.Fatalf("unexpected error: %v", err)
	}

	if len(instances) != 1 {
		t.Errorf("expected 1 instance, got %d", len(instances))
	}

	if instances[0].Key.Type != KeyTypeNone {
		t.Errorf("expected no key type, got %v", instances[0].Key.Type)
	}

	if instances[0].Address != asset.Address {
		t.Errorf("expected address %s, got %s", asset.Address, instances[0].Address)
	}

	if instances[0].Metadata.ExpansionType != ExpansionNone {
		t.Errorf("expected ExpansionNone, got %v", instances[0].Metadata.ExpansionType)
	}
}

// TestInstanceAddresses tests that addresses are correctly formatted
func TestInstanceAddresses(t *testing.T) {
	expander := NewExpander()
	ctx := expression.NewContext()

	// Test count addresses
	countAsset := &types.Asset{
		Address:    "aws_instance.counted",
		Type:       "aws_instance",
		Name:       "counted",
		Attributes: types.Attributes{"count": {Value: 2}},
	}

	countInstances, _ := expander.Expand(countAsset, ctx)
	expectedAddrs := []types.ResourceAddress{
		"aws_instance.counted[0]",
		"aws_instance.counted[1]",
	}

	for i, inst := range countInstances {
		if inst.Address != expectedAddrs[i] {
			t.Errorf("count instance %d: expected address %s, got %s", i, expectedAddrs[i], inst.Address)
		}
	}

	// Test for_each addresses
	forEachAsset := &types.Asset{
		Address: "aws_instance.named",
		Type:    "aws_instance",
		Name:    "named",
		Attributes: types.Attributes{
			"for_each": {Value: map[string]interface{}{"web": 1, "api": 2}},
		},
	}

	forEachInstances, _ := expander.Expand(forEachAsset, ctx)

	// Check that addresses are quoted correctly
	for _, inst := range forEachInstances {
		addrStr := string(inst.Address)
		if inst.Key.StrValue == "api" {
			if addrStr != `aws_instance.named["api"]` {
				t.Errorf("expected address aws_instance.named[\"api\"], got %s", addrStr)
			}
		}
		if inst.Key.StrValue == "web" {
			if addrStr != `aws_instance.named["web"]` {
				t.Errorf("expected address aws_instance.named[\"web\"], got %s", addrStr)
			}
		}
	}
}

// TestExpandedGraph tests the expanded graph construction
func TestExpandedGraph(t *testing.T) {
	instances := []*AssetInstance{
		{
			Address: "aws_instance.test[0]",
			Key:     InstanceKey{Type: KeyTypeInt, NumValue: 0},
			Metadata: InstanceMetadata{
				OriginalAddress: "aws_instance.test",
				ExpansionType:   ExpansionCount,
			},
		},
		{
			Address: "aws_instance.test[1]",
			Key:     InstanceKey{Type: KeyTypeInt, NumValue: 1},
			Metadata: InstanceMetadata{
				OriginalAddress: "aws_instance.test",
				ExpansionType:   ExpansionCount,
			},
		},
		{
			Address: "aws_s3_bucket.single",
			Key:     InstanceKey{Type: KeyTypeNone},
			Metadata: InstanceMetadata{
				OriginalAddress: "aws_s3_bucket.single",
				ExpansionType:   ExpansionNone,
			},
		},
	}

	graph := NewExpandedGraph(instances)

	if len(graph.Instances) != 3 {
		t.Errorf("expected 3 instances, got %d", len(graph.Instances))
	}

	// Test ByAddress lookup
	inst, ok := graph.ByAddress["aws_instance.test[0]"]
	if !ok {
		t.Error("ByAddress lookup failed for aws_instance.test[0]")
	}
	if inst.Key.NumValue != 0 {
		t.Errorf("expected key value 0, got %d", inst.Key.NumValue)
	}

	// Test ByBaseAddress grouping
	baseInstances := graph.ByBaseAddress["aws_instance.test"]
	if len(baseInstances) != 2 {
		t.Errorf("expected 2 instances for base address, got %d", len(baseInstances))
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\expansion\sealed_expander.go
# TYPE: go
# SIZE: 5934 bytes
################################################################################
// Package expansion - Sealed expansion that NEVER creates instances for unknown cardinality
// This file replaces the permissive behavior with strict epistemic honesty.
package expansion

import (
	"fmt"
)

// ExpansionOutcome represents what happened during expansion
type ExpansionOutcome int

const (
	OutcomeExpanded ExpansionOutcome = iota // Known cardinality, instances created
	OutcomeSymbolic                         // Unknown cardinality, symbolic bucket created
	OutcomeBlocked                          // Strict mode, expansion blocked
	OutcomeEmpty                            // count = 0 or empty for_each
)

// SealedExpansionResult is the result of sealed expansion
type SealedExpansionResult struct {
	Outcome ExpansionOutcome

	// Only set for OutcomeExpanded
	Instances []*AssetInstance

	// Only set for OutcomeSymbolic
	SymbolicReason     string
	SymbolicExpression string

	// Only set for OutcomeBlocked
	BlockedError error

	// Warnings
	Warnings []string
}

// SealedExpander is an expander that NEVER creates instances for unknown cardinality
type SealedExpander struct {
	strictMode bool
	// DefaultCountOnUnknown is REMOVED - unknown means unknown
}

// NewSealedExpander creates a sealed expander
func NewSealedExpander(strictMode bool) *SealedExpander {
	return &SealedExpander{
		strictMode: strictMode,
	}
}

// ExpandSealed expands an asset with sealed semantics
// Unknown cardinality NEVER produces instances
func (e *SealedExpander) ExpandSealed(asset *AssetInstance) *SealedExpansionResult {
	// This is already an instance - just return it
	return &SealedExpansionResult{
		Outcome:   OutcomeExpanded,
		Instances: []*AssetInstance{asset},
	}
}

// TryExpandCount attempts count expansion with strict semantics
func (e *SealedExpander) TryExpandCount(address string, count interface{}, isKnown bool) *SealedExpansionResult {
	if !isKnown {
		// UNKNOWN CARDINALITY - NO EXPANSION
		if e.strictMode {
			return &SealedExpansionResult{
				Outcome:      OutcomeBlocked,
				BlockedError: fmt.Errorf("STRICT: cannot expand %s - count is unknown", address),
			}
		}

		// Permissive: symbolic bucket, NOT instances
		return &SealedExpansionResult{
			Outcome:            OutcomeSymbolic,
			SymbolicReason:     "count is unknown",
			SymbolicExpression: "count = <unknown>",
			Warnings:           []string{fmt.Sprintf("%s: count cannot be determined pre-apply", address)},
		}
	}

	// Known cardinality
	countVal, ok := count.(int)
	if !ok {
		if f, fok := count.(float64); fok {
			countVal = int(f)
		} else {
			// Cannot convert - treat as unknown
			if e.strictMode {
				return &SealedExpansionResult{
					Outcome:      OutcomeBlocked,
					BlockedError: fmt.Errorf("STRICT: cannot expand %s - count type invalid", address),
				}
			}
			return &SealedExpansionResult{
				Outcome:        OutcomeSymbolic,
				SymbolicReason: "count type cannot be converted",
			}
		}
	}

	if countVal == 0 {
		return &SealedExpansionResult{
			Outcome: OutcomeEmpty,
		}
	}

	// Create instances
	instances := make([]*AssetInstance, countVal)
	for i := 0; i < countVal; i++ {
		instances[i] = &AssetInstance{
			Key: InstanceKey{Type: KeyTypeInt, NumValue: i},
			Metadata: InstanceMetadata{
				ExpansionType: ExpansionCount,
				IsKnown:       true,
			},
		}
	}

	return &SealedExpansionResult{
		Outcome:   OutcomeExpanded,
		Instances: instances,
	}
}

// TryExpandForEach attempts for_each expansion with strict semantics
func (e *SealedExpander) TryExpandForEach(address string, keys []string, isKnown bool) *SealedExpansionResult {
	if !isKnown {
		// UNKNOWN CARDINALITY - NO EXPANSION
		if e.strictMode {
			return &SealedExpansionResult{
				Outcome:      OutcomeBlocked,
				BlockedError: fmt.Errorf("STRICT: cannot expand %s - for_each is unknown", address),
			}
		}

		// Permissive: symbolic bucket, NOT instances
		return &SealedExpansionResult{
			Outcome:            OutcomeSymbolic,
			SymbolicReason:     "for_each is unknown",
			SymbolicExpression: "for_each = <unknown>",
			Warnings:           []string{fmt.Sprintf("%s: for_each cannot be determined pre-apply", address)},
		}
	}

	if len(keys) == 0 {
		return &SealedExpansionResult{
			Outcome: OutcomeEmpty,
		}
	}

	// Create instances
	instances := make([]*AssetInstance, len(keys))
	for i, key := range keys {
		instances[i] = &AssetInstance{
			Key: InstanceKey{Type: KeyTypeString, StrValue: key},
			Metadata: InstanceMetadata{
				ExpansionType: ExpansionForEach,
				IsKnown:       true,
			},
		}
	}

	return &SealedExpansionResult{
		Outcome:   OutcomeExpanded,
		Instances: instances,
	}
}

// HasInstances returns true if expansion produced instances
func (r *SealedExpansionResult) HasInstances() bool {
	return r.Outcome == OutcomeExpanded && len(r.Instances) > 0
}

// IsSymbolic returns true if expansion resulted in symbolic bucket
func (r *SealedExpansionResult) IsSymbolic() bool {
	return r.Outcome == OutcomeSymbolic
}

// IsBlocked returns true if expansion was blocked
func (r *SealedExpansionResult) IsBlocked() bool {
	return r.Outcome == OutcomeBlocked
}

// BLOCKED: Legacy permissive functions that created instances for unknown

// DefaultCountOnUnknown is REMOVED - this was epistemically dishonest
var DefaultCountOnUnknown = func() {
	panic("REMOVED: DefaultCountOnUnknown - unknown cardinality cannot have a default")
}

// AssumeOneInstance is REMOVED - assuming 1 for unknown is a lie
var AssumeOneInstance = func() {
	panic("REMOVED: AssumeOneInstance - unknown cardinality must use SymbolicCost")
}

// ExpandWithWarning is REMOVED - warnings don't make lies true
var ExpandWithWarning = func() {
	panic("REMOVED: ExpandWithWarning - unknown cardinality must block or emit SymbolicCost")
}

################################################################################
# FILE: :\good projects\cost estimation\core\explanation\api_types.go
# TYPE: go
# SIZE: 3617 bytes
################################################################################
// Package explanation - API response types for explanations
// Safe for JSON serialization and UI consumption
package explanation

// ExplanationResponse is the API response for cost explanations
type ExplanationResponse struct {
	ResourceExplanations []ResourceExplanation `json:"resource_explanations"`
	SymbolicSummary      *SymbolicSummary      `json:"symbolic_summary,omitempty"`
	DiffNarratives       []DiffNarrative       `json:"diff_narratives,omitempty"`
}

// ResourceExplanation is the API-safe explanation for a resource
type ResourceExplanation struct {
	Address      string              `json:"address"`
	ResourceType string              `json:"resource_type"`
	MonthlyCost  float64             `json:"monthly_cost"`
	IsSymbolic   bool                `json:"is_symbolic"`
	Components   []ComponentExplanation `json:"components"`
}

// ComponentExplanation is the API-safe explanation for a cost component
type ComponentExplanation struct {
	Name       string            `json:"name"`
	Cost       float64           `json:"cost"`
	Quantity   float64           `json:"quantity"`
	Unit       string            `json:"unit"`
	Formula    string            `json:"formula,omitempty"`
	Inputs     map[string]string `json:"inputs,omitempty"`
	Confidence float64           `json:"confidence"`
	IsSymbolic bool              `json:"is_symbolic"`
	SymbolicReason string        `json:"symbolic_reason,omitempty"`
}

// SymbolicSummary summarizes all symbolic costs
type SymbolicSummary struct {
	Count    int                    `json:"count"`
	Reasons  map[string]int         `json:"reasons"`
	Details  []SymbolicDetail       `json:"details"`
}

// SymbolicDetail is a single symbolic cost detail
type SymbolicDetail struct {
	Resource    string   `json:"resource"`
	Component   string   `json:"component"`
	Reason      string   `json:"reason"`
	Suggestions []string `json:"suggestions,omitempty"`
}

// BuildExplanationResponse builds an API response from explanations
func BuildExplanationResponse(explanations []*CostExplanation) ExplanationResponse {
	response := ExplanationResponse{
		ResourceExplanations: make([]ResourceExplanation, 0),
	}
	
	// Group by resource
	grouped := make(map[string][]ComponentExplanation)
	symbolicReasons := make(map[string]int)
	var symbolicDetails []SymbolicDetail
	
	for _, exp := range explanations {
		comp := ComponentExplanation{
			Name:       exp.CostUnit,
			Formula:    exp.Formula,
			Confidence: exp.Confidence,
			IsSymbolic: exp.IsSymbolic,
			SymbolicReason: exp.SymbolicReason,
			Inputs:     make(map[string]string),
		}
		
		for _, input := range exp.Inputs {
			comp.Inputs[input.Name] = input.Value
		}
		
		grouped[exp.Resource] = append(grouped[exp.Resource], comp)
		
		if exp.IsSymbolic {
			symbolicReasons[exp.SymbolicReason]++
			symbolicDetails = append(symbolicDetails, SymbolicDetail{
				Resource:  exp.Resource,
				Component: exp.CostUnit,
				Reason:    exp.SymbolicReason,
			})
		}
	}
	
	for resource, components := range grouped {
		isSymbolic := false
		for _, c := range components {
			if c.IsSymbolic {
				isSymbolic = true
				break
			}
		}
		
		response.ResourceExplanations = append(response.ResourceExplanations, ResourceExplanation{
			Address:    resource,
			IsSymbolic: isSymbolic,
			Components: components,
		})
	}
	
	if len(symbolicDetails) > 0 {
		response.SymbolicSummary = &SymbolicSummary{
			Count:   len(symbolicDetails),
			Reasons: symbolicReasons,
			Details: symbolicDetails,
		}
	}
	
	return response
}

################################################################################
# FILE: :\good projects\cost estimation\core\explanation\cost_explanation.go
# TYPE: go
# SIZE: 4144 bytes
################################################################################
// Package explanation - Cost explanation tree
// Exposes WHY costs exist, not just totals.
// Enables enterprise-grade explainability.
package explanation

import (
	"encoding/json"
	"fmt"
	"strings"
)

// CostExplanation provides full transparency for a cost unit
type CostExplanation struct {
	// Identity
	Resource     string `json:"resource"`
	CostUnit     string `json:"cost_unit"`
	
	// Formula breakdown
	Formula      string   `json:"formula"`
	Inputs       []Input  `json:"inputs"`
	
	// Provenance
	UsageSource  string   `json:"usage_source"`
	PricingSource string  `json:"pricing_source,omitempty"`
	
	// Confidence
	Confidence   float64  `json:"confidence"`
	ConfidenceReason string `json:"confidence_reason,omitempty"`
	
	// Dependencies
	Dependencies []string `json:"dependencies,omitempty"`
	
	// Symbolic explanation (if applicable)
	IsSymbolic   bool     `json:"is_symbolic,omitempty"`
	SymbolicReason string `json:"symbolic_reason,omitempty"`
	SymbolicChain []string `json:"symbolic_chain,omitempty"`
}

// Input represents an input to the cost formula
type Input struct {
	Name   string  `json:"name"`
	Value  string  `json:"value"`
	Source string  `json:"source"` // "terraform", "usage_profile", "default", "calculated"
}

// NewExplanation creates a new cost explanation
func NewExplanation(resource, costUnit string) *CostExplanation {
	return &CostExplanation{
		Resource:   resource,
		CostUnit:   costUnit,
		Inputs:     make([]Input, 0),
	}
}

// WithFormula sets the formula description
func (e *CostExplanation) WithFormula(formula string) *CostExplanation {
	e.Formula = formula
	return e
}

// AddInput adds an input to the explanation
func (e *CostExplanation) AddInput(name, value, source string) *CostExplanation {
	e.Inputs = append(e.Inputs, Input{
		Name:   name,
		Value:  value,
		Source: source,
	})
	return e
}

// WithUsageSource sets the usage data source
func (e *CostExplanation) WithUsageSource(source string) *CostExplanation {
	e.UsageSource = source
	return e
}

// WithConfidence sets the confidence with reason
func (e *CostExplanation) WithConfidence(confidence float64, reason string) *CostExplanation {
	e.Confidence = confidence
	e.ConfidenceReason = reason
	return e
}

// AddDependency adds a dependency resource address
func (e *CostExplanation) AddDependency(dep string) *CostExplanation {
	e.Dependencies = append(e.Dependencies, dep)
	return e
}

// AsSymbolic marks this as a symbolic cost with explanation
func (e *CostExplanation) AsSymbolic(reason string, chain []string) *CostExplanation {
	e.IsSymbolic = true
	e.SymbolicReason = reason
	e.SymbolicChain = chain
	e.Confidence = 0
	return e
}

// ToJSON returns JSON representation
func (e *CostExplanation) ToJSON() ([]byte, error) {
	return json.MarshalIndent(e, "", "  ")
}

// ToHover returns a compact hover/tooltip format
func (e *CostExplanation) ToHover() string {
	var sb strings.Builder
	
	sb.WriteString(fmt.Sprintf("**%s** â†’ %s\n", e.Resource, e.CostUnit))
	
	if e.IsSymbolic {
		sb.WriteString(fmt.Sprintf("âš ï¸ *Symbolic*: %s\n", e.SymbolicReason))
		if len(e.SymbolicChain) > 0 {
			sb.WriteString("Chain: " + strings.Join(e.SymbolicChain, " â†’ ") + "\n")
		}
		return sb.String()
	}
	
	if e.Formula != "" {
		sb.WriteString(fmt.Sprintf("Formula: `%s`\n", e.Formula))
	}
	
	if len(e.Inputs) > 0 {
		sb.WriteString("Inputs:\n")
		for _, input := range e.Inputs {
			sb.WriteString(fmt.Sprintf("  â€¢ %s = %s (%s)\n", input.Name, input.Value, input.Source))
		}
	}
	
	sb.WriteString(fmt.Sprintf("Confidence: %.0f%%\n", e.Confidence*100))
	
	return sb.String()
}

// ToNarrative returns a human-readable narrative
func (e *CostExplanation) ToNarrative() string {
	if e.IsSymbolic {
		return fmt.Sprintf("Cost for %s is symbolic because: %s", e.Resource, e.SymbolicReason)
	}
	
	if e.Formula == "" {
		return fmt.Sprintf("%s costs are based on %s", e.Resource, e.CostUnit)
	}
	
	return fmt.Sprintf("%s %s cost calculated as: %s", e.Resource, e.CostUnit, e.Formula)
}

################################################################################
# FILE: :\good projects\cost estimation\core\explanation\diff_narrative.go
# TYPE: go
# SIZE: 5673 bytes
################################################################################
// Package explanation - Diff narratives
// Explains what changed and why costs differ
package explanation

import (
	"fmt"
	"strings"
)

// DiffNarrative explains a cost difference
type DiffNarrative struct {
	Resource     string        `json:"resource"`
	OldCost      float64       `json:"old_cost"`
	NewCost      float64       `json:"new_cost"`
	CostDelta    float64       `json:"cost_delta"`
	ChangeType   string        `json:"change_type"` // "create", "destroy", "update", "no_change"
	Changes      []ChangeItem  `json:"changes"`
	Narrative    string        `json:"narrative"`
}

// ChangeItem represents a single attribute change
type ChangeItem struct {
	Attribute string `json:"attribute"`
	OldValue  string `json:"old_value"`
	NewValue  string `json:"new_value"`
	Impact    string `json:"impact"` // "increase", "decrease", "neutral"
	CostImpact float64 `json:"cost_impact,omitempty"`
}

// NewDiffNarrative creates a diff narrative
func NewDiffNarrative(resource string, oldCost, newCost float64) *DiffNarrative {
	changeType := "update"
	if oldCost == 0 {
		changeType = "create"
	} else if newCost == 0 {
		changeType = "destroy"
	} else if oldCost == newCost {
		changeType = "no_change"
	}
	
	return &DiffNarrative{
		Resource:   resource,
		OldCost:    oldCost,
		NewCost:    newCost,
		CostDelta:  newCost - oldCost,
		ChangeType: changeType,
		Changes:    make([]ChangeItem, 0),
	}
}

// AddChange adds an attribute change
func (d *DiffNarrative) AddChange(attr, oldVal, newVal string, costImpact float64) *DiffNarrative {
	impact := "neutral"
	if costImpact > 0 {
		impact = "increase"
	} else if costImpact < 0 {
		impact = "decrease"
	}
	
	d.Changes = append(d.Changes, ChangeItem{
		Attribute:  attr,
		OldValue:   oldVal,
		NewValue:   newVal,
		Impact:     impact,
		CostImpact: costImpact,
	})
	return d
}

// Build generates the narrative text
func (d *DiffNarrative) Build() *DiffNarrative {
	var parts []string
	
	switch d.ChangeType {
	case "create":
		parts = append(parts, fmt.Sprintf("New resource %s will cost $%.2f/month", d.Resource, d.NewCost))
		
	case "destroy":
		parts = append(parts, fmt.Sprintf("Removing %s will save $%.2f/month", d.Resource, d.OldCost))
		
	case "no_change":
		parts = append(parts, fmt.Sprintf("%s cost unchanged at $%.2f/month", d.Resource, d.NewCost))
		
	case "update":
		if d.CostDelta > 0 {
			parts = append(parts, fmt.Sprintf("%s cost increased by $%.2f (from $%.2f to $%.2f)", 
				d.Resource, d.CostDelta, d.OldCost, d.NewCost))
		} else {
			parts = append(parts, fmt.Sprintf("%s cost decreased by $%.2f (from $%.2f to $%.2f)", 
				d.Resource, -d.CostDelta, d.OldCost, d.NewCost))
		}
	}
	
	if len(d.Changes) > 0 {
		parts = append(parts, "because:")
		for _, change := range d.Changes {
			if change.OldValue == "" {
				parts = append(parts, fmt.Sprintf("  â€¢ %s set to %s", change.Attribute, change.NewValue))
			} else if change.NewValue == "" {
				parts = append(parts, fmt.Sprintf("  â€¢ %s removed (was %s)", change.Attribute, change.OldValue))
			} else {
				parts = append(parts, fmt.Sprintf("  â€¢ %s changed: %s â†’ %s", change.Attribute, change.OldValue, change.NewValue))
			}
		}
	}
	
	d.Narrative = strings.Join(parts, "\n")
	return d
}

// ToMarkdown returns markdown formatted narrative
func (d *DiffNarrative) ToMarkdown() string {
	var sb strings.Builder
	
	// Header with emoji
	switch d.ChangeType {
	case "create":
		sb.WriteString("âž• ")
	case "destroy":
		sb.WriteString("âž– ")
	case "update":
		if d.CostDelta > 0 {
			sb.WriteString("ðŸ“ˆ ")
		} else if d.CostDelta < 0 {
			sb.WriteString("ðŸ“‰ ")
		} else {
			sb.WriteString("ðŸ”„ ")
		}
	default:
		sb.WriteString("â—‹ ")
	}
	
	sb.WriteString(fmt.Sprintf("**%s**\n\n", d.Resource))
	
	// Cost summary
	switch d.ChangeType {
	case "create":
		sb.WriteString(fmt.Sprintf("New resource: **+$%.2f/month**\n\n", d.NewCost))
	case "destroy":
		sb.WriteString(fmt.Sprintf("Removing: **-$%.2f/month**\n\n", d.OldCost))
	default:
		if d.CostDelta != 0 {
			sign := "+"
			if d.CostDelta < 0 {
				sign = ""
			}
			sb.WriteString(fmt.Sprintf("Cost change: **%s$%.2f/month** ($%.2f â†’ $%.2f)\n\n", 
				sign, d.CostDelta, d.OldCost, d.NewCost))
		}
	}
	
	// Changes
	if len(d.Changes) > 0 {
		sb.WriteString("**Changes:**\n")
		for _, change := range d.Changes {
			icon := "â€¢"
			if change.Impact == "increase" {
				icon = "ðŸ”º"
			} else if change.Impact == "decrease" {
				icon = "ðŸ”»"
			}
			
			if change.OldValue == "" {
				sb.WriteString(fmt.Sprintf("- %s `%s` = `%s`\n", icon, change.Attribute, change.NewValue))
			} else if change.NewValue == "" {
				sb.WriteString(fmt.Sprintf("- %s `%s` removed\n", icon, change.Attribute))
			} else {
				sb.WriteString(fmt.Sprintf("- %s `%s`: `%s` â†’ `%s`\n", icon, change.Attribute, change.OldValue, change.NewValue))
			}
		}
	}
	
	return sb.String()
}

// ToPRComment returns a compact PR comment format
func (d *DiffNarrative) ToPRComment() string {
	switch d.ChangeType {
	case "create":
		return fmt.Sprintf("| `%s` | - | $%.2f | +$%.2f |", d.Resource, d.NewCost, d.NewCost)
	case "destroy":
		return fmt.Sprintf("| `%s` | $%.2f | - | -$%.2f |", d.Resource, d.OldCost, d.OldCost)
	case "update":
		sign := "+"
		if d.CostDelta < 0 {
			sign = ""
		}
		return fmt.Sprintf("| `%s` | $%.2f | $%.2f | %s$%.2f |", d.Resource, d.OldCost, d.NewCost, sign, d.CostDelta)
	default:
		return fmt.Sprintf("| `%s` | $%.2f | $%.2f | $0.00 |", d.Resource, d.OldCost, d.NewCost)
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\explanation\symbolic.go
# TYPE: go
# SIZE: 3172 bytes
################################################################################
// Package explanation - Symbolic cost explanations
// Explains why costs cannot be computed
package explanation

import "strings"

// SymbolicExplanation explains why a cost is symbolic
type SymbolicExplanation struct {
	Resource    string   `json:"resource"`
	Reason      string   `json:"reason"`
	Chain       []string `json:"chain,omitempty"`
	Suggestions []string `json:"suggestions,omitempty"`
}

// NewSymbolicExplanation creates a symbolic explanation
func NewSymbolicExplanation(resource, reason string) *SymbolicExplanation {
	return &SymbolicExplanation{
		Resource: resource,
		Reason:   reason,
	}
}

// WithChain adds the dependency chain that led to symbolic
func (s *SymbolicExplanation) WithChain(chain ...string) *SymbolicExplanation {
	s.Chain = chain
	return s
}

// WithSuggestion adds a suggestion for resolution
func (s *SymbolicExplanation) WithSuggestion(suggestion string) *SymbolicExplanation {
	s.Suggestions = append(s.Suggestions, suggestion)
	return s
}

// ToMarkdown returns a markdown explanation
func (s *SymbolicExplanation) ToMarkdown() string {
	var sb strings.Builder
	
	sb.WriteString("### Cost is symbolic\n\n")
	sb.WriteString("**Resource**: `" + s.Resource + "`\n\n")
	sb.WriteString("**Reason**: " + s.Reason + "\n\n")
	
	if len(s.Chain) > 0 {
		sb.WriteString("**Dependency chain**:\n")
		for i, step := range s.Chain {
			sb.WriteString("  " + strings.Repeat("  ", i) + "â†’ " + step + "\n")
		}
		sb.WriteString("\n")
	}
	
	if len(s.Suggestions) > 0 {
		sb.WriteString("**To resolve**:\n")
		for _, suggestion := range s.Suggestions {
			sb.WriteString("- " + suggestion + "\n")
		}
	}
	
	return sb.String()
}

// Common symbolic reasons
const (
	ReasonUnknownCardinality = "instance count depends on module output that cannot be resolved at plan time"
	ReasonUnknownUsage       = "usage data not provided (e.g., requests/month, storage size)"
	ReasonDynamicValue       = "value is computed dynamically and cannot be determined statically"
	ReasonUnsupportedResource = "resource type is not yet supported"
	ReasonMissingAttribute   = "required attribute is not set or uses a dynamic reference"
	ReasonForEachUnknown     = "for_each expression depends on unknown value"
	ReasonCountUnknown       = "count expression depends on unknown value"
)

// StandardExplanation creates a standard symbolic explanation
func StandardExplanation(resource, reasonType string) *SymbolicExplanation {
	exp := NewSymbolicExplanation(resource, reasonType)
	
	switch reasonType {
	case ReasonUnknownCardinality:
		exp.WithSuggestion("Use a usage profile to provide expected instance counts")
		exp.WithSuggestion("Refactor to use static count or for_each with known keys")
		
	case ReasonUnknownUsage:
		exp.WithSuggestion("Provide a usage profile with expected usage metrics")
		exp.WithSuggestion("Add usage annotations to your Terraform configuration")
		
	case ReasonUnsupportedResource:
		exp.WithSuggestion("Check SUPPORTED_SERVICES.md for supported resource types")
		exp.WithSuggestion("Request support for this resource type")
	}
	
	return exp
}

################################################################################
# FILE: :\good projects\cost estimation\core\expression\context.go
# TYPE: go
# SIZE: 9151 bytes
################################################################################
// Package expression - Evaluation context
package expression

import (
	"fmt"
	"sync"
)

// Context provides values for expression evaluation
type Context struct {
	mu sync.RWMutex

	// Variables from tfvars, defaults, CLI
	variables map[string]Value

	// Locals computed from local blocks
	locals map[string]Value

	// Resources indexed by address
	resources map[string]Value

	// Data sources indexed by address
	dataSources map[string]Value

	// Modules indexed by key
	modules map[string]*Context

	// Parent context for nested modules
	parent *Context

	// Module path for this context
	modulePath string

	// Workspace name
	workspace string

	// Path values
	pathModule string
	pathRoot   string
	pathCwd    string

	// Count/for_each context (when evaluating inside a resource)
	countIndex *int
	eachKey    *string
	eachValue  Value

	// Self reference (when evaluating provisioners)
	self Value
}

// NewContext creates a new evaluation context
func NewContext() *Context {
	return &Context{
		variables:   make(map[string]Value),
		locals:      make(map[string]Value),
		resources:   make(map[string]Value),
		dataSources: make(map[string]Value),
		modules:     make(map[string]*Context),
		workspace:   "default",
	}
}

// NewChildContext creates a child context for a module
func (c *Context) NewChildContext(modulePath string) *Context {
	child := NewContext()
	child.parent = c
	child.modulePath = modulePath
	child.workspace = c.workspace
	child.pathRoot = c.pathRoot
	child.pathCwd = c.pathCwd
	return child
}

// SetVariable sets a variable value
func (c *Context) SetVariable(name string, value Value) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.variables[name] = value
}

// SetVariables sets multiple variables
func (c *Context) SetVariables(vars map[string]Value) {
	c.mu.Lock()
	defer c.mu.Unlock()
	for k, v := range vars {
		c.variables[k] = v
	}
}

// SetLocal sets a local value
func (c *Context) SetLocal(name string, value Value) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.locals[name] = value
}

// SetResource sets a resource's computed values
func (c *Context) SetResource(address string, value Value) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.resources[address] = value
}

// SetDataSource sets a data source's values
func (c *Context) SetDataSource(address string, value Value) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.dataSources[address] = value
}

// SetModule adds a child module context
func (c *Context) SetModule(key string, child *Context) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.modules[key] = child
}

// SetWorkspace sets the workspace name
func (c *Context) SetWorkspace(name string) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.workspace = name
}

// SetPaths sets the path.module, path.root, path.cwd values
func (c *Context) SetPaths(module, root, cwd string) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.pathModule = module
	c.pathRoot = root
	c.pathCwd = cwd
}

// SetCountIndex sets the count.index value for resource evaluation
func (c *Context) SetCountIndex(index int) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.countIndex = &index
}

// SetEach sets the each.key and each.value for for_each evaluation
func (c *Context) SetEach(key string, value Value) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.eachKey = &key
	c.eachValue = value
}

// SetSelf sets the self reference value
func (c *Context) SetSelf(value Value) {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.self = value
}

// ClearIterators clears count/for_each context
func (c *Context) ClearIterators() {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.countIndex = nil
	c.eachKey = nil
	c.eachValue = Null()
}

// Resolve resolves a reference to a value
func (c *Context) Resolve(ref *Reference) (Value, error) {
	c.mu.RLock()
	defer c.mu.RUnlock()

	switch ref.Kind {
	case RefVariable:
		return c.resolveVariable(ref)
	case RefLocal:
		return c.resolveLocal(ref)
	case RefResource:
		return c.resolveResource(ref)
	case RefData:
		return c.resolveDataSource(ref)
	case RefModule:
		return c.resolveModule(ref)
	case RefSelf:
		return c.resolveSelf(ref)
	case RefCount:
		return c.resolveCount(ref)
	case RefEach:
		return c.resolveEach(ref)
	case RefPath:
		return c.resolvePath(ref)
	case RefTerraform:
		return c.resolveTerraform(ref)
	default:
		return Unknown(), fmt.Errorf("unknown reference kind: %v", ref.Kind)
	}
}

func (c *Context) resolveVariable(ref *Reference) (Value, error) {
	val, ok := c.variables[ref.Key]
	if !ok {
		return Unknown(), fmt.Errorf("undefined variable: %s", ref.Key)
	}
	return c.traverseValue(val, ref)
}

func (c *Context) resolveLocal(ref *Reference) (Value, error) {
	val, ok := c.locals[ref.Key]
	if !ok {
		return Unknown(), fmt.Errorf("undefined local: %s", ref.Key)
	}
	return c.traverseValue(val, ref)
}

func (c *Context) resolveResource(ref *Reference) (Value, error) {
	// Build address with optional index
	addr := ref.Subject
	if ref.Index != nil {
		addr = ref.ResourceAddress()
	}

	val, ok := c.resources[addr]
	if !ok {
		// Resource not yet computed - return unknown
		return Unknown(), nil
	}
	return c.traverseValue(val, ref)
}

func (c *Context) resolveDataSource(ref *Reference) (Value, error) {
	addr := ref.ResourceAddress()
	val, ok := c.dataSources[addr]
	if !ok {
		// Data source not yet computed - return unknown
		return Unknown(), nil
	}
	return c.traverseValue(val, ref)
}

func (c *Context) resolveModule(ref *Reference) (Value, error) {
	child, ok := c.modules[ref.Key]
	if !ok {
		return Unknown(), fmt.Errorf("undefined module: %s", ref.Key)
	}

	// Module references access outputs
	if ref.Attribute != "" {
		// Look for output in child context
		// Outputs would be stored in a special location
		outputVal, ok := child.locals["__output_"+ref.Attribute]
		if !ok {
			return Unknown(), nil
		}
		return outputVal, nil
	}

	// Return the whole module context as an object
	return Unknown(), nil
}

func (c *Context) resolveSelf(ref *Reference) (Value, error) {
	if c.self.IsNull() {
		return Unknown(), fmt.Errorf("self is not available in this context")
	}
	return c.traverseValue(c.self, ref)
}

func (c *Context) resolveCount(ref *Reference) (Value, error) {
	if ref.Attribute != "index" {
		return Unknown(), fmt.Errorf("count only has 'index' attribute")
	}
	if c.countIndex == nil {
		return Unknown(), fmt.Errorf("count.index not available in this context")
	}
	return NumberFromInt(int64(*c.countIndex)), nil
}

func (c *Context) resolveEach(ref *Reference) (Value, error) {
	switch ref.Attribute {
	case "key":
		if c.eachKey == nil {
			return Unknown(), fmt.Errorf("each.key not available in this context")
		}
		return String(*c.eachKey), nil
	case "value":
		if c.eachKey == nil {
			return Unknown(), fmt.Errorf("each.value not available in this context")
		}
		return c.eachValue, nil
	default:
		return Unknown(), fmt.Errorf("each only has 'key' and 'value' attributes")
	}
}

func (c *Context) resolvePath(ref *Reference) (Value, error) {
	switch ref.Attribute {
	case "module":
		return String(c.pathModule), nil
	case "root":
		return String(c.pathRoot), nil
	case "cwd":
		return String(c.pathCwd), nil
	default:
		return Unknown(), fmt.Errorf("path.%s is not a valid path reference", ref.Attribute)
	}
}

func (c *Context) resolveTerraform(ref *Reference) (Value, error) {
	switch ref.Attribute {
	case "workspace":
		return String(c.workspace), nil
	default:
		return Unknown(), fmt.Errorf("terraform.%s is not a valid terraform reference", ref.Attribute)
	}
}

// traverseValue follows attribute access path through a value
func (c *Context) traverseValue(val Value, ref *Reference) (Value, error) {
	// If we have an attribute to access, traverse
	if ref.Attribute != "" {
		attr, err := val.GetAttr(ref.Attribute)
		if err != nil {
			return Unknown(), nil // Unknown attributes
		}
		val = attr
	}

	// Traverse remaining path
	for _, seg := range ref.Remaining {
		attr, err := val.GetAttr(seg)
		if err != nil {
			return Unknown(), nil
		}
		val = attr
	}

	return val, nil
}

// Clone creates a copy of the context
func (c *Context) Clone() *Context {
	c.mu.RLock()
	defer c.mu.RUnlock()

	clone := NewContext()
	clone.parent = c.parent
	clone.modulePath = c.modulePath
	clone.workspace = c.workspace
	clone.pathModule = c.pathModule
	clone.pathRoot = c.pathRoot
	clone.pathCwd = c.pathCwd

	for k, v := range c.variables {
		clone.variables[k] = v
	}
	for k, v := range c.locals {
		clone.locals[k] = v
	}
	for k, v := range c.resources {
		clone.resources[k] = v
	}
	for k, v := range c.dataSources {
		clone.dataSources[k] = v
	}
	for k, v := range c.modules {
		clone.modules[k] = v
	}

	if c.countIndex != nil {
		idx := *c.countIndex
		clone.countIndex = &idx
	}
	if c.eachKey != nil {
		key := *c.eachKey
		clone.eachKey = &key
		clone.eachValue = c.eachValue
	}
	clone.self = c.self

	return clone
}

################################################################################
# FILE: :\good projects\cost estimation\core\expression\reference.go
# TYPE: go
# SIZE: 7976 bytes
################################################################################
// Package expression - Reference parsing and resolution
package expression

import (
	"fmt"
	"regexp"
	"strconv"
	"strings"
)

// ReferenceKind identifies the type of reference
type ReferenceKind int

const (
	RefUnknown ReferenceKind = iota
	RefVariable      // var.name
	RefLocal         // local.name
	RefResource      // resource_type.name or resource_type.name[index]
	RefData          // data.type.name
	RefModule        // module.name
	RefOutput        // output.name (within modules)
	RefSelf          // self.attr
	RefCount         // count.index
	RefEach          // each.key or each.value
	RefPath          // path.module, path.root, path.cwd
	RefTerraform     // terraform.workspace
)

// Reference represents a reference to another value in HCL
type Reference struct {
	Kind       ReferenceKind
	Subject    string   // The full subject (e.g., "aws_instance.web")
	Key        string   // Primary key (e.g., "web" for aws_instance.web)
	Type       string   // Resource type (e.g., "aws_instance")
	Attribute  string   // Attribute being accessed (e.g., "id")
	Index      *Index   // Optional index for count/for_each
	Remaining  []string // Remaining path segments
	RawString  string   // Original reference string
}

// Index represents a count or for_each index
type Index struct {
	IsNumeric bool
	NumValue  int
	StrValue  string
	IsUnknown bool
}

// NewNumericIndex creates a numeric index
func NewNumericIndex(n int) *Index {
	return &Index{IsNumeric: true, NumValue: n}
}

// NewStringIndex creates a string index
func NewStringIndex(s string) *Index {
	return &Index{IsNumeric: false, StrValue: s}
}

// UnknownIndex creates an unknown index
func UnknownIndex() *Index {
	return &Index{IsUnknown: true}
}

// String returns the index as a string
func (idx *Index) String() string {
	if idx == nil {
		return ""
	}
	if idx.IsUnknown {
		return "[?]"
	}
	if idx.IsNumeric {
		return fmt.Sprintf("[%d]", idx.NumValue)
	}
	return fmt.Sprintf("[%q]", idx.StrValue)
}

// ParseReference parses a reference string into structured form
func ParseReference(ref string) (*Reference, error) {
	ref = strings.TrimSpace(ref)
	if ref == "" {
		return nil, fmt.Errorf("empty reference")
	}

	result := &Reference{RawString: ref}

	// Split by dots, but handle indices specially
	parts := splitReference(ref)
	if len(parts) == 0 {
		return nil, fmt.Errorf("invalid reference: %s", ref)
	}

	// Determine reference kind from first part
	switch parts[0] {
	case "var":
		result.Kind = RefVariable
		if len(parts) < 2 {
			return nil, fmt.Errorf("variable reference requires name: %s", ref)
		}
		result.Key = parts[1]
		result.Subject = "var." + result.Key
		if len(parts) > 2 {
			result.Remaining = parts[2:]
		}

	case "local":
		result.Kind = RefLocal
		if len(parts) < 2 {
			return nil, fmt.Errorf("local reference requires name: %s", ref)
		}
		result.Key = parts[1]
		result.Subject = "local." + result.Key
		if len(parts) > 2 {
			result.Remaining = parts[2:]
		}

	case "data":
		result.Kind = RefData
		if len(parts) < 3 {
			return nil, fmt.Errorf("data reference requires type and name: %s", ref)
		}
		result.Type = parts[1]
		result.Key, result.Index = parseKeyAndIndex(parts[2])
		result.Subject = fmt.Sprintf("data.%s.%s", result.Type, result.Key)
		if len(parts) > 3 {
			result.Remaining = parts[3:]
		}

	case "module":
		result.Kind = RefModule
		if len(parts) < 2 {
			return nil, fmt.Errorf("module reference requires name: %s", ref)
		}
		result.Key, result.Index = parseKeyAndIndex(parts[1])
		result.Subject = "module." + result.Key
		if len(parts) > 2 {
			result.Remaining = parts[2:]
		}

	case "self":
		result.Kind = RefSelf
		result.Subject = "self"
		if len(parts) > 1 {
			result.Attribute = parts[1]
			result.Remaining = parts[2:]
		}

	case "count":
		result.Kind = RefCount
		result.Subject = "count"
		if len(parts) > 1 && parts[1] == "index" {
			result.Attribute = "index"
		}

	case "each":
		result.Kind = RefEach
		result.Subject = "each"
		if len(parts) > 1 {
			result.Attribute = parts[1] // key or value
		}

	case "path":
		result.Kind = RefPath
		result.Subject = "path"
		if len(parts) > 1 {
			result.Attribute = parts[1] // module, root, cwd
		}

	case "terraform":
		result.Kind = RefTerraform
		result.Subject = "terraform"
		if len(parts) > 1 {
			result.Attribute = parts[1] // workspace
		}

	default:
		// Assume it's a resource reference: type.name
		result.Kind = RefResource
		result.Type = parts[0]
		if len(parts) < 2 {
			return nil, fmt.Errorf("resource reference requires name: %s", ref)
		}
		result.Key, result.Index = parseKeyAndIndex(parts[1])
		result.Subject = fmt.Sprintf("%s.%s", result.Type, result.Key)
		if len(parts) > 2 {
			result.Remaining = parts[2:]
		}
	}

	// Extract attribute from remaining if present
	if len(result.Remaining) > 0 {
		result.Attribute = result.Remaining[0]
		result.Remaining = result.Remaining[1:]
	}

	return result, nil
}

// splitReference splits a reference by dots, handling index brackets
func splitReference(ref string) []string {
	var parts []string
	var current strings.Builder
	inBracket := 0

	for _, ch := range ref {
		switch ch {
		case '[':
			inBracket++
			current.WriteRune(ch)
		case ']':
			inBracket--
			current.WriteRune(ch)
		case '.':
			if inBracket > 0 {
				current.WriteRune(ch)
			} else {
				if current.Len() > 0 {
					parts = append(parts, current.String())
					current.Reset()
				}
			}
		default:
			current.WriteRune(ch)
		}
	}

	if current.Len() > 0 {
		parts = append(parts, current.String())
	}

	return parts
}

// indexPattern matches [0], [1], ["key"], etc.
var indexPattern = regexp.MustCompile(`^([^[]+)\[(.+)\]$`)

// parseKeyAndIndex extracts key and optional index from "name[index]"
func parseKeyAndIndex(s string) (string, *Index) {
	matches := indexPattern.FindStringSubmatch(s)
	if matches == nil {
		return s, nil
	}

	key := matches[1]
	indexStr := matches[2]

	// Try numeric index
	if n, err := strconv.Atoi(indexStr); err == nil {
		return key, NewNumericIndex(n)
	}

	// Try string index (quoted)
	if strings.HasPrefix(indexStr, "\"") && strings.HasSuffix(indexStr, "\"") {
		return key, NewStringIndex(indexStr[1 : len(indexStr)-1])
	}

	// Unknown/computed index
	return key, UnknownIndex()
}

// Address returns the full address including index
func (r *Reference) Address() string {
	addr := r.Subject
	if r.Index != nil {
		addr += r.Index.String()
	}
	if r.Attribute != "" {
		addr += "." + r.Attribute
	}
	for _, rem := range r.Remaining {
		addr += "." + rem
	}
	return addr
}

// ResourceAddress returns just the resource address without attribute
func (r *Reference) ResourceAddress() string {
	addr := r.Subject
	if r.Index != nil {
		addr += r.Index.String()
	}
	return addr
}

// String returns the reference as a string
func (r *Reference) String() string {
	return r.Address()
}

// ExtractReferences finds all references in a string (simple heuristic)
func ExtractReferences(s string) []*Reference {
	// Pattern for common reference formats
	patterns := []string{
		`var\.[a-zA-Z_][a-zA-Z0-9_]*`,
		`local\.[a-zA-Z_][a-zA-Z0-9_]*`,
		`data\.[a-zA-Z_][a-zA-Z0-9_]*\.[a-zA-Z_][a-zA-Z0-9_]*`,
		`module\.[a-zA-Z_][a-zA-Z0-9_]*`,
		`[a-zA-Z_][a-zA-Z0-9_]*\.[a-zA-Z_][a-zA-Z0-9_]*(\[[^\]]+\])?(\.[a-zA-Z_][a-zA-Z0-9_]*)*`,
	}

	var refs []*Reference
	seen := make(map[string]bool)

	for _, pat := range patterns {
		re := regexp.MustCompile(pat)
		matches := re.FindAllString(s, -1)
		for _, m := range matches {
			if seen[m] {
				continue
			}
			seen[m] = true

			ref, err := ParseReference(m)
			if err == nil {
				refs = append(refs, ref)
			}
		}
	}

	return refs
}

################################################################################
# FILE: :\good projects\cost estimation\core\expression\value.go
# TYPE: go
# SIZE: 9189 bytes
################################################################################
// Package expression provides HCL expression evaluation.
// This is a clean-room implementation based on Terraform semantics.
package expression

import (
	"fmt"
	"math/big"
	"reflect"
	"strings"
)

// ValueKind represents the type of a value
type ValueKind int

const (
	KindNull ValueKind = iota
	KindBool
	KindNumber
	KindString
	KindList
	KindMap
	KindObject
	KindUnknown   // Value exists but is not yet known
	KindSensitive // Value is marked sensitive
)

// Value represents a Terraform/HCL value with type information
type Value struct {
	kind      ValueKind
	boolVal   bool
	numberVal *big.Float
	stringVal string
	listVal   []Value
	mapVal    map[string]Value
	marks     []ValueMark
}

// ValueMark represents metadata about a value
type ValueMark int

const (
	MarkNone ValueMark = iota
	MarkSensitive
	MarkUnknown
	MarkDynamic
)

// Null creates a null value
func Null() Value {
	return Value{kind: KindNull}
}

// Bool creates a boolean value
func Bool(v bool) Value {
	return Value{kind: KindBool, boolVal: v}
}

// Number creates a numeric value
func Number(v float64) Value {
	return Value{kind: KindNumber, numberVal: big.NewFloat(v)}
}

// NumberFromInt creates a numeric value from an integer
func NumberFromInt(v int64) Value {
	return Value{kind: KindNumber, numberVal: big.NewFloat(float64(v))}
}

// String creates a string value
func String(v string) Value {
	return Value{kind: KindString, stringVal: v}
}

// List creates a list value
func List(elements ...Value) Value {
	return Value{kind: KindList, listVal: elements}
}

// Map creates a map value
func Map(elements map[string]Value) Value {
	return Value{kind: KindMap, mapVal: elements}
}

// Unknown creates an unknown value (computed at runtime)
func Unknown() Value {
	return Value{kind: KindUnknown}
}

// UnknownWithType creates an unknown value with a type hint
func UnknownWithType(kind ValueKind) Value {
	v := Value{kind: kind, marks: []ValueMark{MarkUnknown}}
	return v
}

// FromGo converts a Go value to a Value
func FromGo(v interface{}) Value {
	if v == nil {
		return Null()
	}

	switch val := v.(type) {
	case bool:
		return Bool(val)
	case int:
		return NumberFromInt(int64(val))
	case int64:
		return NumberFromInt(val)
	case float64:
		return Number(val)
	case string:
		return String(val)
	case []interface{}:
		elements := make([]Value, len(val))
		for i, e := range val {
			elements[i] = FromGo(e)
		}
		return List(elements...)
	case map[string]interface{}:
		elements := make(map[string]Value)
		for k, e := range val {
			elements[k] = FromGo(e)
		}
		return Map(elements)
	default:
		// Try reflection for other types
		rv := reflect.ValueOf(v)
		switch rv.Kind() {
		case reflect.Slice, reflect.Array:
			elements := make([]Value, rv.Len())
			for i := 0; i < rv.Len(); i++ {
				elements[i] = FromGo(rv.Index(i).Interface())
			}
			return List(elements...)
		case reflect.Map:
			elements := make(map[string]Value)
			iter := rv.MapRange()
			for iter.Next() {
				k := fmt.Sprintf("%v", iter.Key().Interface())
				elements[k] = FromGo(iter.Value().Interface())
			}
			return Map(elements)
		}
		// Fallback to string representation
		return String(fmt.Sprintf("%v", v))
	}
}

// Kind returns the value kind
func (v Value) Kind() ValueKind {
	return v.kind
}

// IsNull returns true if value is null
func (v Value) IsNull() bool {
	return v.kind == KindNull
}

// IsUnknown returns true if value is unknown
func (v Value) IsUnknown() bool {
	if v.kind == KindUnknown {
		return true
	}
	for _, m := range v.marks {
		if m == MarkUnknown {
			return true
		}
	}
	return false
}

// IsSensitive returns true if value is sensitive
func (v Value) IsSensitive() bool {
	for _, m := range v.marks {
		if m == MarkSensitive {
			return true
		}
	}
	return false
}

// IsKnown returns true if value is not unknown and not null
func (v Value) IsKnown() bool {
	return !v.IsUnknown() && !v.IsNull()
}

// AsBool returns the boolean value
func (v Value) AsBool() (bool, error) {
	if v.kind != KindBool {
		return false, fmt.Errorf("value is %v, not bool", v.kind)
	}
	return v.boolVal, nil
}

// AsNumber returns the numeric value as float64
func (v Value) AsNumber() (float64, error) {
	if v.kind != KindNumber {
		return 0, fmt.Errorf("value is %v, not number", v.kind)
	}
	f, _ := v.numberVal.Float64()
	return f, nil
}

// AsInt returns the numeric value as int64
func (v Value) AsInt() (int64, error) {
	if v.kind != KindNumber {
		return 0, fmt.Errorf("value is %v, not number", v.kind)
	}
	f, _ := v.numberVal.Float64()
	return int64(f), nil
}

// AsString returns the string value
func (v Value) AsString() (string, error) {
	if v.kind != KindString {
		return "", fmt.Errorf("value is %v, not string", v.kind)
	}
	return v.stringVal, nil
}

// AsList returns the list elements
func (v Value) AsList() ([]Value, error) {
	if v.kind != KindList {
		return nil, fmt.Errorf("value is %v, not list", v.kind)
	}
	return v.listVal, nil
}

// AsMap returns the map elements
func (v Value) AsMap() (map[string]Value, error) {
	if v.kind != KindMap && v.kind != KindObject {
		return nil, fmt.Errorf("value is %v, not map", v.kind)
	}
	return v.mapVal, nil
}

// Length returns the length for lists/maps/strings
func (v Value) Length() (int, error) {
	switch v.kind {
	case KindString:
		return len(v.stringVal), nil
	case KindList:
		return len(v.listVal), nil
	case KindMap, KindObject:
		return len(v.mapVal), nil
	default:
		return 0, fmt.Errorf("cannot get length of %v", v.kind)
	}
}

// Index gets an element by index (for lists)
func (v Value) Index(i int) (Value, error) {
	if v.kind != KindList {
		return Null(), fmt.Errorf("cannot index %v", v.kind)
	}
	if i < 0 || i >= len(v.listVal) {
		return Null(), fmt.Errorf("index %d out of range [0, %d)", i, len(v.listVal))
	}
	return v.listVal[i], nil
}

// GetAttr gets an attribute by name (for maps/objects)
func (v Value) GetAttr(name string) (Value, error) {
	if v.kind != KindMap && v.kind != KindObject {
		return Null(), fmt.Errorf("cannot get attribute of %v", v.kind)
	}
	val, ok := v.mapVal[name]
	if !ok {
		return Null(), nil // Missing attributes are null
	}
	return val, nil
}

// Equals compares values for equality
func (v Value) Equals(other Value) bool {
	if v.kind != other.kind {
		return false
	}

	switch v.kind {
	case KindNull:
		return true
	case KindBool:
		return v.boolVal == other.boolVal
	case KindNumber:
		return v.numberVal.Cmp(other.numberVal) == 0
	case KindString:
		return v.stringVal == other.stringVal
	case KindList:
		if len(v.listVal) != len(other.listVal) {
			return false
		}
		for i := range v.listVal {
			if !v.listVal[i].Equals(other.listVal[i]) {
				return false
			}
		}
		return true
	case KindMap, KindObject:
		if len(v.mapVal) != len(other.mapVal) {
			return false
		}
		for k, val := range v.mapVal {
			otherVal, ok := other.mapVal[k]
			if !ok || !val.Equals(otherVal) {
				return false
			}
		}
		return true
	case KindUnknown:
		return false // Unknowns are never equal
	default:
		return false
	}
}

// ToGo converts the value to a Go interface{}
func (v Value) ToGo() interface{} {
	switch v.kind {
	case KindNull:
		return nil
	case KindBool:
		return v.boolVal
	case KindNumber:
		f, _ := v.numberVal.Float64()
		return f
	case KindString:
		return v.stringVal
	case KindList:
		result := make([]interface{}, len(v.listVal))
		for i, e := range v.listVal {
			result[i] = e.ToGo()
		}
		return result
	case KindMap, KindObject:
		result := make(map[string]interface{})
		for k, e := range v.mapVal {
			result[k] = e.ToGo()
		}
		return result
	case KindUnknown:
		return nil // Unknown converts to nil
	default:
		return nil
	}
}

// String returns a string representation
func (v Value) String() string {
	switch v.kind {
	case KindNull:
		return "null"
	case KindBool:
		if v.boolVal {
			return "true"
		}
		return "false"
	case KindNumber:
		return v.numberVal.Text('f', -1)
	case KindString:
		return fmt.Sprintf("%q", v.stringVal)
	case KindList:
		parts := make([]string, len(v.listVal))
		for i, e := range v.listVal {
			parts[i] = e.String()
		}
		return "[" + strings.Join(parts, ", ") + "]"
	case KindMap, KindObject:
		parts := make([]string, 0, len(v.mapVal))
		for k, e := range v.mapVal {
			parts = append(parts, fmt.Sprintf("%q = %s", k, e.String()))
		}
		return "{" + strings.Join(parts, ", ") + "}"
	case KindUnknown:
		return "(unknown)"
	default:
		return "(invalid)"
	}
}

// MarkAsSensitive returns a copy of the value marked as sensitive
func (v Value) MarkAsSensitive() Value {
	newVal := v
	newVal.marks = append(newVal.marks, MarkSensitive)
	return newVal
}

// MarkAsUnknown returns a copy of the value marked as unknown
func (v Value) MarkAsUnknown() Value {
	newVal := v
	newVal.marks = append(newVal.marks, MarkUnknown)
	return newVal
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\bypass_prevention.go
# TYPE: go
# SIZE: 2292 bytes
################################################################################
// Package graph - Bypass prevention
// These functions exist SOLELY to prevent incorrect usage patterns.
// They panic immediately to ensure bypass attempts are caught in development.
package graph

// DEPRECATED CONSTRUCTORS - DO NOT USE
// These exist only to provide clear error messages if someone tries to bypass

// NewCostUnitFromAssetDirect is BLOCKED - use NewEnforcedCostUnit
func NewCostUnitFromAssetDirect(assetID string) {
	BlockBypassAttempt("NewCostUnitFromAssetDirect - cost units must be created via NewEnforcedCostUnit with dependency path")
}

// NewCostGraphWithoutDepGraph is BLOCKED - use NewEnforcedCostGraph
func NewCostGraphWithoutDepGraph() {
	BlockBypassAttempt("NewCostGraphWithoutDepGraph - cost graphs must derive from EnforcedAssetGraph with canonical dependency graph")
}

// ExpandWithoutCardinalityCheck is BLOCKED - use ExpansionGuard.MustExpand
func ExpandWithoutCardinalityCheck(address string, count int) {
	BlockBypassAttempt("ExpandWithoutCardinalityCheck - expansion must verify cardinality via ExpansionGuard")
}

// PriceWithoutProviderFreeze is BLOCKED - use PricingGate.MustGetProvider
func PriceWithoutProviderFreeze(resourceType string) {
	BlockBypassAttempt("PriceWithoutProviderFreeze - pricing must occur after provider finalization via PricingGate")
}

// AggregateConfidenceByAverage is BLOCKED - use confidence.AggregateConfidence
func AggregateConfidenceByAverage(values []float64) {
	BlockBypassAttempt("AggregateConfidenceByAverage - confidence must propagate pessimistically (MIN)")
}

// CreateNumericCostForUnknown is BLOCKED - use NewSymbolicCostUnit
func CreateNumericCostForUnknown(address string, cost float64) {
	BlockBypassAttempt("CreateNumericCostForUnknown - unknown cardinality must use symbolic costs only")
}

// SkipDependencyClosureForDiff is BLOCKED - use DependencyClosureDiff
func SkipDependencyClosureForDiff(addresses []string) {
	BlockBypassAttempt("SkipDependencyClosureForDiff - diffs must use dependency closure, not address matching")
}

// AcceptAssetWithoutDepNode is BLOCKED - assets must have dependency nodes
func AcceptAssetWithoutDepNode(assetID string) {
	BlockBypassAttempt("AcceptAssetWithoutDepNode - all assets must reference a DependencyNodeID")
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\canonical_graph.go
# TYPE: go
# SIZE: 8410 bytes
################################################################################
// Package graph - Canonical dependency graph
// This is THE authoritative source of truth for all dependencies.
// Everything downstream MUST reference this graph.
package graph

// DependencyNodeID uniquely identifies a node in the dependency graph
type DependencyNodeID string

// EdgeType indicates the type of dependency edge
type EdgeType int

const (
	EdgeReference    EdgeType = iota // Expression reference (e.g., aws_instance.web.id)
	EdgeDependsOn                    // Explicit depends_on
	EdgeModuleInput                  // Module input variable
	EdgeModuleOutput                 // Module output reference
	EdgeProviderBinding              // Provider configuration binding
	EdgeDataSource                   // Data source dependency
)

// String returns edge type name
func (t EdgeType) String() string {
	names := []string{"reference", "depends_on", "module_input", "module_output", "provider_binding", "data_source"}
	if int(t) < len(names) {
		return names[t]
	}
	return "unknown"
}

// DependencyEdge represents a directed edge in the dependency graph
type DependencyEdge struct {
	From      DependencyNodeID
	To        DependencyNodeID
	Type      EdgeType
	Attribute string // Which attribute caused this edge (for reference edges)
}

// NodeType indicates what kind of node this is
type CanonicalNodeType int

const (
	CanonicalResource   CanonicalNodeType = iota // resource block
	CanonicalData                                 // data source
	CanonicalModule                               // module call
	CanonicalProvider                             // provider configuration
	CanonicalVariable                             // input variable
	CanonicalLocal                                // local value
	CanonicalOutput                               // output value
)

// NodeMeta contains metadata about a dependency node
type NodeMeta struct {
	ID           DependencyNodeID
	Type         CanonicalNodeType
	Address      string // Terraform address (e.g., aws_instance.web)
	ModulePath   string // Module path (empty for root)
	ResourceType string // For resources/data: aws_instance
	Provider     string // Provider key
	SourceFile   string
	SourceLine   int
}

// CanonicalDependencyGraph is THE authoritative dependency graph
// All downstream systems MUST derive from this graph.
type CanonicalDependencyGraph struct {
	// Nodes indexed by ID
	nodes map[DependencyNodeID]*NodeMeta

	// Forward edges (from â†’ to)
	edges map[DependencyNodeID][]DependencyEdge

	// Reverse edges (to â†’ from) for upstream lookups
	reverseEdges map[DependencyNodeID][]DependencyEdge

	// Root nodes (no incoming edges)
	roots []DependencyNodeID

	// Sealed flag - no modifications after sealing
	sealed bool
}

// NewCanonicalDependencyGraph creates a new graph
func NewCanonicalDependencyGraph() *CanonicalDependencyGraph {
	return &CanonicalDependencyGraph{
		nodes:        make(map[DependencyNodeID]*NodeMeta),
		edges:        make(map[DependencyNodeID][]DependencyEdge),
		reverseEdges: make(map[DependencyNodeID][]DependencyEdge),
		roots:        []DependencyNodeID{},
		sealed:       false,
	}
}

// AddNode adds a node to the graph
func (g *CanonicalDependencyGraph) AddNode(meta *NodeMeta) {
	if g.sealed {
		panic("INVARIANT VIOLATED: cannot modify sealed dependency graph")
	}
	g.nodes[meta.ID] = meta
}

// AddEdge adds an edge to the graph
func (g *CanonicalDependencyGraph) AddEdge(edge DependencyEdge) {
	if g.sealed {
		panic("INVARIANT VIOLATED: cannot modify sealed dependency graph")
	}
	
	// Validate nodes exist
	if _, ok := g.nodes[edge.From]; !ok {
		panic("INVARIANT VIOLATED: edge from non-existent node: " + string(edge.From))
	}
	if _, ok := g.nodes[edge.To]; !ok {
		panic("INVARIANT VIOLATED: edge to non-existent node: " + string(edge.To))
	}

	g.edges[edge.From] = append(g.edges[edge.From], edge)
	g.reverseEdges[edge.To] = append(g.reverseEdges[edge.To], edge)
}

// Seal seals the graph - no more modifications allowed
func (g *CanonicalDependencyGraph) Seal() {
	// Compute roots
	g.roots = []DependencyNodeID{}
	for id := range g.nodes {
		if len(g.reverseEdges[id]) == 0 {
			g.roots = append(g.roots, id)
		}
	}
	g.sealed = true
}

// IsSealed returns whether the graph is sealed
func (g *CanonicalDependencyGraph) IsSealed() bool {
	return g.sealed
}

// IsTransitivelyClosed checks if graph is transitively closed
// A graph is closed if all referenced nodes exist
func (g *CanonicalDependencyGraph) IsTransitivelyClosed() bool {
	for _, edges := range g.edges {
		for _, edge := range edges {
			if _, ok := g.nodes[edge.To]; !ok {
				return false
			}
		}
	}
	return true
}

// MustBeClosed panics if graph is not closed
// CALL THIS BEFORE ASSET EXPANSION
func (g *CanonicalDependencyGraph) MustBeClosed() {
	if !g.sealed {
		panic("INVARIANT VIOLATED: dependency graph must be sealed before use")
	}
	if !g.IsTransitivelyClosed() {
		panic("INVARIANT VIOLATED: dependency graph is not transitively closed")
	}
}

// GetNode returns a node by ID
func (g *CanonicalDependencyGraph) GetNode(id DependencyNodeID) (*NodeMeta, bool) {
	node, ok := g.nodes[id]
	return node, ok
}

// MustGetNode returns a node or panics
func (g *CanonicalDependencyGraph) MustGetNode(id DependencyNodeID) *NodeMeta {
	node, ok := g.nodes[id]
	if !ok {
		panic("INVARIANT VIOLATED: node not found: " + string(id))
	}
	return node
}

// GetDependencies returns direct dependencies of a node
func (g *CanonicalDependencyGraph) GetDependencies(id DependencyNodeID) []DependencyEdge {
	return g.edges[id]
}

// GetDependents returns nodes that depend on this node
func (g *CanonicalDependencyGraph) GetDependents(id DependencyNodeID) []DependencyEdge {
	return g.reverseEdges[id]
}

// GetDependencyPath returns the transitive closure from roots to this node
// This is REQUIRED for CostUnit lineage
func (g *CanonicalDependencyGraph) GetDependencyPath(id DependencyNodeID) []DependencyNodeID {
	if !g.sealed {
		panic("INVARIANT VIOLATED: cannot compute dependency path on unsealed graph")
	}

	visited := make(map[DependencyNodeID]bool)
	path := []DependencyNodeID{}
	g.collectUpstream(id, visited, &path)
	
	// Reverse to get root â†’ target order
	for i, j := 0, len(path)-1; i < j; i, j = i+1, j-1 {
		path[i], path[j] = path[j], path[i]
	}
	
	return path
}

func (g *CanonicalDependencyGraph) collectUpstream(id DependencyNodeID, visited map[DependencyNodeID]bool, path *[]DependencyNodeID) {
	if visited[id] {
		return
	}
	visited[id] = true

	// First collect upstream
	for _, edge := range g.reverseEdges[id] {
		g.collectUpstream(edge.From, visited, path)
	}

	// Then add self
	*path = append(*path, id)
}

// GetTransitiveDependents returns all nodes affected by changes to this node
func (g *CanonicalDependencyGraph) GetTransitiveDependents(id DependencyNodeID) []DependencyNodeID {
	if !g.sealed {
		panic("INVARIANT VIOLATED: cannot compute transitive dependents on unsealed graph")
	}

	visited := make(map[DependencyNodeID]bool)
	result := []DependencyNodeID{}
	g.collectDownstream(id, visited, &result)
	return result
}

func (g *CanonicalDependencyGraph) collectDownstream(id DependencyNodeID, visited map[DependencyNodeID]bool, result *[]DependencyNodeID) {
	for _, edge := range g.edges[id] {
		if !visited[edge.To] {
			visited[edge.To] = true
			*result = append(*result, edge.To)
			g.collectDownstream(edge.To, visited, result)
		}
	}
}

// GetRoots returns root nodes
func (g *CanonicalDependencyGraph) GetRoots() []DependencyNodeID {
	return g.roots
}

// Size returns node count
func (g *CanonicalDependencyGraph) Size() int {
	return len(g.nodes)
}

// EdgeCount returns edge count
func (g *CanonicalDependencyGraph) EdgeCount() int {
	count := 0
	for _, edges := range g.edges {
		count += len(edges)
	}
	return count
}

// AllNodes returns all nodes
func (g *CanonicalDependencyGraph) AllNodes() map[DependencyNodeID]*NodeMeta {
	return g.nodes
}

// ValidateNode asserts a node exists
func (g *CanonicalDependencyGraph) ValidateNode(id DependencyNodeID) {
	if _, ok := g.nodes[id]; !ok {
		panic("INVARIANT VIOLATED: node not in canonical dependency graph: " + string(id))
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\concurrent.go
# TYPE: go
# SIZE: 7747 bytes
################################################################################
// Package graph - Concurrent graph execution
// Resources are processed in parallel respecting dependency order.
package graph

import (
	"context"
	"fmt"
	"sync"
	"sync/atomic"
	"time"
)

// ConcurrentExecutor executes graph nodes in parallel with dependency respect
type ConcurrentExecutor struct {
	// Max concurrent workers
	maxWorkers int

	// Execution stats
	stats *ExecutionStats

	// Error handling
	stopOnError bool
	errors      []ExecutionError

	// Progress tracking
	progress *ExecutionProgress

	mu sync.Mutex
}

// ExecutionStats tracks execution statistics
type ExecutionStats struct {
	TotalNodes       int64
	CompletedNodes   int64
	FailedNodes      int64
	SkippedNodes     int64
	StartTime        time.Time
	EndTime          time.Time
	MaxConcurrency   int
	AverageDuration  time.Duration
	nodeDurations    []time.Duration
	mu               sync.Mutex
}

// ExecutionError records an execution error
type ExecutionError struct {
	NodeID   string
	Phase    string
	Message  string
	Cause    error
	Duration time.Duration
}

// ExecutionProgress tracks live progress
type ExecutionProgress struct {
	Total      int64
	Completed  int64
	InProgress int64
	Failed     int64
	Percent    float64
	ETA        time.Duration
	mu         sync.RWMutex
}

// NodeExecutor is a function that processes a single node
type NodeExecutor func(ctx context.Context, nodeID string) error

// NewConcurrentExecutor creates a new executor
func NewConcurrentExecutor(maxWorkers int) *ConcurrentExecutor {
	if maxWorkers <= 0 {
		maxWorkers = 4
	}
	return &ConcurrentExecutor{
		maxWorkers:  maxWorkers,
		stats:       &ExecutionStats{},
		stopOnError: false,
		errors:      []ExecutionError{},
		progress:    &ExecutionProgress{},
	}
}

// SetStopOnError configures error handling
func (e *ConcurrentExecutor) SetStopOnError(stop bool) {
	e.stopOnError = stop
}

// Execute runs the executor on a graph
func (e *ConcurrentExecutor) Execute(ctx context.Context, graph *InfrastructureGraph, executor NodeExecutor) error {
	// Get topological order
	order, err := graph.TopologicalSort()
	if err != nil {
		return fmt.Errorf("failed to sort graph: %w", err)
	}

	if len(order) == 0 {
		return nil
	}

	// Initialize stats
	e.stats.TotalNodes = int64(len(order))
	e.stats.StartTime = time.Now()
	e.progress.Total = int64(len(order))

	// Group nodes by level (nodes at same level can run in parallel)
	levels := e.groupByLevel(graph, order)

	// Execute level by level
	for levelNum, level := range levels {
		if err := e.executeLevel(ctx, level, levelNum, executor); err != nil {
			if e.stopOnError {
				return err
			}
		}
	}

	e.stats.EndTime = time.Now()
	e.calculateAverageDuration()

	return nil
}

// groupByLevel groups nodes into dependency levels
func (e *ConcurrentExecutor) groupByLevel(graph *InfrastructureGraph, order []string) [][]string {
	levels := [][]string{}
	processed := make(map[string]int) // node -> level

	for _, nodeID := range order {
		// Find the maximum level of dependencies
		maxDepLevel := -1
		deps := graph.GetDependencies(nodeID)
		for _, dep := range deps {
			if level, ok := processed[dep]; ok {
				if level > maxDepLevel {
					maxDepLevel = level
				}
			}
		}

		// This node goes in the next level
		nodeLevel := maxDepLevel + 1
		processed[nodeID] = nodeLevel

		// Ensure we have enough levels
		for len(levels) <= nodeLevel {
			levels = append(levels, []string{})
		}
		levels[nodeLevel] = append(levels[nodeLevel], nodeID)
	}

	return levels
}

// executeLevel executes all nodes in a level concurrently
func (e *ConcurrentExecutor) executeLevel(ctx context.Context, nodes []string, levelNum int, executor NodeExecutor) error {
	if len(nodes) == 0 {
		return nil
	}

	// Create worker pool
	workers := e.maxWorkers
	if len(nodes) < workers {
		workers = len(nodes)
	}

	// Track concurrency
	if workers > e.stats.MaxConcurrency {
		e.stats.MaxConcurrency = workers
	}

	// Channel for work items
	work := make(chan string, len(nodes))
	for _, node := range nodes {
		work <- node
	}
	close(work)

	// Error channel
	errChan := make(chan ExecutionError, len(nodes))

	// WaitGroup for workers
	var wg sync.WaitGroup

	// Start workers
	for i := 0; i < workers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for nodeID := range work {
				select {
				case <-ctx.Done():
					return
				default:
					e.executeNode(ctx, nodeID, executor, errChan)
				}
			}
		}()
	}

	// Wait for completion
	wg.Wait()
	close(errChan)

	// Collect errors
	for err := range errChan {
		e.mu.Lock()
		e.errors = append(e.errors, err)
		e.mu.Unlock()
	}

	return nil
}

func (e *ConcurrentExecutor) executeNode(ctx context.Context, nodeID string, executor NodeExecutor, errChan chan<- ExecutionError) {
	// Update progress
	atomic.AddInt64(&e.progress.InProgress, 1)
	e.updateProgress()

	start := time.Now()
	err := executor(ctx, nodeID)
	duration := time.Since(start)

	// Record duration
	e.stats.mu.Lock()
	e.stats.nodeDurations = append(e.stats.nodeDurations, duration)
	e.stats.mu.Unlock()

	atomic.AddInt64(&e.progress.InProgress, -1)

	if err != nil {
		atomic.AddInt64(&e.stats.FailedNodes, 1)
		atomic.AddInt64(&e.progress.Failed, 1)
		errChan <- ExecutionError{
			NodeID:   nodeID,
			Message:  err.Error(),
			Cause:    err,
			Duration: duration,
		}
	} else {
		atomic.AddInt64(&e.stats.CompletedNodes, 1)
		atomic.AddInt64(&e.progress.Completed, 1)
	}

	e.updateProgress()
}

func (e *ConcurrentExecutor) updateProgress() {
	e.progress.mu.Lock()
	defer e.progress.mu.Unlock()

	if e.progress.Total > 0 {
		e.progress.Percent = float64(e.progress.Completed+e.progress.Failed) / float64(e.progress.Total) * 100
	}

	// Estimate ETA
	elapsed := time.Since(e.stats.StartTime)
	if e.progress.Completed > 0 {
		avgDuration := elapsed / time.Duration(e.progress.Completed)
		remaining := e.progress.Total - e.progress.Completed - e.progress.Failed
		e.progress.ETA = avgDuration * time.Duration(remaining)
	}
}

func (e *ConcurrentExecutor) calculateAverageDuration() {
	e.stats.mu.Lock()
	defer e.stats.mu.Unlock()

	if len(e.stats.nodeDurations) == 0 {
		return
	}

	var total time.Duration
	for _, d := range e.stats.nodeDurations {
		total += d
	}
	e.stats.AverageDuration = total / time.Duration(len(e.stats.nodeDurations))
}

// GetProgress returns current progress
func (e *ConcurrentExecutor) GetProgress() ExecutionProgress {
	e.progress.mu.RLock()
	defer e.progress.mu.RUnlock()
	return *e.progress
}

// GetStats returns execution stats
func (e *ConcurrentExecutor) GetStats() ExecutionStats {
	return *e.stats
}

// GetErrors returns all errors
func (e *ConcurrentExecutor) GetErrors() []ExecutionError {
	e.mu.Lock()
	defer e.mu.Unlock()
	return e.errors
}

// ProgressCallback is called with progress updates
type ProgressCallback func(progress ExecutionProgress)

// ExecuteWithProgress runs with progress callbacks
func (e *ConcurrentExecutor) ExecuteWithProgress(ctx context.Context, graph *InfrastructureGraph, executor NodeExecutor, callback ProgressCallback, interval time.Duration) error {
	// Start progress reporter
	done := make(chan struct{})
	go func() {
		ticker := time.NewTicker(interval)
		defer ticker.Stop()
		for {
			select {
			case <-done:
				return
			case <-ticker.C:
				callback(e.GetProgress())
			}
		}
	}()

	// Execute
	err := e.Execute(ctx, graph, executor)
	close(done)

	// Final callback
	callback(e.GetProgress())

	return err
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\cost_lineage.go
# TYPE: go
# SIZE: 6382 bytes
################################################################################
// Package graph - Single authoritative CostGraph constructor
// This is the ONLY way to create a cost graph.
// All other paths are BLOCKED.
package graph

import (
	"fmt"

	"terraform-cost/core/determinism"
)

// AuthoritativeCostGraph is a cost graph that MUST derive from dependency graph
type AuthoritativeCostGraph struct {
	// REQUIRED source graphs
	depGraph   *CanonicalDependencyGraph
	assetGraph *EnforcedAssetGraph

	// Cost units with mandatory lineage
	units map[string]*AuthoritativeCostUnit

	// Symbolic buckets (for unknown cardinality)
	symbolicBuckets []*SymbolicBucket

	// State
	sealed bool
}

// AuthoritativeCostUnit is a cost unit with MANDATORY lineage
type AuthoritativeCostUnit struct {
	ID      string
	Lineage *MandatoryLineage

	MonthlyCost determinism.Money
	HourlyCost  determinism.Money
	Confidence  float64

	Components []*AuthoritativeCostComponent
}

// MandatoryLineage is REQUIRED for every cost unit
type MandatoryLineage struct {
	AssetID        string
	InstanceID     string
	DependencyPath []DependencyEdge
	ProviderKey    string
}

// Validate returns error if lineage is incomplete
func (l *MandatoryLineage) Validate() error {
	if l.AssetID == "" {
		return fmt.Errorf("AssetID is empty")
	}
	if len(l.DependencyPath) == 0 {
		return fmt.Errorf("DependencyPath is empty for %s", l.AssetID)
	}
	return nil
}

// MustBeValid panics if invalid
func (l *MandatoryLineage) MustBeValid() {
	if err := l.Validate(); err != nil {
		panic("COST UNIT WITHOUT DEPENDENCY LINEAGE: " + err.Error())
	}
}

// AuthoritativeCostComponent is a component
type AuthoritativeCostComponent struct {
	Name        string
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money
	RateKey     string
	Confidence  float64
}

// SymbolicBucket for unknown cardinality
type SymbolicBucket struct {
	AssetID     string
	Reason      string
	Expression  string
	LowerBound  *determinism.Money
	UpperBound  *determinism.Money
	IsUnbounded bool
}

// BuildAuthoritativeCostGraph is the SINGLE AUTHORITATIVE CONSTRUCTOR
// This is the ONLY way to create a cost graph.
func BuildAuthoritativeCostGraph(
	depGraph *CanonicalDependencyGraph,
	assetGraph *EnforcedAssetGraph,
) (*AuthoritativeCostGraph, error) {
	// INVARIANT: depGraph is required
	if depGraph == nil {
		return nil, fmt.Errorf("INVARIANT VIOLATED: depGraph is nil")
	}

	// INVARIANT: assetGraph is required
	if assetGraph == nil {
		return nil, fmt.Errorf("INVARIANT VIOLATED: assetGraph is nil")
	}

	// INVARIANT: depGraph must be sealed
	if !depGraph.IsSealed() {
		return nil, fmt.Errorf("INVARIANT VIOLATED: depGraph is not sealed")
	}

	// INVARIANT: depGraph must be transitively closed
	if !depGraph.IsTransitivelyClosed() {
		return nil, fmt.Errorf("INVARIANT VIOLATED: dependency graph is not transitively closed")
	}

	return &AuthoritativeCostGraph{
		depGraph:        depGraph,
		assetGraph:      assetGraph,
		units:           make(map[string]*AuthoritativeCostUnit),
		symbolicBuckets: []*SymbolicBucket{},
		sealed:          false,
	}, nil
}

// AddUnit adds a cost unit with MANDATORY lineage validation
func (g *AuthoritativeCostGraph) AddUnit(unit *AuthoritativeCostUnit) error {
	if g.sealed {
		return fmt.Errorf("cannot add to sealed graph")
	}
	if unit.Lineage == nil {
		panic("COST UNIT WITHOUT LINEAGE - this is a bug")
	}
	unit.Lineage.MustBeValid()

	g.units[unit.ID] = unit
	return nil
}

// AddSymbolicBucket adds a symbolic cost for unknown cardinality
func (g *AuthoritativeCostGraph) AddSymbolicBucket(bucket *SymbolicBucket) {
	if g.sealed {
		panic("cannot add to sealed graph")
	}
	g.symbolicBuckets = append(g.symbolicBuckets, bucket)
}

// Seal seals the graph
func (g *AuthoritativeCostGraph) Seal() {
	g.sealed = true
}

// IsSealed returns seal state
func (g *AuthoritativeCostGraph) IsSealed() bool {
	return g.sealed
}

// GetDependencyGraph returns the dependency graph
func (g *AuthoritativeCostGraph) GetDependencyGraph() *CanonicalDependencyGraph {
	return g.depGraph
}

// GetAssetGraph returns the asset graph
func (g *AuthoritativeCostGraph) GetAssetGraph() *EnforcedAssetGraph {
	return g.assetGraph
}

// AllUnits returns all cost units
func (g *AuthoritativeCostGraph) AllUnits() []*AuthoritativeCostUnit {
	units := make([]*AuthoritativeCostUnit, 0, len(g.units))
	for _, u := range g.units {
		units = append(units, u)
	}
	return units
}

// GetSymbolicBuckets returns symbolic buckets
func (g *AuthoritativeCostGraph) GetSymbolicBuckets() []*SymbolicBucket {
	return g.symbolicBuckets
}

// HasSymbolicCosts returns true if there are symbolic costs
func (g *AuthoritativeCostGraph) HasSymbolicCosts() bool {
	return len(g.symbolicBuckets) > 0
}

// GetAffectedByChange returns cost units affected by dependency changes
func (g *AuthoritativeCostGraph) GetAffectedByChange(changedNodeIDs []DependencyNodeID) []*AuthoritativeCostUnit {
	affected := make(map[string]*AuthoritativeCostUnit)

	for _, nodeID := range changedNodeIDs {
		// Get transitive dependents
		dependents := g.depGraph.GetTransitiveDependents(nodeID)
		allAffected := append([]DependencyNodeID{nodeID}, dependents...)

		// Find cost units with these nodes in their path
		for _, unit := range g.units {
			for _, edge := range unit.Lineage.DependencyPath {
				for _, affectedID := range allAffected {
					if edge.From == affectedID || edge.To == affectedID {
						affected[unit.ID] = unit
						break
					}
				}
			}
		}
	}

	result := make([]*AuthoritativeCostUnit, 0, len(affected))
	for _, u := range affected {
		result = append(result, u)
	}
	return result
}

// BLOCKED CONSTRUCTORS - these panic immediately

// BuildCostGraphFromAssets is BLOCKED
func BuildCostGraphFromAssets(assets interface{}) {
	BlockBypassAttempt("BuildCostGraphFromAssets - use BuildAuthoritativeCostGraph instead")
}

// BuildCostGraphFromInstances is BLOCKED
func BuildCostGraphFromInstances(instances interface{}) {
	BlockBypassAttempt("BuildCostGraphFromInstances - use BuildAuthoritativeCostGraph instead")
}

// NewCostGraphDirect is BLOCKED
func NewCostGraphDirect() {
	BlockBypassAttempt("NewCostGraphDirect - use BuildAuthoritativeCostGraph instead")
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\dependency_cost.go
# TYPE: go
# SIZE: 7926 bytes
################################################################################
// Package graph - Dependency-aware cost graph
// Cost graph MUST consume dependency graph authoritatively.
// Every CostUnit is traceable through the asset dependency chain.
package graph

import (
	"terraform-cost/core/cost"
	"terraform-cost/core/model"
)

// DependencyAwareCostGraph integrates cost with dependency semantics
type DependencyAwareCostGraph struct {
	// Infrastructure graph (authoritative)
	infra *InfrastructureGraph

	// Cost graph (derived)
	costs *cost.CostGraph

	// Mapping: instance ID â†’ node ID
	instanceToNode map[model.InstanceID]string

	// Dependency costs: how much each node contributes to dependents
	dependencyCosts map[string]*DependencyCost
}

// DependencyCost tracks cost through dependency chains
type DependencyCost struct {
	NodeID          string
	DirectCost      float64 // This node's cost
	DependentCost   float64 // Cost of nodes depending on this
	TransitiveCost  float64 // Full transitive dependent cost
	DependencyDepth int     // How deep in dependency chain
	AffectedNodes   []string
}

// NewDependencyAwareCostGraph creates an integrated graph
func NewDependencyAwareCostGraph(infra *InfrastructureGraph, costs *cost.CostGraph) *DependencyAwareCostGraph {
	g := &DependencyAwareCostGraph{
		infra:           infra,
		costs:           costs,
		instanceToNode:  make(map[model.InstanceID]string),
		dependencyCosts: make(map[string]*DependencyCost),
	}

	// Build mappings
	g.buildMappings()

	// Calculate dependency costs
	g.calculateDependencyCosts()

	return g
}

func (g *DependencyAwareCostGraph) buildMappings() {
	for nodeID, node := range g.infra.nodes {
		if node.IsExpanded {
			// Map expanded instances to their node
			// Instance ID is derived from definition + key
			instID := model.InstanceID(nodeID)
			g.instanceToNode[instID] = nodeID
		}
	}
}

func (g *DependencyAwareCostGraph) calculateDependencyCosts() {
	// Get topological order (dependencies first)
	order, err := g.infra.TopologicalSort()
	if err != nil {
		return
	}

	// Process in reverse order (dependents first)
	for i := len(order) - 1; i >= 0; i-- {
		nodeID := order[i]
		g.calculateNodeDependencyCost(nodeID)
	}
}

func (g *DependencyAwareCostGraph) calculateNodeDependencyCost(nodeID string) {
	// Get this node's direct cost
	instID := model.InstanceID(nodeID)
	costNode := g.costs.GetNode(instID)

	directCost := 0.0
	if costNode != nil {
		directCost = costNode.TotalMonthly.Float64()
	}

	// Get dependents
	dependents := g.infra.GetDependents(nodeID)

	dependentCost := 0.0
	transitiveCost := 0.0
	maxDepth := 0
	affected := []string{}

	for _, depID := range dependents {
		affected = append(affected, depID)

		// Get dependent's cost info
		if depCost, ok := g.dependencyCosts[depID]; ok {
			dependentCost += depCost.DirectCost
			transitiveCost += depCost.DirectCost + depCost.TransitiveCost
			if depCost.DependencyDepth+1 > maxDepth {
				maxDepth = depCost.DependencyDepth + 1
			}
			affected = append(affected, depCost.AffectedNodes...)
		}
	}

	g.dependencyCosts[nodeID] = &DependencyCost{
		NodeID:          nodeID,
		DirectCost:      directCost,
		DependentCost:   dependentCost,
		TransitiveCost:  transitiveCost,
		DependencyDepth: maxDepth,
		AffectedNodes:   affected,
	}
}

// GetBlastRadius returns the cost impact if a node changes
func (g *DependencyAwareCostGraph) GetBlastRadius(nodeID string) *BlastRadius {
	depCost := g.dependencyCosts[nodeID]
	if depCost == nil {
		return nil
	}

	return &BlastRadius{
		NodeID:              nodeID,
		DirectCost:          depCost.DirectCost,
		AffectedNodesCost:   depCost.TransitiveCost,
		TotalPotentialCost:  depCost.DirectCost + depCost.TransitiveCost,
		AffectedNodesCount:  len(depCost.AffectedNodes),
		MaxDependencyDepth:  depCost.DependencyDepth,
		AffectedNodes:       depCost.AffectedNodes,
	}
}

// BlastRadius describes the cost impact of a change
type BlastRadius struct {
	NodeID              string
	DirectCost          float64
	AffectedNodesCost   float64
	TotalPotentialCost  float64
	AffectedNodesCount  int
	MaxDependencyDepth  int
	AffectedNodes       []string
}

// GetCostLineage returns the full lineage of a cost
func (g *DependencyAwareCostGraph) GetCostLineage(instID model.InstanceID) *CostLineage {
	nodeID := string(instID)
	node := g.infra.GetNode(nodeID)
	costNode := g.costs.GetNode(instID)

	if node == nil || costNode == nil {
		return nil
	}

	lineage := &CostLineage{
		InstanceID:     instID,
		InstanceAddress: string(costNode.InstanceAddress),
		ResourceType:   costNode.ResourceType,
		DirectCost:     costNode.TotalMonthly.Float64(),
		Dependencies:   []DependencyLink{},
		Dependents:     []DependencyLink{},
	}

	// Get dependencies
	for _, depID := range g.infra.GetDependencies(nodeID) {
		depInstID := model.InstanceID(depID)
		depCostNode := g.costs.GetNode(depInstID)
		cost := 0.0
		if depCostNode != nil {
			cost = depCostNode.TotalMonthly.Float64()
		}
		lineage.Dependencies = append(lineage.Dependencies, DependencyLink{
			NodeID:   depID,
			Cost:     cost,
			Relation: "depends_on",
		})
	}

	// Get dependents
	for _, depID := range g.infra.GetDependents(nodeID) {
		depInstID := model.InstanceID(depID)
		depCostNode := g.costs.GetNode(depInstID)
		cost := 0.0
		if depCostNode != nil {
			cost = depCostNode.TotalMonthly.Float64()
		}
		lineage.Dependents = append(lineage.Dependents, DependencyLink{
			NodeID:   depID,
			Cost:     cost,
			Relation: "required_by",
		})
	}

	return lineage
}

// CostLineage is the full lineage of a cost
type CostLineage struct {
	InstanceID      model.InstanceID
	InstanceAddress string
	ResourceType    string
	DirectCost      float64
	Dependencies    []DependencyLink
	Dependents      []DependencyLink
}

// DependencyLink is a link in the dependency chain
type DependencyLink struct {
	NodeID   string
	Cost     float64
	Relation string
}

// CalculateChangeCost calculates cost change for a set of changed nodes
func (g *DependencyAwareCostGraph) CalculateChangeCost(changedNodes []string) *ChangeCostAnalysis {
	analysis := &ChangeCostAnalysis{
		ChangedNodes:    changedNodes,
		DirectChanges:   []NodeCostChange{},
		IndirectChanges: []NodeCostChange{},
		TotalDirect:     0,
		TotalIndirect:   0,
	}

	affected := make(map[string]bool)

	// Process each changed node
	for _, nodeID := range changedNodes {
		affected[nodeID] = true

		// Get this node's cost
		instID := model.InstanceID(nodeID)
		costNode := g.costs.GetNode(instID)
		cost := 0.0
		if costNode != nil {
			cost = costNode.TotalMonthly.Float64()
		}

		analysis.DirectChanges = append(analysis.DirectChanges, NodeCostChange{
			NodeID: nodeID,
			Cost:   cost,
			Type:   "direct",
		})
		analysis.TotalDirect += cost

		// Get transitive dependents
		for _, depID := range g.infra.GetTransitiveDependents(nodeID) {
			if !affected[depID] {
				affected[depID] = true

				depInstID := model.InstanceID(depID)
				depCostNode := g.costs.GetNode(depInstID)
				depCost := 0.0
				if depCostNode != nil {
					depCost = depCostNode.TotalMonthly.Float64()
				}

				analysis.IndirectChanges = append(analysis.IndirectChanges, NodeCostChange{
					NodeID: depID,
					Cost:   depCost,
					Type:   "indirect",
				})
				analysis.TotalIndirect += depCost
			}
		}
	}

	return analysis
}

// ChangeCostAnalysis is the result of change cost calculation
type ChangeCostAnalysis struct {
	ChangedNodes    []string
	DirectChanges   []NodeCostChange
	IndirectChanges []NodeCostChange
	TotalDirect     float64
	TotalIndirect   float64
}

// NodeCostChange is a cost change for a node
type NodeCostChange struct {
	NodeID string
	Cost   float64
	Type   string
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\derived_cost.go
# TYPE: go
# SIZE: 8660 bytes
################################################################################
// Package graph - Derived cost graph
// Costs MUST be derived from the dependency graph.
// This is not optional - diffs are meaningless without it.
package graph

import (
	"terraform-cost/core/determinism"
)

// DerivedCostGraph is a cost graph that MUST be derived from a dependency graph
type DerivedCostGraph struct {
	// Source dependency graph (required)
	sourceGraph *InfrastructureGraph

	// Cost nodes indexed by address
	nodes map[string]*DerivedCostNode

	// Dependency edges (from â†’ to) with cost impact
	edges map[string][]*CostEdge

	// Symbolic costs (unknown cardinality)
	symbolicCosts map[string]*SymbolicCost
}

// DerivedCostNode is a cost node with dependency lineage
type DerivedCostNode struct {
	Address         string
	InfraNodeID     string
	DependencyDepth int

	MonthlyCost     determinism.Money
	HourlyCost      determinism.Money
	DirectCost      determinism.Money
	TransitiveCost  determinism.Money
	BlastRadiusCost determinism.Money

	DependsOn  []string
	DependedBy []string

	Confidence float64
}

// CostEdge is a cost-aware dependency edge
type CostEdge struct {
	From     string
	To       string
	CostFrom determinism.Money
	CostTo   determinism.Money
	Relation string
}

// SymbolicCost represents cost for unknown cardinality
type SymbolicCost struct {
	Address      string
	Expression   string
	MinInstances int
	MaxInstances int
	CostPerUnit  determinism.Money
	MinCost      determinism.Money
	MaxCost      determinism.Money
	IsUnbounded  bool
	Confidence   float64
	Warning      string
}

// NewDerivedCostGraph creates a cost graph from a dependency graph
// THIS IS THE ONLY WAY TO CREATE A COST GRAPH
func NewDerivedCostGraph(depGraph *InfrastructureGraph) (*DerivedCostGraph, error) {
	if depGraph == nil {
		return nil, &NoDependencyGraphError{}
	}

	g := &DerivedCostGraph{
		sourceGraph:   depGraph,
		nodes:         make(map[string]*DerivedCostNode),
		edges:         make(map[string][]*CostEdge),
		symbolicCosts: make(map[string]*SymbolicCost),
	}

	// Initialize nodes from dependency graph
	for nodeID := range depGraph.nodes {
		g.nodes[nodeID] = &DerivedCostNode{
			Address:         nodeID,
			InfraNodeID:     nodeID,
			DependencyDepth: 0, // Computed later
			DependsOn:       depGraph.GetDependencies(nodeID),
			DependedBy:      depGraph.GetDependents(nodeID),
			MonthlyCost:     determinism.Zero("USD"),
			HourlyCost:      determinism.Zero("USD"),
			DirectCost:      determinism.Zero("USD"),
			TransitiveCost:  determinism.Zero("USD"),
			BlastRadiusCost: determinism.Zero("USD"),
			Confidence:      1.0,
		}
	}

	// Create cost edges from dependency edges
	for nodeID := range g.nodes {
		for _, depID := range depGraph.GetDependencies(nodeID) {
			edge := &CostEdge{
				From:     nodeID,
				To:       depID,
				CostFrom: determinism.Zero("USD"),
				CostTo:   determinism.Zero("USD"),
				Relation: "depends_on",
			}
			g.edges[nodeID] = append(g.edges[nodeID], edge)
		}
	}

	return g, nil
}

// NoDependencyGraphError indicates cost graph was created without dependency graph
type NoDependencyGraphError struct{}

func (e *NoDependencyGraphError) Error() string {
	return "cost graph MUST be derived from dependency graph"
}

// SetNodeCost sets the cost for a node
func (g *DerivedCostGraph) SetNodeCost(address string, monthly, hourly determinism.Money, confidence float64) error {
	node, ok := g.nodes[address]
	if !ok {
		return &NodeNotInGraphError{Address: address}
	}

	node.MonthlyCost = monthly
	node.HourlyCost = hourly
	node.DirectCost = monthly
	node.Confidence = confidence

	for _, edge := range g.edges[address] {
		edge.CostFrom = monthly
	}

	return nil
}

// NodeNotInGraphError indicates a node doesn't exist
type NodeNotInGraphError struct {
	Address string
}

func (e *NodeNotInGraphError) Error() string {
	return "node " + e.Address + " not in dependency graph"
}

// AddSymbolicCost adds a symbolic cost for unknown cardinality
func (g *DerivedCostGraph) AddSymbolicCost(address string, costPerUnit determinism.Money, minInst, maxInst int, expr string) {
	minCost := costPerUnit.MulFloat(float64(minInst))

	maxCost := determinism.Zero("USD")
	isUnbounded := maxInst < 0
	if !isUnbounded {
		maxCost = costPerUnit.MulFloat(float64(maxInst))
	}

	warning := ""
	if isUnbounded {
		warning = "cardinality is unbounded"
	} else if maxInst > minInst {
		warning = "cardinality is uncertain - cost is a range"
	}

	g.symbolicCosts[address] = &SymbolicCost{
		Address:      address,
		Expression:   expr,
		MinInstances: minInst,
		MaxInstances: maxInst,
		CostPerUnit:  costPerUnit,
		MinCost:      minCost,
		MaxCost:      maxCost,
		IsUnbounded:  isUnbounded,
		Confidence:   0.3,
		Warning:      warning,
	}
}

// CalculateTransitiveCosts calculates costs through the dependency chain
func (g *DerivedCostGraph) CalculateTransitiveCosts() {
	order, err := g.sourceGraph.TopologicalSort()
	if err != nil {
		return
	}

	for i := len(order) - 1; i >= 0; i-- {
		nodeID := order[i]
		node := g.nodes[nodeID]
		if node == nil {
			continue
		}

		transitive := determinism.Zero("USD")
		for _, depByID := range node.DependedBy {
			if depBy := g.nodes[depByID]; depBy != nil {
				transitive = transitive.Add(depBy.DirectCost)
				transitive = transitive.Add(depBy.TransitiveCost)
			}
		}
		node.TransitiveCost = transitive
		node.BlastRadiusCost = node.DirectCost.Add(transitive)
	}
}

// GetChangeImpact calculates the cost impact of changing nodes
func (g *DerivedCostGraph) GetChangeImpact(changedAddresses []string) *CostChangeImpact {
	impact := &CostChangeImpact{
		DirectCost:       determinism.Zero("USD"),
		IndirectCost:     determinism.Zero("USD"),
		TotalCost:        determinism.Zero("USD"),
		AffectedNodes:    []string{},
		DependencyChains: [][]string{},
	}

	affected := make(map[string]bool)

	for _, addr := range changedAddresses {
		node := g.nodes[addr]
		if node == nil {
			continue
		}

		impact.DirectCost = impact.DirectCost.Add(node.DirectCost)
		affected[addr] = true

		dependents := g.sourceGraph.GetTransitiveDependents(addr)
		chain := []string{addr}
		for _, dep := range dependents {
			if !affected[dep] {
				affected[dep] = true
				if depNode := g.nodes[dep]; depNode != nil {
					impact.IndirectCost = impact.IndirectCost.Add(depNode.DirectCost)
				}
				chain = append(chain, dep)
			}
		}
		impact.DependencyChains = append(impact.DependencyChains, chain)
	}

	for addr := range affected {
		impact.AffectedNodes = append(impact.AffectedNodes, addr)
	}

	impact.TotalCost = impact.DirectCost.Add(impact.IndirectCost)
	return impact
}

// CostChangeImpact describes the cost impact of changes
type CostChangeImpact struct {
	DirectCost       determinism.Money
	IndirectCost     determinism.Money
	TotalCost        determinism.Money
	AffectedNodes    []string
	DependencyChains [][]string
}

// GetSymbolicCosts returns all symbolic costs
func (g *DerivedCostGraph) GetSymbolicCosts() []*SymbolicCost {
	result := make([]*SymbolicCost, 0, len(g.symbolicCosts))
	for _, sc := range g.symbolicCosts {
		result = append(result, sc)
	}
	return result
}

// HasUnboundedCosts returns true if any costs are unbounded
func (g *DerivedCostGraph) HasUnboundedCosts() bool {
	for _, sc := range g.symbolicCosts {
		if sc.IsUnbounded {
			return true
		}
	}
	return false
}

// GetTotalCostRange returns the total cost as a range
func (g *DerivedCostGraph) GetTotalCostRange() *CostBounds {
	minTotal := determinism.Zero("USD")
	maxTotal := determinism.Zero("USD")
	hasUnbounded := false

	for _, node := range g.nodes {
		minTotal = minTotal.Add(node.DirectCost)
		maxTotal = maxTotal.Add(node.DirectCost)
	}

	for _, sc := range g.symbolicCosts {
		minTotal = minTotal.Add(sc.MinCost)
		if sc.IsUnbounded {
			hasUnbounded = true
		} else {
			maxTotal = maxTotal.Add(sc.MaxCost)
		}
	}

	return &CostBounds{
		Min:         minTotal,
		Max:         maxTotal,
		IsUnbounded: hasUnbounded,
	}
}

// CostBounds represents a cost range for uncertain cardinality
type CostBounds struct {
	Min         determinism.Money
	Max         determinism.Money
	IsUnbounded bool
}

// String returns the range as a string
func (r *CostBounds) String() string {
	if r.IsUnbounded {
		return r.Min.String() + " - âˆž"
	}
	if r.Min.Cmp(r.Max) == 0 {
		return r.Min.String()
	}
	return r.Min.String() + " - " + r.Max.String()
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\enforced_asset.go
# TYPE: go
# SIZE: 4703 bytes
################################################################################
// Package graph - Enforced assets with dependency lineage
// Every Asset MUST reference a DependencyNodeID.
// This is not optional - assets without lineage cannot exist.
package graph

import (
	"fmt"
)

// EnforcedAsset is an asset that MUST have dependency lineage
type EnforcedAsset struct {
	// Identity
	AssetID string

	// REQUIRED: Link to canonical dependency graph
	DependencyNodeID DependencyNodeID

	// REQUIRED: Upstream dependencies (transitive closure)
	UpstreamDeps []DependencyNodeID

	// Asset metadata
	Address      string
	ResourceType string
	Provider     string
	Region       string

	// Expansion info
	IsExpanded   bool
	ExpandedFrom string
	InstanceKey  interface{}
}

// NewEnforcedAsset creates an asset with REQUIRED dependency linkage
// Panics if dependency graph doesn't contain the node
func NewEnforcedAsset(
	assetID string,
	depNodeID DependencyNodeID,
	graph *CanonicalDependencyGraph,
) *EnforcedAsset {
	// ASSERTION: Node MUST exist in canonical graph
	graph.ValidateNode(depNodeID)

	// Get dependency path
	upstreamDeps := graph.GetDependencyPath(depNodeID)

	return &EnforcedAsset{
		AssetID:          assetID,
		DependencyNodeID: depNodeID,
		UpstreamDeps:     upstreamDeps,
	}
}

// ValidateLineage ensures the asset has proper dependency lineage
func (a *EnforcedAsset) ValidateLineage() error {
	if a.DependencyNodeID == "" {
		return fmt.Errorf("INVARIANT VIOLATED: asset %s has no DependencyNodeID", a.AssetID)
	}
	return nil
}

// EnforcedAssetGraph is a graph of assets with enforced dependency lineage
type EnforcedAssetGraph struct {
	// Source canonical graph (REQUIRED)
	canonical *CanonicalDependencyGraph

	// Assets indexed by ID
	assets map[string]*EnforcedAsset

	// Mapping from DependencyNodeID to assets (one-to-many for expanded resources)
	nodeToAssets map[DependencyNodeID][]*EnforcedAsset
}

// NewEnforcedAssetGraph creates an asset graph from a canonical dependency graph
// The canonical graph is REQUIRED
func NewEnforcedAssetGraph(canonical *CanonicalDependencyGraph) (*EnforcedAssetGraph, error) {
	if canonical == nil {
		return nil, fmt.Errorf("INVARIANT VIOLATED: cannot create asset graph without canonical dependency graph")
	}
	if !canonical.IsSealed() {
		return nil, fmt.Errorf("INVARIANT VIOLATED: canonical graph must be sealed before creating asset graph")
	}

	return &EnforcedAssetGraph{
		canonical:    canonical,
		assets:       make(map[string]*EnforcedAsset),
		nodeToAssets: make(map[DependencyNodeID][]*EnforcedAsset),
	}, nil
}

// AddAsset adds an asset with dependency validation
func (g *EnforcedAssetGraph) AddAsset(asset *EnforcedAsset) error {
	// ASSERTION: Asset must have DependencyNodeID
	if asset.DependencyNodeID == "" {
		panic(fmt.Sprintf("INVARIANT VIOLATED: asset %s has no DependencyNodeID", asset.AssetID))
	}

	// ASSERTION: DependencyNodeID must exist in canonical graph
	g.canonical.ValidateNode(asset.DependencyNodeID)

	g.assets[asset.AssetID] = asset
	g.nodeToAssets[asset.DependencyNodeID] = append(g.nodeToAssets[asset.DependencyNodeID], asset)
	return nil
}

// GetAsset returns an asset by ID
func (g *EnforcedAssetGraph) GetAsset(assetID string) (*EnforcedAsset, bool) {
	asset, ok := g.assets[assetID]
	return asset, ok
}

// GetAssetsByNode returns all assets for a dependency node
func (g *EnforcedAssetGraph) GetAssetsByNode(nodeID DependencyNodeID) []*EnforcedAsset {
	return g.nodeToAssets[nodeID]
}

// GetAffectedAssets returns assets affected by changes to specified nodes
func (g *EnforcedAssetGraph) GetAffectedAssets(changedNodes []DependencyNodeID) []*EnforcedAsset {
	affected := make(map[string]*EnforcedAsset)

	for _, nodeID := range changedNodes {
		// Direct assets
		for _, asset := range g.nodeToAssets[nodeID] {
			affected[asset.AssetID] = asset
		}

		// Transitive dependents
		dependents := g.canonical.GetTransitiveDependents(nodeID)
		for _, depID := range dependents {
			for _, asset := range g.nodeToAssets[depID] {
				affected[asset.AssetID] = asset
			}
		}
	}

	result := make([]*EnforcedAsset, 0, len(affected))
	for _, asset := range affected {
		result = append(result, asset)
	}
	return result
}

// AllAssets returns all assets
func (g *EnforcedAssetGraph) AllAssets() []*EnforcedAsset {
	result := make([]*EnforcedAsset, 0, len(g.assets))
	for _, asset := range g.assets {
		result = append(result, asset)
	}
	return result
}

// GetCanonicalGraph returns the canonical dependency graph
func (g *EnforcedAssetGraph) GetCanonicalGraph() *CanonicalDependencyGraph {
	return g.canonical
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\enforced_cost.go
# TYPE: go
# SIZE: 6630 bytes
################################################################################
// Package graph - Enforced cost units with dependency path
// Every CostUnit MUST carry its dependency path.
// If the path cannot be constructed, estimation is blocked.
package graph

import (
	"fmt"

	"terraform-cost/core/determinism"
)

// EnforcedCostUnit represents a single unit of cost with REQUIRED dependency lineage
type EnforcedCostUnit struct {
	// Identity
	CostUnitID string
	AssetID    string

	// REQUIRED: Dependency path from root to this cost unit
	DependencyPath []DependencyNodeID

	// Cost values
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money

	// Components
	Components []*EnforcedCostComponent

	// Confidence
	Confidence float64

	// Symbolic (for unknown cardinality)
	IsSymbolic   bool
	SymbolicInfo *SymbolicInfo
}

// EnforcedCostComponent is a component of a cost unit
type EnforcedCostComponent struct {
	Name        string
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money
	Confidence  float64
}

// SymbolicInfo represents cost when cardinality is unknown
type SymbolicInfo struct {
	Reason           string
	MinCost          *determinism.Money
	MaxCost          *determinism.Money
	IsUnbounded      bool
	Expression       string
	CardinalityState CardinalityStateType
}

// CardinalityStateType indicates the cardinality knowledge state
type CardinalityStateType int

const (
	CardinalityKnown   CardinalityStateType = iota
	CardinalityUnknown
	CardinalityRange
)

// String returns the state name
func (s CardinalityStateType) String() string {
	names := []string{"known", "unknown", "range"}
	if int(s) < len(names) {
		return names[s]
	}
	return "invalid"
}

// NewEnforcedCostUnit creates a cost unit with REQUIRED dependency path
func NewEnforcedCostUnit(
	costUnitID string,
	asset *EnforcedAsset,
) *EnforcedCostUnit {
	// ASSERTION: Asset must have dependency lineage
	if err := asset.ValidateLineage(); err != nil {
		panic(err.Error())
	}

	return &EnforcedCostUnit{
		CostUnitID:     costUnitID,
		AssetID:        asset.AssetID,
		DependencyPath: asset.UpstreamDeps,
		MonthlyCost:    determinism.Zero("USD"),
		HourlyCost:     determinism.Zero("USD"),
		Components:     []*EnforcedCostComponent{},
		Confidence:     1.0,
		IsSymbolic:     false,
	}
}

// NewSymbolicCostUnit creates a cost unit for unknown cardinality
func NewSymbolicCostUnit(
	costUnitID string,
	asset *EnforcedAsset,
	reason string,
	state CardinalityStateType,
) *EnforcedCostUnit {
	if err := asset.ValidateLineage(); err != nil {
		panic(err.Error())
	}

	return &EnforcedCostUnit{
		CostUnitID:     costUnitID,
		AssetID:        asset.AssetID,
		DependencyPath: asset.UpstreamDeps,
		MonthlyCost:    determinism.Zero("USD"),
		HourlyCost:     determinism.Zero("USD"),
		Confidence:     0.0,
		IsSymbolic:     true,
		SymbolicInfo: &SymbolicInfo{
			Reason:           reason,
			IsUnbounded:      state == CardinalityUnknown,
			CardinalityState: state,
		},
	}
}

// ValidateDependencyPath ensures the cost unit has a dependency path
func (c *EnforcedCostUnit) ValidateDependencyPath() error {
	if len(c.DependencyPath) == 0 {
		return fmt.Errorf("INVARIANT VIOLATED: CostUnit %s has no dependency path", c.CostUnitID)
	}
	return nil
}

// EnforcedCostGraph is a cost graph with REQUIRED dependency lineage
type EnforcedCostGraph struct {
	assetGraph    *EnforcedAssetGraph
	costUnits     map[string]*EnforcedCostUnit
	assetToCosts  map[string][]*EnforcedCostUnit
	nodeToCosts   map[DependencyNodeID][]*EnforcedCostUnit
	symbolicCosts []*EnforcedCostUnit
}

// NewEnforcedCostGraph creates a cost graph from an asset graph
func NewEnforcedCostGraph(assetGraph *EnforcedAssetGraph) (*EnforcedCostGraph, error) {
	if assetGraph == nil {
		return nil, fmt.Errorf("INVARIANT VIOLATED: cannot create cost graph without asset graph")
	}

	return &EnforcedCostGraph{
		assetGraph:    assetGraph,
		costUnits:     make(map[string]*EnforcedCostUnit),
		assetToCosts:  make(map[string][]*EnforcedCostUnit),
		nodeToCosts:   make(map[DependencyNodeID][]*EnforcedCostUnit),
		symbolicCosts: []*EnforcedCostUnit{},
	}, nil
}

// AddCostUnit adds a cost unit with dependency validation
func (g *EnforcedCostGraph) AddCostUnit(unit *EnforcedCostUnit) error {
	if err := unit.ValidateDependencyPath(); err != nil {
		panic(err.Error())
	}

	g.costUnits[unit.CostUnitID] = unit
	g.assetToCosts[unit.AssetID] = append(g.assetToCosts[unit.AssetID], unit)

	for _, nodeID := range unit.DependencyPath {
		g.nodeToCosts[nodeID] = append(g.nodeToCosts[nodeID], unit)
	}

	if unit.IsSymbolic {
		g.symbolicCosts = append(g.symbolicCosts, unit)
	}

	return nil
}

// GetAffectedCostUnits returns cost units affected by changes to specified nodes
func (g *EnforcedCostGraph) GetAffectedCostUnits(changedNodes []DependencyNodeID) []*EnforcedCostUnit {
	affected := make(map[string]*EnforcedCostUnit)
	canonical := g.assetGraph.GetCanonicalGraph()

	for _, nodeID := range changedNodes {
		for _, unit := range g.nodeToCosts[nodeID] {
			affected[unit.CostUnitID] = unit
		}

		dependents := canonical.GetTransitiveDependents(nodeID)
		for _, depID := range dependents {
			for _, unit := range g.nodeToCosts[depID] {
				affected[unit.CostUnitID] = unit
			}
		}
	}

	result := make([]*EnforcedCostUnit, 0, len(affected))
	for _, unit := range affected {
		result = append(result, unit)
	}
	return result
}

// GetSymbolicCosts returns all symbolic costs
func (g *EnforcedCostGraph) GetSymbolicCosts() []*EnforcedCostUnit {
	return g.symbolicCosts
}

// HasSymbolicCosts returns true if there are symbolic costs
func (g *EnforcedCostGraph) HasSymbolicCosts() bool {
	return len(g.symbolicCosts) > 0
}

// AllCostUnits returns all cost units
func (g *EnforcedCostGraph) AllCostUnits() []*EnforcedCostUnit {
	result := make([]*EnforcedCostUnit, 0, len(g.costUnits))
	for _, unit := range g.costUnits {
		result = append(result, unit)
	}
	return result
}

// GetTotalCost returns total cost (excludes symbolic)
func (g *EnforcedCostGraph) GetTotalCost() determinism.Money {
	total := determinism.Zero("USD")
	for _, unit := range g.costUnits {
		if !unit.IsSymbolic {
			total = total.Add(unit.MonthlyCost)
		}
	}
	return total
}

// GetMinConfidence returns minimum confidence (pessimistic)
func (g *EnforcedCostGraph) GetMinConfidence() float64 {
	min := 1.0
	for _, unit := range g.costUnits {
		if unit.Confidence < min {
			min = unit.Confidence
		}
	}
	return min
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\epistemic_cardinality.go
# TYPE: go
# SIZE: 6198 bytes
################################################################################
// Package graph - Epistemic cardinality enforcement
// Unknown cardinality NEVER produces numeric costs.
// This is epistemic honesty, not a feature.
package graph

import (
	"fmt"

	"terraform-cost/core/determinism"
)

// ErrUnknownCardinalityStrict is returned in strict mode
var ErrUnknownCardinalityStrict = fmt.Errorf("STRICT MODE: unknown cardinality - estimation blocked")

// Cardinality represents cardinality knowledge state
type Cardinality int

const (
	CardinalityKnownValue   Cardinality = iota // Cardinality is known
	CardinalityUnknownValue                    // Cardinality is unknowable pre-apply
	CardinalityRangeValue                      // Cardinality is a range
)

// String returns name
func (c Cardinality) String() string {
	names := []string{"known", "unknown", "range"}
	if int(c) < len(names) {
		return names[c]
	}
	return "invalid"
}

// IsUnknown returns true if cardinality is unknown
func (c Cardinality) IsUnknown() bool {
	return c == CardinalityUnknownValue || c == CardinalityRangeValue
}

// GuardExpansion is the SINGLE gate for all expansion
// All expansion paths MUST call this
func GuardExpansion(cardinality Cardinality) error {
	if cardinality == CardinalityUnknownValue {
		return ErrUnknownCardinalityStrict
	}
	return nil
}

// GuardExpansionWithMode checks expansion with mode awareness
func GuardExpansionWithMode(cardinality Cardinality, strictMode bool) (bool, error) {
	if cardinality != CardinalityUnknownValue {
		return true, nil // OK to expand
	}

	if strictMode {
		return false, ErrUnknownCardinalityStrict
	}

	// Permissive: no expansion, but no error - use symbolic instead
	return false, nil
}

// SymbolicCostOutput is the ONLY valid output for unknown cardinality
type SymbolicCostOutput struct {
	AssetAddress string
	Reason       string
	Cardinality  Cardinality
	Expression   string      // The expression that is unknown
	LowerBound   *determinism.Money
	UpperBound   *determinism.Money
	IsUnbounded  bool
}

// ToJSON returns JSON-safe output
func (s *SymbolicCostOutput) ToJSON() map[string]interface{} {
	result := map[string]interface{}{
		"cost":        "unknown",
		"reason":      s.Reason,
		"cardinality": s.Cardinality.String(),
	}
	if s.Expression != "" {
		result["expression"] = s.Expression
	}
	if s.LowerBound != nil {
		result["lower_bound"] = s.LowerBound.String()
	}
	if s.UpperBound != nil {
		result["upper_bound"] = s.UpperBound.String()
	}
	if s.IsUnbounded {
		result["is_unbounded"] = true
	}
	return result
}

// ToCLI returns CLI-friendly output
func (s *SymbolicCostOutput) ToCLI() string {
	return fmt.Sprintf("UNKNOWN (%s)", s.Reason)
}

// CardinalityChecker checks cardinality for common unknown sources
type CardinalityChecker struct {
	unknownSources []string
}

// NewCardinalityChecker creates a checker
func NewCardinalityChecker() *CardinalityChecker {
	return &CardinalityChecker{
		unknownSources: []string{},
	}
}

// CheckForEach checks for_each cardinality
func (c *CardinalityChecker) CheckForEach(expression string, keys interface{}) Cardinality {
	// Unknown sources
	if isDataSourceReference(expression) {
		c.unknownSources = append(c.unknownSources, "data source: "+expression)
		return CardinalityUnknownValue
	}
	if isModuleOutputReference(expression) {
		c.unknownSources = append(c.unknownSources, "module output: "+expression)
		return CardinalityUnknownValue
	}
	if containsImpureFunction(expression) {
		c.unknownSources = append(c.unknownSources, "impure function in: "+expression)
		return CardinalityUnknownValue
	}
	if keys == nil {
		c.unknownSources = append(c.unknownSources, "nil keys: "+expression)
		return CardinalityUnknownValue
	}

	return CardinalityKnownValue
}

// CheckCount checks count cardinality
func (c *CardinalityChecker) CheckCount(expression string, count interface{}) Cardinality {
	if isDataSourceReference(expression) {
		c.unknownSources = append(c.unknownSources, "data source: "+expression)
		return CardinalityUnknownValue
	}
	if isModuleOutputReference(expression) {
		c.unknownSources = append(c.unknownSources, "module output: "+expression)
		return CardinalityUnknownValue
	}
	if count == nil {
		c.unknownSources = append(c.unknownSources, "nil count: "+expression)
		return CardinalityUnknownValue
	}

	return CardinalityKnownValue
}

// GetUnknownSources returns sources of unknown cardinality
func (c *CardinalityChecker) GetUnknownSources() []string {
	return c.unknownSources
}

func isDataSourceReference(expr string) bool {
	return len(expr) > 5 && expr[:5] == "data."
}

func isModuleOutputReference(expr string) bool {
	return len(expr) > 7 && expr[:7] == "module."
}

func containsImpureFunction(expr string) bool {
	impureFunctions := []string{"fileset", "file", "templatefile", "timestamp", "uuid"}
	for _, fn := range impureFunctions {
		if containsSubstring(expr, fn+"(") {
			return true
		}
	}
	return false
}

func containsSubstring(s, substr string) bool {
	for i := 0; i <= len(s)-len(substr); i++ {
		if s[i:i+len(substr)] == substr {
			return true
		}
	}
	return false
}

// BLOCKED: Placeholder expansion functions

// CreatePlaceholderInstances is BLOCKED - use SymbolicCostOutput instead
func CreatePlaceholderInstances(address string, count int) {
	BlockBypassAttempt("CreatePlaceholderInstances - unknown cardinality must use SymbolicCostOutput")
}

// CreateSyntheticCount is BLOCKED - unknown means unknown
func CreateSyntheticCount(address string) {
	BlockBypassAttempt("CreateSyntheticCount - unknown cardinality cannot have synthetic count")
}

// DefaultToOne is BLOCKED - defaulting to 1 is epistemically dishonest  
func DefaultToOne(address string) {
	BlockBypassAttempt("DefaultToOne - unknown cardinality cannot default to 1")
}

// DegradeConfidenceInsteadOfBlocking is BLOCKED - confidence degradation is not a substitute
func DegradeConfidenceInsteadOfBlocking(address string) {
	BlockBypassAttempt("DegradeConfidenceInsteadOfBlocking - unknown cardinality must block or use symbolic")
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\expansion_guard.go
# TYPE: go
# SIZE: 3210 bytes
################################################################################
// Package graph - Hard expansion blocking
// Unknown cardinality NEVER expands. This is non-negotiable.
package graph

import (
	"fmt"
)

// ErrUnknownCardinality is returned when expansion is blocked
var ErrUnknownCardinality = fmt.Errorf("BLOCKED: unknown cardinality - cannot expand")

// CardinalityKind indicates cardinality knowledge state
type CardinalityKind int

const (
	CardinalityKnownKind   CardinalityKind = iota
	CardinalityUnknownKind
	CardinalityRangeKind
)

// String returns the kind name
func (k CardinalityKind) String() string {
	names := []string{"known", "unknown", "range"}
	if int(k) < len(names) {
		return names[k]
	}
	return "invalid"
}

// ExpansionGuard prevents expansion of unknown cardinality
type ExpansionGuard struct {
	strictMode bool
	blocked    []BlockedExpansion
}

// BlockedExpansion records a blocked expansion
type BlockedExpansion struct {
	Address     string
	Reason      string
	Cardinality CardinalityKind
}

// NewExpansionGuard creates a guard
func NewExpansionGuard(strictMode bool) *ExpansionGuard {
	return &ExpansionGuard{
		strictMode: strictMode,
		blocked:    []BlockedExpansion{},
	}
}

// MustExpand expands if cardinality is known, blocks otherwise
// In strict mode: panics
// In permissive mode: returns error
func (g *ExpansionGuard) MustExpand(address string, cardinality CardinalityKind, count int) ([]string, error) {
	if cardinality != CardinalityKnownKind {
		blocked := BlockedExpansion{
			Address:     address,
			Reason:      fmt.Sprintf("cardinality is %s", cardinality),
			Cardinality: cardinality,
		}
		g.blocked = append(g.blocked, blocked)

		if g.strictMode {
			panic(fmt.Sprintf("STRICT MODE: cannot expand %s - %s", address, blocked.Reason))
		}
		return nil, ErrUnknownCardinality
	}

	// Known cardinality - expand
	instances := make([]string, count)
	for i := 0; i < count; i++ {
		instances[i] = fmt.Sprintf("%s[%d]", address, i)
	}
	return instances, nil
}

// MustExpandForEach expands for_each if keys are known, blocks otherwise
func (g *ExpansionGuard) MustExpandForEach(address string, cardinality CardinalityKind, keys []string) ([]string, error) {
	if cardinality != CardinalityKnownKind {
		blocked := BlockedExpansion{
			Address:     address,
			Reason:      fmt.Sprintf("for_each cardinality is %s", cardinality),
			Cardinality: cardinality,
		}
		g.blocked = append(g.blocked, blocked)

		if g.strictMode {
			panic(fmt.Sprintf("STRICT MODE: cannot expand %s - %s", address, blocked.Reason))
		}
		return nil, ErrUnknownCardinality
	}

	// Known keys - expand
	instances := make([]string, len(keys))
	for i, key := range keys {
		instances[i] = fmt.Sprintf("%s[%q]", address, key)
	}
	return instances, nil
}

// GetBlocked returns all blocked expansions
func (g *ExpansionGuard) GetBlocked() []BlockedExpansion {
	return g.blocked
}

// HasBlocked returns true if any expansions were blocked
func (g *ExpansionGuard) HasBlocked() bool {
	return len(g.blocked) > 0
}

// IsStrictMode returns whether strict mode is enabled
func (g *ExpansionGuard) IsStrictMode() bool {
	return g.strictMode
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\infrastructure.go
# TYPE: go
# SIZE: 12673 bytes
################################################################################
// Package graph - Real infrastructure dependency graph
// Resources ARE connected via actual Terraform dependencies.
// depends_on, implicit references, module outputs are ALL modeled.
package graph

import (
	"fmt"
	"sort"
	"strings"

	"terraform-cost/core/model"
)

// InfrastructureGraph is the real dependency graph modeling Terraform semantics
type InfrastructureGraph struct {
	// Nodes by address
	nodes map[string]*InfraNode

	// Edges (from â†’ to)
	edges map[string][]string

	// Reverse edges (to â†’ from) for upstream lookups
	reverseEdges map[string][]string

	// Module hierarchy
	modules map[string]*ModuleNode

	// Topologically sorted order (computed lazily)
	topoOrder []string
	topoValid bool
}

// InfraNode is a node in the infrastructure graph
type InfraNode struct {
	// Identity
	Address    string
	Type       NodeType
	ModulePath string

	// Source definition
	DefinitionID model.DefinitionID
	SourceFile   string
	SourceLine   int

	// Dependencies
	ExplicitDeps   []string // depends_on
	ImplicitDeps   []string // expression references
	ProviderDep    string   // provider binding
	ModuleOutputs  []string // if this is a module output

	// Expansion state
	IsExpanded    bool
	ExpandedFrom  string   // parent definition address
	InstanceKey   interface{}
	SiblingCount  int

	// Lineage
	Lineage *NodeLineage
}

// NodeType indicates the type of infrastructure node
type NodeType int

const (
	NodeResource   NodeType = iota // resource block
	NodeDataSource                  // data block
	NodeModule                      // module block
	NodeVariable                    // variable
	NodeLocal                       // local value
	NodeOutput                      // output
	NodeProvider                    // provider config
)

// String returns the node type name
func (t NodeType) String() string {
	switch t {
	case NodeResource:
		return "resource"
	case NodeDataSource:
		return "data"
	case NodeModule:
		return "module"
	case NodeVariable:
		return "variable"
	case NodeLocal:
		return "local"
	case NodeOutput:
		return "output"
	case NodeProvider:
		return "provider"
	default:
		return "unknown"
	}
}

// NodeLineage tracks the complete derivation of a node
type NodeLineage struct {
	// Expression references that led to this node
	ExpressionRefs []ExpressionRef

	// Module call chain
	ModuleChain []string

	// Provider inheritance chain
	ProviderChain []string

	// Count/for_each expansion path
	ExpansionPath []ExpansionStep
}

// ExpressionRef is a reference from an expression
type ExpressionRef struct {
	FromAttribute string  // e.g., "subnet_id"
	ToAddress     string  // e.g., "aws_subnet.main"
	RefType       RefType
}

// RefType indicates the type of reference
type RefType int

const (
	RefDirect     RefType = iota // Direct resource reference
	RefAttribute                  // Attribute reference (resource.attr)
	RefSplat                      // Splat reference (resource[*].attr)
	RefIndex                      // Index reference (resource[0].attr)
	RefEach                       // each.value reference
	RefCount                      // count.index reference
)

// ExpansionStep records a single expansion step
type ExpansionStep struct {
	Type  string      // "count" or "for_each"
	Key   interface{} // index or key
	From  string      // parent address
}

// ModuleNode represents a module in the hierarchy
type ModuleNode struct {
	Path       string
	Source     string
	ParentPath string
	Inputs     map[string]string // input variable â†’ source expression
	Outputs    map[string]string // output name â†’ expression
	Providers  map[string]string // provider mapping
	Children   []string          // child module paths
}

// NewInfrastructureGraph creates a new graph
func NewInfrastructureGraph() *InfrastructureGraph {
	return &InfrastructureGraph{
		nodes:        make(map[string]*InfraNode),
		edges:        make(map[string][]string),
		reverseEdges: make(map[string][]string),
		modules:      make(map[string]*ModuleNode),
		topoValid:    false,
	}
}

// AddNode adds a node to the graph
func (g *InfrastructureGraph) AddNode(node *InfraNode) {
	g.nodes[node.Address] = node
	g.topoValid = false
}

// AddEdge adds a dependency edge (from depends on to)
func (g *InfrastructureGraph) AddEdge(from, to string) {
	g.edges[from] = append(g.edges[from], to)
	g.reverseEdges[to] = append(g.reverseEdges[to], from)
	g.topoValid = false
}

// AddModule registers a module
func (g *InfrastructureGraph) AddModule(module *ModuleNode) {
	g.modules[module.Path] = module
}

// GetNode returns a node by address
func (g *InfrastructureGraph) GetNode(address string) *InfraNode {
	return g.nodes[address]
}

// GetDependencies returns direct dependencies of a node
func (g *InfrastructureGraph) GetDependencies(address string) []string {
	return g.edges[address]
}

// GetDependents returns nodes that depend on this node
func (g *InfrastructureGraph) GetDependents(address string) []string {
	return g.reverseEdges[address]
}

// GetTransitiveDependencies returns all dependencies (recursive)
func (g *InfrastructureGraph) GetTransitiveDependencies(address string) []string {
	visited := make(map[string]bool)
	result := []string{}
	g.collectDeps(address, visited, &result)
	return result
}

func (g *InfrastructureGraph) collectDeps(address string, visited map[string]bool, result *[]string) {
	for _, dep := range g.edges[address] {
		if !visited[dep] {
			visited[dep] = true
			*result = append(*result, dep)
			g.collectDeps(dep, visited, result)
		}
	}
}

// GetTransitiveDependents returns all dependents (recursive)
func (g *InfrastructureGraph) GetTransitiveDependents(address string) []string {
	visited := make(map[string]bool)
	result := []string{}
	g.collectDependents(address, visited, &result)
	return result
}

func (g *InfrastructureGraph) collectDependents(address string, visited map[string]bool, result *[]string) {
	for _, dep := range g.reverseEdges[address] {
		if !visited[dep] {
			visited[dep] = true
			*result = append(*result, dep)
			g.collectDependents(dep, visited, result)
		}
	}
}

// TopologicalSort returns nodes in dependency order
func (g *InfrastructureGraph) TopologicalSort() ([]string, error) {
	if g.topoValid {
		return g.topoOrder, nil
	}

	visited := make(map[string]bool)
	temp := make(map[string]bool)
	order := []string{}

	var visit func(n string) error
	visit = func(n string) error {
		if temp[n] {
			return &CycleError{Node: n}
		}
		if visited[n] {
			return nil
		}
		temp[n] = true
		for _, dep := range g.edges[n] {
			if err := visit(dep); err != nil {
				return err
			}
		}
		temp[n] = false
		visited[n] = true
		order = append(order, n)
		return nil
	}

	// Sort nodes for determinism
	nodes := make([]string, 0, len(g.nodes))
	for addr := range g.nodes {
		nodes = append(nodes, addr)
	}
	sort.Strings(nodes)

	for _, n := range nodes {
		if err := visit(n); err != nil {
			return nil, err
		}
	}

	// Reverse for correct order
	for i, j := 0, len(order)-1; i < j; i, j = i+1, j-1 {
		order[i], order[j] = order[j], order[i]
	}

	g.topoOrder = order
	g.topoValid = true
	return order, nil
}

// CycleError indicates a dependency cycle
type CycleError struct {
	Node string
}

func (e *CycleError) Error() string {
	return fmt.Sprintf("dependency cycle detected at %s", e.Node)
}

// GetResourcesInModule returns all resources in a module
func (g *InfrastructureGraph) GetResourcesInModule(modulePath string) []*InfraNode {
	var result []*InfraNode
	for _, node := range g.nodes {
		if node.ModulePath == modulePath && node.Type == NodeResource {
			result = append(result, node)
		}
	}
	return result
}

// Size returns the number of nodes
func (g *InfrastructureGraph) Size() int {
	return len(g.nodes)
}

// EdgeCount returns the number of edges
func (g *InfrastructureGraph) EdgeCount() int {
	count := 0
	for _, deps := range g.edges {
		count += len(deps)
	}
	return count
}

// InfraGraphBuilder builds infrastructure graphs from parsed Terraform
type InfraGraphBuilder struct {
	graph *InfrastructureGraph
}

// NewInfraGraphBuilder creates a builder
func NewInfraGraphBuilder() *InfraGraphBuilder {
	return &InfraGraphBuilder{
		graph: NewInfrastructureGraph(),
	}
}

// Build creates the graph from parsed module
func (b *InfraGraphBuilder) Build(parsed *ParsedInfra) (*InfrastructureGraph, error) {
	// Add all resources
	for _, res := range parsed.Resources {
		node := &InfraNode{
			Address:      res.Address,
			Type:         NodeResource,
			ModulePath:   res.ModulePath,
			DefinitionID: res.DefinitionID,
			SourceFile:   res.SourceFile,
			SourceLine:   res.SourceLine,
			ExplicitDeps: res.DependsOn,
			ImplicitDeps: res.ImplicitRefs,
			ProviderDep:  res.Provider,
			Lineage:      b.buildLineage(res),
		}
		b.graph.AddNode(node)
	}

	// Add data sources
	for _, data := range parsed.DataSources {
		node := &InfraNode{
			Address:      data.Address,
			Type:         NodeDataSource,
			ModulePath:   data.ModulePath,
			ImplicitDeps: data.ImplicitRefs,
		}
		b.graph.AddNode(node)
	}

	// Add modules
	for _, mod := range parsed.Modules {
		moduleNode := &ModuleNode{
			Path:       mod.Path,
			Source:     mod.Source,
			ParentPath: mod.ParentPath,
			Inputs:     mod.Inputs,
			Outputs:    mod.Outputs,
			Providers:  mod.Providers,
		}
		b.graph.AddModule(moduleNode)
	}

	// Build edges from dependencies
	for addr, node := range b.graph.nodes {
		// Explicit depends_on
		for _, dep := range node.ExplicitDeps {
			if _, exists := b.graph.nodes[dep]; exists {
				b.graph.AddEdge(addr, dep)
			}
		}
		// Implicit references
		for _, ref := range node.ImplicitDeps {
			// Normalize reference to resource address
			targetAddr := b.normalizeReference(ref)
			if _, exists := b.graph.nodes[targetAddr]; exists {
				b.graph.AddEdge(addr, targetAddr)
			}
		}
	}

	return b.graph, nil
}

func (b *InfraGraphBuilder) normalizeReference(ref string) string {
	// aws_instance.web.id â†’ aws_instance.web
	// module.vpc.aws_subnet.main[0] â†’ module.vpc.aws_subnet.main
	parts := strings.Split(ref, ".")
	if len(parts) >= 2 {
		// Check for index
		if idx := strings.Index(parts[1], "["); idx != -1 {
			parts[1] = parts[1][:idx]
		}
		return parts[0] + "." + parts[1]
	}
	return ref
}

func (b *InfraGraphBuilder) buildLineage(res *ParsedResource) *NodeLineage {
	lineage := &NodeLineage{
		ExpressionRefs: []ExpressionRef{},
		ModuleChain:    []string{},
		ExpansionPath:  []ExpansionStep{},
	}

	// Build expression refs
	for attr, refs := range res.AttributeRefs {
		for _, ref := range refs {
			lineage.ExpressionRefs = append(lineage.ExpressionRefs, ExpressionRef{
				FromAttribute: attr,
				ToAddress:     ref,
				RefType:       b.classifyRef(ref),
			})
		}
	}

	// Build module chain
	if res.ModulePath != "" {
		parts := strings.Split(res.ModulePath, ".")
		for i := range parts {
			lineage.ModuleChain = append(lineage.ModuleChain, strings.Join(parts[:i+1], "."))
		}
	}

	return lineage
}

func (b *InfraGraphBuilder) classifyRef(ref string) RefType {
	if strings.Contains(ref, "[*]") {
		return RefSplat
	}
	if strings.Contains(ref, "[") {
		return RefIndex
	}
	if strings.Contains(ref, "each.") {
		return RefEach
	}
	if strings.Contains(ref, "count.") {
		return RefCount
	}
	if strings.Count(ref, ".") > 1 {
		return RefAttribute
	}
	return RefDirect
}

// ParsedInfra is the input to the graph builder
type ParsedInfra struct {
	Resources   []*ParsedResource
	DataSources []*ParsedDataSource
	Modules     []*ParsedModule
}

// ParsedResource is a parsed resource block
type ParsedResource struct {
	Address       string
	ModulePath    string
	DefinitionID  model.DefinitionID
	SourceFile    string
	SourceLine    int
	DependsOn     []string
	ImplicitRefs  []string
	Provider      string
	AttributeRefs map[string][]string // attribute â†’ references
}

// ParsedDataSource is a parsed data block
type ParsedDataSource struct {
	Address      string
	ModulePath   string
	ImplicitRefs []string
}

// ParsedModule is a parsed module block
type ParsedModule struct {
	Path       string
	Source     string
	ParentPath string
	Inputs     map[string]string
	Outputs    map[string]string
	Providers  map[string]string
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\invariant_checker.go
# TYPE: go
# SIZE: 5379 bytes
################################################################################
// Package graph - Invariant assertions and tests
// These assertions verify correctness at boundaries.
// They intentionally try to violate rules to ensure enforcement works.
package graph

import (
	"fmt"
)

// InvariantViolation represents a detected invariant violation
type InvariantViolation struct {
	Invariant string
	Location  string
	Details   string
}

func (v *InvariantViolation) Error() string {
	return fmt.Sprintf("INVARIANT VIOLATED [%s] at %s: %s", v.Invariant, v.Location, v.Details)
}

// InvariantChecker verifies all architectural invariants
type InvariantChecker struct {
	violations []InvariantViolation
	strictMode bool
}

// NewInvariantChecker creates a checker
func NewInvariantChecker(strictMode bool) *InvariantChecker {
	return &InvariantChecker{
		violations: []InvariantViolation{},
		strictMode: strictMode,
	}
}

// AssertDepGraphClosed asserts dependency graph is closed
func (c *InvariantChecker) AssertDepGraphClosed(g *CanonicalDependencyGraph) error {
	if g == nil {
		return c.fail("DEP_GRAPH_EXISTS", "AssertDepGraphClosed", "dependency graph is nil")
	}
	if !g.IsSealed() {
		return c.fail("DEP_GRAPH_SEALED", "AssertDepGraphClosed", "dependency graph not sealed")
	}
	if !g.IsTransitivelyClosed() {
		return c.fail("DEP_GRAPH_CLOSED", "AssertDepGraphClosed", "dependency graph not transitively closed")
	}
	return nil
}

// AssertAssetHasDepNode asserts asset has a dependency node
func (c *InvariantChecker) AssertAssetHasDepNode(asset *EnforcedAsset) error {
	if asset == nil {
		return c.fail("ASSET_EXISTS", "AssertAssetHasDepNode", "asset is nil")
	}
	if asset.DependencyNodeID == "" {
		return c.fail("ASSET_HAS_DEP_NODE", "AssertAssetHasDepNode", 
			fmt.Sprintf("asset %s has no DependencyNodeID", asset.AssetID))
	}
	return nil
}

// AssertCostUnitHasPath asserts cost unit has dependency path
func (c *InvariantChecker) AssertCostUnitHasPath(unit *EnforcedCostUnit) error {
	if unit == nil {
		return c.fail("COST_UNIT_EXISTS", "AssertCostUnitHasPath", "cost unit is nil")
	}
	if len(unit.DependencyPath) == 0 {
		return c.fail("COST_UNIT_HAS_PATH", "AssertCostUnitHasPath",
			fmt.Sprintf("cost unit %s has no dependency path", unit.CostUnitID))
	}
	return nil
}

// AssertNoNumericCostForUnknown asserts unknown cardinality has no numeric cost
func (c *InvariantChecker) AssertNoNumericCostForUnknown(unit *EnforcedCostUnit) error {
	if unit == nil {
		return nil
	}
	if unit.IsSymbolic {
		// Symbolic costs must not have numeric values
		if !unit.MonthlyCost.IsZero() {
			return c.fail("NO_NUMERIC_FOR_UNKNOWN", "AssertNoNumericCostForUnknown",
				fmt.Sprintf("symbolic cost unit %s has non-zero monthly cost", unit.CostUnitID))
		}
	}
	return nil
}

// AssertCardinalityKnownForExpansion asserts cardinality is known before expansion
func (c *InvariantChecker) AssertCardinalityKnownForExpansion(address string, cardinality CardinalityKind) error {
	if cardinality != CardinalityKnownKind {
		return c.fail("CARDINALITY_KNOWN", "AssertCardinalityKnownForExpansion",
			fmt.Sprintf("cannot expand %s with %s cardinality", address, cardinality))
	}
	return nil
}

// AssertConfidencePessimistic asserts confidence is pessimistic (MIN)
func (c *InvariantChecker) AssertConfidencePessimistic(aggregate float64, components []float64) error {
	if len(components) == 0 {
		return nil
	}
	min := 1.0
	for _, v := range components {
		if v < min {
			min = v
		}
	}
	if aggregate > min {
		return c.fail("CONFIDENCE_PESSIMISTIC", "AssertConfidencePessimistic",
			fmt.Sprintf("aggregate confidence %.2f exceeds minimum component %.2f", aggregate, min))
	}
	return nil
}

func (c *InvariantChecker) fail(invariant, location, details string) error {
	v := InvariantViolation{
		Invariant: invariant,
		Location:  location,
		Details:   details,
	}
	c.violations = append(c.violations, v)
	
	if c.strictMode {
		panic(v.Error())
	}
	return &v
}

// GetViolations returns all recorded violations
func (c *InvariantChecker) GetViolations() []InvariantViolation {
	return c.violations
}

// HasViolations returns true if any violations occurred
func (c *InvariantChecker) HasViolations() bool {
	return len(c.violations) > 0
}

// RunFullCheck runs all invariant checks on a cost graph
func (c *InvariantChecker) RunFullCheck(costGraph *EnforcedCostGraph) error {
	if costGraph == nil {
		return c.fail("COST_GRAPH_EXISTS", "RunFullCheck", "cost graph is nil")
	}

	for _, unit := range costGraph.AllCostUnits() {
		if err := c.AssertCostUnitHasPath(unit); err != nil && c.strictMode {
			return err
		}
		if err := c.AssertNoNumericCostForUnknown(unit); err != nil && c.strictMode {
			return err
		}
	}

	// Check pessimistic confidence
	confidences := []float64{}
	for _, unit := range costGraph.AllCostUnits() {
		confidences = append(confidences, unit.Confidence)
	}
	aggregate := costGraph.GetMinConfidence()
	if err := c.AssertConfidencePessimistic(aggregate, confidences); err != nil && c.strictMode {
		return err
	}

	return nil
}

// BlockBypassAttempt blocks any attempt to bypass dependency semantics
func BlockBypassAttempt(description string) {
	panic(fmt.Sprintf("BYPASS BLOCKED: %s - cost logic must go through dependency graph", description))
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\invariant_test.go
# TYPE: go
# SIZE: 4371 bytes
################################################################################
// Package graph_test - Invariant violation tests
// These tests INTENTIONALLY try to violate rules to ensure enforcement works.
package graph_test

import (
	"testing"

	"terraform-cost/core/graph"
)

// TestBypassAttempts verifies that bypass attempts panic
func TestBypassAttempts(t *testing.T) {
	tests := []struct {
		name     string
		fn       func()
		expected string
	}{
		{
			name: "NewCostUnitFromAssetDirect",
			fn: func() {
				graph.NewCostUnitFromAssetDirect("test-asset")
			},
			expected: "BYPASS BLOCKED",
		},
		{
			name: "NewCostGraphWithoutDepGraph",
			fn: func() {
				graph.NewCostGraphWithoutDepGraph()
			},
			expected: "BYPASS BLOCKED",
		},
		{
			name: "ExpandWithoutCardinalityCheck",
			fn: func() {
				graph.ExpandWithoutCardinalityCheck("aws_instance.test", 5)
			},
			expected: "BYPASS BLOCKED",
		},
		{
			name: "CreateNumericCostForUnknown",
			fn: func() {
				graph.CreateNumericCostForUnknown("aws_instance.test", 100.0)
			},
			expected: "BYPASS BLOCKED",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			defer func() {
				r := recover()
				if r == nil {
					t.Errorf("%s did not panic", tt.name)
					return
				}
				msg, ok := r.(string)
				if !ok {
					t.Errorf("%s panicked with non-string: %v", tt.name, r)
					return
				}
				if len(msg) < len(tt.expected) || msg[:len(tt.expected)] != tt.expected {
					t.Errorf("%s panicked with wrong message: %s", tt.name, msg)
				}
			}()
			tt.fn()
		})
	}
}

// TestUnsealedGraphPanics verifies unsealed graph panics
func TestUnsealedGraphPanics(t *testing.T) {
	g := graph.NewCanonicalDependencyGraph()
	g.AddNode(&graph.NodeMeta{
		ID:      "test",
		Address: "aws_instance.test",
	})
	// Don't seal

	defer func() {
		r := recover()
		if r == nil {
			t.Error("MustBeClosed did not panic on unsealed graph")
		}
	}()

	g.MustBeClosed()
}

// TestExpansionGuardStrict verifies strict mode panics on unknown cardinality
func TestExpansionGuardStrict(t *testing.T) {
	guard := graph.NewExpansionGuard(true) // strict mode

	defer func() {
		r := recover()
		if r == nil {
			t.Error("MustExpand did not panic on unknown cardinality in strict mode")
		}
	}()

	_, _ = guard.MustExpand("aws_instance.test", graph.CardinalityUnknownKind, 5)
}

// TestExpansionGuardPermissive verifies permissive mode returns error
func TestExpansionGuardPermissive(t *testing.T) {
	guard := graph.NewExpansionGuard(false) // permissive mode

	instances, err := guard.MustExpand("aws_instance.test", graph.CardinalityUnknownKind, 5)
	if err == nil {
		t.Error("MustExpand should return error on unknown cardinality")
	}
	if instances != nil {
		t.Error("MustExpand should return nil instances on unknown cardinality")
	}
	if !guard.HasBlocked() {
		t.Error("MustExpand should record blocked expansion")
	}
}

// TestInvariantCheckerStrict verifies strict checker panics
func TestInvariantCheckerStrict(t *testing.T) {
	checker := graph.NewInvariantChecker(true) // strict mode

	defer func() {
		r := recover()
		if r == nil {
			t.Error("AssertAssetHasDepNode did not panic on nil asset")
		}
	}()

	_ = checker.AssertAssetHasDepNode(nil)
}

// TestInvariantCheckerPermissive verifies permissive checker records violations
func TestInvariantCheckerPermissive(t *testing.T) {
	checker := graph.NewInvariantChecker(false) // permissive mode

	// Should not panic
	err := checker.AssertAssetHasDepNode(nil)
	if err == nil {
		t.Error("AssertAssetHasDepNode should return error on nil asset")
	}

	if !checker.HasViolations() {
		t.Error("Checker should record violation")
	}
}

// TestConfidencePessimistic verifies confidence aggregation is pessimistic
func TestConfidencePessimistic(t *testing.T) {
	checker := graph.NewInvariantChecker(true)

	// Valid: aggregate equals minimum
	err := checker.AssertConfidencePessimistic(0.5, []float64{0.9, 0.7, 0.5})
	if err != nil {
		t.Errorf("Valid pessimistic confidence rejected: %v", err)
	}

	// Invalid: aggregate exceeds minimum
	defer func() {
		r := recover()
		if r == nil {
			t.Error("AssertConfidencePessimistic did not panic on optimistic aggregation")
		}
	}()

	_ = checker.AssertConfidencePessimistic(0.8, []float64{0.9, 0.7, 0.5})
}

################################################################################
# FILE: :\good projects\cost estimation\core\graph\no_placeholder.go
# TYPE: go
# SIZE: 5313 bytes
################################################################################
// Package graph - Placeholder expansion removal
// This file REMOVES all placeholder expansion.
// Unknown cardinality = symbolic cost, NEVER instances.
package graph

import (
	"fmt"

	"terraform-cost/core/determinism"
)

// ExpansionResult is the result of attempting expansion
type ExpansionResult struct {
	// Success case
	Instances []string // Only populated if cardinality is known

	// Failure case (unknown cardinality)
	IsSymbolic bool
	Symbolic   *SymbolicCostOutput

	// Blocked in strict mode
	BlockedError error
}

// StrictExpansionGate is the ONLY way to expand resources
// Placeholder expansion does not exist
type StrictExpansionGate struct {
	strictMode bool
	symbolic   []*SymbolicCostOutput
}

// NewStrictExpansionGate creates a gate
func NewStrictExpansionGate(strictMode bool) *StrictExpansionGate {
	return &StrictExpansionGate{
		strictMode: strictMode,
		symbolic:   []*SymbolicCostOutput{},
	}
}

// TryExpand attempts expansion - returns symbolic if unknown
// NEVER creates placeholder instances
func (g *StrictExpansionGate) TryExpand(address string, cardinality Cardinality, count int, keys []string) *ExpansionResult {
	result := &ExpansionResult{}

	if cardinality == CardinalityKnownValue {
		// Known cardinality - expand normally
		if len(keys) > 0 {
			// for_each
			result.Instances = make([]string, len(keys))
			for i, key := range keys {
				result.Instances[i] = fmt.Sprintf("%s[%q]", address, key)
			}
		} else if count >= 0 {
			// count
			result.Instances = make([]string, count)
			for i := 0; i < count; i++ {
				result.Instances[i] = fmt.Sprintf("%s[%d]", address, i)
			}
		} else {
			// No count/for_each - single instance
			result.Instances = []string{address}
		}
		return result
	}

	// Unknown cardinality - NEVER expand
	result.IsSymbolic = true
	result.Symbolic = &SymbolicCostOutput{
		AssetAddress: address,
		Reason:       fmt.Sprintf("cardinality is %s", cardinality),
		Cardinality:  cardinality,
		IsUnbounded:  cardinality == CardinalityUnknownValue,
	}
	g.symbolic = append(g.symbolic, result.Symbolic)

	if g.strictMode {
		result.BlockedError = fmt.Errorf("STRICT MODE: cannot expand %s - cardinality unknown", address)
	}

	return result
}

// TryExpandForEach attempts for_each expansion
func (g *StrictExpansionGate) TryExpandForEach(address string, expression string, keys interface{}) *ExpansionResult {
	// Check cardinality
	checker := NewCardinalityChecker()
	cardinality := checker.CheckForEach(expression, keys)

	if keySlice, ok := keys.([]string); ok && cardinality == CardinalityKnownValue {
		return g.TryExpand(address, cardinality, 0, keySlice)
	}

	return g.TryExpand(address, cardinality, 0, nil)
}

// TryExpandCount attempts count expansion
func (g *StrictExpansionGate) TryExpandCount(address string, expression string, count interface{}) *ExpansionResult {
	// Check cardinality
	checker := NewCardinalityChecker()
	cardinality := checker.CheckCount(expression, count)

	if countInt, ok := count.(int); ok && cardinality == CardinalityKnownValue {
		return g.TryExpand(address, cardinality, countInt, nil)
	}

	return g.TryExpand(address, CardinalityUnknownValue, 0, nil)
}

// GetSymbolicCosts returns all symbolic costs
func (g *StrictExpansionGate) GetSymbolicCosts() []*SymbolicCostOutput {
	return g.symbolic
}

// HasSymbolicCosts returns true if any expansion resulted in symbolic cost
func (g *StrictExpansionGate) HasSymbolicCosts() bool {
	return len(g.symbolic) > 0
}

// SymbolicCostBudget represents a budget for symbolic costs
type SymbolicCostBudget struct {
	Reason      string
	LowerBound  determinism.Money
	UpperBound  *determinism.Money // nil = unbounded
	Expression  string
	Cardinality Cardinality
}

// ToOutput converts to output format
func (b *SymbolicCostBudget) ToOutput() map[string]interface{} {
	result := map[string]interface{}{
		"type":        "symbolic",
		"reason":      b.Reason,
		"cardinality": b.Cardinality.String(),
	}
	if b.Expression != "" {
		result["expression"] = b.Expression
	}
	result["lower_bound"] = b.LowerBound.String()
	if b.UpperBound != nil {
		result["upper_bound"] = b.UpperBound.String()
	} else {
		result["upper_bound"] = "unbounded"
	}
	return result
}

// BLOCKED PLACEHOLDERS - These panic to prevent accidental use

// CreatePlaceholderInstance is REMOVED - use TryExpand instead
func CreatePlaceholderInstance(address string) {
	panic("REMOVED: CreatePlaceholderInstance - placeholder expansion no longer exists")
}

// ExpandWithDefaultCount is REMOVED - defaults are epistemically dishonest
func ExpandWithDefaultCount(address string, defaultCount int) {
	panic("REMOVED: ExpandWithDefaultCount - unknown cardinality must use SymbolicCost")
}

// InferCardinalityFromUsage is REMOVED - inference is not knowledge
func InferCardinalityFromUsage(address string) {
	panic("REMOVED: InferCardinalityFromUsage - cardinality must be explicitly known")
}

// RetainCardinalityFromState is REMOVED - state cardinality may have changed
func RetainCardinalityFromState(address string) {
	panic("REMOVED: RetainCardinalityFromState - state is not authoritative for pre-apply estimation")
}

################################################################################
# FILE: :\good projects\cost estimation\core\guards\invariants.go
# TYPE: go
# SIZE: 5607 bytes
################################################################################
// Package guards - Runtime assertion guards
// These assertions PANIC if violated - there is no recovery.
package guards

import (
	"fmt"

	"terraform-cost/core/graph"
	"terraform-cost/core/terraform"
)

// InvariantEnforcer enforces critical architectural invariants
type InvariantEnforcer struct {
	dependencyGraphBuilt bool
	providersFrozen      bool
	expansionComplete    bool
	costGraphBuilt       bool
	pricingComplete      bool
	depGraph            *graph.InfrastructureGraph
	finalizer           *terraform.ProviderFinalizer
}

// NewInvariantEnforcer creates an enforcer
func NewInvariantEnforcer() *InvariantEnforcer {
	return &InvariantEnforcer{}
}

// MarkDependencyGraphBuilt marks the dependency graph as built
func (e *InvariantEnforcer) MarkDependencyGraphBuilt(g *graph.InfrastructureGraph) {
	if g == nil {
		panic("INVARIANT VIOLATED: dependency graph cannot be nil")
	}
	e.depGraph = g
	e.dependencyGraphBuilt = true
}

// MarkProvidersFrozen marks providers as frozen
func (e *InvariantEnforcer) MarkProvidersFrozen(f *terraform.ProviderFinalizer) {
	if !e.dependencyGraphBuilt {
		panic("INVARIANT VIOLATED: providers cannot be frozen before dependency graph is built")
	}
	if f == nil {
		panic("INVARIANT VIOLATED: provider finalizer cannot be nil")
	}
	if !f.IsFinalized() {
		panic("INVARIANT VIOLATED: provider finalizer must be finalized before marking frozen")
	}
	e.finalizer = f
	e.providersFrozen = true
}

// MarkExpansionComplete marks expansion as complete
func (e *InvariantEnforcer) MarkExpansionComplete() {
	if !e.providersFrozen {
		panic("INVARIANT VIOLATED: expansion cannot complete before providers are frozen")
	}
	e.expansionComplete = true
}

// MarkCostGraphBuilt marks cost graph as built
func (e *InvariantEnforcer) MarkCostGraphBuilt() {
	if !e.expansionComplete {
		panic("INVARIANT VIOLATED: cost graph cannot be built before expansion is complete")
	}
	e.costGraphBuilt = true
}

// MarkPricingComplete marks pricing as complete
func (e *InvariantEnforcer) MarkPricingComplete() {
	if !e.costGraphBuilt {
		panic("INVARIANT VIOLATED: pricing cannot complete before cost graph is built")
	}
	e.pricingComplete = true
}

// AssertDependencyGraphBuilt asserts dependency graph is built
func (e *InvariantEnforcer) AssertDependencyGraphBuilt() {
	if !e.dependencyGraphBuilt {
		panic("ASSERTION FAILED: dependency graph not built")
	}
}

// AssertProvidersFrozen asserts providers are frozen
func (e *InvariantEnforcer) AssertProvidersFrozen() {
	if !e.providersFrozen {
		panic("ASSERTION FAILED: providers not frozen")
	}
}

// AssertExpansionComplete asserts expansion is complete
func (e *InvariantEnforcer) AssertExpansionComplete() {
	if !e.expansionComplete {
		panic("ASSERTION FAILED: expansion not complete")
	}
}

// AssertCostGraphBuilt asserts cost graph is built
func (e *InvariantEnforcer) AssertCostGraphBuilt() {
	if !e.costGraphBuilt {
		panic("ASSERTION FAILED: cost graph not built")
	}
}

// AssertCanPrice asserts pricing is allowed for an address
func (e *InvariantEnforcer) AssertCanPrice(address string) {
	e.AssertProvidersFrozen()
	e.AssertExpansionComplete()
	e.AssertCostGraphBuilt()
}

// AssertNodeInDependencyGraph asserts a node exists in the dependency graph
func (e *InvariantEnforcer) AssertNodeInDependencyGraph(address string) {
	e.AssertDependencyGraphBuilt()
	if e.depGraph.GetNode(address) == nil {
		panic(fmt.Sprintf("ASSERTION FAILED: node %s not in dependency graph", address))
	}
}

// GuardedExpansion ensures expansion only happens after providers are frozen
type GuardedExpansion struct {
	enforcer            *InvariantEnforcer
	cardinalityWarnings []string
}

// NewGuardedExpansion creates guarded expansion
func NewGuardedExpansion(enforcer *InvariantEnforcer) *GuardedExpansion {
	return &GuardedExpansion{
		enforcer:            enforcer,
		cardinalityWarnings: []string{},
	}
}

// ExpandResource expands a resource, respecting invariants
func (g *GuardedExpansion) ExpandResource(address string, count int, isCountKnown bool) ([]string, error) {
	g.enforcer.AssertProvidersFrozen()

	if !isCountKnown {
		g.cardinalityWarnings = append(g.cardinalityWarnings,
			fmt.Sprintf("CARDINALITY UNKNOWN: %s - not expanded", address))
		return nil, &UnknownCardinalityError{Address: address, Type: "count"}
	}

	instances := make([]string, count)
	for i := 0; i < count; i++ {
		instances[i] = fmt.Sprintf("%s[%d]", address, i)
	}
	return instances, nil
}

// ExpandForEach expands for_each, respecting invariants
func (g *GuardedExpansion) ExpandForEach(address string, keys []string, isKeysKnown bool) ([]string, error) {
	g.enforcer.AssertProvidersFrozen()

	if !isKeysKnown {
		g.cardinalityWarnings = append(g.cardinalityWarnings,
			fmt.Sprintf("CARDINALITY UNKNOWN: %s - not expanded", address))
		return nil, &UnknownCardinalityError{Address: address, Type: "for_each"}
	}

	instances := make([]string, len(keys))
	for i, key := range keys {
		instances[i] = fmt.Sprintf("%s[%q]", address, key)
	}
	return instances, nil
}

// GetWarnings returns cardinality warnings
func (g *GuardedExpansion) GetWarnings() []string {
	return g.cardinalityWarnings
}

// UnknownCardinalityError indicates expansion was blocked
type UnknownCardinalityError struct {
	Address string
	Type    string
}

func (e *UnknownCardinalityError) Error() string {
	return fmt.Sprintf("%s at %s is unknown - expansion blocked", e.Type, e.Address)
}

################################################################################
# FILE: :\good projects\cost estimation\core\input\envelope.go
# TYPE: go
# SIZE: 8741 bytes
################################################################################
// Package input - Normalized input envelope
// EVERYTHING downstream consumes this only.
// Decouples CLI, Git, API semantics from Terraform parsing.
package input

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"io/fs"
	"os"
	"path/filepath"
	"sort"
	"time"
)

// Envelope is the normalized input to the estimation engine
// All sources (CLI, Git, API) produce this format
type Envelope struct {
	// Source information
	Source SourceInfo

	// Normalized filesystem
	FileSystem *NormalizedFS

	// Context
	Workspace  string
	Variables  map[string]interface{}
	VarFiles   []string

	// Metadata
	Metadata EnvelopeMetadata
}

// SourceInfo describes where the input came from
type SourceInfo struct {
	Type      SourceType
	Path      string            // For CLI: local path
	RepoURL   string            // For Git: repository URL
	CommitSHA string            // For Git: commit hash
	Branch    string            // For Git: branch name
	PRNumber  int               // For Git: PR number if applicable
	APISource string            // For API: source identifier
	Tags      map[string]string // Additional tags
}

// SourceType indicates the source of input
type SourceType int

const (
	SourceCLI SourceType = iota // Local CLI invocation
	SourceGit                    // Git repository
	SourceAPI                    // API request
	SourceCI                     // CI/CD pipeline
)

// String returns the source type name
func (t SourceType) String() string {
	switch t {
	case SourceCLI:
		return "cli"
	case SourceGit:
		return "git"
	case SourceAPI:
		return "api"
	case SourceCI:
		return "ci"
	default:
		return "unknown"
	}
}

// NormalizedFS is a normalized representation of the filesystem
type NormalizedFS struct {
	// Root path (virtual)
	Root string

	// Files by path
	Files map[string]*NormalizedFile

	// Content hash of entire FS
	ContentHash string

	// Stats
	TotalFiles int
	TotalBytes int64
}

// NormalizedFile is a normalized file
type NormalizedFile struct {
	Path        string
	Content     []byte
	ContentHash string
	ModTime     time.Time
	Size        int64
}

// EnvelopeMetadata contains metadata about the envelope
type EnvelopeMetadata struct {
	CreatedAt   time.Time
	Version     string
	EngineID    string
	ReplayToken string // For CI reproducibility
}

// NewEnvelope creates a new envelope from a source
func NewEnvelope(source SourceInfo) *Envelope {
	return &Envelope{
		Source:    source,
		Workspace: "default",
		Variables: make(map[string]interface{}),
		VarFiles:  []string{},
		Metadata: EnvelopeMetadata{
			CreatedAt: time.Now().UTC(),
			Version:   "1.0",
		},
	}
}

// NewEnvelopeFromCLI creates an envelope from CLI input
func NewEnvelopeFromCLI(path string, workspace string, vars map[string]interface{}) (*Envelope, error) {
	env := NewEnvelope(SourceInfo{
		Type: SourceCLI,
		Path: path,
	})
	env.Workspace = workspace
	env.Variables = vars

	// Normalize filesystem
	nfs, err := NormalizeDirectory(path)
	if err != nil {
		return nil, fmt.Errorf("failed to normalize filesystem: %w", err)
	}
	env.FileSystem = nfs

	// Generate replay token
	env.Metadata.ReplayToken = generateReplayToken(env)

	return env, nil
}

// NewEnvelopeFromGit creates an envelope from Git input
func NewEnvelopeFromGit(repoURL, commitSHA, branch string) *Envelope {
	return NewEnvelope(SourceInfo{
		Type:      SourceGit,
		RepoURL:   repoURL,
		CommitSHA: commitSHA,
		Branch:    branch,
	})
}

// NormalizeDirectory creates a normalized FS from a directory
func NormalizeDirectory(root string) (*NormalizedFS, error) {
	nfs := &NormalizedFS{
		Root:  root,
		Files: make(map[string]*NormalizedFile),
	}

	err := filepath.WalkDir(root, func(path string, d fs.DirEntry, err error) error {
		if err != nil {
			return err
		}

		// Skip directories
		if d.IsDir() {
			// Skip hidden directories
			if d.Name()[0] == '.' && d.Name() != "." {
				return filepath.SkipDir
			}
			return nil
		}

		// Only include .tf and .tfvars files
		ext := filepath.Ext(path)
		if ext != ".tf" && ext != ".tfvars" {
			return nil
		}

		// Read file
		content, err := os.ReadFile(path)
		if err != nil {
			return err
		}

		// Get relative path
		relPath, err := filepath.Rel(root, path)
		if err != nil {
			return err
		}

		// Normalize path separators
		relPath = filepath.ToSlash(relPath)

		info, _ := d.Info()
		modTime := time.Time{}
		if info != nil {
			modTime = info.ModTime()
		}

		nfs.Files[relPath] = &NormalizedFile{
			Path:        relPath,
			Content:     content,
			ContentHash: hashContent(content),
			ModTime:     modTime,
			Size:        int64(len(content)),
		}

		nfs.TotalFiles++
		nfs.TotalBytes += int64(len(content))

		return nil
	})

	if err != nil {
		return nil, err
	}

	// Compute overall hash
	nfs.ContentHash = nfs.computeHash()

	return nfs, nil
}

func (nfs *NormalizedFS) computeHash() string {
	h := sha256.New()

	// Sort paths for determinism
	paths := make([]string, 0, len(nfs.Files))
	for p := range nfs.Files {
		paths = append(paths, p)
	}
	sort.Strings(paths)

	for _, p := range paths {
		h.Write([]byte(p))
		h.Write([]byte{0})
		h.Write([]byte(nfs.Files[p].ContentHash))
		h.Write([]byte{0})
	}

	return hex.EncodeToString(h.Sum(nil))
}

func hashContent(content []byte) string {
	h := sha256.Sum256(content)
	return hex.EncodeToString(h[:])
}

func generateReplayToken(env *Envelope) string {
	h := sha256.New()
	h.Write([]byte(env.Source.Type.String()))
	h.Write([]byte(env.Source.Path))
	h.Write([]byte(env.Workspace))
	if env.FileSystem != nil {
		h.Write([]byte(env.FileSystem.ContentHash))
	}
	h.Write([]byte(env.Metadata.CreatedAt.Format(time.RFC3339)))
	return hex.EncodeToString(h.Sum(nil))[:16]
}

// GetFile returns a file by path
func (nfs *NormalizedFS) GetFile(path string) *NormalizedFile {
	return nfs.Files[path]
}

// GetTerraformFiles returns all .tf files
func (nfs *NormalizedFS) GetTerraformFiles() []*NormalizedFile {
	var result []*NormalizedFile
	for path, f := range nfs.Files {
		if filepath.Ext(path) == ".tf" {
			result = append(result, f)
		}
	}
	// Sort for determinism
	sort.Slice(result, func(i, j int) bool {
		return result[i].Path < result[j].Path
	})
	return result
}

// GetVarFiles returns all .tfvars files
func (nfs *NormalizedFS) GetVarFiles() []*NormalizedFile {
	var result []*NormalizedFile
	for path, f := range nfs.Files {
		if filepath.Ext(path) == ".tfvars" {
			result = append(result, f)
		}
	}
	sort.Slice(result, func(i, j int) bool {
		return result[i].Path < result[j].Path
	})
	return result
}

// EnvelopeValidator validates an envelope
type EnvelopeValidator struct {
	errors []string
}

// NewEnvelopeValidator creates a validator
func NewEnvelopeValidator() *EnvelopeValidator {
	return &EnvelopeValidator{
		errors: []string{},
	}
}

// Validate validates an envelope
func (v *EnvelopeValidator) Validate(env *Envelope) []string {
	v.errors = []string{}

	// Must have source type
	if env.Source.Type < SourceCLI || env.Source.Type > SourceCI {
		v.errors = append(v.errors, "invalid source type")
	}

	// CLI must have path
	if env.Source.Type == SourceCLI && env.Source.Path == "" {
		v.errors = append(v.errors, "CLI source must have path")
	}

	// Git must have repo and commit
	if env.Source.Type == SourceGit {
		if env.Source.RepoURL == "" {
			v.errors = append(v.errors, "Git source must have repo URL")
		}
		if env.Source.CommitSHA == "" {
			v.errors = append(v.errors, "Git source must have commit SHA")
		}
	}

	// Must have filesystem
	if env.FileSystem == nil {
		v.errors = append(v.errors, "envelope must have normalized filesystem")
	} else if len(env.FileSystem.Files) == 0 {
		v.errors = append(v.errors, "no Terraform files found")
	}

	return v.errors
}

// IsReplayable returns true if the envelope can be replayed
func (env *Envelope) IsReplayable() bool {
	return env.Metadata.ReplayToken != "" &&
		env.FileSystem != nil &&
		env.FileSystem.ContentHash != ""
}

// GetReplayInfo returns info needed to replay this envelope
func (env *Envelope) GetReplayInfo() map[string]string {
	info := map[string]string{
		"replay_token":  env.Metadata.ReplayToken,
		"content_hash":  "",
		"source_type":   env.Source.Type.String(),
		"workspace":     env.Workspace,
		"created_at":    env.Metadata.CreatedAt.Format(time.RFC3339),
	}
	if env.FileSystem != nil {
		info["content_hash"] = env.FileSystem.ContentHash
	}
	return info
}

################################################################################
# FILE: :\good projects\cost estimation\core\mapper\helpers.go
# TYPE: go
# SIZE: 1380 bytes
################################################################################
// Package mapper - Helper functions for building usage and cost units
package mapper

// NewUsageVector creates a concrete usage vector
func NewUsageVector(metric string, value float64, confidence float64) UsageVector {
	return UsageVector{
		Metric:     metric,
		Value:      &value,
		Confidence: confidence,
	}
}

// SymbolicUsage creates a symbolic usage vector
func SymbolicUsage(metric string, reason string) UsageVector {
	return UsageVector{
		Metric:         metric,
		IsSymbolic:     true,
		SymbolicReason: reason,
		Confidence:     0,
	}
}

// NewCostUnit creates a concrete cost unit
func NewCostUnit(name, measure string, quantity float64, rateKey RateKey, confidence float64) CostUnit {
	return CostUnit{
		Name:       name,
		Measure:    measure,
		Quantity:   &quantity,
		RateKey:    rateKey,
		Confidence: confidence,
	}
}

// SymbolicCost creates a symbolic cost unit
func SymbolicCost(name, reason string) CostUnit {
	return CostUnit{
		Name:           name,
		IsSymbolic:     true,
		SymbolicReason: reason,
		Confidence:     0,
	}
}

// Common metrics
const (
	MetricMonthlyHours    = "monthly_hours"
	MetricMonthlyRequests = "monthly_requests"
	MetricStorageGB       = "storage_gb"
	MetricDataTransferGB  = "data_transfer_gb"
	MetricIOPS            = "iops"
	MetricThroughputMBps  = "throughput_mbps"
)

################################################################################
# FILE: :\good projects\cost estimation\core\mapper\interface.go
# TYPE: go
# SIZE: 4132 bytes
################################################################################
// Package mapper - Mapper interface definition
// All cloud mappers must implement this interface.
package mapper

// AssetNode represents a Terraform resource in the asset graph
type AssetNode struct {
	// Address is the Terraform address (e.g., "aws_instance.web")
	Address string

	// Type is the resource type (e.g., "aws_instance")
	Type string

	// Attributes are the resolved Terraform attributes
	Attributes map[string]interface{}

	// ProviderContext contains provider-level information
	ProviderContext ProviderContext

	// Cardinality indicates whether the instance count is known
	Cardinality Cardinality

	// InstanceKey for expanded resources (count/for_each)
	InstanceKey string
}

// Attr returns an attribute value as string
func (a AssetNode) Attr(key string) string {
	if v, ok := a.Attributes[key].(string); ok {
		return v
	}
	return ""
}

// AttrFloat returns an attribute value as float64
func (a AssetNode) AttrFloat(key string, defaultVal float64) float64 {
	if v, ok := a.Attributes[key].(float64); ok {
		return v
	}
	if v, ok := a.Attributes[key].(int); ok {
		return float64(v)
	}
	return defaultVal
}

// AttrInt returns an attribute value as int
func (a AssetNode) AttrInt(key string, defaultVal int) int {
	if v, ok := a.Attributes[key].(int); ok {
		return v
	}
	if v, ok := a.Attributes[key].(float64); ok {
		return int(v)
	}
	return defaultVal
}

// AttrBool returns an attribute value as bool
func (a AssetNode) AttrBool(key string, defaultVal bool) bool {
	if v, ok := a.Attributes[key].(bool); ok {
		return v
	}
	return defaultVal
}

// ProviderContext contains provider-level information
type ProviderContext struct {
	ProviderID string
	Alias      string
	Region     string
	AccountID  string
}

// Cardinality represents whether instance count is known
type Cardinality struct {
	IsKnown bool
	Count   int
	Reason  string
}

// IsUnknown returns true if cardinality is not deterministic
func (c Cardinality) IsUnknown() bool {
	return !c.IsKnown
}

// UsageContext provides context for usage resolution
type UsageContext struct {
	Profile    string
	Overrides  map[string]interface{}
	Confidence float64
}

// ResolveOrDefault returns an override value or default
func (ctx UsageContext) ResolveOrDefault(key string, defaultVal float64) float64 {
	if v, ok := ctx.Overrides[key].(float64); ok {
		return v
	}
	return defaultVal
}

// UsageVector represents a usage measurement
type UsageVector struct {
	Metric         string
	Value          *float64
	IsSymbolic     bool
	SymbolicReason string
	Confidence     float64
}

// UsageVectors is a collection of usage vectors
type UsageVectors []UsageVector

// IsSymbolic returns true if any usage is symbolic
func (vs UsageVectors) IsSymbolic() bool {
	for _, v := range vs {
		if v.IsSymbolic {
			return true
		}
	}
	return false
}

// Get returns the value for a metric
func (vs UsageVectors) Get(metric string) (float64, bool) {
	for _, v := range vs {
		if v.Metric == metric && v.Value != nil {
			return *v.Value, true
		}
	}
	return 0, false
}

// CostUnit represents a billable cost component
type CostUnit struct {
	Name           string
	Measure        string
	Quantity       *float64
	RateKey        RateKey
	IsSymbolic     bool
	SymbolicReason string
	Confidence     float64
}

// RateKey identifies a pricing rate
type RateKey struct {
	Provider   string
	Service    string
	Region     string
	Attributes map[string]string
}

// AssetCostMapper is the interface all cloud resource mappers must implement
type AssetCostMapper interface {
	// Metadata returns the mapper's metadata contract
	Metadata() MapperMetadata

	// BuildUsage extracts usage from an asset
	// Returns symbolic usage if cardinality is unknown
	BuildUsage(asset AssetNode, ctx UsageContext) (UsageVectors, error)

	// BuildCostUnits creates cost units from asset and usage
	// Returns symbolic cost if usage is symbolic
	BuildCostUnits(asset AssetNode, usage UsageVectors) ([]CostUnit, error)
}

################################################################################
# FILE: :\good projects\cost estimation\core\mapper\metadata.go
# TYPE: go
# SIZE: 5842 bytes
################################################################################
// Package mapper - Mapper metadata governance
// Enforces explicit contracts, metadata, and safety guarantees.
// Prevents mapper chaos as the system scales to 50â€“250+ mappers.
package mapper

import (
	"fmt"
)

// CoverageTier classifies mappers by cost coverage capability
type CoverageTier int

const (
	// Tier1Numeric - Must produce numeric cost (EC2, RDS, etc.)
	Tier1Numeric CoverageTier = iota

	// Tier2Symbolic - Numeric only with usage data, otherwise symbolic
	Tier2Symbolic

	// Tier3Indirect - Never numeric, zero-cost graph node (VPC, IAM)
	Tier3Indirect
)

// String returns the string representation
func (t CoverageTier) String() string {
	switch t {
	case Tier1Numeric:
		return "tier1_numeric"
	case Tier2Symbolic:
		return "tier2_symbolic"
	case Tier3Indirect:
		return "tier3_indirect"
	default:
		return "unknown"
	}
}

// CostBehaviorType defines how a resource affects cost
type CostBehaviorType int

const (
	// CostDirect - Always billable (EC2, RDS, etc.)
	CostDirect CostBehaviorType = iota

	// CostUsageBased - Billable with usage data (Lambda, S3 requests)
	CostUsageBased

	// CostIndirect - Enables costs elsewhere but has no direct cost (VPC, IAM)
	CostIndirect

	// CostUnsupported - Not yet modeled, cost unknown
	CostUnsupported
)

// String returns the string representation
func (c CostBehaviorType) String() string {
	switch c {
	case CostDirect:
		return "direct"
	case CostUsageBased:
		return "usage_based"
	case CostIndirect:
		return "indirect"
	case CostUnsupported:
		return "unsupported"
	default:
		return "unknown"
	}
}

// CloudProvider identifies a cloud provider
type CloudProvider string

const (
	AWS   CloudProvider = "aws"
	Azure CloudProvider = "azure"
	GCP   CloudProvider = "gcp"
)

// MapperMetadata defines the contract for a mapper
// Every field is required - no defaults, no optionals
type MapperMetadata struct {
	// ResourceType is the Terraform resource type (e.g., "aws_instance")
	ResourceType string

	// Cloud is the cloud provider
	Cloud CloudProvider

	// Tier classifies the mapper's coverage capability
	Tier CoverageTier

	// CostBehavior classifies cost impact
	CostBehavior CostBehaviorType

	// RequiresUsage indicates if usage data is needed for numeric cost
	RequiresUsage bool

	// CanBeSymbolic indicates if this mapper can produce symbolic costs
	// Tier1 mappers: should be false (but can be true if cardinality is unknown)
	// Tier2 mappers: must be true
	// Tier3 mappers: always true (they're always symbolic)
	CanBeSymbolic bool

	// ConfidenceCeiling is the maximum confidence this mapper can produce (0.0-1.0)
	ConfidenceCeiling float64

	// HighImpact indicates if this resource is a significant cost driver
	HighImpact bool

	// Category is the service category (compute, storage, database, etc.)
	Category string

	// CostComponents lists the cost components this mapper produces
	CostComponents []string

	// Notes provides additional context
	Notes string
}

// Validate checks that metadata is complete and consistent
// Returns an error describing all validation failures
func (m MapperMetadata) Validate() error {
	// Required fields - FAIL FAST
	if m.ResourceType == "" {
		return fmt.Errorf("mapper missing resource type")
	}

	if m.Cloud == "" {
		return fmt.Errorf("mapper %s missing cloud provider", m.ResourceType)
	}

	if m.Category == "" {
		return fmt.Errorf("mapper %s missing category", m.ResourceType)
	}

	// Confidence ceiling validation
	if m.ConfidenceCeiling <= 0 || m.ConfidenceCeiling > 1.0 {
		return fmt.Errorf("mapper %s has invalid confidence ceiling: %f (must be 0.0-1.0)",
			m.ResourceType, m.ConfidenceCeiling)
	}

	// TIER-BASED INVARIANTS (NON-NEGOTIABLE)

	// Tier1 rules: must produce numeric costs
	if m.Tier == Tier1Numeric {
		// Tier1 can be symbolic ONLY due to unknown cardinality
		// But should not be marked as CanBeSymbolic by default
		if m.CostBehavior == CostIndirect {
			return fmt.Errorf("mapper %s: Tier1 cannot have CostIndirect behavior", m.ResourceType)
		}
	}

	// Tier2 rules: symbolic by default, numeric with usage
	if m.Tier == Tier2Symbolic {
		if !m.CanBeSymbolic {
			return fmt.Errorf("mapper %s: Tier2 must have CanBeSymbolic=true", m.ResourceType)
		}
	}

	// Tier3 rules: NEVER numeric
	if m.Tier == Tier3Indirect {
		if m.CostBehavior != CostIndirect {
			return fmt.Errorf("mapper %s: Tier3 must have CostIndirect behavior", m.ResourceType)
		}
		if !m.CanBeSymbolic {
			return fmt.Errorf("mapper %s: Tier3 must have CanBeSymbolic=true", m.ResourceType)
		}
	}

	// Usage-based consistency
	if m.CostBehavior == CostUsageBased && !m.RequiresUsage {
		return fmt.Errorf("mapper %s is usage-based but RequiresUsage is false", m.ResourceType)
	}

	return nil
}

// IsNumeric returns true if this mapper produces numeric costs
func (m MapperMetadata) IsNumeric() bool {
	return m.Tier == Tier1Numeric && !m.CanBeSymbolic
}

// CanProduceNumeric returns true if this mapper CAN produce numeric costs
func (m MapperMetadata) CanProduceNumeric() bool {
	return m.Tier == Tier1Numeric || (m.Tier == Tier2Symbolic && m.RequiresUsage)
}

// MustValidate panics if metadata is invalid
// Call this at mapper registration time to fail fast
func (m MapperMetadata) MustValidate() {
	if err := m.Validate(); err != nil {
		panic(fmt.Sprintf("FATAL: invalid mapper metadata: %v", err))
	}
}

// TierFromCatalog creates metadata tier from catalog tier
func TierFromCatalog(tier int) CoverageTier {
	switch tier {
	case 0:
		return Tier1Numeric
	case 1:
		return Tier2Symbolic
	case 2:
		return Tier3Indirect
	default:
		return Tier2Symbolic // Default to symbolic for safety
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\mapper\registry.go
# TYPE: go
# SIZE: 5056 bytes
################################################################################
// Package mapper - Mapper registry with validation
// Enforces metadata validation at registration time.
// Fails fast if any mapper is invalid.
package mapper

import (
	"fmt"
	"sync"
)

// Registry holds all registered mappers with validation
type Registry struct {
	mu       sync.RWMutex
	mappers  map[string]AssetCostMapper
	metadata map[string]MapperMetadata
}

// NewRegistry creates a new validated mapper registry
func NewRegistry() *Registry {
	return &Registry{
		mappers:  make(map[string]AssetCostMapper),
		metadata: make(map[string]MapperMetadata),
	}
}

// Register adds a mapper to the registry with validation
// Panics if metadata is invalid (fail fast)
func (r *Registry) Register(mapper AssetCostMapper) {
	md := mapper.Metadata()

	// Validate metadata - panic on failure
	md.MustValidate()

	r.mu.Lock()
	defer r.mu.Unlock()

	key := string(md.Cloud) + ":" + md.ResourceType
	if _, exists := r.mappers[key]; exists {
		panic(fmt.Sprintf("mapper already registered: %s", key))
	}

	r.mappers[key] = mapper
	r.metadata[key] = md
}

// RegisterSafe adds a mapper returning error instead of panic
func (r *Registry) RegisterSafe(mapper AssetCostMapper) error {
	md := mapper.Metadata()

	if err := md.Validate(); err != nil {
		return err
	}

	r.mu.Lock()
	defer r.mu.Unlock()

	key := string(md.Cloud) + ":" + md.ResourceType
	if _, exists := r.mappers[key]; exists {
		return fmt.Errorf("mapper already registered: %s", key)
	}

	r.mappers[key] = mapper
	r.metadata[key] = md
	return nil
}

// Get returns a mapper by cloud and resource type
func (r *Registry) Get(cloud CloudProvider, resourceType string) (AssetCostMapper, bool) {
	r.mu.RLock()
	defer r.mu.RUnlock()

	key := string(cloud) + ":" + resourceType
	mapper, ok := r.mappers[key]
	return mapper, ok
}

// GetMetadata returns metadata by cloud and resource type
func (r *Registry) GetMetadata(cloud CloudProvider, resourceType string) (MapperMetadata, bool) {
	r.mu.RLock()
	defer r.mu.RUnlock()

	key := string(cloud) + ":" + resourceType
	md, ok := r.metadata[key]
	return md, ok
}

// ListByCloud returns all mappers for a cloud
func (r *Registry) ListByCloud(cloud CloudProvider) []MapperMetadata {
	r.mu.RLock()
	defer r.mu.RUnlock()

	var result []MapperMetadata
	for _, md := range r.metadata {
		if md.Cloud == cloud {
			result = append(result, md)
		}
	}
	return result
}

// ListByCategory returns all mappers in a category
func (r *Registry) ListByCategory(category string) []MapperMetadata {
	r.mu.RLock()
	defer r.mu.RUnlock()

	var result []MapperMetadata
	for _, md := range r.metadata {
		if md.Category == category {
			result = append(result, md)
		}
	}
	return result
}

// ListHighImpact returns all high-impact mappers
func (r *Registry) ListHighImpact() []MapperMetadata {
	r.mu.RLock()
	defer r.mu.RUnlock()

	var result []MapperMetadata
	for _, md := range r.metadata {
		if md.HighImpact {
			result = append(result, md)
		}
	}
	return result
}

// ListByTier returns all mappers in a coverage tier
func (r *Registry) ListByTier(tier CoverageTier) []MapperMetadata {
	r.mu.RLock()
	defer r.mu.RUnlock()

	var result []MapperMetadata
	for _, md := range r.metadata {
		if md.Tier == tier {
			result = append(result, md)
		}
	}
	return result
}

// Stats returns registry statistics
func (r *Registry) Stats() RegistryStats {
	r.mu.RLock()
	defer r.mu.RUnlock()

	stats := RegistryStats{
		ByCloud:    make(map[CloudProvider]int),
		ByCategory: make(map[string]int),
		ByBehavior: make(map[CostBehaviorType]int),
		ByTier:     make(map[CoverageTier]int),
	}

	for _, md := range r.metadata {
		stats.Total++
		stats.ByCloud[md.Cloud]++
		stats.ByCategory[md.Category]++
		stats.ByBehavior[md.CostBehavior]++
		stats.ByTier[md.Tier]++

		if md.HighImpact {
			stats.HighImpact++
		}
		if md.RequiresUsage {
			stats.RequiresUsage++
		}
	}

	return stats
}

// RegistryStats holds registry statistics
type RegistryStats struct {
	Total         int
	HighImpact    int
	RequiresUsage int
	ByCloud       map[CloudProvider]int
	ByCategory    map[string]int
	ByBehavior    map[CostBehaviorType]int
	ByTier        map[CoverageTier]int
}

// ValidateAllMappers validates all registered mappers
func (r *Registry) ValidateAllMappers() []error {
	r.mu.RLock()
	defer r.mu.RUnlock()

	var errors []error
	for key, md := range r.metadata {
		if err := md.Validate(); err != nil {
			errors = append(errors, fmt.Errorf("%s: %w", key, err))
		}
	}
	return errors
}

// GlobalRegistry is the default global registry
var GlobalRegistry = NewRegistry()

// Register registers a mapper in the global registry
func Register(mapper AssetCostMapper) {
	GlobalRegistry.Register(mapper)
}

// Get gets a mapper from the global registry
func Get(cloud CloudProvider, resourceType string) (AssetCostMapper, bool) {
	return GlobalRegistry.Get(cloud, resourceType)
}

################################################################################
# FILE: :\good projects\cost estimation\core\model\definition.go
# TYPE: go
# SIZE: 11788 bytes
################################################################################
// Package model provides the core domain model with strict separation
// between definitions (static) and instances (expanded).
package model

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"sort"
	"time"
)

// DefinitionID uniquely identifies an asset definition (hash-based, stable)
type DefinitionID string

// InstanceID uniquely identifies an expanded instance
type InstanceID string

// InstanceAddress is the full Terraform address with index
// Examples: "aws_instance.web[0]", "module.app.aws_s3_bucket.data[\"logs\"]"
type InstanceAddress string

// DefinitionAddress is the address without index
// Examples: "aws_instance.web", "module.app.aws_s3_bucket.data"
type DefinitionAddress string

// ProviderKey identifies a provider configuration
// Examples: "aws", "aws.west", "google.europe"
type ProviderKey string

// ResourceType is the Terraform resource type
// Examples: "aws_instance", "google_compute_instance"
type ResourceType string

// InstanceKey represents the index for count/for_each
type InstanceKey struct {
	Type     KeyType
	IntValue int
	StrValue string
}

// KeyType indicates how an instance was indexed
type KeyType int

const (
	KeyTypeNone   KeyType = iota // No expansion (single instance)
	KeyTypeInt                   // count expansion: [0], [1], ...
	KeyTypeString                // for_each expansion: ["key"], ...
)

// String returns the key as an address suffix
func (k InstanceKey) String() string {
	switch k.Type {
	case KeyTypeInt:
		return fmt.Sprintf("[%d]", k.IntValue)
	case KeyTypeString:
		return fmt.Sprintf("[%q]", k.StrValue)
	default:
		return ""
	}
}

// SourceLocation tracks where in the source files something was defined
type SourceLocation struct {
	File      string
	StartLine int
	EndLine   int
	Module    string // Module path, empty for root
}

// Expression represents an unevaluated HCL expression
type Expression struct {
	Raw         string   // Original HCL text
	References  []string // Extracted references
	IsLiteral   bool     // True if no references
	LiteralVal  any      // Value if literal
}

// IsStatic returns true if the expression has no dependencies
func (e Expression) IsStatic() bool {
	return e.IsLiteral || len(e.References) == 0
}

// DynamicBlock represents a Terraform dynamic block
type DynamicBlock struct {
	Name      string     // Block type being generated
	ForEach   Expression // Iterator expression
	Iterator  string     // Iterator variable name (default: Name)
	Content   map[string]Expression
	Labels    []Expression
}

// LifecycleConfig holds lifecycle meta-argument values
type LifecycleConfig struct {
	CreateBeforeDestroy bool
	PreventDestroy      bool
	IgnoreChanges       []string
	ReplaceTriggeredBy  []string
}

// AssetDefinition is the STATIC Terraform resource/data block.
// This is what's written in .tf files, before any expansion.
type AssetDefinition struct {
	// Identity
	ID       DefinitionID      // Hash of address + provider + source location
	Address  DefinitionAddress // aws_instance.web
	Provider ProviderKey       // aws, aws.west
	Type     ResourceType      // aws_instance
	Name     string            // web
	Mode     ResourceMode      // managed, data

	// Meta-arguments (unevaluated)
	Count     *Expression   // count meta-argument
	ForEach   *Expression   // for_each meta-argument
	DependsOn []string      // Explicit dependencies
	Lifecycle LifecycleConfig

	// Attributes (may contain expressions)
	Attributes map[string]Expression

	// Dynamic blocks (must be expanded)
	DynamicBlocks []DynamicBlock

	// Provisioners (for cost implications like null_resource)
	Provisioners []Provisioner

	// Source tracking
	Location SourceLocation
}

// ResourceMode indicates managed resource vs data source
type ResourceMode int

const (
	ModeManaged ResourceMode = iota
	ModeData
)

// Provisioner represents a provisioner block
type Provisioner struct {
	Type       string // local-exec, remote-exec, file
	When       string // create, destroy
	OnFailure  string // continue, fail
	Attributes map[string]Expression
}

// ComputeID generates a stable ID for the definition
func (d *AssetDefinition) ComputeID() DefinitionID {
	h := sha256.New()
	h.Write([]byte(d.Address))
	h.Write([]byte(d.Provider))
	h.Write([]byte(fmt.Sprintf("%s:%d", d.Location.File, d.Location.StartLine)))
	return DefinitionID(hex.EncodeToString(h.Sum(nil))[:16])
}

// HasExpansion returns true if count or for_each is set
func (d *AssetDefinition) HasExpansion() bool {
	return d.Count != nil || d.ForEach != nil
}

// ResolvedAttribute is a fully evaluated attribute value
type ResolvedAttribute struct {
	Value     any           // Concrete value
	IsUnknown bool          // True if value couldn't be determined
	Reason    UnknownReason // Why it's unknown
	Sensitive bool          // Marked as sensitive
}

// UnknownReason explains why a value couldn't be determined
type UnknownReason int

const (
	ReasonKnown             UnknownReason = iota // Value is known
	ReasonComputedAtApply                        // Depends on infrastructure state
	ReasonDataSourcePending                      // Data source not yet evaluated
	ReasonCyclicReference                        // Circular dependency
	ReasonMissingVariable                        // Variable not provided
	ReasonExpressionError                        // Evaluation failed
)

// ResolvedProvider is a fully resolved provider configuration
type ResolvedProvider struct {
	Type       string            // aws, google, azurerm
	Alias      string            // Optional alias
	Region     string            // Resolved region
	Attributes map[string]any    // Other provider config
}

// AssetInstance is a CONCRETE, EXPANDED instance.
// This is what we actually cost - after count/for_each expansion.
type AssetInstance struct {
	// Identity
	ID           InstanceID        // Globally unique, hash-based
	DefinitionID DefinitionID      // Links back to definition
	Address      InstanceAddress   // aws_instance.web[0]

	// Instance-specific
	Key          InstanceKey       // The expansion key (0, "prod", etc.)

	// Fully resolved values (no expressions)
	Attributes   map[string]ResolvedAttribute

	// Provider after alias resolution
	Provider     ResolvedProvider

	// Dependencies after resolution (instance-level)
	Dependencies []InstanceID

	// Derived from dynamic blocks
	DynamicData  map[string][]map[string]ResolvedAttribute

	// Metadata
	Metadata     InstanceMetadata
}

// InstanceMetadata contains instance-level metadata
type InstanceMetadata struct {
	CreatedAt     time.Time
	Source        InstanceSource
	IsPlaceholder bool   // True if created for unknown expansion
	Warning       string // Any warning during expansion
}

// InstanceSource tracks how the instance was created
type InstanceSource int

const (
	SourceHCL         InstanceSource = iota // From .tf files
	SourcePlanJSON                          // From terraform plan JSON
	SourceState                             // From terraform state
	SourcePlaceholder                       // Synthetic for unknown count
)

// ComputeID generates a stable ID for the instance
func (i *AssetInstance) ComputeID() InstanceID {
	h := sha256.New()
	h.Write([]byte(i.DefinitionID))
	h.Write([]byte(i.Key.String()))
	return InstanceID(hex.EncodeToString(h.Sum(nil))[:16])
}

// GetAttribute returns an attribute value, handling unknowns
func (i *AssetInstance) GetAttribute(name string) (any, bool, UnknownReason) {
	attr, ok := i.Attributes[name]
	if !ok {
		return nil, false, ReasonKnown
	}
	return attr.Value, !attr.IsUnknown, attr.Reason
}

// InstanceEdge represents a dependency between instances
type InstanceEdge struct {
	From   InstanceID
	To     InstanceID
	Type   EdgeType
}

// EdgeType indicates the type of dependency
type EdgeType int

const (
	EdgeExplicit  EdgeType = iota // depends_on
	EdgeImplicit                  // Reference-based
	EdgeProvider                  // Provider dependency
)

// InstanceGraph is a DAG of AssetInstances.
// All operations happen on instances, NOT definitions.
type InstanceGraph struct {
	// Core data (use sorted access only)
	instances map[InstanceID]*AssetInstance
	edges     []InstanceEdge

	// Indexes (maintained automatically)
	byAddress    map[InstanceAddress]*AssetInstance
	byDefinition map[DefinitionID][]*AssetInstance

	// Computed on demand
	topologicalOrder []InstanceID
	orderValid       bool
}

// NewInstanceGraph creates an empty instance graph
func NewInstanceGraph() *InstanceGraph {
	return &InstanceGraph{
		instances:    make(map[InstanceID]*AssetInstance),
		byAddress:    make(map[InstanceAddress]*AssetInstance),
		byDefinition: make(map[DefinitionID][]*AssetInstance),
	}
}

// AddInstance adds an instance to the graph
func (g *InstanceGraph) AddInstance(inst *AssetInstance) {
	g.instances[inst.ID] = inst
	g.byAddress[inst.Address] = inst
	g.byDefinition[inst.DefinitionID] = append(g.byDefinition[inst.DefinitionID], inst)
	g.orderValid = false
}

// AddEdge adds a dependency edge
func (g *InstanceGraph) AddEdge(from, to InstanceID, edgeType EdgeType) {
	g.edges = append(g.edges, InstanceEdge{From: from, To: to, Type: edgeType})
	g.orderValid = false
}

// Instances returns all instances in stable, sorted order
func (g *InstanceGraph) Instances() []*AssetInstance {
	ids := make([]InstanceID, 0, len(g.instances))
	for id := range g.instances {
		ids = append(ids, id)
	}
	sort.Slice(ids, func(i, j int) bool {
		return ids[i] < ids[j]
	})

	result := make([]*AssetInstance, len(ids))
	for i, id := range ids {
		result[i] = g.instances[id]
	}
	return result
}

// ByAddress looks up an instance by its full address
func (g *InstanceGraph) ByAddress(addr InstanceAddress) (*AssetInstance, bool) {
	inst, ok := g.byAddress[addr]
	return inst, ok
}

// ByDefinition returns all instances expanded from a definition
func (g *InstanceGraph) ByDefinition(defID DefinitionID) []*AssetInstance {
	instances := g.byDefinition[defID]
	// Return sorted copy
	sorted := make([]*AssetInstance, len(instances))
	copy(sorted, instances)
	sort.Slice(sorted, func(i, j int) bool {
		return sorted[i].Address < sorted[j].Address
	})
	return sorted
}

// TopologicalOrder returns instances in dependency order
func (g *InstanceGraph) TopologicalOrder() []InstanceID {
	if g.orderValid {
		return g.topologicalOrder
	}

	// Kahn's algorithm for topological sort
	inDegree := make(map[InstanceID]int)
	for id := range g.instances {
		inDegree[id] = 0
	}
	for _, edge := range g.edges {
		inDegree[edge.To]++
	}

	// Find all nodes with no incoming edges
	queue := make([]InstanceID, 0)
	for id, degree := range inDegree {
		if degree == 0 {
			queue = append(queue, id)
		}
	}
	sort.Slice(queue, func(i, j int) bool { return queue[i] < queue[j] })

	result := make([]InstanceID, 0, len(g.instances))
	for len(queue) > 0 {
		// Pop (stable: always take first)
		node := queue[0]
		queue = queue[1:]
		result = append(result, node)

		// Reduce in-degree for neighbors
		for _, edge := range g.edges {
			if edge.From == node {
				inDegree[edge.To]--
				if inDegree[edge.To] == 0 {
					queue = append(queue, edge.To)
					sort.Slice(queue, func(i, j int) bool { return queue[i] < queue[j] })
				}
			}
		}
	}

	g.topologicalOrder = result
	g.orderValid = true
	return result
}

// Size returns the number of instances
func (g *InstanceGraph) Size() int {
	return len(g.instances)
}

################################################################################
# FILE: :\good projects\cost estimation\core\model\enforced_identity.go
# TYPE: go
# SIZE: 8026 bytes
################################################################################
// Package model - Enforced canonical identity
// A single canonical format used EVERYWHERE.
package model

import (
	"errors"
	"fmt"
	"regexp"
	"strconv"
	"strings"
)

// ErrInvalidAddress is returned when an address cannot be parsed
var ErrInvalidAddress = errors.New("invalid resource address")

// CanonicalFormat is the ONLY accepted identity format.
// Pattern: [module.name:]...<type>.<name>[<key_type>=<key>]
//
// Examples:
//   aws_instance.web                           - single resource
//   aws_instance.web[count=0]                  - count expansion
//   aws_instance.web[for_each=prod]            - for_each expansion
//   module.vpc:aws_subnet.main[count=0]        - in module
//   module.vpc:module.db:aws_rds.main          - nested modules
const canonicalPattern = `^((?:module\.[a-zA-Z_][a-zA-Z0-9_]*:)*)?([a-zA-Z_][a-zA-Z0-9_]*)\.([a-zA-Z_][a-zA-Z0-9_\-]*)(\[(count|for_each)=([^\]]+)\])?$`

var canonicalRegex = regexp.MustCompile(canonicalPattern)

// EnforcedCanonicalAddress is a validated canonical address.
// Once created, it is guaranteed to be in the correct format.
type EnforcedCanonicalAddress struct {
	raw          string
	modulePath   []string
	resourceType string
	resourceName string
	keyType      KeyType
	keyValue     string
	intKey       int
}

// NewEnforcedAddress creates and validates a canonical address
func NewEnforcedAddress(addr string) (*EnforcedCanonicalAddress, error) {
	// First try to parse as canonical
	if match := canonicalRegex.FindStringSubmatch(addr); match != nil {
		return parseCanonicalMatch(addr, match)
	}

	// Try to normalize from Terraform format
	return normalizeFromTerraform(addr)
}

// MustNewEnforcedAddress creates an address or panics
func MustNewEnforcedAddress(addr string) *EnforcedCanonicalAddress {
	a, err := NewEnforcedAddress(addr)
	if err != nil {
		panic(fmt.Sprintf("invalid address %q: %v", addr, err))
	}
	return a
}

func parseCanonicalMatch(addr string, match []string) (*EnforcedCanonicalAddress, error) {
	a := &EnforcedCanonicalAddress{raw: addr}

	// Parse module path
	if match[1] != "" {
		modulePart := strings.TrimSuffix(match[1], ":")
		for _, part := range strings.Split(modulePart, ":") {
			if strings.HasPrefix(part, "module.") {
				a.modulePath = append(a.modulePath, strings.TrimPrefix(part, "module."))
			}
		}
	}

	a.resourceType = match[2]
	a.resourceName = match[3]

	// Parse key
	if match[4] != "" {
		keyTypeStr := match[5]
		keyVal := match[6]

		if keyTypeStr == "count" {
			a.keyType = KeyTypeInt
			n, err := strconv.Atoi(keyVal)
			if err != nil {
				return nil, fmt.Errorf("invalid count value: %s", keyVal)
			}
			a.intKey = n
			a.keyValue = keyVal
		} else if keyTypeStr == "for_each" {
			a.keyType = KeyTypeString
			a.keyValue = keyVal
		}
	} else {
		a.keyType = KeyTypeNone
	}

	return a, nil
}

func normalizeFromTerraform(addr string) (*EnforcedCanonicalAddress, error) {
	a := &EnforcedCanonicalAddress{}

	// Handle module path
	remaining := addr
	for strings.HasPrefix(remaining, "module.") {
		remaining = strings.TrimPrefix(remaining, "module.")
		dotIdx := strings.Index(remaining, ".")
		if dotIdx == -1 {
			return nil, ErrInvalidAddress
		}
		a.modulePath = append(a.modulePath, remaining[:dotIdx])
		remaining = remaining[dotIdx+1:]
	}

	// Parse resource type.name[key]
	bracketIdx := strings.Index(remaining, "[")
	resourcePart := remaining
	keyPart := ""
	if bracketIdx != -1 {
		resourcePart = remaining[:bracketIdx]
		keyPart = remaining[bracketIdx:]
	}

	// Split type.name
	dotIdx := strings.LastIndex(resourcePart, ".")
	if dotIdx == -1 {
		return nil, ErrInvalidAddress
	}
	a.resourceType = resourcePart[:dotIdx]
	a.resourceName = resourcePart[dotIdx+1:]

	// Parse key
	if keyPart != "" {
		// Remove brackets
		keyPart = strings.TrimPrefix(keyPart, "[")
		keyPart = strings.TrimSuffix(keyPart, "]")

		// Check if it's a number (count) or string (for_each)
		if n, err := strconv.Atoi(keyPart); err == nil {
			a.keyType = KeyTypeInt
			a.intKey = n
			a.keyValue = keyPart
		} else {
			a.keyType = KeyTypeString
			// Remove quotes if present
			a.keyValue = strings.Trim(keyPart, "\"'")
		}
	}

	// Build canonical form
	a.raw = a.String()
	return a, nil
}

// String returns the canonical string representation
func (a *EnforcedCanonicalAddress) String() string {
	if a.raw != "" {
		return a.raw
	}

	var sb strings.Builder

	// Module path
	for _, mod := range a.modulePath {
		sb.WriteString("module.")
		sb.WriteString(mod)
		sb.WriteString(":")
	}

	// Resource
	sb.WriteString(a.resourceType)
	sb.WriteString(".")
	sb.WriteString(a.resourceName)

	// Key
	switch a.keyType {
	case KeyTypeInt:
		sb.WriteString("[count=")
		sb.WriteString(strconv.Itoa(a.intKey))
		sb.WriteString("]")
	case KeyTypeString:
		sb.WriteString("[for_each=")
		sb.WriteString(a.keyValue)
		sb.WriteString("]")
	}

	return sb.String()
}

// ModulePath returns the module path components
func (a *EnforcedCanonicalAddress) ModulePath() []string {
	return a.modulePath
}

// ResourceType returns the resource type
func (a *EnforcedCanonicalAddress) ResourceType() string {
	return a.resourceType
}

// ResourceName returns the resource name
func (a *EnforcedCanonicalAddress) ResourceName() string {
	return a.resourceName
}

// Key returns the expansion key
func (a *EnforcedCanonicalAddress) Key() InstanceKey {
	return InstanceKey{
		Type:     a.keyType,
		IntValue: a.intKey,
		StrValue: a.keyValue,
	}
}

// IsInModule returns true if the resource is inside a module
func (a *EnforcedCanonicalAddress) IsInModule() bool {
	return len(a.modulePath) > 0
}

// BaseAddress returns the address without the expansion key
func (a *EnforcedCanonicalAddress) BaseAddress() string {
	var sb strings.Builder
	for _, mod := range a.modulePath {
		sb.WriteString("module.")
		sb.WriteString(mod)
		sb.WriteString(":")
	}
	sb.WriteString(a.resourceType)
	sb.WriteString(".")
	sb.WriteString(a.resourceName)
	return sb.String()
}

// WithKey returns a new address with a different key
func (a *EnforcedCanonicalAddress) WithKey(keyType KeyType, value interface{}) *EnforcedCanonicalAddress {
	newAddr := &EnforcedCanonicalAddress{
		modulePath:   a.modulePath,
		resourceType: a.resourceType,
		resourceName: a.resourceName,
		keyType:      keyType,
	}

	switch keyType {
	case KeyTypeInt:
		newAddr.intKey = value.(int)
		newAddr.keyValue = strconv.Itoa(value.(int))
	case KeyTypeString:
		newAddr.keyValue = value.(string)
	}

	newAddr.raw = newAddr.String()
	return newAddr
}

// Equals compares two addresses
func (a *EnforcedCanonicalAddress) Equals(other *EnforcedCanonicalAddress) bool {
	return a.String() == other.String()
}

// CanonicalAddressRegistry ensures unique addresses
type CanonicalAddressRegistry struct {
	addresses map[string]*EnforcedCanonicalAddress
}

// NewCanonicalAddressRegistry creates a new registry
func NewCanonicalAddressRegistry() *CanonicalAddressRegistry {
	return &CanonicalAddressRegistry{
		addresses: make(map[string]*EnforcedCanonicalAddress),
	}
}

// Register adds an address, returning error if duplicate
func (r *CanonicalAddressRegistry) Register(addr *EnforcedCanonicalAddress) error {
	key := addr.String()
	if _, exists := r.addresses[key]; exists {
		return fmt.Errorf("duplicate address: %s", key)
	}
	r.addresses[key] = addr
	return nil
}

// Get retrieves an address by string
func (r *CanonicalAddressRegistry) Get(addr string) *EnforcedCanonicalAddress {
	return r.addresses[addr]
}

// All returns all registered addresses
func (r *CanonicalAddressRegistry) All() []*EnforcedCanonicalAddress {
	result := make([]*EnforcedCanonicalAddress, 0, len(r.addresses))
	for _, a := range r.addresses {
		result = append(result, a)
	}
	return result
}

################################################################################
# FILE: :\good projects\cost estimation\core\model\identity.go
# TYPE: go
# SIZE: 9029 bytes
################################################################################
// Package model - Canonical instance identity
// Instance identity is NORMALIZED everywhere: cost lineage, policy, diffing, output.
package model

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"regexp"
	"sort"
	"strings"
)

// CanonicalAddress is a normalized, stable instance identity.
// Format: module.path:resource_type.name[key_type=key_value]
// Examples:
//   aws_instance.web                           (single instance)
//   aws_instance.web[count=0]                  (count expansion)
//   aws_instance.web[for_each=prod]            (for_each expansion)
//   module.app:aws_instance.web[count=0]      (in module)
//   module.app:module.db:aws_rds_instance.main (nested modules)
type CanonicalAddress string

// AddressBuilder constructs canonical addresses
type AddressBuilder struct {
	modulePath   []string
	resourceType string
	resourceName string
	keyType      string
	keyValue     string
}

// NewAddressBuilder creates a new builder
func NewAddressBuilder() *AddressBuilder {
	return &AddressBuilder{}
}

// InModule adds a module to the path
func (b *AddressBuilder) InModule(name string) *AddressBuilder {
	b.modulePath = append(b.modulePath, name)
	return b
}

// Resource sets the resource type and name
func (b *AddressBuilder) Resource(resourceType, name string) *AddressBuilder {
	b.resourceType = resourceType
	b.resourceName = name
	return b
}

// WithCount sets a count key
func (b *AddressBuilder) WithCount(index int) *AddressBuilder {
	b.keyType = "count"
	b.keyValue = fmt.Sprintf("%d", index)
	return b
}

// WithForEach sets a for_each key
func (b *AddressBuilder) WithForEach(key string) *AddressBuilder {
	b.keyType = "for_each"
	b.keyValue = key
	return b
}

// Build creates the canonical address
func (b *AddressBuilder) Build() CanonicalAddress {
	var sb strings.Builder

	// Module path
	for i, mod := range b.modulePath {
		if i > 0 {
			sb.WriteString(":")
		}
		sb.WriteString("module.")
		sb.WriteString(mod)
	}

	// Separator if we have modules
	if len(b.modulePath) > 0 {
		sb.WriteString(":")
	}

	// Resource
	sb.WriteString(b.resourceType)
	sb.WriteString(".")
	sb.WriteString(b.resourceName)

	// Key
	if b.keyType != "" {
		sb.WriteString("[")
		sb.WriteString(b.keyType)
		sb.WriteString("=")
		sb.WriteString(b.keyValue)
		sb.WriteString("]")
	}

	return CanonicalAddress(sb.String())
}

// ParseAddress parses any address format into canonical form
func ParseAddress(addr string) (CanonicalAddress, error) {
	// Already canonical?
	if isCanonical(addr) {
		return CanonicalAddress(addr), nil
	}

	// Parse Terraform-style address
	builder := NewAddressBuilder()

	// Split into parts
	parts := strings.Split(addr, ".")

	i := 0
	// Collect module path
	for i < len(parts)-2 {
		if parts[i] == "module" {
			builder.InModule(parts[i+1])
			i += 2
		} else {
			break
		}
	}

	// Resource type and name
	if i+1 >= len(parts) {
		return "", fmt.Errorf("invalid address: %s", addr)
	}

	resourceType := parts[i]
	resourceName := parts[i+1]

	// Check for index in resource name
	if idx := strings.Index(resourceName, "["); idx != -1 {
		keyPart := resourceName[idx+1 : len(resourceName)-1]
		resourceName = resourceName[:idx]

		// Parse key
		if num, err := fmt.Sscanf(keyPart, "%d", new(int)); err == nil && num == 1 {
			var index int
			fmt.Sscanf(keyPart, "%d", &index)
			builder.WithCount(index)
		} else {
			// Remove quotes if present
			keyPart = strings.Trim(keyPart, "\"")
			builder.WithForEach(keyPart)
		}
	}

	builder.Resource(resourceType, resourceName)
	return builder.Build(), nil
}

// isCanonical checks if address is already in canonical form
func isCanonical(addr string) bool {
	// Canonical format uses [key_type=value] not [index] or ["key"]
	return strings.Contains(addr, "[count=") || strings.Contains(addr, "[for_each=")
}

// StableID generates a hash-based ID from a canonical address
func (a CanonicalAddress) StableID() InstanceID {
	h := sha256.New()
	h.Write([]byte(a))
	return InstanceID(hex.EncodeToString(h.Sum(nil))[:16])
}

// ModulePath returns the module path component
func (a CanonicalAddress) ModulePath() string {
	s := string(a)
	idx := strings.LastIndex(s, ":")
	if idx == -1 {
		return ""
	}
	return s[:idx]
}

// ResourceAddress returns just the resource part
func (a CanonicalAddress) ResourceAddress() string {
	s := string(a)
	idx := strings.LastIndex(s, ":")
	if idx == -1 {
		return s
	}
	return s[idx+1:]
}

// BaseAddress returns the address without the key
func (a CanonicalAddress) BaseAddress() string {
	s := string(a)
	idx := strings.Index(s, "[")
	if idx == -1 {
		return s
	}
	return s[:idx]
}

// Key returns the key part, if any
func (a CanonicalAddress) Key() (keyType, keyValue string) {
	s := string(a)
	re := regexp.MustCompile(`\[(count|for_each)=([^\]]+)\]`)
	matches := re.FindStringSubmatch(s)
	if len(matches) == 3 {
		return matches[1], matches[2]
	}
	return "", ""
}

// String implements Stringer
func (a CanonicalAddress) String() string {
	return string(a)
}

// InstanceIdentity provides complete identity information
type InstanceIdentity struct {
	// Canonical address (normalized)
	Canonical CanonicalAddress

	// Stable ID (hash-based)
	ID InstanceID

	// Components
	ModulePath   string
	ResourceType string
	ResourceName string
	KeyType      string // "count" or "for_each" or ""
	KeyValue     string

	// Parent definition
	DefinitionID DefinitionID

	// For nested expansion tracking
	ParentKey    *InstanceIdentity
}

// NewInstanceIdentity creates identity from an instance
func NewInstanceIdentity(inst *AssetInstance) *InstanceIdentity {
	canonical, _ := ParseAddress(string(inst.Address))

	keyType, keyValue := "", ""
	switch inst.Key.Type {
	case KeyTypeInt:
		keyType = "count"
		keyValue = fmt.Sprintf("%d", inst.Key.IntValue)
	case KeyTypeString:
		keyType = "for_each"
		keyValue = inst.Key.StrValue
	}

	parts := strings.Split(canonical.BaseAddress(), ".")
	resourceType, resourceName := "", ""
	if len(parts) >= 2 {
		// Find last two parts that aren't module names
		for i := len(parts) - 2; i >= 0; i-- {
			if parts[i] != "module" {
				resourceType = parts[i]
				resourceName = parts[i+1]
				break
			}
		}
	}

	return &InstanceIdentity{
		Canonical:    canonical,
		ID:           canonical.StableID(),
		ModulePath:   canonical.ModulePath(),
		ResourceType: resourceType,
		ResourceName: resourceName,
		KeyType:      keyType,
		KeyValue:     keyValue,
		DefinitionID: inst.DefinitionID,
	}
}

// IdentityIndex indexes instances by various identity components
type IdentityIndex struct {
	byCanonical    map[CanonicalAddress]*InstanceIdentity
	byID           map[InstanceID]*InstanceIdentity
	byModule       map[string][]*InstanceIdentity
	byResourceType map[string][]*InstanceIdentity
	byDefinition   map[DefinitionID][]*InstanceIdentity
}

// NewIdentityIndex creates an empty index
func NewIdentityIndex() *IdentityIndex {
	return &IdentityIndex{
		byCanonical:    make(map[CanonicalAddress]*InstanceIdentity),
		byID:           make(map[InstanceID]*InstanceIdentity),
		byModule:       make(map[string][]*InstanceIdentity),
		byResourceType: make(map[string][]*InstanceIdentity),
		byDefinition:   make(map[DefinitionID][]*InstanceIdentity),
	}
}

// Add adds an identity to the index
func (idx *IdentityIndex) Add(id *InstanceIdentity) {
	idx.byCanonical[id.Canonical] = id
	idx.byID[id.ID] = id
	idx.byModule[id.ModulePath] = append(idx.byModule[id.ModulePath], id)
	idx.byResourceType[id.ResourceType] = append(idx.byResourceType[id.ResourceType], id)
	idx.byDefinition[id.DefinitionID] = append(idx.byDefinition[id.DefinitionID], id)
}

// ByCanonical looks up by canonical address
func (idx *IdentityIndex) ByCanonical(addr CanonicalAddress) *InstanceIdentity {
	return idx.byCanonical[addr]
}

// ByID looks up by ID
func (idx *IdentityIndex) ByID(id InstanceID) *InstanceIdentity {
	return idx.byID[id]
}

// ByModule returns all instances in a module
func (idx *IdentityIndex) ByModule(path string) []*InstanceIdentity {
	result := idx.byModule[path]
	sort.Slice(result, func(i, j int) bool {
		return result[i].Canonical < result[j].Canonical
	})
	return result
}

// ByResourceType returns all instances of a type
func (idx *IdentityIndex) ByResourceType(t string) []*InstanceIdentity {
	result := idx.byResourceType[t]
	sort.Slice(result, func(i, j int) bool {
		return result[i].Canonical < result[j].Canonical
	})
	return result
}

// ByDefinition returns all instances from a definition
func (idx *IdentityIndex) ByDefinition(id DefinitionID) []*InstanceIdentity {
	result := idx.byDefinition[id]
	sort.Slice(result, func(i, j int) bool {
		return result[i].Canonical < result[j].Canonical
	})
	return result
}

################################################################################
# FILE: :\good projects\cost estimation\core\output\formatter.go
# TYPE: go
# SIZE: 4597 bytes
################################################################################
// Package output provides output formatting interfaces.
// This package produces human and machine-readable outputs.
package output

import (
	"io"

	"terraform-cost/core/policy"
	"terraform-cost/core/types"
)

// Format represents output format type
type Format string

const (
	// FormatCLI is a human-readable CLI table
	FormatCLI Format = "cli"

	// FormatJSON is machine-readable JSON
	FormatJSON Format = "json"

	// FormatHTML is an HTML report
	FormatHTML Format = "html"

	// FormatMarkdown is a markdown report
	FormatMarkdown Format = "markdown"

	// FormatPR is a PR comment format
	FormatPR Format = "pr"
)

// Formatter produces output in a specific format
type Formatter interface {
	// Format returns the format type
	Format() Format

	// Render produces output for the given result
	Render(w io.Writer, result *EstimationResult) error
}

// EstimationResult contains the complete estimation output
type EstimationResult struct {
	// CostGraph is the calculated cost graph
	CostGraph *types.CostGraph `json:"cost_graph"`

	// AssetGraph is the source asset graph
	AssetGraph *types.AssetGraph `json:"asset_graph,omitempty"`

	// PolicyResult contains policy evaluation results
	PolicyResult *policy.EvaluationResult `json:"policy_result,omitempty"`

	// PricingSnapshot identifies the pricing data used
	PricingSnapshot *types.PricingSnapshot `json:"pricing_snapshot"`

	// UsageProfile is the usage profile that was applied
	UsageProfile *types.UsageProfile `json:"usage_profile,omitempty"`

	// Assumptions documents estimation assumptions
	Assumptions []Assumption `json:"assumptions,omitempty"`

	// Confidence is the overall confidence level (0.0 to 1.0)
	Confidence float64 `json:"confidence"`

	// Metadata contains execution context
	Metadata EstimationMetadata `json:"metadata"`

	// Diff contains comparison with previous estimate
	Diff *EstimationDiff `json:"diff,omitempty"`
}

// Assumption documents an estimation assumption
type Assumption struct {
	// Resource is the resource this assumption applies to
	Resource types.ResourceAddress `json:"resource,omitempty"`

	// Category is the assumption category
	Category string `json:"category"`

	// Description explains the assumption
	Description string `json:"description"`

	// Impact describes the potential impact
	Impact string `json:"impact,omitempty"`

	// Confidence is the confidence in this assumption
	Confidence float64 `json:"confidence,omitempty"`
}

// EstimationMetadata contains execution context
type EstimationMetadata struct {
	// Timestamp is when the estimation was performed
	Timestamp string `json:"timestamp"`

	// Duration is how long the estimation took
	Duration string `json:"duration"`

	// InputHash is a hash of the input for caching
	InputHash string `json:"input_hash"`

	// SnapshotID is the pricing snapshot ID
	SnapshotID string `json:"snapshot_id"`

	// Version is the tool version
	Version string `json:"version"`

	// Source is the input source
	Source types.InputSource `json:"source"`

	// Environment is the target environment
	Environment string `json:"environment,omitempty"`
}

// EstimationDiff contains comparison with a previous estimate
type EstimationDiff struct {
	// Previous is the previous cost
	Previous types.CostGraph `json:"previous"`

	// Added are new resources
	Added []DiffItem `json:"added,omitempty"`

	// Removed are removed resources
	Removed []DiffItem `json:"removed,omitempty"`

	// Changed are resources with cost changes
	Changed []DiffItem `json:"changed,omitempty"`

	// TotalChange is the difference in total cost
	TotalChange string `json:"total_change"`

	// PercentChange is the percentage change
	PercentChange float64 `json:"percent_change"`
}

// DiffItem represents a single diff entry
type DiffItem struct {
	// Resource is the resource address
	Resource string `json:"resource"`

	// PreviousCost is the old cost
	PreviousCost string `json:"previous_cost,omitempty"`

	// CurrentCost is the new cost
	CurrentCost string `json:"current_cost,omitempty"`

	// Change is the cost difference
	Change string `json:"change,omitempty"`
}

// FormatterRegistry manages formatter registration
type FormatterRegistry interface {
	// Register adds a formatter to the registry
	Register(formatter Formatter) error

	// GetFormatter returns a formatter for a format type
	GetFormatter(format Format) (Formatter, bool)

	// GetAll returns all registered formatters
	GetAll() []Formatter
}

################################################################################
# FILE: :\good projects\cost estimation\core\policy\deep_policy.go
# TYPE: go
# SIZE: 12552 bytes
################################################################################
// Package policy provides the policy evaluation engine with deep context access.
// Policies can access cost lineage, usage confidence, and instance identity.
package policy

import (
	"context"
	"fmt"
	"sort"

	"terraform-cost/core/determinism"
	"terraform-cost/core/model"
	"terraform-cost/core/pricing"
)

// DeepEvaluator evaluates cost policies with full context access
type DeepEvaluator struct {
	policies []DeepPolicy
}

// NewDeepEvaluator creates a new policy evaluator
func NewDeepEvaluator() *DeepEvaluator {
	return &DeepEvaluator{
		policies: []DeepPolicy{},
	}
}

// Register adds a policy
func (e *DeepEvaluator) Register(p DeepPolicy) {
	e.policies = append(e.policies, p)
}

// DeepPolicy is an interface for cost policies with deep context
type DeepPolicy interface {
	Name() string
	Evaluate(ctx context.Context, input *PolicyInput) (*PolicyOutput, error)
}

// PolicyInput provides DEEP context for policy evaluation
type PolicyInput struct {
	// Instance costs (per-instance, not aggregated)
	InstanceCosts map[model.InstanceID]*InstanceCostDetail

	// Total costs
	TotalMonthlyCost determinism.Money
	TotalHourlyCost  determinism.Money

	// Confidence information
	OverallConfidence float64
	LowConfidenceItems []LowConfidenceItem

	// Unknowns
	UnknownValues []UnknownValueInfo

	// Definitions (for grouping)
	Definitions map[model.DefinitionID]*model.AssetDefinition

	// Full lineage for tracing
	AllLineage []*pricing.CostLineage

	// Pricing snapshot used
	Snapshot *pricing.PricingSnapshot
}

// InstanceCostDetail provides deep detail for a single instance
type InstanceCostDetail struct {
	// Instance identity
	InstanceID   model.InstanceID
	Address      model.InstanceAddress
	DefinitionID model.DefinitionID
	InstanceKey  model.InstanceKey

	// Provider and region
	Provider string
	Region   string

	// Costs
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money
	Components  []ComponentDetail

	// Confidence
	Confidence float64
	Factors    []ConfidenceFactor

	// Full lineage
	Lineage []*pricing.CostLineage

	// Usage information
	Usage UsageInfo

	// Tags/labels for targeting
	Tags map[string]string
}

// ComponentDetail provides detail for a cost component
type ComponentDetail struct {
	Name        string
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money

	// Rate used
	Rate RateInfo

	// Usage
	UsageValue float64
	UsageUnit  string

	// Formula applied
	Formula pricing.FormulaApplication

	// Confidence
	Confidence float64
}

// RateInfo describes the pricing rate used
type RateInfo struct {
	ID       pricing.RateID
	Key      pricing.RateKey
	Price    string
	Unit     string
	Currency string
}

// UsageInfo provides usage details
type UsageInfo struct {
	Source      pricing.UsageSource
	Confidence  float64
	Assumptions []string
	Overridden  bool
}

// ConfidenceFactor explains why confidence is reduced
type ConfidenceFactor struct {
	Reason    string
	Impact    float64
	Component string
	IsUnknown bool
}

// LowConfidenceItem identifies items with low confidence
type LowConfidenceItem struct {
	InstanceID model.InstanceID
	Address    model.InstanceAddress
	Component  string
	Confidence float64
	Reason     string
}

// UnknownValueInfo describes an unknown value
type UnknownValueInfo struct {
	Address string
	Reason  string
	Impact  string
}

// PolicyOutput is the result of a single policy
type PolicyOutput struct {
	Passed  bool
	Message string

	// Affected instances (for targeting)
	AffectedInstances []model.InstanceID

	// Cost impact
	AffectedCost determinism.Money

	// Lineage references (for explainability)
	LineageRefs []*pricing.CostLineage

	// Suggested actions
	Suggestions []string
}

// DeepResult is the complete result of all policies
type DeepResult struct {
	Passed   bool
	Policies []DeepPolicyResult
}

// DeepPolicyResult is the result of a single policy
type DeepPolicyResult struct {
	Name    string
	Passed  bool
	Message string

	AffectedInstances []model.InstanceID
	AffectedCost      determinism.Money
	LineageRefs       []*pricing.CostLineage
	Suggestions       []string
}

// Evaluate runs all policies
func (e *DeepEvaluator) Evaluate(ctx context.Context, input *PolicyInput) (*DeepResult, error) {
	result := &DeepResult{
		Passed:   true,
		Policies: make([]DeepPolicyResult, 0, len(e.policies)),
	}

	for _, p := range e.policies {
		output, err := p.Evaluate(ctx, input)
		if err != nil {
			return nil, fmt.Errorf("policy %s failed: %w", p.Name(), err)
		}

		pr := DeepPolicyResult{
			Name:              p.Name(),
			Passed:            output.Passed,
			Message:           output.Message,
			AffectedInstances: output.AffectedInstances,
			AffectedCost:      output.AffectedCost,
			LineageRefs:       output.LineageRefs,
			Suggestions:       output.Suggestions,
		}
		result.Policies = append(result.Policies, pr)

		if !output.Passed {
			result.Passed = false
		}
	}

	return result, nil
}

// BudgetPolicy checks if total cost exceeds a budget
type BudgetPolicy struct {
	name          string
	monthlyBudget determinism.Money
	threshold     float64 // 0.0-1.0, warn when at this percentage
}

// NewBudgetPolicy creates a budget policy
func NewBudgetPolicy(name string, monthlyBudget determinism.Money, threshold float64) *BudgetPolicy {
	return &BudgetPolicy{
		name:          name,
		monthlyBudget: monthlyBudget,
		threshold:     threshold,
	}
}

func (p *BudgetPolicy) Name() string { return p.name }

func (p *BudgetPolicy) Evaluate(ctx context.Context, input *PolicyInput) (*PolicyOutput, error) {
	output := &PolicyOutput{
		Passed: true,
	}

	// Check if over budget
	if input.TotalMonthlyCost.Cmp(p.monthlyBudget) > 0 {
		output.Passed = false
		output.Message = fmt.Sprintf("Monthly cost $%s exceeds budget $%s",
			input.TotalMonthlyCost.String(), p.monthlyBudget.String())

		// Find top cost contributors
		output.AffectedInstances = p.findTopContributors(input, 5)
		output.AffectedCost = input.TotalMonthlyCost.Sub(p.monthlyBudget)
		output.Suggestions = []string{
			"Consider using smaller instance types",
			"Review usage assumptions for accuracy",
			"Check for unused resources",
		}
	} else {
		// Check threshold warning
		thresholdAmount := p.monthlyBudget.MulFloat(p.threshold)
		if input.TotalMonthlyCost.Cmp(thresholdAmount) > 0 {
			output.Message = fmt.Sprintf("Monthly cost $%s is at %.0f%% of budget $%s",
				input.TotalMonthlyCost.String(),
				(input.TotalMonthlyCost.Float64()/p.monthlyBudget.Float64())*100,
				p.monthlyBudget.String())
		} else {
			output.Message = fmt.Sprintf("Monthly cost $%s is within budget $%s",
				input.TotalMonthlyCost.String(), p.monthlyBudget.String())
		}
	}

	return output, nil
}

func (p *BudgetPolicy) findTopContributors(input *PolicyInput, n int) []model.InstanceID {
	// Sort instances by cost
	type costItem struct {
		id   model.InstanceID
		cost determinism.Money
	}

	items := make([]costItem, 0, len(input.InstanceCosts))
	for id, detail := range input.InstanceCosts {
		items = append(items, costItem{id: id, cost: detail.MonthlyCost})
	}

	sort.Slice(items, func(i, j int) bool {
		return items[i].cost.Cmp(items[j].cost) > 0
	})

	result := make([]model.InstanceID, 0, n)
	for i := 0; i < n && i < len(items); i++ {
		result = append(result, items[i].id)
	}
	return result
}

// ConfidencePolicy checks if estimation confidence is acceptable
type ConfidencePolicy struct {
	name          string
	minConfidence float64
}

// NewConfidencePolicy creates a confidence policy
func NewConfidencePolicy(name string, minConfidence float64) *ConfidencePolicy {
	return &ConfidencePolicy{
		name:          name,
		minConfidence: minConfidence,
	}
}

func (p *ConfidencePolicy) Name() string { return p.name }

func (p *ConfidencePolicy) Evaluate(ctx context.Context, input *PolicyInput) (*PolicyOutput, error) {
	output := &PolicyOutput{
		Passed: true,
	}

	if input.OverallConfidence < p.minConfidence {
		output.Passed = false
		output.Message = fmt.Sprintf("Estimation confidence %.2f%% is below minimum %.2f%%",
			input.OverallConfidence*100, p.minConfidence*100)

		// Find low confidence items
		for _, item := range input.LowConfidenceItems {
			output.AffectedInstances = append(output.AffectedInstances, item.InstanceID)
		}

		// Collect lineage for affected items
		for _, lineage := range input.AllLineage {
			if lineage.Confidence < p.minConfidence {
				output.LineageRefs = append(output.LineageRefs, lineage)
			}
		}

		output.Suggestions = []string{
			"Provide usage overrides for low-confidence components",
			"Check that all required variables are provided",
			"Review unknown values in the configuration",
		}
	} else {
		output.Message = fmt.Sprintf("Estimation confidence %.2f%% meets minimum %.2f%%",
			input.OverallConfidence*100, p.minConfidence*100)
	}

	return output, nil
}

// ResourceTypePolicy checks limits on specific resource types
type ResourceTypePolicy struct {
	name         string
	resourceType string
	maxInstances int
	maxCost      *determinism.Money
}

// NewResourceTypePolicy creates a resource type policy
func NewResourceTypePolicy(name, resourceType string, maxInstances int, maxCost *determinism.Money) *ResourceTypePolicy {
	return &ResourceTypePolicy{
		name:         name,
		resourceType: resourceType,
		maxInstances: maxInstances,
		maxCost:      maxCost,
	}
}

func (p *ResourceTypePolicy) Name() string { return p.name }

func (p *ResourceTypePolicy) Evaluate(ctx context.Context, input *PolicyInput) (*PolicyOutput, error) {
	output := &PolicyOutput{
		Passed: true,
	}

	// Count instances and sum cost for this resource type
	var count int
	totalCost := determinism.Zero("USD")
	affected := []model.InstanceID{}

	for id, detail := range input.InstanceCosts {
		// Check if this instance matches the resource type
		addr := string(detail.Address)
		if len(addr) >= len(p.resourceType) && addr[:len(p.resourceType)] == p.resourceType {
			count++
			totalCost = totalCost.Add(detail.MonthlyCost)
			affected = append(affected, id)
		}
	}

	// Check instance count
	if p.maxInstances > 0 && count > p.maxInstances {
		output.Passed = false
		output.Message = fmt.Sprintf("%s: %d instances exceeds limit of %d",
			p.resourceType, count, p.maxInstances)
		output.AffectedInstances = affected
	}

	// Check cost
	if p.maxCost != nil && totalCost.Cmp(*p.maxCost) > 0 {
		output.Passed = false
		if output.Message != "" {
			output.Message += "; "
		}
		output.Message += fmt.Sprintf("%s cost $%s exceeds limit $%s",
			p.resourceType, totalCost.String(), p.maxCost.String())
		output.AffectedInstances = affected
		output.AffectedCost = totalCost.Sub(*p.maxCost)
	}

	if output.Passed {
		output.Message = fmt.Sprintf("%s: %d instances, $%s/month - within limits",
			p.resourceType, count, totalCost.String())
	}

	return output, nil
}

// TagRequirementPolicy checks that instances have required tags
type TagRequirementPolicy struct {
	name         string
	requiredTags []string
}

// NewTagRequirementPolicy creates a tag requirement policy
func NewTagRequirementPolicy(name string, requiredTags []string) *TagRequirementPolicy {
	return &TagRequirementPolicy{
		name:         name,
		requiredTags: requiredTags,
	}
}

func (p *TagRequirementPolicy) Name() string { return p.name }

func (p *TagRequirementPolicy) Evaluate(ctx context.Context, input *PolicyInput) (*PolicyOutput, error) {
	output := &PolicyOutput{
		Passed: true,
	}

	missingTags := make(map[model.InstanceID][]string)

	for id, detail := range input.InstanceCosts {
		for _, req := range p.requiredTags {
			if _, ok := detail.Tags[req]; !ok {
				missingTags[id] = append(missingTags[id], req)
			}
		}
	}

	if len(missingTags) > 0 {
		output.Passed = false
		output.Message = fmt.Sprintf("%d instances missing required tags", len(missingTags))

		for id := range missingTags {
			output.AffectedInstances = append(output.AffectedInstances, id)
		}

		output.Suggestions = []string{
			"Add required tags: " + fmt.Sprintf("%v", p.requiredTags),
		}
	} else {
		output.Message = "All instances have required tags"
	}

	return output, nil
}

################################################################################
# FILE: :\good projects\cost estimation\core\policy\diff_policy.go
# TYPE: go
# SIZE: 10216 bytes
################################################################################
// Package policy - Diff-aware policy engine
// Policies can reason over change sets, not just aggregates.
// Can block "new unknown costs" and evaluate "new resources only".
package policy

import (
	"terraform-cost/core/graph"
	"terraform-cost/core/model"
)

// DiffAwarePolicy evaluates changes, not just totals
type DiffAwarePolicy interface {
	// Name returns the policy name
	Name() string

	// EvaluateDiff evaluates a diff
	EvaluateDiff(ctx *DiffPolicyContext) *DiffPolicyResult
}

// DiffPolicyContext provides diff context to policies
type DiffPolicyContext struct {
	// Before state (nil for new infrastructure)
	Before *CostSnapshot

	// After state
	After *CostSnapshot

	// Change analysis
	Changes *graph.ChangeCostAnalysis

	// Scope filter
	Scope DiffScope

	// Confidence context
	ConfidenceInfo *DiffConfidenceInfo
}

// CostSnapshot is a point-in-time cost state
type CostSnapshot struct {
	TotalMonthly  float64
	Resources     map[model.InstanceID]float64
	ByService     map[string]float64
	Confidence    float64
	Timestamp     string
}

// DiffScope defines what to evaluate
type DiffScope struct {
	// Only evaluate new resources
	NewResourcesOnly bool

	// Only evaluate production changes
	ProductionOnly bool

	// Only evaluate specific services
	Services []string

	// Only evaluate specific resource types
	ResourceTypes []string
}

// DiffConfidenceInfo tracks confidence changes
type DiffConfidenceInfo struct {
	// Before confidence
	BeforeConfidence float64

	// After confidence
	AfterConfidence float64

	// New unknowns introduced
	NewUnknowns []NewUnknownItem

	// Low confidence items
	LowConfidenceItems []LowConfItem
}

// NewUnknownItem is a new unknown cost
type NewUnknownItem struct {
	Address    string
	Reason     string
	CostImpact float64
}

// LowConfItem is a low confidence item
type LowConfItem struct {
	Address    string
	Confidence float64
	Reason     string
	Cost       float64
}

// DiffPolicyResult is the result of diff policy evaluation
type DiffPolicyResult struct {
	PolicyName    string
	Passed        bool
	Violations    []DiffViolation
	Warnings      []DiffWarning
	CostImpact    float64
	Recommendation string
}

// DiffViolation is a policy violation in a diff
type DiffViolation struct {
	Type        ViolationType
	Address     string
	Reason      string
	CostImpact  float64
	Blocking    bool
}

// ViolationType classifies violations
type ViolationType int

const (
	ViolationBudgetExceeded    ViolationType = iota
	ViolationNewUnknown
	ViolationConfidenceDropped
	ViolationNewHighCost
	ViolationUnauthorizedService
)

// String returns the violation type name
func (v ViolationType) String() string {
	switch v {
	case ViolationBudgetExceeded:
		return "budget_exceeded"
	case ViolationNewUnknown:
		return "new_unknown"
	case ViolationConfidenceDropped:
		return "confidence_dropped"
	case ViolationNewHighCost:
		return "new_high_cost"
	case ViolationUnauthorizedService:
		return "unauthorized_service"
	default:
		return "unknown"
	}
}

// DiffWarning is a warning in a diff
type DiffWarning struct {
	Type    string
	Message string
	Address string
}

// NewUnknownsPolicy blocks new unknown costs
type NewUnknownsPolicy struct {
	// Block on any new unknowns
	BlockOnNew bool

	// Minimum confidence for new resources
	MinConfidence float64
}

// NewNewUnknownsPolicy creates a policy
func NewNewUnknownsPolicy(block bool, minConfidence float64) *NewUnknownsPolicy {
	return &NewUnknownsPolicy{
		BlockOnNew:    block,
		MinConfidence: minConfidence,
	}
}

// Name returns the policy name
func (p *NewUnknownsPolicy) Name() string {
	return "new-unknowns"
}

// EvaluateDiff evaluates for new unknowns
func (p *NewUnknownsPolicy) EvaluateDiff(ctx *DiffPolicyContext) *DiffPolicyResult {
	result := &DiffPolicyResult{
		PolicyName: p.Name(),
		Passed:     true,
		Violations: []DiffViolation{},
		Warnings:   []DiffWarning{},
	}

	if ctx.ConfidenceInfo == nil {
		return result
	}

	// Check for new unknowns
	for _, unknown := range ctx.ConfidenceInfo.NewUnknowns {
		if p.BlockOnNew {
			result.Passed = false
			result.Violations = append(result.Violations, DiffViolation{
				Type:       ViolationNewUnknown,
				Address:    unknown.Address,
				Reason:     unknown.Reason,
				CostImpact: unknown.CostImpact,
				Blocking:   true,
			})
		} else {
			result.Warnings = append(result.Warnings, DiffWarning{
				Type:    "new_unknown",
				Message: unknown.Reason,
				Address: unknown.Address,
			})
		}
	}

	// Check confidence threshold
	for _, item := range ctx.ConfidenceInfo.LowConfidenceItems {
		if item.Confidence < p.MinConfidence {
			result.Violations = append(result.Violations, DiffViolation{
				Type:       ViolationConfidenceDropped,
				Address:    item.Address,
				Reason:     item.Reason,
				CostImpact: item.Cost,
				Blocking:   false,
			})
		}
	}

	return result
}

// DeltaBudgetPolicy checks change amounts against budgets
type DeltaBudgetPolicy struct {
	// Maximum monthly increase
	MaxMonthlyIncrease float64

	// Maximum percentage increase
	MaxPercentIncrease float64

	// Per-service limits
	ServiceLimits map[string]float64
}

// NewDeltaBudgetPolicy creates a policy
func NewDeltaBudgetPolicy(maxIncrease, maxPercent float64) *DeltaBudgetPolicy {
	return &DeltaBudgetPolicy{
		MaxMonthlyIncrease: maxIncrease,
		MaxPercentIncrease: maxPercent,
		ServiceLimits:      make(map[string]float64),
	}
}

// Name returns the policy name
func (p *DeltaBudgetPolicy) Name() string {
	return "delta-budget"
}

// EvaluateDiff evaluates budget against changes
func (p *DeltaBudgetPolicy) EvaluateDiff(ctx *DiffPolicyContext) *DiffPolicyResult {
	result := &DiffPolicyResult{
		PolicyName: p.Name(),
		Passed:     true,
		Violations: []DiffViolation{},
	}

	if ctx.Before == nil || ctx.After == nil {
		return result
	}

	// Calculate delta
	delta := ctx.After.TotalMonthly - ctx.Before.TotalMonthly
	result.CostImpact = delta

	// Check absolute increase
	if p.MaxMonthlyIncrease > 0 && delta > p.MaxMonthlyIncrease {
		result.Passed = false
		result.Violations = append(result.Violations, DiffViolation{
			Type:       ViolationBudgetExceeded,
			Reason:     "monthly increase exceeds limit",
			CostImpact: delta,
			Blocking:   true,
		})
	}

	// Check percentage increase
	if ctx.Before.TotalMonthly > 0 && p.MaxPercentIncrease > 0 {
		percentIncrease := (delta / ctx.Before.TotalMonthly) * 100
		if percentIncrease > p.MaxPercentIncrease {
			result.Passed = false
			result.Violations = append(result.Violations, DiffViolation{
				Type:       ViolationBudgetExceeded,
				Reason:     "percentage increase exceeds limit",
				CostImpact: delta,
				Blocking:   true,
			})
		}
	}

	// Check per-service limits
	for service, limit := range p.ServiceLimits {
		beforeCost := ctx.Before.ByService[service]
		afterCost := ctx.After.ByService[service]
		serviceDelta := afterCost - beforeCost

		if serviceDelta > limit {
			result.Passed = false
			result.Violations = append(result.Violations, DiffViolation{
				Type:       ViolationBudgetExceeded,
				Reason:     service + " service increase exceeds limit",
				CostImpact: serviceDelta,
				Blocking:   true,
			})
		}
	}

	return result
}

// NewResourcesOnlyPolicy evaluates only new resources
type NewResourcesOnlyPolicy struct {
	// Inner policy to apply
	inner DiffAwarePolicy
}

// NewNewResourcesOnlyPolicy creates a wrapper
func NewNewResourcesOnlyPolicy(inner DiffAwarePolicy) *NewResourcesOnlyPolicy {
	return &NewResourcesOnlyPolicy{inner: inner}
}

// Name returns the policy name
func (p *NewResourcesOnlyPolicy) Name() string {
	return "new-resources-only:" + p.inner.Name()
}

// EvaluateDiff evaluates only new resources
func (p *NewResourcesOnlyPolicy) EvaluateDiff(ctx *DiffPolicyContext) *DiffPolicyResult {
	// Create filtered context with only new resources
	filteredCtx := &DiffPolicyContext{
		Before: &CostSnapshot{
			TotalMonthly: 0,
			Resources:    make(map[model.InstanceID]float64),
			ByService:    make(map[string]float64),
			Confidence:   1.0,
		},
		After:          ctx.After,
		ConfidenceInfo: ctx.ConfidenceInfo,
		Scope:          ctx.Scope,
	}

	// Remove resources that existed before
	if ctx.Before != nil {
		for id := range ctx.Before.Resources {
			delete(filteredCtx.After.Resources, id)
		}
	}

	// Recalculate total
	filteredCtx.After.TotalMonthly = 0
	for _, cost := range filteredCtx.After.Resources {
		filteredCtx.After.TotalMonthly += cost
	}

	return p.inner.EvaluateDiff(filteredCtx)
}

// DiffPolicyEngine evaluates multiple diff-aware policies
type DiffPolicyEngine struct {
	policies []DiffAwarePolicy
}

// NewDiffPolicyEngine creates an engine
func NewDiffPolicyEngine() *DiffPolicyEngine {
	return &DiffPolicyEngine{
		policies: []DiffAwarePolicy{},
	}
}

// AddPolicy adds a policy
func (e *DiffPolicyEngine) AddPolicy(policy DiffAwarePolicy) {
	e.policies = append(e.policies, policy)
}

// Evaluate evaluates all policies
func (e *DiffPolicyEngine) Evaluate(ctx *DiffPolicyContext) *DiffPolicyEngineResult {
	result := &DiffPolicyEngineResult{
		Passed:  true,
		Results: []*DiffPolicyResult{},
	}

	for _, policy := range e.policies {
		policyResult := policy.EvaluateDiff(ctx)
		result.Results = append(result.Results, policyResult)

		if !policyResult.Passed {
			result.Passed = false
		}
	}

	return result
}

// DiffPolicyEngineResult is the result of evaluating all policies
type DiffPolicyEngineResult struct {
	Passed  bool
	Results []*DiffPolicyResult
}

// BlockingViolations returns all blocking violations
func (r *DiffPolicyEngineResult) BlockingViolations() []DiffViolation {
	var violations []DiffViolation
	for _, result := range r.Results {
		for _, v := range result.Violations {
			if v.Blocking {
				violations = append(violations, v)
			}
		}
	}
	return violations
}

################################################################################
# FILE: :\good projects\cost estimation\core\policy\evaluator.go
# TYPE: go
# SIZE: 4143 bytes
################################################################################
// Package policy provides the policy evaluation interface.
// This package enforces cost guardrails before deployment.
package policy

import (
	"context"

	"terraform-cost/core/types"
)

// Rule defines a single policy rule
type Rule interface {
	// Name returns the rule identifier
	Name() string

	// Description returns a human-readable description
	Description() string

	// Evaluate checks the rule against the cost graph
	// prev is the previous cost graph for diff-based policies (can be nil)
	Evaluate(ctx context.Context, current *types.CostGraph, prev *types.CostGraph) (*RuleResult, error)
}

// RuleResult contains the evaluation output for a single rule
type RuleResult struct {
	// RuleName is the rule that was evaluated
	RuleName string `json:"rule_name"`

	// Passed indicates if the rule passed
	Passed bool `json:"passed"`

	// Severity is the rule severity
	Severity Severity `json:"severity"`

	// Message is a human-readable result message
	Message string `json:"message"`

	// Details contains additional context
	Details map[string]interface{} `json:"details,omitempty"`

	// Violations lists specific violations
	Violations []Violation `json:"violations,omitempty"`
}

// Violation represents a specific policy violation
type Violation struct {
	// Resource is the violating resource
	Resource string `json:"resource"`

	// Message describes the violation
	Message string `json:"message"`

	// Details contains additional context
	Details map[string]interface{} `json:"details,omitempty"`
}

// Severity levels for policy violations
type Severity string

const (
	// SeverityInfo is informational only
	SeverityInfo Severity = "info"

	// SeverityWarning is a warning that doesn't block
	SeverityWarning Severity = "warning"

	// SeverityError is an error but doesn't block
	SeverityError Severity = "error"

	// SeverityBlock blocks deployment
	SeverityBlock Severity = "block"
)

// Evaluator runs all policy rules
type Evaluator interface {
	// RegisterRule adds a rule to the evaluator
	RegisterRule(rule Rule) error

	// Evaluate runs all rules and returns results
	Evaluate(ctx context.Context, current *types.CostGraph, prev *types.CostGraph) (*EvaluationResult, error)

	// EvaluateRules runs specific rules
	EvaluateRules(ctx context.Context, ruleNames []string, current *types.CostGraph, prev *types.CostGraph) (*EvaluationResult, error)
}

// EvaluationResult contains all rule results
type EvaluationResult struct {
	// Results contains individual rule results
	Results []*RuleResult `json:"results"`

	// PassedCount is the number of passed rules
	PassedCount int `json:"passed_count"`

	// FailedCount is the number of failed rules
	FailedCount int `json:"failed_count"`

	// Blocked indicates if any rule blocks deployment
	Blocked bool `json:"blocked"`

	// BlockReason explains why deployment is blocked
	BlockReason string `json:"block_reason,omitempty"`
}

// HasFailures returns true if any rules failed
func (r *EvaluationResult) HasFailures() bool {
	return r.FailedCount > 0
}

// GetBlockingRules returns rules that block deployment
func (r *EvaluationResult) GetBlockingRules() []*RuleResult {
	var blocking []*RuleResult
	for _, result := range r.Results {
		if !result.Passed && result.Severity == SeverityBlock {
			blocking = append(blocking, result)
		}
	}
	return blocking
}

// PolicyConfig contains policy configuration
type PolicyConfig struct {
	// Rules are the rules to evaluate
	Rules []RuleConfig `json:"rules"`

	// StopOnBlock stops evaluation on first blocking rule
	StopOnBlock bool `json:"stop_on_block"`
}

// RuleConfig contains configuration for a specific rule
type RuleConfig struct {
	// Name is the rule name
	Name string `json:"name"`

	// Enabled indicates if the rule is enabled
	Enabled bool `json:"enabled"`

	// Severity overrides the default severity
	Severity *Severity `json:"severity,omitempty"`

	// Parameters contains rule-specific parameters
	Parameters map[string]interface{} `json:"parameters,omitempty"`
}

################################################################################
# FILE: :\good projects\cost estimation\core\policy\explanation.go
# TYPE: go
# SIZE: 11794 bytes
################################################################################
// Package policy - Explainable policy results
// Policies explain WHY they failed, not just THAT they failed.
package policy

import (
	"fmt"
	"sort"
	"strings"

	"terraform-cost/core/determinism"
	"terraform-cost/core/model"
)

// ExplainedResult is a policy result with full explanation
type ExplainedResult struct {
	PolicyName string
	Passed     bool

	// Short summary
	Summary string

	// Detailed explanation
	Explanation *PolicyExplanation

	// Recommendations
	Recommendations []Recommendation
}

// PolicyExplanation provides deep explanation of policy outcome
type PolicyExplanation struct {
	// What the policy checks
	PolicyDescription string

	// What threshold/limit was applied
	Threshold *ThresholdInfo

	// What was analyzed
	AnalyzedScope AnalysisScope

	// What caused the violation (if failed)
	Violations []ViolationDetail

	// What contributed most to the outcome
	TopContributors []Contributor

	// Confidence considerations
	ConfidenceImpact *ConfidenceImpactInfo
}

// ThresholdInfo describes policy thresholds
type ThresholdInfo struct {
	Name      string // e.g., "monthly_budget"
	Value     string // e.g., "$1000.00"
	Actual    string // e.g., "$1234.56"
	Exceeded  bool
	ExcessBy  string // e.g., "$234.56 (23.5%)"
}

// AnalysisScope describes what was analyzed
type AnalysisScope struct {
	TotalInstances   int
	TotalComponents  int
	AnalyzedTypes    []string
	ExcludedTypes    []string
	TimeRange        string // if applicable
}

// ViolationDetail explains a specific violation
type ViolationDetail struct {
	// What violated
	InstanceAddress model.CanonicalAddress
	Component       string

	// Why it violated
	Reason string

	// How much impact
	CostImpact determinism.Money

	// What would fix it
	SuggestedFix string

	// Related lineage
	FormulaUsed   string
	RateUsed      string
	UsageAssumed  string
}

// Contributor identifies what contributed to outcome
type Contributor struct {
	Category string // "instance", "component", "rate", "usage"
	Name     string
	Impact   determinism.Money
	Percent  float64
	Reason   string
}

// ConfidenceImpactInfo describes how confidence affected the policy
type ConfidenceImpactInfo struct {
	OverallConfidence float64
	LowConfidenceItems int
	AffectedByUnknowns bool
	UnknownCount       int
	Caveat             string // e.g., "Result may change when unknowns resolve"
}

// Recommendation is a suggested action
type Recommendation struct {
	Priority    int    // 1=critical, 2=high, 3=medium
	Action      string
	Rationale   string
	EstimatedSavings *determinism.Money
}

// ExplainablePolicy is a policy that provides explanations
type ExplainablePolicy interface {
	Name() string
	Description() string
	EvaluateWithExplanation(ctx *FullLineageContext) (*ExplainedResult, error)
}

// ExplainedBudgetPolicy is a budget policy with explanations
type ExplainedBudgetPolicy struct {
	name          string
	description   string
	monthlyBudget determinism.Money
	warnThreshold float64
}

// NewExplainedBudgetPolicy creates an explainable budget policy
func NewExplainedBudgetPolicy(name string, budget determinism.Money, warnAt float64) *ExplainedBudgetPolicy {
	return &ExplainedBudgetPolicy{
		name:          name,
		description:   fmt.Sprintf("Ensures monthly costs stay within $%s budget", budget.String()),
		monthlyBudget: budget,
		warnThreshold: warnAt,
	}
}

func (p *ExplainedBudgetPolicy) Name() string        { return p.name }
func (p *ExplainedBudgetPolicy) Description() string { return p.description }

func (p *ExplainedBudgetPolicy) EvaluateWithExplanation(ctx *FullLineageContext) (*ExplainedResult, error) {
	result := &ExplainedResult{
		PolicyName: p.name,
		Passed:     true,
		Explanation: &PolicyExplanation{
			PolicyDescription: p.description,
			AnalyzedScope: AnalysisScope{
				TotalInstances: len(ctx.Instances),
			},
		},
	}

	// Count components
	for _, inst := range ctx.Instances {
		result.Explanation.AnalyzedScope.TotalComponents += len(inst.Components)
	}

	// Set threshold info
	result.Explanation.Threshold = &ThresholdInfo{
		Name:   "monthly_budget",
		Value:  "$" + p.monthlyBudget.String(),
		Actual: "$" + ctx.TotalMonthlyCost.String(),
	}

	// Check budget
	if ctx.TotalMonthlyCost.Cmp(p.monthlyBudget) > 0 {
		result.Passed = false
		excess := ctx.TotalMonthlyCost.Sub(p.monthlyBudget)
		percent := (ctx.TotalMonthlyCost.Float64() / p.monthlyBudget.Float64() - 1) * 100

		result.Summary = fmt.Sprintf("Monthly cost $%s exceeds budget $%s by $%s (%.1f%%)",
			ctx.TotalMonthlyCost.String(), p.monthlyBudget.String(), excess.String(), percent)

		result.Explanation.Threshold.Exceeded = true
		result.Explanation.Threshold.ExcessBy = fmt.Sprintf("$%s (%.1f%%)", excess.String(), percent)

		// Find top contributors
		result.Explanation.TopContributors = p.findTopContributors(ctx, 5)
		result.Explanation.Violations = p.buildViolations(ctx, excess)

		// Add recommendations
		result.Recommendations = p.generateRecommendations(ctx, excess)
	} else {
		percent := ctx.TotalMonthlyCost.Float64() / p.monthlyBudget.Float64() * 100
		result.Summary = fmt.Sprintf("Monthly cost $%s is within budget $%s (%.1f%% utilized)",
			ctx.TotalMonthlyCost.String(), p.monthlyBudget.String(), percent)

		// Warn if close to threshold
		if percent >= p.warnThreshold*100 {
			result.Recommendations = append(result.Recommendations, Recommendation{
				Priority:  3,
				Action:    "Monitor cost growth",
				Rationale: fmt.Sprintf("Currently at %.1f%% of budget", percent),
			})
		}
	}

	// Add confidence impact
	result.Explanation.ConfidenceImpact = &ConfidenceImpactInfo{
		OverallConfidence: ctx.OverallConfidence,
		LowConfidenceItems: len(ctx.LowConfidenceItems),
		UnknownCount:       len(ctx.Unknowns),
	}

	if ctx.OverallConfidence < 0.9 {
		result.Explanation.ConfidenceImpact.Caveat = 
			"Cost estimate has reduced confidence; actual costs may vary"
	}
	if len(ctx.Unknowns) > 0 {
		result.Explanation.ConfidenceImpact.AffectedByUnknowns = true
	}

	return result, nil
}

func (p *ExplainedBudgetPolicy) findTopContributors(ctx *FullLineageContext, n int) []Contributor {
	type item struct {
		addr model.CanonicalAddress
		cost determinism.Money
	}

	var items []item
	for _, inst := range ctx.Instances {
		items = append(items, item{
			addr: model.CanonicalAddress(inst.Address),
			cost: inst.MonthlyCost,
		})
	}

	sort.Slice(items, func(i, j int) bool {
		return items[i].cost.Cmp(items[j].cost) > 0
	})

	if n > len(items) {
		n = len(items)
	}

	contributors := make([]Contributor, n)
	for i := 0; i < n; i++ {
		percent := items[i].cost.Float64() / ctx.TotalMonthlyCost.Float64() * 100
		contributors[i] = Contributor{
			Category: "instance",
			Name:     string(items[i].addr),
			Impact:   items[i].cost,
			Percent:  percent,
			Reason:   fmt.Sprintf("%.1f%% of total cost", percent),
		}
	}

	return contributors
}

func (p *ExplainedBudgetPolicy) buildViolations(ctx *FullLineageContext, excess determinism.Money) []ViolationDetail {
	var violations []ViolationDetail

	// Find top 3 cost drivers as "violations"
	type item struct {
		inst *InstanceLineage
		cost determinism.Money
	}

	var items []item
	for _, inst := range ctx.Instances {
		items = append(items, item{inst: inst, cost: inst.MonthlyCost})
	}

	sort.Slice(items, func(i, j int) bool {
		return items[i].cost.Cmp(items[j].cost) > 0
	})

	n := 3
	if n > len(items) {
		n = len(items)
	}

	for i := 0; i < n; i++ {
		inst := items[i].inst
		violations = append(violations, ViolationDetail{
			InstanceAddress: model.CanonicalAddress(inst.Address),
			Reason:          fmt.Sprintf("High cost: $%s/month", inst.MonthlyCost.String()),
			CostImpact:      inst.MonthlyCost,
			SuggestedFix:    p.suggestFix(inst),
		})
	}

	return violations
}

func (p *ExplainedBudgetPolicy) suggestFix(inst *InstanceLineage) string {
	// Generate context-aware suggestions
	resourceType := strings.Split(string(inst.Address), ".")[0]

	switch {
	case strings.Contains(resourceType, "instance"):
		return "Consider using a smaller instance type or Spot instances"
	case strings.Contains(resourceType, "db") || strings.Contains(resourceType, "rds"):
		return "Consider Reserved Instances or Aurora Serverless"
	case strings.Contains(resourceType, "nat"):
		return "Consider VPC endpoints to reduce NAT traffic"
	case strings.Contains(resourceType, "lb"):
		return "Review target groups and consider consolidation"
	default:
		return "Review configuration for cost optimization"
	}
}

func (p *ExplainedBudgetPolicy) generateRecommendations(ctx *FullLineageContext, excess determinism.Money) []Recommendation {
	var recs []Recommendation

	recs = append(recs, Recommendation{
		Priority:  1,
		Action:    "Review top cost contributors",
		Rationale: "Focus on highest-cost instances for maximum impact",
	})

	// If many low confidence items
	if len(ctx.LowConfidenceItems) > len(ctx.Instances)/4 {
		recs = append(recs, Recommendation{
			Priority:  2,
			Action:    "Provide usage overrides for low-confidence components",
			Rationale: fmt.Sprintf("%d components have uncertain cost estimates", len(ctx.LowConfidenceItems)),
		})
	}

	// If unknowns present
	if len(ctx.Unknowns) > 0 {
		recs = append(recs, Recommendation{
			Priority:  2,
			Action:    "Resolve unknown Terraform values",
			Rationale: fmt.Sprintf("%d unknown values may affect final cost", len(ctx.Unknowns)),
		})
	}

	return recs
}

// FormatExplanation returns a human-readable explanation
func FormatExplanation(result *ExplainedResult) string {
	var sb strings.Builder

	// Header
	status := "âœ“ PASS"
	if !result.Passed {
		status = "âœ— FAIL"
	}
	sb.WriteString(fmt.Sprintf("Policy: %s [%s]\n", result.PolicyName, status))
	sb.WriteString(fmt.Sprintf("Summary: %s\n\n", result.Summary))

	if result.Explanation == nil {
		return sb.String()
	}

	// Threshold
	if t := result.Explanation.Threshold; t != nil {
		sb.WriteString("Threshold:\n")
		sb.WriteString(fmt.Sprintf("  %s: %s (actual: %s)\n", t.Name, t.Value, t.Actual))
		if t.Exceeded {
			sb.WriteString(fmt.Sprintf("  EXCEEDED by: %s\n", t.ExcessBy))
		}
		sb.WriteString("\n")
	}

	// Top contributors
	if len(result.Explanation.TopContributors) > 0 {
		sb.WriteString("Top Cost Contributors:\n")
		for i, c := range result.Explanation.TopContributors {
			sb.WriteString(fmt.Sprintf("  %d. %s: $%s (%.1f%%)\n", i+1, c.Name, c.Impact.String(), c.Percent))
		}
		sb.WriteString("\n")
	}

	// Violations
	if len(result.Explanation.Violations) > 0 {
		sb.WriteString("Violations:\n")
		for _, v := range result.Explanation.Violations {
			sb.WriteString(fmt.Sprintf("  â€¢ %s\n", v.InstanceAddress))
			sb.WriteString(fmt.Sprintf("    Reason: %s\n", v.Reason))
			sb.WriteString(fmt.Sprintf("    Suggestion: %s\n", v.SuggestedFix))
		}
		sb.WriteString("\n")
	}

	// Recommendations
	if len(result.Recommendations) > 0 {
		sb.WriteString("Recommendations:\n")
		for _, r := range result.Recommendations {
			priority := "!"
			if r.Priority == 1 {
				priority = "!!!"
			} else if r.Priority == 2 {
				priority = "!!"
			}
			sb.WriteString(fmt.Sprintf("  [%s] %s\n", priority, r.Action))
			sb.WriteString(fmt.Sprintf("       %s\n", r.Rationale))
		}
		sb.WriteString("\n")
	}

	// Confidence caveat
	if c := result.Explanation.ConfidenceImpact; c != nil && c.Caveat != "" {
		sb.WriteString(fmt.Sprintf("Note: %s\n", c.Caveat))
	}

	return sb.String()
}

################################################################################
# FILE: :\good projects\cost estimation\core\policy\full_lineage.go
# TYPE: go
# SIZE: 10052 bytes
################################################################################
// Package policy - Full lineage access for policies
// Policies can see the COMPLETE derivation chain.
package policy

import (
	"fmt"

	"terraform-cost/core/determinism"
	"terraform-cost/core/model"
	"terraform-cost/core/pricing"
)

// FullLineageContext provides COMPLETE cost derivation information to policies
type FullLineageContext struct {
	// Per-instance costs with full derivation
	Instances map[model.InstanceID]*InstanceLineage

	// Rollups
	TotalMonthlyCost determinism.Money
	TotalHourlyCost  determinism.Money

	// Confidence breakdown
	OverallConfidence    float64
	ConfidenceByInstance map[model.InstanceID]float64
	ConfidenceByComponent map[string]float64

	// Low confidence items
	LowConfidenceItems []LowConfidenceItem

	// Unknown tracking
	Unknowns []UnknownInfo
	UnknownsByInstance map[model.InstanceID][]UnknownInfo

	// Snapshot reference
	Snapshot SnapshotInfo
}

// InstanceLineage is the FULL derivation for a single instance
type InstanceLineage struct {
	// Instance identity
	InstanceID   model.InstanceID
	Address      model.InstanceAddress
	DefinitionID model.DefinitionID
	InstanceKey  model.InstanceKey

	// Provider context
	Provider string
	Region   string

	// Cost summary
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money
	Confidence  float64

	// FULL component breakdown
	Components []ComponentLineage

	// Resource tags
	Tags map[string]string

	// Unknowns affecting this instance
	Unknowns []UnknownInfo

	// Degradation reasons
	DegradedParts []DegradationInfo
}

// ComponentLineage is the FULL derivation for a cost component
type ComponentLineage struct {
	// Component identity
	Name        string
	ResourceType string

	// Cost
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money
	Confidence  float64

	// RATE: Which pricing rate was used
	Rate RateLineage

	// USAGE: Where usage data came from
	Usage UsageLineage

	// FORMULA: How cost was calculated
	Formula FormulaLineage

	// Is this component degraded?
	IsDegraded       bool
	DegradationReason string
}

// RateLineage tracks the pricing rate used
type RateLineage struct {
	// Rate identity
	RateID      pricing.RateID
	RateKey     pricing.RateKey

	// Rate details
	Price       string
	Unit        string
	Currency    string
	Description string

	// Tier info (for tiered pricing)
	Tier        *TierInfo

	// Was this rate found?
	Found       bool
	MissingReason string
}

// TierInfo describes pricing tier
type TierInfo struct {
	TierIndex   int
	StartUsage  string
	EndUsage    string
	TierPrice   string
}

// UsageLineage tracks where usage data came from
type UsageLineage struct {
	// Source of usage data
	Source UsageSourceType

	// The value used
	Value       float64
	Unit        string

	// Confidence in this value
	Confidence  float64

	// Was this overridden by user?
	IsOverridden bool

	// Profile used (if any)
	Profile     string

	// Assumptions made
	Assumptions []string

	// Was this unknown?
	IsUnknown   bool
	UnknownReason string
}

// UsageSourceType indicates where usage came from
type UsageSourceType int

const (
	UsageFromDefault UsageSourceType = iota
	UsageFromProfile
	UsageFromOverride
	UsageFromHistorical
	UsageFromEstimate
	UsageUnknown
)

// String returns the source name
func (s UsageSourceType) String() string {
	switch s {
	case UsageFromDefault:
		return "default"
	case UsageFromProfile:
		return "profile"
	case UsageFromOverride:
		return "override"
	case UsageFromHistorical:
		return "historical"
	case UsageFromEstimate:
		return "estimate"
	case UsageUnknown:
		return "unknown"
	default:
		return "unknown"
	}
}

// FormulaLineage tracks how cost was calculated
type FormulaLineage struct {
	// Formula name
	Name       string

	// Readable expression
	Expression string

	// All inputs used
	Inputs     map[string]FormulaInput

	// The output
	Output     string
}

// FormulaInput is a single input to a formula
type FormulaInput struct {
	Name       string
	Value      string
	Source     string // "rate", "usage", "constant"
	Confidence float64
}

// UnknownInfo describes an unknown value
type UnknownInfo struct {
	// What is unknown
	Address   string
	Component string
	Attribute string

	// Why it's unknown
	Reason    string

	// Impact on cost
	Impact    UnknownImpact
}

// UnknownImpact describes how an unknown affects cost
type UnknownImpact int

const (
	ImpactHigh   UnknownImpact = iota // Cost is unreliable
	ImpactMedium                       // Cost is approximate
	ImpactLow                          // Cost is slightly affected
)

// String returns the impact level
func (i UnknownImpact) String() string {
	switch i {
	case ImpactHigh:
		return "high"
	case ImpactMedium:
		return "medium"
	case ImpactLow:
		return "low"
	default:
		return "unknown"
	}
}

// DegradationInfo describes why a cost is degraded
type DegradationInfo struct {
	Component string
	Reason    string
	Impact    float64
}

// SnapshotInfo is the pricing snapshot reference
type SnapshotInfo struct {
	ID          pricing.SnapshotID
	ContentHash string
	Provider    string
	Region      string
	CreatedAt   string
	EffectiveAt string
	IsStale     bool
}

// LineageAwarePolicy is a policy that uses full lineage
type LineageAwarePolicy interface {
	Name() string
	EvaluateWithLineage(ctx *FullLineageContext) (*LineageAwarePolicyResult, error)
}

// LineageAwarePolicyResult is the result of a lineage-aware policy
type LineageAwarePolicyResult struct {
	Passed  bool
	Message string

	// What was analyzed
	AnalyzedInstances int
	AnalyzedComponents int

	// What failed
	FailedInstances   []model.InstanceID
	FailedComponents  []string

	// Cost impact
	AffectedCost determinism.Money

	// Full lineage for failures (for explainability)
	FailureLineage []*InstanceLineage

	// Recommendations
	Recommendations []string
}

// UsageConfidencePolicy fails if usage confidence is too low
type UsageConfidencePolicy struct {
	name          string
	minConfidence float64
}

// NewUsageConfidencePolicy creates a usage confidence policy
func NewUsageConfidencePolicy(name string, minConfidence float64) *UsageConfidencePolicy {
	return &UsageConfidencePolicy{name: name, minConfidence: minConfidence}
}

// Name returns the policy name
func (p *UsageConfidencePolicy) Name() string { return p.name }

// EvaluateWithLineage evaluates with full lineage access
func (p *UsageConfidencePolicy) EvaluateWithLineage(ctx *FullLineageContext) (*LineageAwarePolicyResult, error) {
	result := &LineageAwarePolicyResult{
		Passed: true,
	}

	var lowConfidenceInstances []*InstanceLineage
	var lowConfidenceComponents []string

	for _, inst := range ctx.Instances {
		result.AnalyzedInstances++

		for _, comp := range inst.Components {
			result.AnalyzedComponents++

			// Check USAGE confidence specifically
			if comp.Usage.Confidence < p.minConfidence {
				result.Passed = false

				if !containsID(result.FailedInstances, inst.InstanceID) {
					result.FailedInstances = append(result.FailedInstances, inst.InstanceID)
					lowConfidenceInstances = append(lowConfidenceInstances, inst)
				}

				lowConfidenceComponents = append(lowConfidenceComponents,
					string(inst.Address)+"/"+comp.Name)

				result.AffectedCost = result.AffectedCost.Add(comp.MonthlyCost)
			}
		}
	}

	if !result.Passed {
		result.Message = fmt.Sprintf(
			"%d components have usage confidence below %.0f%%",
			len(lowConfidenceComponents), p.minConfidence*100)

		result.FailedComponents = lowConfidenceComponents
		result.FailureLineage = lowConfidenceInstances

		result.Recommendations = []string{
			"Provide usage overrides for low-confidence components",
			"Use a usage profile to set expected values",
			"Review assumptions in the usage estimation",
		}
	} else {
		result.Message = fmt.Sprintf(
			"All %d components meet %.0f%% usage confidence",
			result.AnalyzedComponents, p.minConfidence*100)
	}

	return result, nil
}

// FormulaAuditPolicy checks that all formulas are documented
type FormulaAuditPolicy struct {
	name string
}

// NewFormulaAuditPolicy creates a formula audit policy
func NewFormulaAuditPolicy(name string) *FormulaAuditPolicy {
	return &FormulaAuditPolicy{name: name}
}

// Name returns the policy name
func (p *FormulaAuditPolicy) Name() string { return p.name }

// EvaluateWithLineage evaluates with full lineage access
func (p *FormulaAuditPolicy) EvaluateWithLineage(ctx *FullLineageContext) (*LineageAwarePolicyResult, error) {
	result := &LineageAwarePolicyResult{
		Passed: true,
	}

	var undocumentedFormulas []string

	for _, inst := range ctx.Instances {
		result.AnalyzedInstances++

		for _, comp := range inst.Components {
			result.AnalyzedComponents++

			// Check formula documentation
			if comp.Formula.Name == "" || comp.Formula.Expression == "" {
				result.Passed = false

				if !containsID(result.FailedInstances, inst.InstanceID) {
					result.FailedInstances = append(result.FailedInstances, inst.InstanceID)
				}

				undocumentedFormulas = append(undocumentedFormulas,
					string(inst.Address)+"/"+comp.Name)
			}
		}
	}

	if !result.Passed {
		result.Message = fmt.Sprintf(
			"%d formulas are undocumented",
			len(undocumentedFormulas))

		result.FailedComponents = undocumentedFormulas

		result.Recommendations = []string{
			"Ensure all pricing formulas are documented",
			"Review cost calculation logic",
		}
	} else {
		result.Message = fmt.Sprintf(
			"All %d formulas are documented",
			result.AnalyzedComponents)
	}

	return result, nil
}

func containsID(slice []model.InstanceID, id model.InstanceID) bool {
	for _, item := range slice {
		if item == id {
			return true
		}
	}
	return false
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\alias_rate_key.go
# TYPE: go
# SIZE: 6070 bytes
################################################################################
// Package pricing - Alias-aware rate key
// Alias MUST be part of rate key - no exceptions
package pricing

import (
	"fmt"
)

// AliasAwareRateKey is a rate key that ALWAYS includes provider alias
type AliasAwareRateKey struct {
	Provider     string
	Alias        string  // REQUIRED - empty means default
	Region       string
	AccountID    string  // Optional but recommended
	ResourceType string
	Component    string
	SKU          string

	// Computed key
	key string
}

// NewAliasAwareRateKey creates a rate key with required alias
func NewAliasAwareRateKey(provider, alias, region, resourceType, component string) *AliasAwareRateKey {
	k := &AliasAwareRateKey{
		Provider:     provider,
		Alias:        alias,
		Region:       region,
		ResourceType: resourceType,
		Component:    component,
	}
	k.computeKey()
	return k
}

// WithAccountID adds account ID to the key
func (k *AliasAwareRateKey) WithAccountID(accountID string) *AliasAwareRateKey {
	k.AccountID = accountID
	k.computeKey()
	return k
}

// WithSKU adds SKU to the key
func (k *AliasAwareRateKey) WithSKU(sku string) *AliasAwareRateKey {
	k.SKU = sku
	k.computeKey()
	return k
}

func (k *AliasAwareRateKey) computeKey() {
	// Format: provider:alias:region:account:type:component:sku
	// Alias is ALWAYS included (empty = default)
	aliasStr := k.Alias
	if aliasStr == "" {
		aliasStr = "_default_"
	}
	
	accountStr := k.AccountID
	if accountStr == "" {
		accountStr = "_"
	}

	skuStr := k.SKU
	if skuStr == "" {
		skuStr = "_"
	}

	k.key = fmt.Sprintf("%s:%s:%s:%s:%s:%s:%s",
		k.Provider, aliasStr, k.Region, accountStr,
		k.ResourceType, k.Component, skuStr,
	)
}

// Key returns the computed key string
func (k *AliasAwareRateKey) Key() string {
	return k.key
}

// String returns the key
func (k *AliasAwareRateKey) String() string {
	return k.key
}

// Matches checks if this key matches another
func (k *AliasAwareRateKey) Matches(other *AliasAwareRateKey) bool {
	return k.key == other.key
}

// MatchesProvider checks if provider/alias/region match
func (k *AliasAwareRateKey) MatchesProvider(provider, alias, region string) bool {
	return k.Provider == provider && k.Alias == alias && k.Region == region
}

// RateKeyBuilder builds alias-aware rate keys
type RateKeyBuilder struct {
	provider  string
	alias     string
	region    string
	accountID string
}

// NewRateKeyBuilder creates a builder
func NewRateKeyBuilder(provider, alias, region string) *RateKeyBuilder {
	return &RateKeyBuilder{
		provider: provider,
		alias:    alias,
		region:   region,
	}
}

// WithAccount sets account ID
func (b *RateKeyBuilder) WithAccount(accountID string) *RateKeyBuilder {
	b.accountID = accountID
	return b
}

// Build creates a rate key for a resource
func (b *RateKeyBuilder) Build(resourceType, component string) *AliasAwareRateKey {
	k := NewAliasAwareRateKey(b.provider, b.alias, b.region, resourceType, component)
	if b.accountID != "" {
		k.WithAccountID(b.accountID)
	}
	return k
}

// BuildWithSKU creates a rate key with SKU
func (b *RateKeyBuilder) BuildWithSKU(resourceType, component, sku string) *AliasAwareRateKey {
	k := NewAliasAwareRateKey(b.provider, b.alias, b.region, resourceType, component)
	if b.accountID != "" {
		k.WithAccountID(b.accountID)
	}
	k.WithSKU(sku)
	return k
}

// RateKeyValidator ensures rate keys include alias
type RateKeyValidator struct {
	errors []RateKeyError
}

// RateKeyError is an error in rate key construction
type RateKeyError struct {
	Context string
	Message string
}

// NewRateKeyValidator creates a validator
func NewRateKeyValidator() *RateKeyValidator {
	return &RateKeyValidator{
		errors: []RateKeyError{},
	}
}

// ValidateKey ensures a key is properly formed
func (v *RateKeyValidator) ValidateKey(key *AliasAwareRateKey, context string) bool {
	if key.Provider == "" {
		v.errors = append(v.errors, RateKeyError{
			Context: context,
			Message: "provider is required",
		})
		return false
	}
	if key.Region == "" {
		v.errors = append(v.errors, RateKeyError{
			Context: context,
			Message: "region is required",
		})
		return false
	}
	if key.ResourceType == "" {
		v.errors = append(v.errors, RateKeyError{
			Context: context,
			Message: "resource type is required",
		})
		return false
	}
	return true
}

// GetErrors returns all errors
func (v *RateKeyValidator) GetErrors() []RateKeyError {
	return v.errors
}

// AliasAwareRateResolver resolves rates with alias awareness
type AliasAwareRateResolver struct {
	validator *RateKeyValidator
}

// NewAliasAwareRateResolver creates a resolver
func NewAliasAwareRateResolver() *AliasAwareRateResolver {
	return &AliasAwareRateResolver{
		validator: NewRateKeyValidator(),
	}
}

// ResolveRate resolves a rate, ensuring alias is included
func (r *AliasAwareRateResolver) ResolveRate(snapshot *PricingSnapshot, key *AliasAwareRateKey) (*RateEntry, error) {
	if !r.validator.ValidateKey(key, key.ResourceType) {
		return nil, fmt.Errorf("invalid rate key for %s", key.ResourceType)
	}

	// Lookup with full alias-aware key
	rate, ok := snapshot.LookupRateByKey(key.Key())
	if !ok {
		// Try fallback to default alias
		if key.Alias != "" {
			fallbackKey := NewAliasAwareRateKey(key.Provider, "", key.Region, key.ResourceType, key.Component)
			rate, ok = snapshot.LookupRateByKey(fallbackKey.Key())
			if ok {
				return rate, nil
			}
		}
		return nil, &RateNotFoundError{Key: key.Key()}
	}

	return rate, nil
}

// RateNotFoundError indicates a rate was not found
type RateNotFoundError struct {
	Key string
}

func (e *RateNotFoundError) Error() string {
	return "rate not found: " + e.Key
}

// LookupRateByKey looks up a rate by key string
func (s *PricingSnapshot) LookupRateByKey(key string) (*RateEntry, bool) {
	for i := range s.rates {
		if s.rates[i].Key.String() == key {
			return &s.rates[i], true
		}
	}
	return nil, false
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\cache_governance.go
# TYPE: go
# SIZE: 7679 bytes
################################################################################
// Package pricing - Cache governance with TTL and schema versioning
// Stale pricing is silent failure. Governance is mandatory.
package pricing

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"sync"
	"time"
)

// CacheGovernance manages pricing cache lifecycle
type CacheGovernance struct {
	// TTL policy
	defaultTTL time.Duration
	perSourceTTL map[string]time.Duration

	// Schema versioning
	schemaVersions map[string]string

	// Provider metadata hashes
	providerHashes map[string]string

	// Cache entries with metadata
	entries map[string]*CacheEntry

	// Lock
	mu sync.RWMutex
}

// CacheEntry is a cached pricing entry with governance metadata
type CacheEntry struct {
	Key           string
	Value         interface{}
	SnapshotID    string
	SchemaVersion string
	ProviderHash  string
	CreatedAt     time.Time
	ExpiresAt     time.Time
	AccessCount   int
	LastAccessed  time.Time
}

// IsExpired checks if the entry has expired
func (e *CacheEntry) IsExpired() bool {
	return time.Now().After(e.ExpiresAt)
}

// IsStale checks if the entry is stale (schema/provider changed)
func (e *CacheEntry) IsStale(currentSchema, currentProviderHash string) bool {
	if e.SchemaVersion != currentSchema {
		return true
	}
	if e.ProviderHash != currentProviderHash {
		return true
	}
	return false
}

// CachePolicy defines cache behavior
type CachePolicy struct {
	// TTL for entries
	TTL time.Duration

	// Max entries
	MaxEntries int

	// Schema version
	SchemaVersion string

	// Force refresh on schema change
	RefreshOnSchemaChange bool

	// Force refresh on provider update
	RefreshOnProviderUpdate bool
}

// DefaultCachePolicy returns the default policy
func DefaultCachePolicy() *CachePolicy {
	return &CachePolicy{
		TTL:                     24 * time.Hour,
		MaxEntries:              10000,
		SchemaVersion:           "1.0",
		RefreshOnSchemaChange:   true,
		RefreshOnProviderUpdate: true,
	}
}

// NewCacheGovernance creates a new governance instance
func NewCacheGovernance(policy *CachePolicy) *CacheGovernance {
	if policy == nil {
		policy = DefaultCachePolicy()
	}
	return &CacheGovernance{
		defaultTTL:     policy.TTL,
		perSourceTTL:   make(map[string]time.Duration),
		schemaVersions: make(map[string]string),
		providerHashes: make(map[string]string),
		entries:        make(map[string]*CacheEntry),
	}
}

// SetSourceTTL sets TTL for a specific source
func (g *CacheGovernance) SetSourceTTL(source string, ttl time.Duration) {
	g.mu.Lock()
	defer g.mu.Unlock()
	g.perSourceTTL[source] = ttl
}

// SetSchemaVersion sets the schema version for a provider
func (g *CacheGovernance) SetSchemaVersion(provider, version string) {
	g.mu.Lock()
	defer g.mu.Unlock()
	g.schemaVersions[provider] = version
}

// SetProviderHash sets the metadata hash for a provider
func (g *CacheGovernance) SetProviderHash(provider, hash string) {
	g.mu.Lock()
	defer g.mu.Unlock()
	g.providerHashes[provider] = hash
}

// Get retrieves an entry if valid
func (g *CacheGovernance) Get(key, provider string) (interface{}, bool) {
	g.mu.RLock()
	entry, exists := g.entries[key]
	g.mu.RUnlock()

	if !exists {
		return nil, false
	}

	// Check expiration
	if entry.IsExpired() {
		g.Invalidate(key)
		return nil, false
	}

	// Check staleness
	currentSchema := g.schemaVersions[provider]
	currentHash := g.providerHashes[provider]
	if entry.IsStale(currentSchema, currentHash) {
		g.Invalidate(key)
		return nil, false
	}

	// Update access stats
	g.mu.Lock()
	entry.AccessCount++
	entry.LastAccessed = time.Now()
	g.mu.Unlock()

	return entry.Value, true
}

// Put stores an entry with metadata
func (g *CacheGovernance) Put(key string, value interface{}, provider, snapshotID string) {
	g.mu.Lock()
	defer g.mu.Unlock()

	ttl := g.defaultTTL
	if sourceTTL, ok := g.perSourceTTL[provider]; ok {
		ttl = sourceTTL
	}

	now := time.Now()
	g.entries[key] = &CacheEntry{
		Key:           key,
		Value:         value,
		SnapshotID:    snapshotID,
		SchemaVersion: g.schemaVersions[provider],
		ProviderHash:  g.providerHashes[provider],
		CreatedAt:     now,
		ExpiresAt:     now.Add(ttl),
		AccessCount:   0,
		LastAccessed:  now,
	}
}

// Invalidate removes an entry
func (g *CacheGovernance) Invalidate(key string) {
	g.mu.Lock()
	defer g.mu.Unlock()
	delete(g.entries, key)
}

// InvalidateProvider invalidates all entries for a provider
func (g *CacheGovernance) InvalidateProvider(provider string) {
	g.mu.Lock()
	defer g.mu.Unlock()

	// Build list of keys to remove
	toRemove := []string{}
	currentSchema := g.schemaVersions[provider]
	currentHash := g.providerHashes[provider]

	for key, entry := range g.entries {
		if entry.IsStale(currentSchema, currentHash) {
			toRemove = append(toRemove, key)
		}
	}

	for _, key := range toRemove {
		delete(g.entries, key)
	}
}

// InvalidateExpired removes all expired entries
func (g *CacheGovernance) InvalidateExpired() int {
	g.mu.Lock()
	defer g.mu.Unlock()

	count := 0
	for key, entry := range g.entries {
		if entry.IsExpired() {
			delete(g.entries, key)
			count++
		}
	}
	return count
}

// Stats returns cache statistics
func (g *CacheGovernance) Stats() *CacheStats {
	g.mu.RLock()
	defer g.mu.RUnlock()

	stats := &CacheStats{
		TotalEntries:   len(g.entries),
		ExpiredEntries: 0,
		StaleEntries:   0,
	}

	for _, entry := range g.entries {
		if entry.IsExpired() {
			stats.ExpiredEntries++
		}
	}

	return stats
}

// CacheStats contains cache statistics
type CacheStats struct {
	TotalEntries   int
	ExpiredEntries int
	StaleEntries   int
}

// ComputeProviderHash computes a hash of provider metadata
func ComputeProviderHash(provider string, version string, lastUpdated time.Time) string {
	h := sha256.New()
	h.Write([]byte(provider))
	h.Write([]byte(version))
	h.Write([]byte(lastUpdated.Format(time.RFC3339)))
	return hex.EncodeToString(h.Sum(nil))[:16]
}

// SchemaRegistry tracks schema versions
type SchemaRegistry struct {
	versions map[string]SchemaVersion
	mu       sync.RWMutex
}

// SchemaVersion describes a schema version
type SchemaVersion struct {
	Provider    string
	Version     string
	Hash        string
	FieldCount  int
	LastUpdated time.Time
}

// NewSchemaRegistry creates a new registry
func NewSchemaRegistry() *SchemaRegistry {
	return &SchemaRegistry{
		versions: make(map[string]SchemaVersion),
	}
}

// Register registers a schema version
func (r *SchemaRegistry) Register(provider, version string, fieldCount int) {
	r.mu.Lock()
	defer r.mu.Unlock()

	hash := computeSchemaHash(provider, version, fieldCount)
	r.versions[provider] = SchemaVersion{
		Provider:    provider,
		Version:     version,
		Hash:        hash,
		FieldCount:  fieldCount,
		LastUpdated: time.Now(),
	}
}

// Get returns the schema version for a provider
func (r *SchemaRegistry) Get(provider string) (SchemaVersion, bool) {
	r.mu.RLock()
	defer r.mu.RUnlock()
	v, ok := r.versions[provider]
	return v, ok
}

// HasChanged checks if schema has changed
func (r *SchemaRegistry) HasChanged(provider, previousHash string) bool {
	r.mu.RLock()
	defer r.mu.RUnlock()
	if v, ok := r.versions[provider]; ok {
		return v.Hash != previousHash
	}
	return true
}

func computeSchemaHash(provider, version string, fieldCount int) string {
	h := sha256.New()
	h.Write([]byte(provider))
	h.Write([]byte(version))
	h.Write([]byte(fmt.Sprintf("%d", fieldCount)))
	return hex.EncodeToString(h.Sum(nil))[:16]
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\enforcer.go
# TYPE: go
# SIZE: 7864 bytes
################################################################################
// Package pricing - Mandatory snapshot enforcement
// No cost can be computed without a valid, verified snapshot.
package pricing

import (
	"context"
	"errors"
	"fmt"
	"sync"
	"time"

	"terraform-cost/core/determinism"
)

// ErrNoSnapshot is returned when no pricing snapshot is available
var ErrNoSnapshot = errors.New("pricing snapshot required but not provided")

// ErrSnapshotInvalid is returned when snapshot fails verification
var ErrSnapshotInvalid = errors.New("pricing snapshot failed integrity verification")

// ErrSnapshotExpired is returned when snapshot is too old
var ErrSnapshotExpired = errors.New("pricing snapshot has expired")

// ErrRateNotFound is returned when a rate is not in the snapshot
var ErrRateNotFound = errors.New("rate not found in pricing snapshot")

// EnforcedResolver wraps a pricing resolver with mandatory snapshot enforcement.
// It is IMPOSSIBLE to get pricing without a valid snapshot.
type EnforcedResolver struct {
	store         SnapshotStore
	maxAge        time.Duration
	strictMode    bool
	mu            sync.RWMutex
	activeSnapshot *PricingSnapshot
}

// SnapshotStore provides snapshot storage
type SnapshotStore interface {
	// Get retrieves a specific snapshot by ID
	Get(ctx context.Context, id SnapshotID) (*PricingSnapshot, error)

	// GetLatest retrieves the latest snapshot for a provider/region
	// Returns error if no snapshot exists
	GetLatest(ctx context.Context, provider, region string) (*PricingSnapshot, error)

	// Store saves a snapshot
	Store(ctx context.Context, snapshot *PricingSnapshot) error
}

// EnforcedResolverConfig configures the enforced resolver
type EnforcedResolverConfig struct {
	// MaxAge is the maximum age of a snapshot before it's considered expired
	MaxAge time.Duration

	// StrictMode fails on any missing rate (vs degraded estimation)
	StrictMode bool
}

// NewEnforcedResolver creates a resolver that REQUIRES snapshots
func NewEnforcedResolver(store SnapshotStore, config EnforcedResolverConfig) *EnforcedResolver {
	maxAge := config.MaxAge
	if maxAge == 0 {
		maxAge = 24 * time.Hour // Default: 24 hours
	}
	return &EnforcedResolver{
		store:      store,
		maxAge:     maxAge,
		strictMode: config.StrictMode,
	}
}

// SnapshotRequest specifies which snapshot to use
type SnapshotRequest struct {
	// SnapshotID - if provided, use this specific snapshot
	SnapshotID SnapshotID

	// Otherwise, find latest for provider/region
	Provider string
	Region   string

	// AllowExpired allows using expired snapshots (with warning)
	AllowExpired bool
}

// ResolveResult contains the resolution result
type ResolveResult struct {
	// Snapshot used (ALWAYS set on success)
	Snapshot *PricingSnapshot

	// Rate found (nil if not found)
	Rate *RateEntry

	// Status
	Found   bool
	Reason  string
	Warning string
}

// GetSnapshot retrieves a snapshot - NEVER returns nil snapshot on success
func (r *EnforcedResolver) GetSnapshot(ctx context.Context, req SnapshotRequest) (*PricingSnapshot, error) {
	var snapshot *PricingSnapshot
	var err error

	// Try specific ID first
	if req.SnapshotID != "" {
		snapshot, err = r.store.Get(ctx, req.SnapshotID)
		if err != nil {
			return nil, fmt.Errorf("failed to get snapshot %s: %w", req.SnapshotID, err)
		}
	} else if req.Provider != "" && req.Region != "" {
		snapshot, err = r.store.GetLatest(ctx, req.Provider, req.Region)
		if err != nil {
			return nil, fmt.Errorf("no snapshot for %s/%s: %w", req.Provider, req.Region, ErrNoSnapshot)
		}
	} else {
		return nil, ErrNoSnapshot
	}

	if snapshot == nil {
		return nil, ErrNoSnapshot
	}

	// Verify integrity
	if !snapshot.Verify() {
		return nil, ErrSnapshotInvalid
	}

	// Check expiry
	if time.Since(snapshot.CreatedAt) > r.maxAge {
		if !req.AllowExpired {
			return nil, fmt.Errorf("%w: snapshot is %v old (max: %v)",
				ErrSnapshotExpired, time.Since(snapshot.CreatedAt), r.maxAge)
		}
	}

	return snapshot, nil
}

// LookupRate finds a rate in a snapshot - snapshot is REQUIRED
func (r *EnforcedResolver) LookupRate(
	snapshot *PricingSnapshot,
	resourceType, component string,
	attrs map[string]string,
) (*ResolveResult, error) {
	if snapshot == nil {
		return nil, ErrNoSnapshot
	}

	result := &ResolveResult{
		Snapshot: snapshot,
	}

	rate, found := snapshot.LookupRate(resourceType, component, attrs)
	if !found {
		result.Found = false
		result.Reason = fmt.Sprintf("no rate for %s/%s in snapshot %s", resourceType, component, snapshot.ID)

		if r.strictMode {
			return result, ErrRateNotFound
		}
		return result, nil
	}

	result.Found = true
	result.Rate = rate
	return result, nil
}

// MustHaveSnapshot ensures a snapshot exists or panics - for critical paths
func MustHaveSnapshot(snapshot *PricingSnapshot) {
	if snapshot == nil {
		panic("BUG: pricing snapshot is nil - this should never happen")
	}
}

// CostCalculation tracks a cost calculation with mandatory snapshot reference
type CostCalculation struct {
	// MANDATORY: Snapshot reference
	SnapshotID   SnapshotID
	SnapshotHash determinism.ContentHash

	// The calculation
	InstanceID  string
	Component   string
	MonthlyCost determinism.Money
	HourlyCost  determinism.Money

	// Rate used
	RateID  RateID
	RateKey RateKey

	// Formula applied
	Formula FormulaApplication

	// Confidence (reduced if rate was missing or usage unknown)
	Confidence float64

	// Degradation info
	IsDegraded    bool
	DegradedParts []DegradedPart
}

// DegradedPart describes why a calculation was degraded
type DegradedPart struct {
	Component string
	Reason    DegradationReason
	Message   string
}

// DegradationReason explains why estimation is degraded
type DegradationReason int

const (
	ReasonRateMissing DegradationReason = iota
	ReasonUsageUnknown
	ReasonResourceUnknown
	ReasonSnapshotStale
)

// String returns the reason name
func (r DegradationReason) String() string {
	switch r {
	case ReasonRateMissing:
		return "rate_missing"
	case ReasonUsageUnknown:
		return "usage_unknown"
	case ReasonResourceUnknown:
		return "resource_unknown"
	case ReasonSnapshotStale:
		return "snapshot_stale"
	default:
		return "unknown"
	}
}

// InMemorySnapshotStore is a simple in-memory store for testing
type InMemorySnapshotStore struct {
	mu        sync.RWMutex
	snapshots map[SnapshotID]*PricingSnapshot
	latest    map[string]*PricingSnapshot // key: provider:region
}

// NewInMemorySnapshotStore creates an in-memory store
func NewInMemorySnapshotStore() *InMemorySnapshotStore {
	return &InMemorySnapshotStore{
		snapshots: make(map[SnapshotID]*PricingSnapshot),
		latest:    make(map[string]*PricingSnapshot),
	}
}

// Get retrieves a snapshot by ID
func (s *InMemorySnapshotStore) Get(ctx context.Context, id SnapshotID) (*PricingSnapshot, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	snap, ok := s.snapshots[id]
	if !ok {
		return nil, ErrNoSnapshot
	}
	return snap, nil
}

// GetLatest retrieves the latest snapshot for provider/region
func (s *InMemorySnapshotStore) GetLatest(ctx context.Context, provider, region string) (*PricingSnapshot, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()
	key := provider + ":" + region
	snap, ok := s.latest[key]
	if !ok {
		return nil, ErrNoSnapshot
	}
	return snap, nil
}

// Store saves a snapshot
func (s *InMemorySnapshotStore) Store(ctx context.Context, snapshot *PricingSnapshot) error {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.snapshots[snapshot.ID] = snapshot
	key := snapshot.Provider + ":" + snapshot.Region
	// Update latest if this is newer
	if existing, ok := s.latest[key]; !ok || snapshot.CreatedAt.After(existing.CreatedAt) {
		s.latest[key] = snapshot
	}
	return nil
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\immutable_store.go
# TYPE: go
# SIZE: 8980 bytes
################################################################################
// Package pricing - Immutable snapshot storage
// Snapshots are write-once, content-hashed, and versioned.
// No silent updates. Ever.
package pricing

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"errors"
	"fmt"
	"os"
	"path/filepath"
	"sync"
	"time"
)

// ImmutabilityError is returned when attempting to violate immutability
var ErrImmutabilityViolation = errors.New("immutability violation: snapshot cannot be modified")

// ErrHashMismatch is returned when stored hash doesn't match computed hash
var ErrHashMismatch = errors.New("snapshot hash mismatch: data may be corrupted")

// ImmutableSnapshotStore is a storage layer that ENFORCES immutability.
// Once a snapshot is written, it can NEVER be overwritten.
type ImmutableSnapshotStore struct {
	mu       sync.RWMutex
	basePath string

	// In-memory index
	index map[SnapshotID]*SnapshotMetadata

	// Latest per provider:region
	latest map[string]SnapshotID
}

// SnapshotMetadata is stored alongside each snapshot
type SnapshotMetadata struct {
	ID          SnapshotID `json:"id"`
	ContentHash string     `json:"content_hash"`
	CreatedAt   time.Time  `json:"created_at"`
	EffectiveAt time.Time  `json:"effective_at"`
	Provider    string     `json:"provider"`
	Region      string     `json:"region"`
	Version     int        `json:"version"`
	Size        int64      `json:"size"`
	FilePath    string     `json:"file_path"`
}

// NewImmutableSnapshotStore creates a new immutable store
func NewImmutableSnapshotStore(basePath string) (*ImmutableSnapshotStore, error) {
	if err := os.MkdirAll(basePath, 0755); err != nil {
		return nil, fmt.Errorf("failed to create snapshot directory: %w", err)
	}

	store := &ImmutableSnapshotStore{
		basePath: basePath,
		index:    make(map[SnapshotID]*SnapshotMetadata),
		latest:   make(map[string]SnapshotID),
	}

	// Load existing index
	if err := store.loadIndex(); err != nil {
		// Index doesn't exist yet - that's OK
	}

	return store, nil
}

// Store writes a snapshot - FAILS if already exists
func (s *ImmutableSnapshotStore) Store(ctx context.Context, snapshot *PricingSnapshot) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	// Check if already exists
	if _, exists := s.index[snapshot.ID]; exists {
		return ErrImmutabilityViolation
	}

	// Compute content hash
	data, err := s.serialize(snapshot)
	if err != nil {
		return fmt.Errorf("failed to serialize snapshot: %w", err)
	}

	computedHash := sha256.Sum256(data)
	hashStr := hex.EncodeToString(computedHash[:])

	// Verify against snapshot's hash
	if hashStr != snapshot.ContentHash.Hex() {
		return ErrHashMismatch
	}

	// Write to file
	filename := fmt.Sprintf("%s_%s.json", snapshot.ID, hashStr[:8])
	filePath := filepath.Join(s.basePath, filename)

	// Check file doesn't already exist (belt and suspenders)
	if _, err := os.Stat(filePath); err == nil {
		return ErrImmutabilityViolation
	}

	// Write file
	if err := os.WriteFile(filePath, data, 0444); err != nil { // Read-only!
		return fmt.Errorf("failed to write snapshot: %w", err)
	}

	// Update index
	meta := &SnapshotMetadata{
		ID:          snapshot.ID,
		ContentHash: hashStr,
		CreatedAt:   snapshot.CreatedAt,
		EffectiveAt: snapshot.EffectiveAt,
		Provider:    snapshot.Provider,
		Region:      snapshot.Region,
		Version:     1, // First version
		Size:        int64(len(data)),
		FilePath:    filePath,
	}

	s.index[snapshot.ID] = meta

	// Update latest
	key := snapshot.Provider + ":" + snapshot.Region
	if current, ok := s.latest[key]; !ok {
		s.latest[key] = snapshot.ID
	} else {
		// Only update if newer
		if currentMeta := s.index[current]; currentMeta.CreatedAt.Before(snapshot.CreatedAt) {
			s.latest[key] = snapshot.ID
		}
	}

	// Persist index
	return s.saveIndex()
}

// Get retrieves a snapshot by ID - verifies hash
func (s *ImmutableSnapshotStore) Get(ctx context.Context, id SnapshotID) (*PricingSnapshot, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	meta, ok := s.index[id]
	if !ok {
		return nil, ErrNoSnapshot
	}

	// Read file
	data, err := os.ReadFile(meta.FilePath)
	if err != nil {
		return nil, fmt.Errorf("failed to read snapshot: %w", err)
	}

	// Verify hash
	computedHash := sha256.Sum256(data)
	hashStr := hex.EncodeToString(computedHash[:])
	if hashStr != meta.ContentHash {
		return nil, ErrHashMismatch
	}

	// Deserialize
	return s.deserialize(data)
}

// GetLatest retrieves the latest snapshot for provider/region
func (s *ImmutableSnapshotStore) GetLatest(ctx context.Context, provider, region string) (*PricingSnapshot, error) {
	s.mu.RLock()
	key := provider + ":" + region
	id, ok := s.latest[key]
	s.mu.RUnlock()

	if !ok {
		return nil, ErrNoSnapshot
	}

	return s.Get(ctx, id)
}

// ListVersions returns all versions for a provider/region
func (s *ImmutableSnapshotStore) ListVersions(provider, region string) []*SnapshotMetadata {
	s.mu.RLock()
	defer s.mu.RUnlock()

	var result []*SnapshotMetadata
	for _, meta := range s.index {
		if meta.Provider == provider && meta.Region == region {
			result = append(result, meta)
		}
	}
	return result
}

// VerifyIntegrity checks all stored snapshots
func (s *ImmutableSnapshotStore) VerifyIntegrity() ([]string, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	var corrupted []string

	for id, meta := range s.index {
		data, err := os.ReadFile(meta.FilePath)
		if err != nil {
			corrupted = append(corrupted, fmt.Sprintf("%s: file missing", id))
			continue
		}

		computedHash := sha256.Sum256(data)
		hashStr := hex.EncodeToString(computedHash[:])
		if hashStr != meta.ContentHash {
			corrupted = append(corrupted, fmt.Sprintf("%s: hash mismatch", id))
		}
	}

	return corrupted, nil
}

func (s *ImmutableSnapshotStore) serialize(snapshot *PricingSnapshot) ([]byte, error) {
	// Create a serializable version
	type serializableSnapshot struct {
		ID          SnapshotID         `json:"id"`
		ContentHash string             `json:"content_hash"`
		CreatedAt   time.Time          `json:"created_at"`
		EffectiveAt time.Time          `json:"effective_at"`
		Provider    string             `json:"provider"`
		Region      string             `json:"region"`
		Rates       []RateEntry        `json:"rates"`
		Coverage    SnapshotCoverage   `json:"coverage"`
	}

	ss := serializableSnapshot{
		ID:          snapshot.ID,
		ContentHash: snapshot.ContentHash.Hex(),
		CreatedAt:   snapshot.CreatedAt,
		EffectiveAt: snapshot.EffectiveAt,
		Provider:    snapshot.Provider,
		Region:      snapshot.Region,
		Rates:       snapshot.Rates(),
		Coverage:    snapshot.Coverage,
	}

	return json.MarshalIndent(ss, "", "  ")
}

func (s *ImmutableSnapshotStore) deserialize(data []byte) (*PricingSnapshot, error) {
	type serializableSnapshot struct {
		ID          SnapshotID         `json:"id"`
		ContentHash string             `json:"content_hash"`
		CreatedAt   time.Time          `json:"created_at"`
		EffectiveAt time.Time          `json:"effective_at"`
		Provider    string             `json:"provider"`
		Region      string             `json:"region"`
		Rates       []RateEntry        `json:"rates"`
		Coverage    SnapshotCoverage   `json:"coverage"`
	}

	var ss serializableSnapshot
	if err := json.Unmarshal(data, &ss); err != nil {
		return nil, err
	}

	// Rebuild snapshot using builder
	builder := NewSnapshotBuilder(ss.Provider, ss.Region).
		WithEffectiveAt(ss.EffectiveAt)

	for _, rate := range ss.Rates {
		builder.AddRate(rate.Key, rate.Price, rate.Unit, rate.Currency)
	}

	snapshot := builder.Build()
	return snapshot, nil
}

func (s *ImmutableSnapshotStore) loadIndex() error {
	indexPath := filepath.Join(s.basePath, "index.json")
	data, err := os.ReadFile(indexPath)
	if err != nil {
		return err
	}

	type indexFile struct {
		Snapshots map[SnapshotID]*SnapshotMetadata `json:"snapshots"`
		Latest    map[string]SnapshotID            `json:"latest"`
	}

	var idx indexFile
	if err := json.Unmarshal(data, &idx); err != nil {
		return err
	}

	s.index = idx.Snapshots
	s.latest = idx.Latest
	return nil
}

func (s *ImmutableSnapshotStore) saveIndex() error {
	indexPath := filepath.Join(s.basePath, "index.json")

	type indexFile struct {
		Snapshots map[SnapshotID]*SnapshotMetadata `json:"snapshots"`
		Latest    map[string]SnapshotID            `json:"latest"`
		UpdatedAt time.Time                        `json:"updated_at"`
	}

	idx := indexFile{
		Snapshots: s.index,
		Latest:    s.latest,
		UpdatedAt: time.Now().UTC(),
	}

	data, err := json.MarshalIndent(idx, "", "  ")
	if err != nil {
		return err
	}

	// Write atomically using temp file
	tempPath := indexPath + ".tmp"
	if err := os.WriteFile(tempPath, data, 0644); err != nil {
		return err
	}

	return os.Rename(tempPath, indexPath)
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\pricing_gate.go
# TYPE: go
# SIZE: 3094 bytes
################################################################################
// Package pricing - Pricing gate enforcement
// No pricing may occur before provider finalization.
// This is enforced with panic, not error return.
package pricing

import (
	"fmt"
	"sync"
)

// PricingGate enforces that pricing only occurs after provider finalization
type PricingGate struct {
	mu              sync.RWMutex
	frozen          bool
	frozenProviders map[string]*FrozenProvider
}

// FrozenProvider is an immutable provider configuration
type FrozenProvider struct {
	Provider  string
	Alias     string
	Region    string
	Account   string
	frozen    bool
}

// NewPricingGate creates a new gate
func NewPricingGate() *PricingGate {
	return &PricingGate{
		frozenProviders: make(map[string]*FrozenProvider),
	}
}

// FreezeProvider freezes a provider configuration
func (g *PricingGate) FreezeProvider(provider, alias, region, account string) *FrozenProvider {
	g.mu.Lock()
	defer g.mu.Unlock()

	if g.frozen {
		panic("INVARIANT VIOLATED: cannot add providers after gate is frozen")
	}

	key := provider + ":" + alias
	fp := &FrozenProvider{
		Provider: provider,
		Alias:    alias,
		Region:   region,
		Account:  account,
		frozen:   true,
	}
	g.frozenProviders[key] = fp
	return fp
}

// Freeze freezes the gate - no more providers can be added
func (g *PricingGate) Freeze() {
	g.mu.Lock()
	defer g.mu.Unlock()
	g.frozen = true
}

// IsFrozen returns whether the gate is frozen
func (g *PricingGate) IsFrozen() bool {
	g.mu.RLock()
	defer g.mu.RUnlock()
	return g.frozen
}

// MustGetProvider returns a provider or panics
func (g *PricingGate) MustGetProvider(provider, alias string) *FrozenProvider {
	g.mu.RLock()
	defer g.mu.RUnlock()

	if !g.frozen {
		panic("INVARIANT VIOLATED: pricing before provider finalization")
	}

	key := provider + ":" + alias
	fp, ok := g.frozenProviders[key]
	if !ok {
		panic(fmt.Sprintf("INVARIANT VIOLATED: provider %s not frozen", key))
	}
	return fp
}

// AssertCanPrice panics if pricing is not allowed
func (g *PricingGate) AssertCanPrice() {
	if !g.IsFrozen() {
		panic("INVARIANT VIOLATED: pricing before provider finalization")
	}
}

// BuildRateKey builds a rate key with mandatory alias
func (fp *FrozenProvider) BuildRateKey(resourceType, component string) *AliasAwareRateKey {
	if !fp.frozen {
		panic("INVARIANT VIOLATED: building rate key from unfrozen provider")
	}
	return NewAliasAwareRateKey(fp.Provider, fp.Alias, fp.Region, resourceType, component)
}

// BuildRateKeyWithAccount builds a rate key with account
func (fp *FrozenProvider) BuildRateKeyWithAccount(resourceType, component string) *AliasAwareRateKey {
	if !fp.frozen {
		panic("INVARIANT VIOLATED: building rate key from unfrozen provider")
	}
	key := NewAliasAwareRateKey(fp.Provider, fp.Alias, fp.Region, resourceType, component)
	key.WithAccountID(fp.Account)
	return key
}

// String returns provider identity
func (fp *FrozenProvider) String() string {
	if fp.Alias != "" {
		return fp.Provider + "." + fp.Alias
	}
	return fp.Provider
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\pricing_test.go
# TYPE: go
# SIZE: 4422 bytes
################################################################################
// Package pricing - Pricing invariant tests
// These tests PROVE the invariants are real by intentionally violating them.
package pricing

import (
	"testing"
)

// TestPricingBeforeFinalizationPanics proves pricing cannot occur before finalization
func TestPricingBeforeFinalizationPanics(t *testing.T) {
	defer func() {
		r := recover()
		if r == nil {
			t.Fatal("Expected panic when pricing before finalization, but no panic occurred")
		}
		msg, ok := r.(string)
		if !ok {
			t.Fatalf("Expected string panic, got %T: %v", r, r)
		}
		if len(msg) < 10 {
			t.Fatalf("Panic message too short: %s", msg)
		}
		t.Logf("Correctly panicked: %s", msg)
	}()

	// Create gate but DO NOT freeze it
	gate := NewPricingGate()
	gate.FreezeProvider("aws", "prod", "us-east-1", "123456789")
	// gate.Freeze() - intentionally NOT called

	// This MUST panic
	gate.AssertCanPrice()
}

// TestRateKeyWithoutAliasPanics proves alias is mandatory
func TestRateKeyWithoutAliasPanics(t *testing.T) {
	defer func() {
		r := recover()
		if r == nil {
			t.Fatal("Expected panic for RateKey without finalized provider, but no panic occurred")
		}
		t.Logf("Correctly panicked: %v", r)
	}()

	// Create unfinalized provider
	unfinalizedProvider := &unfinalizedProviderMock{}

	// This MUST panic
	_ = NewRateKeyStrict(unfinalizedProvider, "ec2", "us-east-1", nil)
}

// unfinalizedProviderMock is a mock that is NOT finalized
type unfinalizedProviderMock struct{}

func (m *unfinalizedProviderMock) Provider() string  { return "aws" }
func (m *unfinalizedProviderMock) Alias() string     { return "" }
func (m *unfinalizedProviderMock) IsFinalized() bool { return false }

// TestPricingGateFreezeWorks proves freezing works correctly
func TestPricingGateFreezeWorks(t *testing.T) {
	gate := NewPricingGate()
	gate.FreezeProvider("aws", "prod", "us-east-1", "123456789")
	gate.Freeze()

	// This should NOT panic
	defer func() {
		if r := recover(); r != nil {
			t.Fatalf("Unexpected panic after proper freezing: %v", r)
		}
	}()

	gate.AssertCanPrice()
	provider := gate.MustGetProvider("aws", "prod")
	if provider.Provider != "aws" {
		t.Errorf("Expected provider 'aws', got '%s'", provider.Provider)
	}
	if provider.Alias != "prod" {
		t.Errorf("Expected alias 'prod', got '%s'", provider.Alias)
	}
}

// TestRateKeyIncludesAlias proves alias is embedded in rate key
func TestRateKeyIncludesAlias(t *testing.T) {
	provider := NewFinalizedProvider("aws", "prod", "us-east-1", "123456789")
	rateKey := NewRateKeyStrict(provider, "ec2", "us-east-1", nil)

	key := rateKey.Key()
	if key == "" {
		t.Fatal("RateKey.Key() returned empty string")
	}

	// Key should include alias
	providerKey := rateKey.ProviderFullKey()
	if providerKey != "aws.prod" {
		t.Errorf("Expected ProviderFullKey 'aws.prod', got '%s'", providerKey)
	}

	t.Logf("RateKey: %s, ProviderFullKey: %s", key, providerKey)
}

// TestScopedPricingSnapshot proves snapshots are alias-scoped
func TestScopedPricingSnapshot(t *testing.T) {
	// Create two snapshots for different aliases
	snapshotProd := NewScopedPricingSnapshot("aws.prod", "us-east-1")
	snapshotDev := NewScopedPricingSnapshot("aws.dev", "us-east-1")

	// Add same rate key to both
	snapshotProd.AddRate("aws.prod:us-east-1:ec2", ScopedRate{
		Key:      "aws.prod:us-east-1:ec2",
		Price:    "0.10",
		Currency: "USD",
		Unit:     "hour",
	})
	snapshotDev.AddRate("aws.dev:us-east-1:ec2", ScopedRate{
		Key:      "aws.dev:us-east-1:ec2",
		Price:    "0.05",
		Currency: "USD",
		Unit:     "hour",
	})

	// Verify isolation
	providerProd := NewFinalizedProvider("aws", "prod", "us-east-1", "123456789")
	providerDev := NewFinalizedProvider("aws", "dev", "us-east-1", "987654321")

	rateKeyProd := NewRateKeyStrict(providerProd, "ec2", "us-east-1", nil)
	rateKeyDev := NewRateKeyStrict(providerDev, "ec2", "us-east-1", nil)

	// Prod snapshot should not return dev rate
	_, found := snapshotProd.GetRate(rateKeyDev)
	if found {
		t.Error("Prod snapshot should not return dev rate - snapshots not properly isolated")
	}

	// Dev snapshot should not return prod rate
	_, found = snapshotDev.GetRate(rateKeyProd)
	if found {
		t.Error("Dev snapshot should not return prod rate - snapshots not properly isolated")
	}

	t.Log("Pricing snapshots are correctly alias-scoped")
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\resolver.go
# TYPE: go
# SIZE: 3323 bytes
################################################################################
// Package pricing provides the pricing resolution interface.
// This package resolves prices from cache, database, and cloud APIs.
package pricing

import (
	"context"

	"terraform-cost/core/types"
)

// Resolver resolves pricing for rate keys
type Resolver interface {
	// Resolve fetches rates for the given keys
	Resolve(ctx context.Context, keys []types.RateKey, snapshot *types.PricingSnapshot) (*types.PricingResult, error)

	// GetSnapshot returns the current pricing snapshot for a provider/region
	GetSnapshot(ctx context.Context, provider types.Provider, region string) (*types.PricingSnapshot, error)

	// RefreshSnapshot updates pricing data from cloud APIs
	RefreshSnapshot(ctx context.Context, provider types.Provider, region string) (*types.PricingSnapshot, error)
}

// Cache provides in-memory pricing caching
type Cache interface {
	// Get retrieves a rate from cache
	Get(key types.RateKey) (*types.Rate, bool)

	// Set stores a rate in cache
	Set(key types.RateKey, rate *types.Rate)

	// GetMulti retrieves multiple rates
	GetMulti(keys []types.RateKey) map[string]*types.Rate

	// SetMulti stores multiple rates
	SetMulti(rates map[string]*types.Rate)

	// Invalidate removes a rate from cache
	Invalidate(key types.RateKey)

	// Clear removes all cached rates
	Clear()

	// Size returns the number of cached entries
	Size() int
}

// Store provides persistent pricing storage
type Store interface {
	// GetRates retrieves rates from storage
	GetRates(ctx context.Context, keys []types.RateKey, snapshotID string) ([]types.Rate, error)

	// SaveRates stores rates in storage
	SaveRates(ctx context.Context, rates []types.Rate) error

	// GetSnapshot retrieves a pricing snapshot
	GetSnapshot(ctx context.Context, id string) (*types.PricingSnapshot, error)

	// SaveSnapshot stores a pricing snapshot
	SaveSnapshot(ctx context.Context, snapshot *types.PricingSnapshot) error

	// GetLatestSnapshot returns the most recent snapshot for a provider/region
	GetLatestSnapshot(ctx context.Context, provider types.Provider, region string) (*types.PricingSnapshot, error)

	// ListSnapshots returns all snapshots for a provider/region
	ListSnapshots(ctx context.Context, provider types.Provider, region string) ([]types.PricingSnapshot, error)
}

// Source fetches pricing from external cloud APIs
type Source interface {
	// Provider returns the cloud provider
	Provider() types.Provider

	// FetchRates retrieves rates for the given keys
	FetchRates(ctx context.Context, keys []types.RateKey) ([]types.Rate, error)

	// FetchAll retrieves all rates for a region
	FetchAll(ctx context.Context, region string) ([]types.Rate, error)

	// SupportedRegions returns the list of supported regions
	SupportedRegions() []string
}

// SourceRegistry manages pricing source registration
type SourceRegistry interface {
	// Register adds a source to the registry
	Register(source Source) error

	// GetSource returns a source for a provider
	GetSource(provider types.Provider) (Source, bool)

	// GetAll returns all registered sources
	GetAll() []Source
}

// CompositeResolver implements Resolver using cache, store, and sources
type CompositeResolver struct {
	Cache   Cache
	Store   Store
	Sources SourceRegistry
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\snapshot.go
# TYPE: go
# SIZE: 11387 bytes
################################################################################
// Package pricing provides immutable pricing snapshots with content hashing.
package pricing

import (
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"sort"
	"time"

	"github.com/shopspring/decimal"

	"terraform-cost/core/determinism"
)

// SnapshotID uniquely identifies a pricing snapshot
type SnapshotID string

// RateID uniquely identifies a rate within a snapshot
type RateID string

// PricingSnapshot is IMMUTABLE after creation.
// It represents a point-in-time capture of pricing data.
type PricingSnapshot struct {
	// Identity
	ID          SnapshotID              // UUID or hash-based
	ContentHash determinism.ContentHash // SHA-256 of all rates
	CreatedAt   time.Time               // When snapshot was created
	EffectiveAt time.Time               // When prices became effective
	ExpiresAt   *time.Time              // Optional expiry (for cached data)

	// Source information
	Source      PricingSource
	Region      string
	Provider    string // aws, azure, gcp

	// The actual rates (sorted for determinism)
	rates       []RateEntry
	rateIndex   map[RateKey]*RateEntry

	// Coverage information
	Coverage    SnapshotCoverage

	// Immutability flag
	sealed      bool
}

// PricingSource indicates where pricing data came from
type PricingSource int

const (
	SourceCloudAPI    PricingSource = iota // From cloud provider API
	SourceLocalCache                       // From local cache
	SourceDatabase                         // From pricing database
	SourceManual                           // Manually specified
	SourceDefault                          // Hardcoded defaults
)

// String returns the source name
func (s PricingSource) String() string {
	switch s {
	case SourceCloudAPI:
		return "cloud_api"
	case SourceLocalCache:
		return "local_cache"
	case SourceDatabase:
		return "database"
	case SourceManual:
		return "manual"
	case SourceDefault:
		return "default"
	default:
		return "unknown"
	}
}

// RateKey uniquely identifies a rate
type RateKey struct {
	ResourceType string // aws_instance
	Component    string // Compute, Storage
	UsageType    string // BoxUsage, DataTransfer
	Attributes   string // Serialized attributes (instance_type=t3.micro)
}

// String returns a deterministic string representation
func (k RateKey) String() string {
	return k.ResourceType + "/" + k.Component + "/" + k.UsageType + "/" + k.Attributes
}

// RateEntry is a single pricing rate
type RateEntry struct {
	ID          RateID
	Key         RateKey
	Price       decimal.Decimal // Price per unit
	Unit        string          // hour, GB, request
	Currency    string          // USD
	Description string
	Tiers       []RateTier // For tiered pricing
	Conditions  []RateCondition
}

// RateTier represents a tier in tiered pricing
type RateTier struct {
	StartUsage decimal.Decimal // Start of tier
	EndUsage   *decimal.Decimal // End of tier (nil = unlimited)
	Price      decimal.Decimal  // Price in this tier
}

// RateCondition is a condition that must match for the rate
type RateCondition struct {
	Attribute string
	Operator  string // eq, neq, contains, prefix
	Value     string
}

// Bytes returns deterministic bytes for hashing
func (r *RateEntry) Bytes() []byte {
	// Use JSON for deterministic serialization
	data, _ := json.Marshal(map[string]interface{}{
		"key":      r.Key.String(),
		"price":    r.Price.String(),
		"unit":     r.Unit,
		"currency": r.Currency,
	})
	return data
}

// SnapshotCoverage tracks what's included and what's missing
type SnapshotCoverage struct {
	IncludedServices []string
	ResourceTypes    int
	TotalRates       int
	MissingRates     []MissingRate
	CoveragePercent  float64 // Estimated coverage
}

// MissingRate documents an EXPLICIT missing rate
type MissingRate struct {
	ResourceType string
	Component    string
	Reason       MissingReason
	Message      string // Human-readable explanation
}

// MissingReason explains why a rate is missing
type MissingReason int

const (
	ReasonNotInAPI           MissingReason = iota // API doesn't provide this
	ReasonRegionNotSupported                       // Region not available
	ReasonServiceNotImpl                           // We haven't implemented this
	ReasonRateLimitHit                             // API rate limit
	ReasonParseError                               // Couldn't parse response
	ReasonNotApplicable                            // Resource is free
)

// String returns the reason name
func (r MissingReason) String() string {
	switch r {
	case ReasonNotInAPI:
		return "not_in_api"
	case ReasonRegionNotSupported:
		return "region_not_supported"
	case ReasonServiceNotImpl:
		return "not_implemented"
	case ReasonRateLimitHit:
		return "rate_limit"
	case ReasonParseError:
		return "parse_error"
	case ReasonNotApplicable:
		return "not_applicable"
	default:
		return "unknown"
	}
}

// SnapshotBuilder builds a pricing snapshot
type SnapshotBuilder struct {
	provider    string
	region      string
	source      PricingSource
	effectiveAt time.Time
	rates       []RateEntry
	missing     []MissingRate
	services    map[string]bool
}

// NewSnapshotBuilder creates a new builder
func NewSnapshotBuilder(provider, region string) *SnapshotBuilder {
	return &SnapshotBuilder{
		provider:    provider,
		region:      region,
		source:      SourceDefault,
		effectiveAt: time.Now().UTC(),
		services:    make(map[string]bool),
	}
}

// WithSource sets the pricing source
func (b *SnapshotBuilder) WithSource(source PricingSource) *SnapshotBuilder {
	b.source = source
	return b
}

// WithEffectiveAt sets the effective date
func (b *SnapshotBuilder) WithEffectiveAt(t time.Time) *SnapshotBuilder {
	b.effectiveAt = t
	return b
}

// AddRate adds a rate to the snapshot
func (b *SnapshotBuilder) AddRate(key RateKey, price decimal.Decimal, unit, currency string) *SnapshotBuilder {
	b.rates = append(b.rates, RateEntry{
		Key:      key,
		Price:    price,
		Unit:     unit,
		Currency: currency,
	})
	b.services[key.ResourceType] = true
	return b
}

// AddMissing documents a missing rate
func (b *SnapshotBuilder) AddMissing(resourceType, component string, reason MissingReason, message string) *SnapshotBuilder {
	b.missing = append(b.missing, MissingRate{
		ResourceType: resourceType,
		Component:    component,
		Reason:       reason,
		Message:      message,
	})
	return b
}

// Build creates an immutable snapshot
func (b *SnapshotBuilder) Build() *PricingSnapshot {
	// Sort rates for deterministic ordering
	sort.Slice(b.rates, func(i, j int) bool {
		return b.rates[i].Key.String() < b.rates[j].Key.String()
	})

	// Generate IDs for each rate
	idGen := determinism.NewIDGenerator("rate")
	for i := range b.rates {
		b.rates[i].ID = RateID(idGen.Generate(b.rates[i].Key.String()))
	}

	// Build index
	index := make(map[RateKey]*RateEntry)
	for i := range b.rates {
		index[b.rates[i].Key] = &b.rates[i]
	}

	// Collect services
	services := make([]string, 0, len(b.services))
	for svc := range b.services {
		services = append(services, svc)
	}
	sort.Strings(services)

	// Create snapshot
	snap := &PricingSnapshot{
		CreatedAt:   time.Now().UTC(),
		EffectiveAt: b.effectiveAt,
		Source:      b.source,
		Region:      b.region,
		Provider:    b.provider,
		rates:       b.rates,
		rateIndex:   index,
		Coverage: SnapshotCoverage{
			IncludedServices: services,
			ResourceTypes:    len(b.services),
			TotalRates:       len(b.rates),
			MissingRates:     b.missing,
		},
	}

	// Compute content hash
	snap.ContentHash = snap.computeHash()

	// Generate ID from hash
	snap.ID = SnapshotID(hex.EncodeToString(snap.ContentHash[:8]))

	// Seal the snapshot
	snap.sealed = true

	return snap
}

// computeHash creates a content hash of all rates
func (s *PricingSnapshot) computeHash() determinism.ContentHash {
	h := sha256.New()
	h.Write([]byte(s.Provider))
	h.Write([]byte(s.Region))
	h.Write([]byte(s.EffectiveAt.Format(time.RFC3339)))
	for _, rate := range s.rates {
		h.Write(rate.Bytes())
	}
	var hash determinism.ContentHash
	copy(hash[:], h.Sum(nil))
	return hash
}

// GetRate looks up a rate by key
func (s *PricingSnapshot) GetRate(key RateKey) (*RateEntry, bool) {
	rate, ok := s.rateIndex[key]
	return rate, ok
}

// LookupRate finds a rate by resource type and component
func (s *PricingSnapshot) LookupRate(resourceType, component string, attrs map[string]string) (*RateEntry, bool) {
	// Serialize attributes deterministically
	attrKeys := determinism.SortedKeys(attrs)
	var attrStr string
	for _, k := range attrKeys {
		if attrStr != "" {
			attrStr += ","
		}
		attrStr += k + "=" + attrs[k]
	}

	key := RateKey{
		ResourceType: resourceType,
		Component:    component,
		Attributes:   attrStr,
	}
	return s.GetRate(key)
}

// Rates returns all rates in sorted order
func (s *PricingSnapshot) Rates() []RateEntry {
	result := make([]RateEntry, len(s.rates))
	copy(result, s.rates)
	return result
}

// Verify checks content hash integrity
func (s *PricingSnapshot) Verify() bool {
	computed := s.computeHash()
	return computed == s.ContentHash
}

// CostEstimate MUST reference a snapshot
type CostEstimate struct {
	// Snapshot reference (mandatory)
	SnapshotID   SnapshotID
	SnapshotHash determinism.ContentHash // For verification

	// The estimate
	InstanceID   string
	Component    string
	MonthlyCost  determinism.Money
	HourlyCost   determinism.Money

	// Lineage (see Gap 5)
	Lineage      *CostLineage
}

// CostLineage tracks the full derivation chain (Gap 5)
type CostLineage struct {
	// What was priced
	InstanceID  string
	Component   string

	// Pricing source
	SnapshotID  SnapshotID
	RateID      RateID
	RateKey     RateKey

	// Formula applied
	Formula     FormulaApplication

	// Usage input
	Usage       UsageLineage

	// Derived costs (for aggregated)
	DerivedFrom []*CostLineage

	// Confidence
	Confidence  float64 // 0.0 - 1.0

	// Timestamp
	Timestamp   time.Time
}

// FormulaApplication tracks how cost was calculated
type FormulaApplication struct {
	Name       string            // "hourly_compute"
	Expression string            // "rate * hours * quantity"
	Inputs     map[string]string // rate=0.10, hours=730, quantity=3
	Output     string            // 219.00
}

// UsageLineage tracks usage source
type UsageLineage struct {
	Source      UsageSource
	Profile     string   // "production", "dev"
	Confidence  float64  // 0.0 - 1.0
	Assumptions []string // ["assumed 75% utilization"]
}

// UsageSource indicates where usage data came from
type UsageSource int

const (
	UsageDefault   UsageSource = iota // Hardcoded defaults
	UsageOverride                     // User provided
	UsageEstimated                    // ML/heuristic estimated
	UsageActual                       // Historical actual
)

// String returns the source name
func (s UsageSource) String() string {
	switch s {
	case UsageDefault:
		return "default"
	case UsageOverride:
		return "override"
	case UsageEstimated:
		return "estimated"
	case UsageActual:
		return "actual"
	default:
		return "unknown"
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\strict_rate_key.go
# TYPE: go
# SIZE: 5250 bytes
################################################################################
// Package pricing - RateKey constructor enforcement
// RateKeys can ONLY be created via constructor - no struct literals allowed.
// This ensures provider alias is always present.
package pricing

import (
	"fmt"
	"strings"
)

// RateKeyStrict is a rate key that can ONLY be created via constructor
type RateKeyStrict struct {
	provider  string
	alias     string
	region    string
	service   string
	sku       string
	attrs     map[string]string
	validated bool
}

// NewRateKeyStrict creates a rate key with REQUIRED provider identity
// Panics if provider is not finalized
func NewRateKeyStrict(provider ProviderIdentity, service, region string, attrs map[string]string) *RateKeyStrict {
	if !provider.IsFinalized() {
		panic("INVARIANT VIOLATED: pricing requested before provider finalization")
	}

	key := &RateKeyStrict{
		provider:  provider.Provider(),
		alias:     provider.Alias(),
		region:    region,
		service:   service,
		attrs:     attrs,
		validated: true,
	}

	return key
}

// ProviderIdentity represents a finalized provider
type ProviderIdentity interface {
	Provider() string
	Alias() string
	IsFinalized() bool
}

// FinalizedProvider is a provider that has been frozen
type FinalizedProvider struct {
	provider  string
	alias     string
	region    string
	account   string
	finalized bool
}

// NewFinalizedProvider creates a finalized provider
func NewFinalizedProvider(provider, alias, region, account string) *FinalizedProvider {
	return &FinalizedProvider{
		provider:  provider,
		alias:     alias,
		region:    region,
		account:   account,
		finalized: true,
	}
}

// Provider returns the provider name
func (p *FinalizedProvider) Provider() string { return p.provider }

// Alias returns the alias
func (p *FinalizedProvider) Alias() string { return p.alias }

// Region returns the region
func (p *FinalizedProvider) Region() string { return p.region }

// Account returns the account
func (p *FinalizedProvider) Account() string { return p.account }

// IsFinalized returns true if finalized
func (p *FinalizedProvider) IsFinalized() bool { return p.finalized }

// FullKey returns the full provider key (provider.alias)
func (p *FinalizedProvider) FullKey() string {
	if p.alias == "" || p.alias == "default" {
		return p.provider
	}
	return p.provider + "." + p.alias
}

// Key returns the lookup key for this rate
func (k *RateKeyStrict) Key() string {
	if !k.validated {
		panic("INVARIANT VIOLATED: using unvalidated RateKey")
	}

	parts := []string{k.provider}
	if k.alias != "" && k.alias != "default" {
		parts = append(parts, k.alias)
	}
	parts = append(parts, k.region, k.service)
	if k.sku != "" {
		parts = append(parts, k.sku)
	}

	return strings.Join(parts, ":")
}

// WithSKU adds SKU to the key
func (k *RateKeyStrict) WithSKU(sku string) *RateKeyStrict {
	k.sku = sku
	return k
}

// WithAttr adds an attribute
func (k *RateKeyStrict) WithAttr(key, value string) *RateKeyStrict {
	if k.attrs == nil {
		k.attrs = make(map[string]string)
	}
	k.attrs[key] = value
	return k
}

// String returns string representation
func (k *RateKeyStrict) String() string {
	return k.Key()
}

// ProviderFullKey returns provider.alias
func (k *RateKeyStrict) ProviderFullKey() string {
	if k.alias == "" || k.alias == "default" {
		return k.provider
	}
	return k.provider + "." + k.alias
}

// ValidateProviderFinalization validates that provider is finalized
func ValidateProviderFinalization(provider ProviderIdentity) error {
	if provider == nil {
		return fmt.Errorf("provider is nil")
	}
	if !provider.IsFinalized() {
		return fmt.Errorf("provider %s is not finalized", provider.Provider())
	}
	return nil
}

// MustBeFinalized panics if provider is not finalized
func MustBeFinalized(provider ProviderIdentity) {
	if err := ValidateProviderFinalization(provider); err != nil {
		panic("INVARIANT VIOLATED: " + err.Error())
	}
}

// PricingSnapshot must be scoped by provider + alias + region
type ScopedPricingSnapshot struct {
	// Scope
	ProviderKey string // provider.alias
	Region      string

	// Rates
	rates map[string]ScopedRate

	// Metadata
	Version     string
	EffectiveAt string
	ContentHash string
}

// ScopedRate is a rate scoped to provider + alias + region
type ScopedRate struct {
	Key      string
	Price    string // decimal
	Currency string
	Unit     string
}

// NewScopedPricingSnapshot creates a scoped snapshot
func NewScopedPricingSnapshot(providerKey, region string) *ScopedPricingSnapshot {
	return &ScopedPricingSnapshot{
		ProviderKey: providerKey,
		Region:      region,
		rates:       make(map[string]ScopedRate),
	}
}

// AddRate adds a rate
func (s *ScopedPricingSnapshot) AddRate(key string, rate ScopedRate) {
	s.rates[key] = rate
}

// GetRate returns a rate
func (s *ScopedPricingSnapshot) GetRate(key *RateKeyStrict) (*ScopedRate, bool) {
	// Validate scope
	if key.ProviderFullKey() != s.ProviderKey {
		return nil, false
	}
	if key.region != s.Region {
		return nil, false
	}

	rate, ok := s.rates[key.Key()]
	if !ok {
		return nil, false
	}
	return &rate, true
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\primitives\compute.go
# TYPE: go
# SIZE: 3038 bytes
################################################################################
// Package primitives - Compute pricing primitives
// Instance hours, vCPU hours, memory hours
package primitives

// InstanceHours creates a cost unit for compute instance hours
func InstanceHours(
	instanceType string,
	hours float64,
	provider CloudProvider,
	region string,
	os string,
	tenancy string,
	confidence float64,
) CostUnit {
	if instanceType == "" {
		return Symbolic("compute", "instance type not specified")
	}

	if hours <= 0 {
		return Symbolic("compute", "hours must be positive")
	}

	attrs := map[string]string{
		"instanceType": instanceType,
	}
	if os != "" {
		attrs["operatingSystem"] = os
	}
	if tenancy != "" {
		attrs["tenancy"] = tenancy
	}

	service := computeService(provider)

	return CostUnit{
		Name:       "compute",
		Measure:    "instance-hours",
		Quantity:   hours,
		Confidence: confidence,
		RateKey: RateKey{
			Provider:   string(provider),
			Service:    service,
			Region:     region,
			Attributes: attrs,
		},
	}
}

// NodeHours creates a cost unit for managed service node hours
// Used for: ElastiCache, OpenSearch, Redshift, etc.
func NodeHours(
	nodeType string,
	nodeCount int,
	hours float64,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	if nodeType == "" {
		return Symbolic("nodes", "node type not specified")
	}

	return CostUnit{
		Name:       "nodes",
		Measure:    "node-hours",
		Quantity:   float64(nodeCount) * hours,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"nodeType": nodeType,
			},
		},
	}
}

// VCPUHours creates a cost unit for vCPU-based pricing
// Used for: Fargate, Lambda duration, etc.
func VCPUHours(
	vcpus float64,
	hours float64,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	return CostUnit{
		Name:       "vcpu",
		Measure:    "vCPU-hours",
		Quantity:   vcpus * hours,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"usageType": "vCPU-Hours",
			},
		},
	}
}

// MemoryGBHours creates a cost unit for memory-based pricing
func MemoryGBHours(
	memoryGB float64,
	hours float64,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	return CostUnit{
		Name:       "memory",
		Measure:    "GB-hours",
		Quantity:   memoryGB * hours,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"usageType": "Memory-Hours",
			},
		},
	}
}

func computeService(provider CloudProvider) string {
	switch provider {
	case AWS:
		return "AmazonEC2"
	case Azure:
		return "Virtual Machines"
	case GCP:
		return "Compute Engine"
	default:
		return "Compute"
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\primitives\requests.go
# TYPE: go
# SIZE: 2857 bytes
################################################################################
// Package primitives - Request and usage-based pricing primitives
// Requests, API calls, data processing
package primitives

// Requests creates a cost unit for request-based pricing
func Requests(
	count float64,
	requestType string,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	if count <= 0 {
		return CostUnit{} // No cost for zero requests
	}

	// Normalize to millions for pricing
	countMillions := count / 1_000_000

	return CostUnit{
		Name:       "requests",
		Measure:    "million-requests",
		Quantity:   countMillions,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"requestType": requestType,
			},
		},
	}
}

// APIOperations creates a cost unit for API operations (S3 PUT/GET, SQS, etc.)
func APIOperations(
	count float64,
	operationType string,
	tier string,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	if count <= 0 {
		return CostUnit{}
	}

	// Different APIs use different units (per 1K, per 10K, per 1M)
	countThousands := count / 1_000

	return CostUnit{
		Name:       "operations",
		Measure:    "thousand-operations",
		Quantity:   countThousands,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"operationType": operationType,
				"tier":          tier,
			},
		},
	}
}

// Invocations creates a cost unit for function invocations (Lambda, Cloud Functions)
func Invocations(
	count float64,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	if count <= 0 {
		return CostUnit{}
	}

	countMillions := count / 1_000_000

	return CostUnit{
		Name:       "invocations",
		Measure:    "million-invocations",
		Quantity:   countMillions,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"usageType": "Invocations",
			},
		},
	}
}

// Duration creates a cost unit for duration-based pricing (Lambda GB-seconds)
func Duration(
	gbSeconds float64,
	architecture string,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	if gbSeconds <= 0 {
		return CostUnit{}
	}

	return CostUnit{
		Name:       "duration",
		Measure:    "GB-seconds",
		Quantity:   gbSeconds,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"architecture": architecture,
				"usageType":    "Duration",
			},
		},
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\primitives\storage.go
# TYPE: go
# SIZE: 3234 bytes
################################################################################
// Package primitives - Storage pricing primitives
// GB-months, IOPS-months, throughput
package primitives

// StorageType for volume/storage classification
type StorageType string

const (
	StorageSSD      StorageType = "ssd"
	StorageHDD      StorageType = "hdd"
	StorageStandard StorageType = "standard"
	StorageArchive  StorageType = "archive"
)

// StorageGB creates a cost unit for storage by GB-month
func StorageGB(
	gb float64,
	storageType StorageType,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	if gb <= 0 {
		return Symbolic("storage", "storage size must be positive")
	}

	return CostUnit{
		Name:       "storage",
		Measure:    "GB-months",
		Quantity:   gb,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"storageType": string(storageType),
			},
		},
	}
}

// VolumeStorage creates a cost unit for block storage (EBS, Persistent Disk)
func VolumeStorage(
	gb float64,
	volumeType string,
	provider CloudProvider,
	region string,
	confidence float64,
) CostUnit {
	if gb <= 0 {
		return Symbolic("storage", "volume size must be positive")
	}

	service := volumeService(provider)

	return CostUnit{
		Name:       "storage",
		Measure:    "GB-months",
		Quantity:   gb,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"volumeType": volumeType,
			},
		},
	}
}

// ProvisionedIOPS creates a cost unit for provisioned IOPS
func ProvisionedIOPS(
	iops float64,
	volumeType string,
	provider CloudProvider,
	region string,
	confidence float64,
) CostUnit {
	if iops <= 0 {
		return CostUnit{} // No cost for zero IOPS
	}

	service := volumeService(provider)

	return CostUnit{
		Name:       "iops",
		Measure:    "IOPS-months",
		Quantity:   iops,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"volumeType": volumeType,
				"usageType":  "ProvisionedIOPS",
			},
		},
	}
}

// ProvisionedThroughput creates a cost unit for provisioned throughput
func ProvisionedThroughput(
	mbps float64,
	volumeType string,
	provider CloudProvider,
	region string,
	confidence float64,
) CostUnit {
	if mbps <= 0 {
		return CostUnit{} // No cost for zero throughput
	}

	service := volumeService(provider)

	return CostUnit{
		Name:       "throughput",
		Measure:    "MBps-months",
		Quantity:   mbps,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"volumeType": volumeType,
				"usageType":  "ProvisionedThroughput",
			},
		},
	}
}

func volumeService(provider CloudProvider) string {
	switch provider {
	case AWS:
		return "AmazonEC2" // EBS is under EC2
	case Azure:
		return "Managed Disks"
	case GCP:
		return "Compute Engine" // Persistent Disk is under GCE
	default:
		return "Storage"
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\primitives\symbolic.go
# TYPE: go
# SIZE: 1343 bytes
################################################################################
// Package primitives - Symbolic cost helpers
// Used when cost cannot be determined
package primitives

// Symbolic creates a symbolic (unknown) cost unit
func Symbolic(name string, reason string) CostUnit {
	return CostUnit{
		Name:           name,
		IsSymbolic:     true,
		SymbolicReason: reason,
		Confidence:     0,
	}
}

// SymbolicWithEstimate creates a symbolic cost with an upper bound estimate
func SymbolicWithEstimate(name string, reason string, estimatedMax float64) CostUnit {
	return CostUnit{
		Name:           name,
		Measure:        "estimated",
		Quantity:       estimatedMax,
		IsSymbolic:     true,
		SymbolicReason: reason,
		Confidence:     0,
	}
}

// ZeroCost creates a cost unit that is explicitly zero
// Used for indirect/free resources
func ZeroCost(name string, reason string) CostUnit {
	return CostUnit{
		Name:       name,
		Measure:    "none",
		Quantity:   0,
		Confidence: 1.0,
		RateKey: RateKey{
			Attributes: map[string]string{
				"reason": reason,
			},
		},
	}
}

// Unsupported creates a cost unit for unsupported resources
func Unsupported(resourceType string) CostUnit {
	return CostUnit{
		Name:           "unsupported",
		IsSymbolic:     true,
		SymbolicReason: "resource type " + resourceType + " is not supported",
		Confidence:     0,
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\primitives\tiered.go
# TYPE: go
# SIZE: 2445 bytes
################################################################################
// Package primitives - Tiered pricing primitives
// Handles AWS/Azure/GCP tiered pricing models
package primitives

// TieredUsage creates a cost unit for tiered pricing
// Calculates cost across multiple pricing tiers
func TieredUsage(
	quantity float64,
	tiers []PricingTier,
	measure string,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	if quantity <= 0 || len(tiers) == 0 {
		return CostUnit{}
	}

	// For cost graph, we emit the total quantity
	// Pricing resolution handles tier calculation
	return CostUnit{
		Name:       "tiered_usage",
		Measure:    measure,
		Quantity:   quantity,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"pricingModel": "tiered",
			},
		},
	}
}

// CalculateTieredCost computes the actual cost for tiered pricing
// This is called at pricing resolution time, not in mappers
func CalculateTieredCost(quantity float64, tiers []PricingTier) float64 {
	if quantity <= 0 || len(tiers) == 0 {
		return 0
	}

	var totalCost float64
	remaining := quantity
	previousLimit := 0.0

	for _, tier := range tiers {
		if remaining <= 0 {
			break
		}

		tierLimit := tier.UpTo
		if tierLimit == 0 {
			// Unlimited tier - all remaining goes here
			totalCost += remaining * tier.UnitRate
			remaining = 0
		} else {
			tierSize := tierLimit - previousLimit
			usageInTier := min(remaining, tierSize)
			totalCost += usageInTier * tier.UnitRate
			remaining -= usageInTier
			previousLimit = tierLimit
		}
	}

	return totalCost
}

// FreeTier creates a cost unit that accounts for free tier
func FreeTier(
	quantity float64,
	freeAmount float64,
	measure string,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	billableQuantity := quantity - freeAmount
	if billableQuantity <= 0 {
		return CostUnit{} // Entirely within free tier
	}

	return CostUnit{
		Name:       "usage",
		Measure:    measure,
		Quantity:   billableQuantity,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"pricingModel": "free_tier_applied",
			},
		},
	}
}

func min(a, b float64) float64 {
	if a < b {
		return a
	}
	return b
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\primitives\transfer.go
# TYPE: go
# SIZE: 2222 bytes
################################################################################
// Package primitives - Data transfer pricing primitives
// Bandwidth, egress, inter-region transfer
package primitives

// DataTransferGB creates a cost unit for data transfer
func DataTransferGB(
	gb float64,
	direction TransferDirection,
	provider CloudProvider,
	region string,
	confidence float64,
) CostUnit {
	if gb <= 0 {
		return CostUnit{}
	}

	service := dataTransferService(provider)

	return CostUnit{
		Name:       "data_transfer",
		Measure:    "GB",
		Quantity:   gb,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"direction": string(direction),
			},
		},
	}
}

// DataProcessedGB creates a cost unit for data processing (NAT Gateway, etc.)
func DataProcessedGB(
	gb float64,
	processingType string,
	provider CloudProvider,
	service string,
	region string,
	confidence float64,
) CostUnit {
	if gb <= 0 {
		return CostUnit{}
	}

	return CostUnit{
		Name:       "data_processed",
		Measure:    "GB",
		Quantity:   gb,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   region,
			Attributes: map[string]string{
				"processingType": processingType,
			},
		},
	}
}

// InterRegionTransferGB creates a cost unit for inter-region data transfer
func InterRegionTransferGB(
	gb float64,
	sourceRegion string,
	destRegion string,
	provider CloudProvider,
	confidence float64,
) CostUnit {
	if gb <= 0 {
		return CostUnit{}
	}

	service := dataTransferService(provider)

	return CostUnit{
		Name:       "inter_region_transfer",
		Measure:    "GB",
		Quantity:   gb,
		Confidence: confidence,
		RateKey: RateKey{
			Provider: string(provider),
			Service:  service,
			Region:   sourceRegion,
			Attributes: map[string]string{
				"direction":  "inter_region",
				"destRegion": destRegion,
			},
		},
	}
}

func dataTransferService(provider CloudProvider) string {
	switch provider {
	case AWS:
		return "AWSDataTransfer"
	case Azure:
		return "Bandwidth"
	case GCP:
		return "Network Egress"
	default:
		return "DataTransfer"
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\pricing\primitives\types.go
# TYPE: go
# SIZE: 1289 bytes
################################################################################
// Package primitives - Centralized pricing math
// Mappers declare intent, not do math.
// All pricing logic flows through these primitives.
package primitives

// CloudProvider identifies a cloud provider
type CloudProvider string

const (
	AWS   CloudProvider = "aws"
	Azure CloudProvider = "azure"
	GCP   CloudProvider = "gcp"
)

// TransferDirection for data transfer pricing
type TransferDirection string

const (
	TransferInbound   TransferDirection = "inbound"
	TransferOutbound  TransferDirection = "outbound"
	TransferInterAZ   TransferDirection = "inter_az"
	TransferInterReg  TransferDirection = "inter_region"
	TransferToInternet TransferDirection = "to_internet"
)

// CostUnit represents a billable cost component
type CostUnit struct {
	Name           string
	Measure        string
	Quantity       float64
	RateKey        RateKey
	IsSymbolic     bool
	SymbolicReason string
	Confidence     float64
}

// RateKey identifies a pricing rate
type RateKey struct {
	Provider   string
	Service    string
	Region     string
	Attributes map[string]string
}

// PricingTier represents a tiered pricing level
type PricingTier struct {
	UpTo     float64 // Upper limit (0 = unlimited)
	UnitRate float64 // Rate per unit in this tier
}

################################################################################
# FILE: :\good projects\cost estimation\core\scanner\registry.go
# TYPE: go
# SIZE: 2844 bytes
################################################################################
// Package scanner - Registry for scanner implementations
package scanner

import (
	"context"
	"fmt"
	"sync"

	"terraform-cost/core/types"
)

// Registry manages scanner registration and lookup
type Registry interface {
	// Register adds a scanner to the registry
	Register(scanner Scanner) error

	// GetScanner returns a scanner by name
	GetScanner(name string) (Scanner, bool)

	// GetAll returns all registered scanners
	GetAll() []Scanner

	// DetectAndScan finds the appropriate scanner and scans the input
	DetectAndScan(ctx context.Context, input *types.ProjectInput) (*ScanResult, error)
}

// DefaultRegistry is the default scanner registry implementation
type DefaultRegistry struct {
	mu       sync.RWMutex
	scanners map[string]Scanner
	order    []string // maintains registration order for priority
}

// NewRegistry creates a new scanner registry
func NewRegistry() *DefaultRegistry {
	return &DefaultRegistry{
		scanners: make(map[string]Scanner),
		order:    make([]string, 0),
	}
}

// Register adds a scanner to the registry
func (r *DefaultRegistry) Register(scanner Scanner) error {
	r.mu.Lock()
	defer r.mu.Unlock()

	name := scanner.Name()
	if _, exists := r.scanners[name]; exists {
		return fmt.Errorf("scanner already registered: %s", name)
	}

	r.scanners[name] = scanner
	r.order = append(r.order, name)
	return nil
}

// GetScanner returns a scanner by name
func (r *DefaultRegistry) GetScanner(name string) (Scanner, bool) {
	r.mu.RLock()
	defer r.mu.RUnlock()

	scanner, ok := r.scanners[name]
	return scanner, ok
}

// GetAll returns all registered scanners in registration order
func (r *DefaultRegistry) GetAll() []Scanner {
	r.mu.RLock()
	defer r.mu.RUnlock()

	scanners := make([]Scanner, 0, len(r.order))
	for _, name := range r.order {
		if scanner, ok := r.scanners[name]; ok {
			scanners = append(scanners, scanner)
		}
	}
	return scanners
}

// DetectAndScan finds the first scanner that can handle the input and runs it
func (r *DefaultRegistry) DetectAndScan(ctx context.Context, input *types.ProjectInput) (*ScanResult, error) {
	r.mu.RLock()
	defer r.mu.RUnlock()

	for _, name := range r.order {
		scanner := r.scanners[name]

		canScan, err := scanner.CanScan(ctx, input)
		if err != nil {
			continue // Skip scanners that error on detection
		}

		if canScan {
			return scanner.Scan(ctx, input)
		}
	}

	return nil, fmt.Errorf("no scanner found for input: %s", input.Path)
}

// Global default registry
var defaultRegistry = NewRegistry()

// Register adds a scanner to the default registry
func Register(scanner Scanner) error {
	return defaultRegistry.Register(scanner)
}

// GetDefault returns the default registry
func GetDefault() *DefaultRegistry {
	return defaultRegistry
}

################################################################################
# FILE: :\good projects\cost estimation\core\scanner\scanner.go
# TYPE: go
# SIZE: 2917 bytes
################################################################################
// Package scanner defines the interface for infrastructure scanners.
// Scanners parse IaC configurations into RawAsset descriptors.
// NO pricing or cost logic belongs here.
package scanner

import (
	"context"

	"terraform-cost/core/types"
)

// Scanner parses infrastructure code into raw assets
type Scanner interface {
	// Name returns the scanner identifier
	Name() string

	// CanScan determines if this scanner can handle the input
	CanScan(ctx context.Context, input *types.ProjectInput) (bool, error)

	// Scan parses the input and returns raw assets
	Scan(ctx context.Context, input *types.ProjectInput) (*ScanResult, error)
}

// ScanResult contains the output of a scan operation
type ScanResult struct {
	// Assets are the parsed infrastructure resources
	Assets []types.RawAsset `json:"assets"`

	// Modules are referenced modules
	Modules []ModuleReference `json:"modules,omitempty"`

	// Variables are the resolved variables
	Variables map[string]interface{} `json:"variables,omitempty"`

	// Warnings are non-fatal issues encountered
	Warnings []ScanWarning `json:"warnings,omitempty"`

	// Errors are parsing errors
	Errors []ScanError `json:"errors,omitempty"`
}

// ModuleReference tracks module dependencies
type ModuleReference struct {
	// Source is the module source (registry, git, local)
	Source string `json:"source"`

	// Version is the module version constraint
	Version string `json:"version,omitempty"`

	// Path is the local path to the module
	Path string `json:"path"`

	// Key is the module key in the configuration
	Key string `json:"key"`
}

// ScanWarning represents a non-fatal scanning issue
type ScanWarning struct {
	// File is the file where the warning occurred
	File string `json:"file"`

	// Line is the line number
	Line int `json:"line,omitempty"`

	// Message describes the warning
	Message string `json:"message"`

	// Code is a warning code for programmatic handling
	Code string `json:"code,omitempty"`
}

// ScanError represents a scanning error
type ScanError struct {
	// File is the file where the error occurred
	File string `json:"file"`

	// Line is the line number
	Line int `json:"line,omitempty"`

	// Message describes the error
	Message string `json:"message"`

	// Code is an error code for programmatic handling
	Code string `json:"code,omitempty"`

	// Err is the underlying error
	Err error `json:"-"`
}

// Error implements the error interface
func (e ScanError) Error() string {
	return e.Message
}

// Unwrap returns the underlying error
func (e ScanError) Unwrap() error {
	return e.Err
}

// HasErrors returns true if there are any errors
func (r *ScanResult) HasErrors() bool {
	return len(r.Errors) > 0
}

// HasWarnings returns true if there are any warnings
func (r *ScanResult) HasWarnings() bool {
	return len(r.Warnings) > 0
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\data_barrier.go
# TYPE: go
# SIZE: 8072 bytes
################################################################################
// Package terraform - Data source estimation barriers
// Data sources create HARD uncertainty. They cannot be estimated deterministically.
package terraform

import (
	"fmt"
	"strings"

	"terraform-cost/core/confidence"
)

// DataSourceBarrier enforces estimation rules for data sources
type DataSourceBarrier struct {
	// Data sources that are inherently unpriceable
	unpriceable map[string]bool

	// Attributes that when sourced from data, block pricing
	blockingAttributes map[string][]string

	// Confidence impacts per data source type
	confidenceImpacts map[string]float64
}

// NewDataSourceBarrier creates a new barrier
func NewDataSourceBarrier() *DataSourceBarrier {
	return &DataSourceBarrier{
		unpriceable: map[string]bool{
			"aws_ami":                true, // Runtime lookup
			"aws_availability_zones": true, // Runtime lookup
			"aws_caller_identity":    true, // Runtime lookup
			"aws_region":             true, // Runtime lookup
			"aws_vpc":                true, // External resource
			"aws_subnet":             true, // External resource
			"aws_security_group":     true, // External resource
			"aws_iam_role":           true, // External resource
		},
		blockingAttributes: map[string][]string{
			"aws_instance": {"ami", "subnet_id"},
			"aws_db_instance": {"db_subnet_group_name"},
			"aws_lambda_function": {"role"},
			"aws_ecs_service": {"cluster"},
		},
		confidenceImpacts: map[string]float64{
			"aws_ami":                0.25, // AMI affects pricing
			"aws_availability_zones": 0.10, // AZ is minor
			"aws_caller_identity":    0.05, // No pricing impact
			"aws_vpc":                0.15, // VPC affects networking
			"aws_subnet":             0.15,
			"aws_security_group":     0.05,
			"aws_iam_role":           0.05,
			"default":                0.20,
		},
	}
}

// DataSourceReference represents a reference to a data source
type DataSourceReference struct {
	DataType      string // e.g., "aws_ami"
	DataName      string // e.g., "latest"
	Attribute     string // e.g., "id"
	FullReference string // e.g., "data.aws_ami.latest.id"
}

// ParseDataSourceReference parses a data source reference
func ParseDataSourceReference(ref string) (*DataSourceReference, bool) {
	if !strings.HasPrefix(ref, "data.") {
		return nil, false
	}

	parts := strings.Split(ref, ".")
	if len(parts) < 3 {
		return nil, false
	}

	result := &DataSourceReference{
		DataType:      parts[1],
		DataName:      parts[2],
		FullReference: ref,
	}

	if len(parts) >= 4 {
		result.Attribute = strings.Join(parts[3:], ".")
	}

	return result, true
}

// CanEstimate checks if an attribute can be estimated when sourced from data
func (b *DataSourceBarrier) CanEstimate(resourceType, attribute string, dataRef *DataSourceReference) EstimationDecision {
	decision := EstimationDecision{
		CanEstimate:      true,
		ConfidenceImpact: 0,
		Reason:           "",
		Recommendations:  []string{},
	}

	// Check if data source is inherently unpriceable
	if b.unpriceable[dataRef.DataType] {
		decision.ConfidenceImpact = b.getConfidenceImpact(dataRef.DataType)
		decision.Reason = fmt.Sprintf("data source %s is resolved at runtime", dataRef.DataType)
		decision.Recommendations = append(decision.Recommendations,
			fmt.Sprintf("Consider providing explicit value for %s.%s", resourceType, attribute))
	}

	// Check if this attribute blocks pricing when from data
	blockingAttrs := b.blockingAttributes[resourceType]
	for _, blocked := range blockingAttrs {
		if blocked == attribute {
			decision.CanEstimate = false
			decision.ConfidenceImpact = 0.4 // Severe
			decision.Reason = fmt.Sprintf("attribute %s cannot be estimated from data source", attribute)
			decision.Recommendations = append(decision.Recommendations,
				fmt.Sprintf("Provide explicit %s value or use usage override", attribute))
			return decision
		}
	}

	return decision
}

// EstimationDecision is the result of checking if estimation is possible
type EstimationDecision struct {
	CanEstimate      bool
	ConfidenceImpact float64
	Reason           string
	Recommendations  []string
}

func (b *DataSourceBarrier) getConfidenceImpact(dataType string) float64 {
	if impact, ok := b.confidenceImpacts[dataType]; ok {
		return impact
	}
	return b.confidenceImpacts["default"]
}

// ApplyDataSourceImpacts applies confidence impacts for all data source references
func (b *DataSourceBarrier) ApplyDataSourceImpacts(
	tracker *confidence.ConfidenceTracker,
	resourceType string,
	attributes map[string]interface{},
	dataRefs map[string]*DataSourceReference,
) []EstimationDecision {
	var decisions []EstimationDecision

	for attrName, dataRef := range dataRefs {
		decision := b.CanEstimate(resourceType, attrName, dataRef)
		decisions = append(decisions, decision)

		if !decision.CanEstimate {
			tracker.Apply("data_source_barrier", decision.Reason)
		} else if decision.ConfidenceImpact > 0 {
			tracker.Apply("data_source_uncertainty", decision.Reason)
		}
	}

	return decisions
}

// AttributeSourceAnalyzer analyzes where attribute values come from
type AttributeSourceAnalyzer struct {
	barrier *DataSourceBarrier
}

// NewAttributeSourceAnalyzer creates an analyzer
func NewAttributeSourceAnalyzer() *AttributeSourceAnalyzer {
	return &AttributeSourceAnalyzer{
		barrier: NewDataSourceBarrier(),
	}
}

// AttributeSource describes where an attribute value comes from
type AttributeSource struct {
	// Source type
	Type AttributeSourceType

	// Reference (if from data or resource)
	Reference string

	// Is this estimable?
	IsEstimable bool

	// Confidence impact
	ConfidenceImpact float64

	// Reason if not estimable
	Reason string
}

// AttributeSourceType indicates the source of an attribute
type AttributeSourceType int

const (
	SourceLiteral     AttributeSourceType = iota // Hardcoded value
	SourceVariable                                // From variable
	SourceLocal                                   // From local
	SourceDataSource                              // From data source
	SourceResource                                // From another resource
	SourceUnknown                                 // Cannot determine
)

// String returns the source type name
func (t AttributeSourceType) String() string {
	switch t {
	case SourceLiteral:
		return "literal"
	case SourceVariable:
		return "variable"
	case SourceLocal:
		return "local"
	case SourceDataSource:
		return "data_source"
	case SourceResource:
		return "resource"
	default:
		return "unknown"
	}
}

// AnalyzeAttribute determines the source of an attribute value
func (a *AttributeSourceAnalyzer) AnalyzeAttribute(resourceType, attrName, expression string, references []string) AttributeSource {
	source := AttributeSource{
		Type:        SourceUnknown,
		IsEstimable: true,
	}

	// No references = literal
	if len(references) == 0 {
		source.Type = SourceLiteral
		return source
	}

	// Check first reference to determine type
	ref := references[0]

	if strings.HasPrefix(ref, "var.") {
		source.Type = SourceVariable
		source.Reference = ref
		source.ConfidenceImpact = 0.1 // Variables are usually known
		return source
	}

	if strings.HasPrefix(ref, "local.") {
		source.Type = SourceLocal
		source.Reference = ref
		source.ConfidenceImpact = 0.05 // Locals are resolvable
		return source
	}

	if strings.HasPrefix(ref, "data.") {
		source.Type = SourceDataSource
		source.Reference = ref

		dataRef, _ := ParseDataSourceReference(ref)
		if dataRef != nil {
			decision := a.barrier.CanEstimate(resourceType, attrName, dataRef)
			source.IsEstimable = decision.CanEstimate
			source.ConfidenceImpact = decision.ConfidenceImpact
			source.Reason = decision.Reason
		}
		return source
	}

	// Resource reference
	source.Type = SourceResource
	source.Reference = ref
	source.ConfidenceImpact = 0.15 // Resource refs are runtime
	return source
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\dependencies.go
# TYPE: go
# SIZE: 8737 bytes
################################################################################
// Package terraform - Dependency graph and depends_on handling
package terraform

import (
	"sort"
	"strings"

	"terraform-cost/core/determinism"
	"terraform-cost/core/model"
)

// DependencyResolver builds the dependency graph between instances
type DependencyResolver struct {
	// Instance index for lookups
	instanceByAddr  map[model.InstanceAddress]*model.AssetInstance
	instanceByDefn  map[model.DefinitionID][]*model.AssetInstance
}

// NewDependencyResolver creates a new resolver
func NewDependencyResolver() *DependencyResolver {
	return &DependencyResolver{
		instanceByAddr: make(map[model.InstanceAddress]*model.AssetInstance),
		instanceByDefn: make(map[model.DefinitionID][]*model.AssetInstance),
	}
}

// ResolveDependencies builds all dependency edges
func (r *DependencyResolver) ResolveDependencies(
	instances []*model.AssetInstance,
	definitions map[model.DefinitionID]*model.AssetDefinition,
) []model.InstanceEdge {
	// Build indexes
	r.buildIndexes(instances)

	var edges []model.InstanceEdge

	for _, inst := range instances {
		def := definitions[inst.DefinitionID]
		if def == nil {
			continue
		}

		// 1. Explicit depends_on
		explicitEdges := r.resolveExplicitDeps(inst, def.DependsOn)
		edges = append(edges, explicitEdges...)

		// 2. Implicit reference-based dependencies
		implicitEdges := r.resolveImplicitDeps(inst, def)
		edges = append(edges, implicitEdges...)

		// 3. Provider dependencies
		providerEdges := r.resolveProviderDeps(inst)
		edges = append(edges, providerEdges...)
	}

	// Sort edges for determinism
	sort.Slice(edges, func(i, j int) bool {
		if edges[i].From != edges[j].From {
			return edges[i].From < edges[j].From
		}
		return edges[i].To < edges[j].To
	})

	// Deduplicate
	return r.deduplicate(edges)
}

func (r *DependencyResolver) buildIndexes(instances []*model.AssetInstance) {
	for _, inst := range instances {
		r.instanceByAddr[inst.Address] = inst
		r.instanceByDefn[inst.DefinitionID] = append(r.instanceByDefn[inst.DefinitionID], inst)
	}
}

// resolveExplicitDeps handles depends_on meta-argument
func (r *DependencyResolver) resolveExplicitDeps(
	inst *model.AssetInstance,
	dependsOn []string,
) []model.InstanceEdge {
	var edges []model.InstanceEdge

	for _, dep := range dependsOn {
		// depends_on references definitions, not instances
		// We need to create edges to ALL instances of that definition
		targetInstances := r.findInstancesByAddress(dep)
		for _, target := range targetInstances {
			if target.ID != inst.ID { // No self-loops
				edges = append(edges, model.InstanceEdge{
					From: inst.ID,
					To:   target.ID,
					Type: model.EdgeExplicit,
				})
			}
		}
	}

	return edges
}

// resolveImplicitDeps finds dependencies from attribute references
func (r *DependencyResolver) resolveImplicitDeps(
	inst *model.AssetInstance,
	def *model.AssetDefinition,
) []model.InstanceEdge {
	var edges []model.InstanceEdge

	// Collect all references from attributes
	for _, expr := range def.Attributes {
		for _, ref := range expr.References {
			// Parse reference to find target
			targetAddr := r.parseRefToAddress(ref)
			if targetAddr == "" {
				continue
			}

			targetInstances := r.findInstancesByAddress(targetAddr)
			for _, target := range targetInstances {
				if target.ID != inst.ID {
					edges = append(edges, model.InstanceEdge{
						From: inst.ID,
						To:   target.ID,
						Type: model.EdgeImplicit,
					})
				}
			}
		}
	}

	return edges
}

// resolveProviderDeps creates edges for provider requirements
func (r *DependencyResolver) resolveProviderDeps(inst *model.AssetInstance) []model.InstanceEdge {
	// Provider dependencies are generally implicit in Terraform
	// but we track them for completeness
	return nil
}

// findInstancesByAddress finds instances matching an address pattern
func (r *DependencyResolver) findInstancesByAddress(addr string) []*model.AssetInstance {
	var result []*model.AssetInstance

	// First try exact match
	if inst, ok := r.instanceByAddr[model.InstanceAddress(addr)]; ok {
		return []*model.AssetInstance{inst}
	}

	// Try as definition address (returns all instances)
	for instAddr, inst := range r.instanceByAddr {
		// Check if instance address starts with the definition address
		if strings.HasPrefix(string(instAddr), addr+"[") || string(instAddr) == addr {
			result = append(result, inst)
		}
	}

	// Sort for determinism
	sort.Slice(result, func(i, j int) bool {
		return result[i].Address < result[j].Address
	})

	return result
}

// parseRefToAddress extracts the resource address from a reference
// e.g., "aws_instance.web.id" -> "aws_instance.web"
// e.g., "module.app.aws_s3_bucket.data" -> "module.app.aws_s3_bucket.data"
func (r *DependencyResolver) parseRefToAddress(ref string) string {
	parts := strings.Split(ref, ".")

	// Skip variable/local references
	if len(parts) < 2 {
		return ""
	}

	switch parts[0] {
	case "var", "local", "path", "terraform":
		return "" // Not a resource reference
	case "data":
		if len(parts) >= 3 {
			return strings.Join(parts[:3], ".")
		}
	case "module":
		// Find where the resource part starts
		for i := 0; i < len(parts)-1; i += 2 {
			if parts[i] != "module" {
				// parts[i] is the resource type
				return strings.Join(parts[:i+2], ".")
			}
		}
	default:
		// Regular resource reference
		if len(parts) >= 2 {
			return parts[0] + "." + parts[1]
		}
	}

	return ""
}

func (r *DependencyResolver) deduplicate(edges []model.InstanceEdge) []model.InstanceEdge {
	seen := make(map[string]bool)
	result := make([]model.InstanceEdge, 0, len(edges))

	for _, e := range edges {
		key := string(e.From) + "->" + string(e.To)
		if !seen[key] {
			seen[key] = true
			result = append(result, e)
		}
	}

	return result
}

// TopologicalSort sorts instances in dependency order
func TopologicalSort(instances []*model.AssetInstance, edges []model.InstanceEdge) []model.InstanceID {
	// Build adjacency list
	adj := make(map[model.InstanceID][]model.InstanceID)
	inDegree := make(map[model.InstanceID]int)

	for _, inst := range instances {
		adj[inst.ID] = []model.InstanceID{}
		inDegree[inst.ID] = 0
	}

	for _, edge := range edges {
		adj[edge.From] = append(adj[edge.From], edge.To)
		inDegree[edge.To]++
	}

	// Kahn's algorithm with stable ordering
	var queue []model.InstanceID
	for id, degree := range inDegree {
		if degree == 0 {
			queue = append(queue, id)
		}
	}
	determinism.SortSlice(queue, func(a, b model.InstanceID) bool {
		return a < b
	})

	var result []model.InstanceID
	for len(queue) > 0 {
		node := queue[0]
		queue = queue[1:]
		result = append(result, node)

		for _, neighbor := range adj[node] {
			inDegree[neighbor]--
			if inDegree[neighbor] == 0 {
				queue = append(queue, neighbor)
				determinism.SortSlice(queue, func(a, b model.InstanceID) bool {
					return a < b
				})
			}
		}
	}

	// Check for cycles
	if len(result) != len(instances) {
		// Cycle detected - return what we have
		// Caller should handle this error case
	}

	return result
}

// DetectCycles finds all cycles in the dependency graph
func DetectCycles(instances []*model.AssetInstance, edges []model.InstanceEdge) [][]model.InstanceID {
	// Build adjacency list
	adj := make(map[model.InstanceID][]model.InstanceID)
	for _, inst := range instances {
		adj[inst.ID] = []model.InstanceID{}
	}
	for _, edge := range edges {
		adj[edge.From] = append(adj[edge.From], edge.To)
	}

	// DFS-based cycle detection
	var cycles [][]model.InstanceID
	color := make(map[model.InstanceID]int) // 0=white, 1=gray, 2=black
	parent := make(map[model.InstanceID]model.InstanceID)

	var dfs func(node model.InstanceID)
	dfs = func(node model.InstanceID) {
		color[node] = 1 // Gray

		for _, neighbor := range adj[node] {
			if color[neighbor] == 1 {
				// Back edge found - cycle detected
				cycle := []model.InstanceID{neighbor}
				for n := node; n != neighbor; n = parent[n] {
					cycle = append([]model.InstanceID{n}, cycle...)
				}
				cycles = append(cycles, cycle)
			} else if color[neighbor] == 0 {
				parent[neighbor] = node
				dfs(neighbor)
			}
		}

		color[node] = 2 // Black
	}

	// Sort nodes for deterministic traversal
	nodes := make([]model.InstanceID, 0, len(adj))
	for id := range adj {
		nodes = append(nodes, id)
	}
	determinism.SortSlice(nodes, func(a, b model.InstanceID) bool {
		return a < b
	})

	for _, node := range nodes {
		if color[node] == 0 {
			dfs(node)
		}
	}

	return cycles
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\determinism_class.go
# TYPE: go
# SIZE: 6531 bytes
################################################################################
// Package terraform - Function classification by determinism
// Functions are classified as PureDeterministic, PureContextual, or Impure.
// Impure functions block estimation in strict mode.
package terraform

// DeterminismClass indicates function determinism
type DeterminismClass int

const (
	// PureDeterministic - same inputs always produce same outputs
	PureDeterministic DeterminismClass = iota

	// PureContextual - deterministic given context (e.g., provider region)
	PureContextual

	// Impure - not deterministic (timestamp, uuid, external calls)
	Impure
)

// String returns the class name
func (c DeterminismClass) String() string {
	names := []string{"pure_deterministic", "pure_contextual", "impure"}
	if int(c) < len(names) {
		return names[c]
	}
	return "unknown"
}

// FunctionDeterminism maps Terraform functions to their determinism class
var FunctionDeterminism = map[string]DeterminismClass{
	// Pure Deterministic - safe
	"abs":           PureDeterministic,
	"ceil":          PureDeterministic,
	"floor":         PureDeterministic,
	"max":           PureDeterministic,
	"min":           PureDeterministic,
	"pow":           PureDeterministic,
	"signum":        PureDeterministic,
	"length":        PureDeterministic,
	"concat":        PureDeterministic,
	"contains":      PureDeterministic,
	"distinct":      PureDeterministic,
	"flatten":       PureDeterministic,
	"keys":          PureDeterministic,
	"values":        PureDeterministic,
	"lookup":        PureDeterministic,
	"merge":         PureDeterministic,
	"reverse":       PureDeterministic,
	"sort":          PureDeterministic,
	"zipmap":        PureDeterministic,
	"coalesce":      PureDeterministic,
	"compact":       PureDeterministic,
	"element":       PureDeterministic,
	"index":         PureDeterministic,
	"list":          PureDeterministic,
	"map":           PureDeterministic,
	"range":         PureDeterministic,
	"setintersection": PureDeterministic,
	"setproduct":    PureDeterministic,
	"setunion":      PureDeterministic,
	"slice":         PureDeterministic,
	"chomp":         PureDeterministic,
	"format":        PureDeterministic,
	"formatlist":    PureDeterministic,
	"indent":        PureDeterministic,
	"join":          PureDeterministic,
	"lower":         PureDeterministic,
	"upper":         PureDeterministic,
	"regex":         PureDeterministic,
	"regexall":      PureDeterministic,
	"replace":       PureDeterministic,
	"split":         PureDeterministic,
	"strrev":        PureDeterministic,
	"substr":        PureDeterministic,
	"title":         PureDeterministic,
	"trim":          PureDeterministic,
	"trimprefix":    PureDeterministic,
	"trimsuffix":    PureDeterministic,
	"trimspace":     PureDeterministic,
	"base64decode":  PureDeterministic,
	"base64encode":  PureDeterministic,
	"jsonencode":    PureDeterministic,
	"jsondecode":    PureDeterministic,
	"yamlencode":    PureDeterministic,
	"yamldecode":    PureDeterministic,
	"csvdecode":     PureDeterministic,
	"urlencode":     PureDeterministic,
	"md5":           PureDeterministic,
	"sha1":          PureDeterministic,
	"sha256":        PureDeterministic,
	"sha512":        PureDeterministic,
	"tolist":        PureDeterministic,
	"toset":         PureDeterministic,
	"tomap":         PureDeterministic,
	"tonumber":      PureDeterministic,
	"tostring":      PureDeterministic,
	"try":           PureDeterministic,
	"can":           PureDeterministic,

	// Pure Contextual - depends on provider/environment context
	"cidrhost":      PureContextual,
	"cidrnetmask":   PureContextual,
	"cidrsubnet":    PureContextual,
	"cidrsubnets":   PureContextual,
	"pathexpand":    PureContextual, // Depends on home directory

	// Impure - not deterministic, blocks in strict mode
	"timestamp":     Impure,
	"uuid":          Impure,
	"file":          Impure, // Reads from filesystem
	"fileexists":    Impure,
	"fileset":       Impure, // Directory listing
	"filebase64":    Impure,
	"templatefile":  Impure,
	"filemd5":       Impure,
	"filesha1":      Impure,
	"filesha256":    Impure,
	"filesha512":    Impure,
	"filebase64sha256": Impure,
	"filebase64sha512": Impure,
	"bcrypt":        Impure, // Random salt
	"rsadecrypt":    Impure, // External key
	"textencodebase64": PureDeterministic,
	"textdecodebase64": PureDeterministic,
}

// GetDeterminismClass returns the determinism class for a function
func GetDeterminismClass(function string) DeterminismClass {
	if class, ok := FunctionDeterminism[function]; ok {
		return class
	}
	// Unknown functions are treated as impure for safety
	return Impure
}

// IsPure returns true if function is deterministic
func IsPure(function string) bool {
	class := GetDeterminismClass(function)
	return class == PureDeterministic || class == PureContextual
}

// BlocksStrictMode returns true if function blocks strict mode
func BlocksStrictMode(function string) bool {
	return GetDeterminismClass(function) == Impure
}

// GetConfidenceImpact returns confidence impact for a function
func GetConfidenceImpact(function string) float64 {
	switch GetDeterminismClass(function) {
	case PureDeterministic:
		return 0.0 // No impact
	case PureContextual:
		return 0.1 // Small impact
	case Impure:
		return 0.5 // Large impact
	default:
		return 0.3 // Unknown
	}
}

// DeterminismAnalysis analyzes an expression for determinism
type DeterminismAnalysis struct {
	IsDeterministic bool
	ImpureFunctions []string
	ContextualFunctions []string
	TotalImpact     float64
}

// AnalyzeFunctions analyzes a list of function calls
func AnalyzeFunctions(functions []string) *DeterminismAnalysis {
	analysis := &DeterminismAnalysis{
		IsDeterministic: true,
		ImpureFunctions: []string{},
		ContextualFunctions: []string{},
		TotalImpact: 0.0,
	}

	for _, fn := range functions {
		class := GetDeterminismClass(fn)
		impact := GetConfidenceImpact(fn)
		analysis.TotalImpact += impact

		switch class {
		case Impure:
			analysis.IsDeterministic = false
			analysis.ImpureFunctions = append(analysis.ImpureFunctions, fn)
		case PureContextual:
			analysis.ContextualFunctions = append(analysis.ContextualFunctions, fn)
		}
	}

	return analysis
}

// ShouldBlock returns true if analysis should block estimation in strict mode
func (a *DeterminismAnalysis) ShouldBlock(strictMode bool) bool {
	return strictMode && len(a.ImpureFunctions) > 0
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\dynamic.go
# TYPE: go
# SIZE: 6073 bytes
################################################################################
// Package terraform - Dynamic block expansion
package terraform

import (
	"fmt"
	"sort"

	"terraform-cost/core/model"
)

// DynamicBlockExpander handles Terraform dynamic blocks
type DynamicBlockExpander struct{}

// NewDynamicBlockExpander creates a new expander
func NewDynamicBlockExpander() *DynamicBlockExpander {
	return &DynamicBlockExpander{}
}

// ExpandDynamicBlocks expands all dynamic blocks in a definition
func (e *DynamicBlockExpander) ExpandDynamicBlocks(
	def *model.AssetDefinition,
	evalCtx *EvalContext,
) (map[string][]map[string]model.ResolvedAttribute, []string) {
	result := make(map[string][]map[string]model.ResolvedAttribute)
	var warnings []string

	for _, dyn := range def.DynamicBlocks {
		blocks, warn := e.expandSingle(dyn, evalCtx)
		if warn != "" {
			warnings = append(warnings, warn)
		}
		result[dyn.Name] = blocks
	}

	return result, warnings
}

func (e *DynamicBlockExpander) expandSingle(
	dyn model.DynamicBlock,
	evalCtx *EvalContext,
) ([]map[string]model.ResolvedAttribute, string) {
	// Resolve the for_each expression
	forEachValue, ok := e.resolveForEach(dyn.ForEach, evalCtx)
	if !ok {
		return nil, fmt.Sprintf("dynamic %q: for_each could not be resolved", dyn.Name)
	}

	// Determine iterator name (default to block name)
	iterator := dyn.Iterator
	if iterator == "" {
		iterator = dyn.Name
	}

	var blocks []map[string]model.ResolvedAttribute

	// Iterate based on type
	switch v := forEachValue.(type) {
	case []any:
		for i, item := range v {
			block := e.expandContent(dyn.Content, iterator, i, item, evalCtx)
			blocks = append(blocks, block)
		}
	case map[string]any:
		// Sort keys for determinism
		keys := make([]string, 0, len(v))
		for k := range v {
			keys = append(keys, k)
		}
		sort.Strings(keys)

		for _, key := range keys {
			block := e.expandContent(dyn.Content, iterator, key, v[key], evalCtx)
			blocks = append(blocks, block)
		}
	default:
		return nil, fmt.Sprintf("dynamic %q: for_each must be list or map", dyn.Name)
	}

	return blocks, ""
}

func (e *DynamicBlockExpander) resolveForEach(expr model.Expression, ctx *EvalContext) (any, bool) {
	if expr.IsLiteral {
		return expr.LiteralVal, true
	}

	// Evaluate expression
	if ctx != nil {
		val, err := ctx.Evaluate(expr)
		if err != nil {
			return nil, false
		}
		return val, true
	}

	return nil, false
}

func (e *DynamicBlockExpander) expandContent(
	content map[string]model.Expression,
	iterator string,
	key any,
	value any,
	parentCtx *EvalContext,
) map[string]model.ResolvedAttribute {
	// Create child context with iterator variables
	ctx := parentCtx.Clone()
	ctx.SetLocal(iterator+".key", key)
	ctx.SetLocal(iterator+".value", value)

	result := make(map[string]model.ResolvedAttribute)

	for name, expr := range content {
		if expr.IsLiteral {
			result[name] = model.ResolvedAttribute{
				Value:     expr.LiteralVal,
				IsUnknown: false,
			}
		} else {
			// Try to evaluate with iterator context
			val, err := ctx.Evaluate(expr)
			if err != nil {
				result[name] = model.ResolvedAttribute{
					IsUnknown: true,
					Reason:    model.ReasonExpressionError,
				}
			} else {
				result[name] = model.ResolvedAttribute{
					Value:     val,
					IsUnknown: false,
				}
			}
		}
	}

	return result
}

// EvalContext provides evaluation context for expressions
type EvalContext struct {
	variables map[string]any
	locals    map[string]any
	resources map[string]any
	data      map[string]any
	parent    *EvalContext
}

// NewEvalContext creates a new evaluation context
func NewEvalContext() *EvalContext {
	return &EvalContext{
		variables: make(map[string]any),
		locals:    make(map[string]any),
		resources: make(map[string]any),
		data:      make(map[string]any),
	}
}

// Clone creates a child context
func (c *EvalContext) Clone() *EvalContext {
	return &EvalContext{
		variables: make(map[string]any),
		locals:    make(map[string]any),
		resources: make(map[string]any),
		data:      make(map[string]any),
		parent:    c,
	}
}

// SetLocal sets a local value
func (c *EvalContext) SetLocal(name string, value any) {
	c.locals[name] = value
}

// GetLocal gets a local value (searching parent chain)
func (c *EvalContext) GetLocal(name string) (any, bool) {
	if val, ok := c.locals[name]; ok {
		return val, true
	}
	if c.parent != nil {
		return c.parent.GetLocal(name)
	}
	return nil, false
}

// Evaluate evaluates an expression in this context
func (c *EvalContext) Evaluate(expr model.Expression) (any, error) {
	if expr.IsLiteral {
		return expr.LiteralVal, nil
	}

	// Parse references and resolve
	for _, ref := range expr.References {
		// Try to resolve reference
		// This is simplified - real implementation would parse the reference
		if val, ok := c.GetLocal(ref); ok {
			return val, nil
		}
	}

	return nil, fmt.Errorf("cannot evaluate expression: %s", expr.Raw)
}

// NestedDynamicBlock handles nested dynamic blocks (dynamic within dynamic)
type NestedDynamicBlock struct {
	Parent  string
	Block   model.DynamicBlock
}

// ExpandNested expands nested dynamic blocks
func (e *DynamicBlockExpander) ExpandNested(
	nested []NestedDynamicBlock,
	parentBlocks map[string][]map[string]model.ResolvedAttribute,
	evalCtx *EvalContext,
) map[string][]map[string]model.ResolvedAttribute {
	// For each parent block instance, expand child dynamics
	result := make(map[string][]map[string]model.ResolvedAttribute)

	for _, n := range nested {
		parentInstances := parentBlocks[n.Parent]
		for _, parentAttrs := range parentInstances {
			// Create context with parent block values
			childCtx := evalCtx.Clone()
			for k, v := range parentAttrs {
				childCtx.SetLocal(n.Parent+"."+k, v.Value)
			}

			// Expand the nested block
			blocks, _ := e.expandSingle(n.Block, childCtx)
			result[n.Block.Name] = append(result[n.Block.Name], blocks...)
		}
	}

	return result
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\function_class.go
# TYPE: go
# SIZE: 7306 bytes
################################################################################
// Package terraform - Function classification
// Pure vs impure, deterministic vs environment-dependent
package terraform

// FunctionClass classifies Terraform functions
type FunctionClass int

const (
	FunctionPure          FunctionClass = iota // Pure, deterministic (length, concat)
	FunctionImpure                              // Side effects (file, timestamp)
	FunctionEnvironment                         // Depends on environment (pathexpand)
	FunctionRandom                              // Non-deterministic (uuid)
	FunctionExternal                            // External data (data sources)
)

// String returns the class name
func (c FunctionClass) String() string {
	switch c {
	case FunctionPure:
		return "pure"
	case FunctionImpure:
		return "impure"
	case FunctionEnvironment:
		return "environment"
	case FunctionRandom:
		return "random"
	case FunctionExternal:
		return "external"
	default:
		return "unknown"
	}
}

// IsDeterministic returns true if the function is deterministic
func (c FunctionClass) IsDeterministic() bool {
	return c == FunctionPure
}

// FunctionInfo contains metadata about a function
type FunctionInfo struct {
	Name             string
	Class            FunctionClass
	AffectsCardinality bool
	ConfidenceImpact float64
	Description      string
}

// FunctionClassifier classifies Terraform functions
type FunctionClassifier struct {
	functions map[string]*FunctionInfo
}

// NewFunctionClassifier creates a classifier with known functions
func NewFunctionClassifier() *FunctionClassifier {
	fc := &FunctionClassifier{
		functions: make(map[string]*FunctionInfo),
	}
	fc.registerBuiltins()
	return fc
}

func (fc *FunctionClassifier) registerBuiltins() {
	// Pure functions - deterministic, no side effects
	pureFunctions := []string{
		"abs", "ceil", "floor", "log", "max", "min", "pow", "signum",
		"chomp", "format", "formatlist", "indent", "join", "lower", "upper",
		"regex", "regexall", "replace", "split", "strrev", "substr", "title", "trim",
		"trimprefix", "trimsuffix", "trimspace",
		"chunklist", "coalesce", "coalescelist", "compact", "concat", "contains",
		"distinct", "element", "flatten", "index", "keys", "length", "list",
		"lookup", "map", "matchkeys", "merge", "range", "reverse", "setintersection",
		"setproduct", "setsubtract", "setunion", "slice", "sort", "sum", "transpose",
		"values", "zipmap",
		"alltrue", "anytrue", "can", "try",
		"tobool", "tolist", "tomap", "tonumber", "toset", "tostring",
		"base64decode", "base64encode", "base64gzip", "csvdecode", "jsondecode",
		"jsonencode", "textdecodebase64", "textencodebase64", "urlencode", "yamldecode",
		"yamlencode",
		"cidrhost", "cidrnetmask", "cidrsubnet", "cidrsubnets",
		"md5", "sha1", "sha256", "sha512", "bcrypt",
	}

	for _, name := range pureFunctions {
		fc.functions[name] = &FunctionInfo{
			Name:             name,
			Class:            FunctionPure,
			AffectsCardinality: false,
			ConfidenceImpact: 0,
			Description:      "Pure function",
		}
	}

	// Cardinality-affecting pure functions
	cardinalityFunctions := []string{"range", "setproduct", "flatten", "concat"}
	for _, name := range cardinalityFunctions {
		if f, ok := fc.functions[name]; ok {
			f.AffectsCardinality = true
		}
	}

	// Impure functions - file system access
	impureFunctions := map[string]string{
		"file":          "reads file from disk",
		"fileexists":    "checks file existence",
		"fileset":       "globs files on disk",
		"filebase64":    "reads file as base64",
		"templatefile":  "reads and renders template",
		"abspath":       "resolves absolute path",
	}

	for name, desc := range impureFunctions {
		fc.functions[name] = &FunctionInfo{
			Name:             name,
			Class:            FunctionImpure,
			AffectsCardinality: name == "fileset",
			ConfidenceImpact: 0.2,
			Description:      desc,
		}
	}

	// Environment-dependent functions
	envFunctions := map[string]string{
		"pathexpand": "expands ~ to home dir",
		"dirname":    "depends on path separator",
		"basename":   "depends on path separator",
	}

	for name, desc := range envFunctions {
		fc.functions[name] = &FunctionInfo{
			Name:             name,
			Class:            FunctionEnvironment,
			AffectsCardinality: false,
			ConfidenceImpact: 0.1,
			Description:      desc,
		}
	}

	// Random/non-deterministic functions
	randomFunctions := map[string]string{
		"uuid":     "generates random UUID",
		"bcrypt":   "generates random salt",
		"timestamp":"returns current time",
	}

	for name, desc := range randomFunctions {
		fc.functions[name] = &FunctionInfo{
			Name:             name,
			Class:            FunctionRandom,
			AffectsCardinality: false,
			ConfidenceImpact: 0.3,
			Description:      desc,
		}
	}
}

// Classify returns the classification for a function
func (fc *FunctionClassifier) Classify(name string) *FunctionInfo {
	if info, ok := fc.functions[name]; ok {
		return info
	}
	// Unknown function - assume impure
	return &FunctionInfo{
		Name:             name,
		Class:            FunctionImpure,
		AffectsCardinality: false,
		ConfidenceImpact: 0.15,
		Description:      "Unknown function",
	}
}

// IsDeterministic checks if a function is deterministic
func (fc *FunctionClassifier) IsDeterministic(name string) bool {
	info := fc.Classify(name)
	return info.Class.IsDeterministic()
}

// GetConfidenceImpact returns the confidence impact of using a function
func (fc *FunctionClassifier) GetConfidenceImpact(name string) float64 {
	info := fc.Classify(name)
	return info.ConfidenceImpact
}

// ClassifyExpression classifies an expression based on functions used
func (fc *FunctionClassifier) ClassifyExpression(expr string, functions []string) *ExpressionClassification {
	result := &ExpressionClassification{
		Expression:         expr,
		IsDeterministic:    true,
		Functions:          []string{},
		NonDeterministic:   []string{},
		ConfidenceImpact:   0,
		AffectsCardinality: false,
	}

	for _, fn := range functions {
		info := fc.Classify(fn)
		result.Functions = append(result.Functions, fn)

		if !info.Class.IsDeterministic() {
			result.IsDeterministic = false
			result.NonDeterministic = append(result.NonDeterministic, fn)
		}

		if info.ConfidenceImpact > result.ConfidenceImpact {
			result.ConfidenceImpact = info.ConfidenceImpact
		}

		if info.AffectsCardinality {
			result.AffectsCardinality = true
		}
	}

	return result
}

// ExpressionClassification is the result of classifying an expression
type ExpressionClassification struct {
	Expression         string
	IsDeterministic    bool
	Functions          []string
	NonDeterministic   []string
	ConfidenceImpact   float64
	AffectsCardinality bool
}

// Warning returns a warning message if non-deterministic
func (ec *ExpressionClassification) Warning() string {
	if ec.IsDeterministic {
		return ""
	}
	return "expression uses non-deterministic functions: " + joinStrings(ec.NonDeterministic)
}

func joinStrings(strs []string) string {
	if len(strs) == 0 {
		return ""
	}
	result := strs[0]
	for i := 1; i < len(strs); i++ {
		result += ", " + strs[i]
	}
	return result
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\module_outputs.go
# TYPE: go
# SIZE: 7246 bytes
################################################################################
// Package terraform - Module output semantics
// Module outputs are NOT locals. They are:
// - Dependency edges
// - Potentially unknown
// - Cardinality-affecting
package terraform

import (
	"fmt"
	"strings"
)

// ModuleOutput represents a module output value
type ModuleOutput struct {
	// Path to the module
	ModulePath string

	// Output name
	Name string

	// Full address (module.name.output_name)
	Address string

	// Is this output known?
	IsKnown bool

	// Value if known
	Value interface{}

	// Expression if unknown
	Expression string

	// References in the expression
	References []string

	// Is this a dependency edge?
	IsDependencyEdge bool

	// Can this affect cardinality?
	AffectsCardinality bool

	// Confidence impact
	ConfidenceImpact float64
}

// ModuleOutputAnalyzer analyzes module outputs
type ModuleOutputAnalyzer struct {
	outputs map[string]*ModuleOutput
}

// NewModuleOutputAnalyzer creates an analyzer
func NewModuleOutputAnalyzer() *ModuleOutputAnalyzer {
	return &ModuleOutputAnalyzer{
		outputs: make(map[string]*ModuleOutput),
	}
}

// RegisterOutput registers a module output
func (a *ModuleOutputAnalyzer) RegisterOutput(modulePath, name string, expr *ExpressionValue) *ModuleOutput {
	address := modulePath + "." + name

	output := &ModuleOutput{
		ModulePath:         modulePath,
		Name:               name,
		Address:            address,
		IsKnown:            expr != nil && expr.IsKnown,
		References:         []string{},
		IsDependencyEdge:   true, // Module outputs are ALWAYS dependency edges
		AffectsCardinality: false,
		ConfidenceImpact:   0,
	}

	if expr != nil {
		output.Value = expr.Value
		output.Expression = expr.Expression
		output.References = expr.References

		// Check if this could affect cardinality
		output.AffectsCardinality = a.couldAffectCardinality(expr)

		// Calculate confidence impact
		output.ConfidenceImpact = a.calculateConfidenceImpact(output)
	}

	a.outputs[address] = output
	return output
}

// GetOutput returns an output by address
func (a *ModuleOutputAnalyzer) GetOutput(address string) (*ModuleOutput, bool) {
	output, ok := a.outputs[address]
	return output, ok
}

// IsModuleOutputRef checks if a reference is to a module output
func (a *ModuleOutputAnalyzer) IsModuleOutputRef(ref string) bool {
	// module.name.output_name
	return strings.HasPrefix(ref, "module.") && strings.Count(ref, ".") >= 2
}

// GetReferencedOutput gets the output for a reference
func (a *ModuleOutputAnalyzer) GetReferencedOutput(ref string) (*ModuleOutput, bool) {
	if !a.IsModuleOutputRef(ref) {
		return nil, false
	}
	return a.GetOutput(ref)
}

func (a *ModuleOutputAnalyzer) couldAffectCardinality(expr *ExpressionValue) bool {
	if expr == nil {
		return false
	}

	// Check if expression returns a collection
	if expr.Expression != "" {
		collectors := []string{"list", "map", "set", "tolist", "toset", "tomap"}
		for _, c := range collectors {
			if strings.Contains(expr.Expression, c) {
				return true
			}
		}
	}

	// Check if value is a collection
	switch expr.Value.(type) {
	case []interface{}, map[string]interface{}:
		return true
	}

	return false
}

func (a *ModuleOutputAnalyzer) calculateConfidenceImpact(output *ModuleOutput) float64 {
	if output.IsKnown {
		return 0.0
	}

	impact := 0.2 // Base impact for unknown output

	// Higher impact if it affects cardinality
	if output.AffectsCardinality {
		impact += 0.15
	}

	// Higher impact if references data sources
	for _, ref := range output.References {
		if strings.HasPrefix(ref, "data.") {
			impact += 0.1
			break
		}
	}

	return impact
}

// OutputDependencyEdge represents a dependency through module output
type OutputDependencyEdge struct {
	// Source: the module producing the output
	SourceModule string
	OutputName   string

	// Target: the consumer of the output
	TargetAddress string
	TargetAttr    string

	// Semantics
	IsKnown            bool
	AffectsCardinality bool
}

// ExtractOutputDependencies extracts dependency edges from references
func (a *ModuleOutputAnalyzer) ExtractOutputDependencies(address, attribute string, references []string) []*OutputDependencyEdge {
	var edges []*OutputDependencyEdge

	for _, ref := range references {
		if a.IsModuleOutputRef(ref) {
			output, _ := a.GetReferencedOutput(ref)

			edge := &OutputDependencyEdge{
				TargetAddress: address,
				TargetAttr:    attribute,
				IsKnown:       false,
			}

			// Parse module.name.output
			parts := strings.Split(ref, ".")
			if len(parts) >= 3 {
				edge.SourceModule = parts[0] + "." + parts[1]
				edge.OutputName = parts[2]
			}

			if output != nil {
				edge.IsKnown = output.IsKnown
				edge.AffectsCardinality = output.AffectsCardinality
			}

			edges = append(edges, edge)
		}
	}

	return edges
}

// ModuleOutputValidator validates module output usage
type ModuleOutputValidator struct {
	analyzer *ModuleOutputAnalyzer
	warnings []ModuleOutputWarning
}

// ModuleOutputWarning is a warning about module output usage
type ModuleOutputWarning struct {
	TargetAddress string
	OutputRef     string
	Type          OutputWarningType
	Message       string
}

// OutputWarningType classifies warnings
type OutputWarningType int

const (
	WarnUnknownOutput          OutputWarningType = iota // Output value unknown
	WarnCardinalityFromOutput                            // Using output for cardinality
	WarnDataSourceInOutput                               // Output depends on data source
)

// NewModuleOutputValidator creates a validator
func NewModuleOutputValidator(analyzer *ModuleOutputAnalyzer) *ModuleOutputValidator {
	return &ModuleOutputValidator{
		analyzer: analyzer,
		warnings: []ModuleOutputWarning{},
	}
}

// ValidateUsage validates usage of module outputs
func (v *ModuleOutputValidator) ValidateUsage(address, attribute string, references []string, isCardinalityContext bool) {
	for _, ref := range references {
		if v.analyzer.IsModuleOutputRef(ref) {
			output, ok := v.analyzer.GetReferencedOutput(ref)

			if !ok {
				// Unknown output
				v.warnings = append(v.warnings, ModuleOutputWarning{
					TargetAddress: address,
					OutputRef:     ref,
					Type:          WarnUnknownOutput,
					Message:       fmt.Sprintf("module output %s is not registered", ref),
				})
				continue
			}

			if !output.IsKnown {
				v.warnings = append(v.warnings, ModuleOutputWarning{
					TargetAddress: address,
					OutputRef:     ref,
					Type:          WarnUnknownOutput,
					Message:       fmt.Sprintf("module output %s has unknown value", ref),
				})
			}

			if isCardinalityContext && output.AffectsCardinality {
				v.warnings = append(v.warnings, ModuleOutputWarning{
					TargetAddress: address,
					OutputRef:     ref,
					Type:          WarnCardinalityFromOutput,
					Message:       fmt.Sprintf("cardinality depends on module output %s", ref),
				})
			}
		}
	}
}

// GetWarnings returns all warnings
func (v *ModuleOutputValidator) GetWarnings() []ModuleOutputWarning {
	return v.warnings
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\phased_expansion.go
# TYPE: go
# SIZE: 13766 bytes
################################################################################
// Package terraform - Phased module expansion
// Expansion happens in strict order to avoid phantom resources:
// 1. Parse â†’ 2. Bind Providers â†’ 3. Resolve Variables â†’ 4. Expand Modules â†’ 5. Expand Resources
package terraform

import (
	"context"
	"fmt"
	"sort"
)

// ExpansionPhase represents a distinct expansion stage
type ExpansionPhase int

const (
	ExpansionPhaseParse           ExpansionPhase = iota // Parse HCL
	ExpansionPhaseBindProviders                          // Bind provider configurations
	ExpansionPhaseResolveVars                            // Resolve variables and locals
	ExpansionPhaseExpandModules                          // Expand module calls
	ExpansionPhaseExpandResources                        // Expand count/for_each
	ExpansionPhaseBuildGraph                             // Build final graph
)

// String returns the phase name
func (p ExpansionPhase) String() string {
	switch p {
	case ExpansionPhaseParse:
		return "parse"
	case ExpansionPhaseBindProviders:
		return "bind_providers"
	case ExpansionPhaseResolveVars:
		return "resolve_vars"
	case ExpansionPhaseExpandModules:
		return "expand_modules"
	case ExpansionPhaseExpandResources:
		return "expand_resources"
	case ExpansionPhaseBuildGraph:
		return "build_graph"
	default:
		return "unknown"
	}
}

// PhasedExpander expands infrastructure in strict phases
type PhasedExpander struct {
	// Current phase
	currentPhase ExpansionPhase

	// Mode for handling unknowns
	mode EvaluationMode

	// Enforcer for strict mode
	enforcer *StrictModeEnforcer

	// Phase results
	phaseResults map[ExpansionPhase]*PhaseResult

	// Provider resolver
	providerResolver *ModuleProviderResolver

	// Expansion stats
	stats ExpansionStats
}

// PhaseResult is the result of a single phase
type PhaseResult struct {
	Phase       ExpansionPhase
	Success     bool
	Errors      []PhaseError
	Warnings    []PhaseWarning
	ItemCount   int
	DurationMs  int64
}

// PhaseError is an error from a phase
type PhaseError struct {
	Phase   ExpansionPhase
	Address string
	Message string
	Cause   error
}

// PhaseWarning is a warning from a phase
type PhaseWarning struct {
	Phase   ExpansionPhase
	Address string
	Message string
}

// ExpansionStats tracks expansion statistics
type ExpansionStats struct {
	ModulesFound      int
	ModulesExpanded   int
	ResourcesFound    int
	ResourcesExpanded int
	InstancesCreated  int
	UnknownsDeferred  int
	ProvidersResolved int
	VariablesResolved int
}

// NewPhasedExpander creates a new phased expander
func NewPhasedExpander(mode EvaluationMode) *PhasedExpander {
	return &PhasedExpander{
		currentPhase:     ExpansionPhaseParse,
		mode:             mode,
		enforcer:         NewStrictModeEnforcer(mode),
		phaseResults:     make(map[ExpansionPhase]*PhaseResult),
		providerResolver: NewModuleProviderResolver(),
	}
}

// ExpansionInput is the input to phased expansion
type ExpansionInput struct {
	// Parsed modules
	Modules []*ModuleDefinition

	// Root variables
	Variables map[string]interface{}

	// Provider configurations
	Providers []*ProviderConfig

	// Workspace
	Workspace string
}

// ModuleDefinition is a parsed module
type ModuleDefinition struct {
	Path      string
	Source    string
	Parent    string
	Count     *ExpressionValue
	ForEach   *ExpressionValue
	Providers map[string]string
	Inputs    map[string]*ExpressionValue
	Resources []*ResourceDefinition
	Children  []string
}

// ResourceDefinition is a parsed resource
type ResourceDefinition struct {
	Address      string
	ModulePath   string
	Type         string
	Name         string
	Provider     string
	Count        *ExpressionValue
	ForEach      *ExpressionValue
	Attributes   map[string]*ExpressionValue
	DependsOn    []string
}

// ExpressionValue is an expression that may or may not be evaluated
type ExpressionValue struct {
	IsKnown    bool
	Value      interface{}
	Expression string
	References []string
}

// ExpansionOutput is the output of phased expansion
type ExpansionOutput struct {
	// Final instances
	Instances []*ExpandedInstance

	// Phase results
	Phases []*PhaseResult

	// Stats
	Stats ExpansionStats

	// Is expansion complete?
	Complete bool

	// Blocked on unknowns?
	Blocked bool
	BlockedReasons []string
}

// ExpandedInstance is an expanded resource instance
type ExpandedInstance struct {
	Address       string
	ModulePath    string
	DefinitionID  string
	ResourceType  string
	InstanceKey   interface{}
	Provider      *ProviderContext
	Attributes    map[string]interface{}
	DependsOn     []string
	References    []string
}

// Expand runs all phases in order
func (e *PhasedExpander) Expand(ctx context.Context, input *ExpansionInput) (*ExpansionOutput, error) {
	output := &ExpansionOutput{
		Instances: []*ExpandedInstance{},
		Phases:    []*PhaseResult{},
		Complete:  false,
	}

	// Phase 1: Parse (already done - input is parsed)
	e.recordPhase(ExpansionPhaseParse, true, 0, nil)

	// Phase 2: Bind Providers
	if err := e.executeBindProviders(ctx, input); err != nil {
		output.Phases = e.getPhaseResults()
		return output, err
	}

	// Phase 3: Resolve Variables
	resolvedVars, err := e.executeResolveVars(ctx, input)
	if err != nil && e.mode == ModeStrict {
		output.Phases = e.getPhaseResults()
		return output, err
	}

	// Phase 4: Expand Modules
	expandedModules, err := e.executeExpandModules(ctx, input, resolvedVars)
	if err != nil && e.mode == ModeStrict {
		output.Phases = e.getPhaseResults()
		return output, err
	}

	// Phase 5: Expand Resources
	instances, err := e.executeExpandResources(ctx, expandedModules, resolvedVars)
	if err != nil && e.mode == ModeStrict {
		output.Phases = e.getPhaseResults()
		return output, err
	}

	output.Instances = instances
	output.Phases = e.getPhaseResults()
	output.Stats = e.stats
	output.Complete = !e.enforcer.IsBlocked()
	output.Blocked = e.enforcer.IsBlocked()

	if output.Blocked {
		for _, err := range e.enforcer.GetBlockingErrors() {
			output.BlockedReasons = append(output.BlockedReasons, err.Reason)
		}
	}

	return output, nil
}

func (e *PhasedExpander) executeBindProviders(ctx context.Context, input *ExpansionInput) error {
	e.currentPhase = ExpansionPhaseBindProviders

	// Register root providers
	for _, p := range input.Providers {
		e.providerResolver.RegisterRootProvider(p)
		e.stats.ProvidersResolved++
	}

	// Register module provider mappings
	for _, mod := range input.Modules {
		if len(mod.Providers) > 0 {
			e.providerResolver.RegisterModuleCall(mod.Parent, mod.Path, mod.Providers)
		}
	}

	e.recordPhase(ExpansionPhaseBindProviders, true, len(input.Providers), nil)
	return nil
}

func (e *PhasedExpander) executeResolveVars(ctx context.Context, input *ExpansionInput) (map[string]interface{}, error) {
	e.currentPhase = ExpansionPhaseResolveVars

	resolved := make(map[string]interface{})
	var errors []PhaseError

	// Copy input variables
	for k, v := range input.Variables {
		resolved[k] = v
		e.stats.VariablesResolved++
	}

	// NOTE: In full implementation, this would:
	// - Resolve locals in dependency order
	// - Evaluate variable defaults
	// - Handle workspace-specific values

	hasErrors := len(errors) > 0
	e.recordPhase(ExpansionPhaseResolveVars, !hasErrors, e.stats.VariablesResolved, errors)

	if hasErrors && e.mode == ModeStrict {
		return resolved, fmt.Errorf("variable resolution failed in strict mode")
	}

	return resolved, nil
}

func (e *PhasedExpander) executeExpandModules(ctx context.Context, input *ExpansionInput, vars map[string]interface{}) ([]*ModuleDefinition, error) {
	e.currentPhase = ExpansionPhaseExpandModules

	var expanded []*ModuleDefinition
	var errors []PhaseError

	for _, mod := range input.Modules {
		e.stats.ModulesFound++

		// Check count/for_each
		if mod.Count != nil {
			if !mod.Count.IsKnown {
				if err := e.enforcer.CheckUnknownCount(mod.Path, "module count is unknown"); err != nil {
					errors = append(errors, PhaseError{
						Phase:   ExpansionPhaseExpandModules,
						Address: mod.Path,
						Message: "unknown module count",
						Cause:   err,
					})
					e.stats.UnknownsDeferred++
					continue
				}
			}
		}

		if mod.ForEach != nil {
			if !mod.ForEach.IsKnown {
				if err := e.enforcer.CheckUnknownForEach(mod.Path, "module for_each is unknown"); err != nil {
					errors = append(errors, PhaseError{
						Phase:   ExpansionPhaseExpandModules,
						Address: mod.Path,
						Message: "unknown module for_each",
						Cause:   err,
					})
					e.stats.UnknownsDeferred++
					continue
				}
			}
		}

		expanded = append(expanded, mod)
		e.stats.ModulesExpanded++
	}

	hasErrors := len(errors) > 0
	e.recordPhase(ExpansionPhaseExpandModules, !hasErrors, e.stats.ModulesExpanded, errors)

	return expanded, nil
}

func (e *PhasedExpander) executeExpandResources(ctx context.Context, modules []*ModuleDefinition, vars map[string]interface{}) ([]*ExpandedInstance, error) {
	e.currentPhase = ExpansionPhaseExpandResources

	var instances []*ExpandedInstance
	var errors []PhaseError

	for _, mod := range modules {
		for _, res := range mod.Resources {
			e.stats.ResourcesFound++

			// Resolve provider for this resource
			providerCtx, err := e.providerResolver.ResolveProvider(res.ModulePath, res.Type, res.Provider)
			if err != nil {
				if strictErr := e.enforcer.CheckUnknownProvider(res.Address, res.Provider); strictErr != nil {
					errors = append(errors, PhaseError{
						Phase:   ExpansionPhaseExpandResources,
						Address: res.Address,
						Message: err.Error(),
						Cause:   strictErr,
					})
					continue
				}
			}

			// Expand count
			if res.Count != nil {
				if !res.Count.IsKnown {
					if err := e.enforcer.CheckUnknownCount(res.Address, "resource count is unknown"); err != nil {
						errors = append(errors, PhaseError{
							Phase:   ExpansionPhaseExpandResources,
							Address: res.Address,
							Message: "unknown count",
							Cause:   err,
						})
						e.stats.UnknownsDeferred++
						continue
					}
					// In permissive/estimate mode, expand with default
					res.Count.Value = GetModeConfig(e.mode).DefaultUnknownCount
				}

				count := e.toInt(res.Count.Value)
				for i := 0; i < count; i++ {
					inst := e.createInstance(res, i, nil, providerCtx)
					instances = append(instances, inst)
					e.stats.InstancesCreated++
				}
				e.stats.ResourcesExpanded++
				continue
			}

			// Expand for_each
			if res.ForEach != nil {
				if !res.ForEach.IsKnown {
					if err := e.enforcer.CheckUnknownForEach(res.Address, "resource for_each is unknown"); err != nil {
						errors = append(errors, PhaseError{
							Phase:   ExpansionPhaseExpandResources,
							Address: res.Address,
							Message: "unknown for_each",
							Cause:   err,
						})
						e.stats.UnknownsDeferred++
						continue
					}
				}

				keys := e.extractKeys(res.ForEach.Value)
				for _, key := range keys {
					inst := e.createInstance(res, 0, key, providerCtx)
					instances = append(instances, inst)
					e.stats.InstancesCreated++
				}
				e.stats.ResourcesExpanded++
				continue
			}

			// Single instance
			inst := e.createInstance(res, 0, nil, providerCtx)
			instances = append(instances, inst)
			e.stats.InstancesCreated++
			e.stats.ResourcesExpanded++
		}
	}

	// Sort for determinism
	sort.Slice(instances, func(i, j int) bool {
		return instances[i].Address < instances[j].Address
	})

	hasErrors := len(errors) > 0
	e.recordPhase(ExpansionPhaseExpandResources, !hasErrors, e.stats.InstancesCreated, errors)

	return instances, nil
}

func (e *PhasedExpander) createInstance(res *ResourceDefinition, countIdx int, forEachKey interface{}, provider *ProviderContext) *ExpandedInstance {
	address := res.Address
	if countIdx > 0 || res.Count != nil {
		address = fmt.Sprintf("%s[%d]", res.Address, countIdx)
	}
	if forEachKey != nil {
		address = fmt.Sprintf("%s[%q]", res.Address, forEachKey)
	}

	return &ExpandedInstance{
		Address:      address,
		ModulePath:   res.ModulePath,
		DefinitionID: res.Address,
		ResourceType: res.Type,
		InstanceKey:  forEachKey,
		Provider:     provider,
		DependsOn:    res.DependsOn,
	}
}

func (e *PhasedExpander) recordPhase(phase ExpansionPhase, success bool, count int, errors []PhaseError) {
	result := &PhaseResult{
		Phase:     phase,
		Success:   success,
		ItemCount: count,
		Errors:    errors,
	}
	e.phaseResults[phase] = result
}

func (e *PhasedExpander) getPhaseResults() []*PhaseResult {
	results := make([]*PhaseResult, 0, len(e.phaseResults))
	for phase := ExpansionPhaseParse; phase <= ExpansionPhaseBuildGraph; phase++ {
		if r, ok := e.phaseResults[phase]; ok {
			results = append(results, r)
		}
	}
	return results
}

func (e *PhasedExpander) toInt(v interface{}) int {
	switch n := v.(type) {
	case int:
		return n
	case int64:
		return int(n)
	case float64:
		return int(n)
	default:
		return 1
	}
}

func (e *PhasedExpander) extractKeys(v interface{}) []string {
	switch val := v.(type) {
	case map[string]interface{}:
		keys := make([]string, 0, len(val))
		for k := range val {
			keys = append(keys, k)
		}
		sort.Strings(keys)
		return keys
	case []interface{}:
		keys := make([]string, 0, len(val))
		for _, item := range val {
			if s, ok := item.(string); ok {
				keys = append(keys, s)
			}
		}
		return keys
	default:
		return []string{}
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\pipeline.go
# TYPE: go
# SIZE: 14785 bytes
################################################################################
// Package terraform provides a formal evaluation pipeline with strict phase separation.
// Phases: PARSE â†’ EVALUATE â†’ RESOLVE â†’ EXPAND â†’ BUILD
package terraform

import (
	"context"
	"fmt"
	"sort"

	"terraform-cost/core/determinism"
	"terraform-cost/core/model"
)

// Phase represents a distinct stage in evaluation
type Phase int

const (
	PhaseParse    Phase = iota // Parse HCL into raw blocks
	PhaseEvaluate              // Evaluate expressions
	PhaseResolve               // Resolve variables, locals, data sources
	PhaseExpand                // Expand count/for_each
	PhaseBuild                 // Build instance graph
)

// String returns the phase name
func (p Phase) String() string {
	switch p {
	case PhaseParse:
		return "parse"
	case PhaseEvaluate:
		return "evaluate"
	case PhaseResolve:
		return "resolve"
	case PhaseExpand:
		return "expand"
	case PhaseBuild:
		return "build"
	default:
		return "unknown"
	}
}

// Pipeline orchestrates all evaluation phases in strict order
type Pipeline struct {
	parser    *Parser
	evaluator *Evaluator
	resolver  *Resolver
	expander  *Expander
	builder   *GraphBuilder

	// Options
	opts PipelineOptions
}

// PipelineOptions configures pipeline behavior
type PipelineOptions struct {
	// Workspace name (default: "default")
	Workspace string

	// Variables from CLI/environment
	Variables map[string]any

	// Target resources (partial apply)
	Targets []string

	// Continue on errors
	ContinueOnError bool

	// Provider defaults
	DefaultProviders map[string]ProviderConfig

	// Unknown handling
	UnknownCountDefault int
}

// NewPipeline creates a new evaluation pipeline
func NewPipeline(opts PipelineOptions) *Pipeline {
	if opts.Workspace == "" {
		opts.Workspace = "default"
	}
	if opts.UnknownCountDefault == 0 {
		opts.UnknownCountDefault = 1
	}

	return &Pipeline{
		parser:    NewParser(),
		evaluator: NewEvaluator(),
		resolver:  NewResolver(opts.Variables),
		expander:  NewExpander(opts.UnknownCountDefault),
		builder:   NewGraphBuilder(),
		opts:      opts,
	}
}

// PipelineResult is the output of the pipeline
type PipelineResult struct {
	Graph    *model.InstanceGraph
	Warnings []Warning
	Errors   []Error
	Stats    PipelineStats
}

// PipelineStats tracks statistics from the pipeline run
type PipelineStats struct {
	DefinitionsFound int
	InstancesCreated int
	EdgesCreated     int
	UnknownValues    int
	ParseDuration    int64 // milliseconds
	TotalDuration    int64
}

// Warning is a non-fatal issue
type Warning struct {
	Phase   Phase
	Address string
	Message string
}

// Error is a fatal issue (may be recoverable if ContinueOnError)
type Error struct {
	Phase   Phase
	Address string
	Message string
	Cause   error
}

// Execute runs all phases in strict order
func (p *Pipeline) Execute(ctx context.Context, input *ScanInput) (*PipelineResult, error) {
	result := &PipelineResult{
		Warnings: []Warning{},
		Errors:   []Error{},
	}

	// Phase 1: Parse
	parsed, err := p.runParse(ctx, input, result)
	if err != nil && !p.opts.ContinueOnError {
		return result, fmt.Errorf("parse phase failed: %w", err)
	}

	// Phase 2: Evaluate expressions
	evaluated, err := p.runEvaluate(ctx, parsed, result)
	if err != nil && !p.opts.ContinueOnError {
		return result, fmt.Errorf("evaluate phase failed: %w", err)
	}

	// Phase 3: Resolve variables, locals, data sources
	resolved, err := p.runResolve(ctx, evaluated, result)
	if err != nil && !p.opts.ContinueOnError {
		return result, fmt.Errorf("resolve phase failed: %w", err)
	}

	// Phase 4: Expand instances
	expanded, err := p.runExpand(ctx, resolved, result)
	if err != nil && !p.opts.ContinueOnError {
		return result, fmt.Errorf("expand phase failed: %w", err)
	}

	// Phase 5: Build instance graph
	graph, err := p.runBuild(ctx, expanded, result)
	if err != nil {
		return result, fmt.Errorf("build phase failed: %w", err)
	}

	result.Graph = graph
	result.Stats.DefinitionsFound = len(parsed.Definitions)
	result.Stats.InstancesCreated = graph.Size()
	return result, nil
}

// ScanInput is the input to the pipeline
type ScanInput struct {
	RootPath    string
	Files       []string
	ModulePaths []string
	Workspace   string
}

// ParsedModule represents parsed HCL content
type ParsedModule struct {
	Path        string
	Definitions []*model.AssetDefinition
	Variables   []*VariableBlock
	Locals      []*LocalBlock
	Outputs     []*OutputBlock
	Providers   []*ProviderBlock
	Modules     []*ModuleCall
	DataSources []*model.AssetDefinition
}

// VariableBlock is a Terraform variable
type VariableBlock struct {
	Name        string
	Type        string
	Default     any
	Description string
	Sensitive   bool
	Validation  []ValidationRule
}

// LocalBlock is a Terraform local
type LocalBlock struct {
	Name       string
	Expression model.Expression
}

// OutputBlock is a Terraform output
type OutputBlock struct {
	Name        string
	Expression  model.Expression
	Description string
	Sensitive   bool
	DependsOn   []string
}

// ProviderBlock is a Terraform provider configuration
type ProviderBlock struct {
	Type       string
	Alias      string
	Attributes map[string]model.Expression
}

// ProviderConfig is a resolved provider
type ProviderConfig struct {
	Type   string
	Alias  string
	Region string
	Module string              // Module where defined
	Config map[string]any
}

// ModuleCall is a Terraform module block
type ModuleCall struct {
	Name       string
	Source     string
	Version    string
	Count      *model.Expression
	ForEach    *model.Expression
	Providers  map[string]string // Provider aliases
	Inputs     map[string]model.Expression
	DependsOn  []string
}

// ValidationRule is a variable validation
type ValidationRule struct {
	Condition    model.Expression
	ErrorMessage string
}

// runParse executes the parse phase
func (p *Pipeline) runParse(ctx context.Context, input *ScanInput, result *PipelineResult) (*ParsedModule, error) {
	return p.parser.Parse(ctx, input)
}

// EvaluatedModule has expressions partially evaluated
type EvaluatedModule struct {
	*ParsedModule
	// Local values computed
	ComputedLocals map[string]any
	// Provider configs resolved
	ResolvedProviders map[string]ProviderConfig
}

func (p *Pipeline) runEvaluate(ctx context.Context, parsed *ParsedModule, result *PipelineResult) (*EvaluatedModule, error) {
	return p.evaluator.Evaluate(ctx, parsed)
}

// ResolvedModule has all references resolved
type ResolvedModule struct {
	*EvaluatedModule
	// Variable values after resolution
	ResolvedVariables map[string]any
	// Data sources evaluated (some may be unknown)
	ResolvedData map[string]ResolvedData
}

// ResolvedData is a resolved data source
type ResolvedData struct {
	Address    string
	Attributes map[string]model.ResolvedAttribute
	IsKnown    bool
}

func (p *Pipeline) runResolve(ctx context.Context, evaluated *EvaluatedModule, result *PipelineResult) (*ResolvedModule, error) {
	return p.resolver.Resolve(ctx, evaluated)
}

// ExpandedModule has all count/for_each expanded
type ExpandedModule struct {
	*ResolvedModule
	// Instances after expansion
	Instances []*model.AssetInstance
}

func (p *Pipeline) runExpand(ctx context.Context, resolved *ResolvedModule, result *PipelineResult) (*ExpandedModule, error) {
	return p.expander.Expand(ctx, resolved, result)
}

func (p *Pipeline) runBuild(ctx context.Context, expanded *ExpandedModule, result *PipelineResult) (*model.InstanceGraph, error) {
	return p.builder.Build(ctx, expanded)
}

// Parser handles Phase 1: Parse
type Parser struct{}

func NewParser() *Parser { return &Parser{} }

func (p *Parser) Parse(ctx context.Context, input *ScanInput) (*ParsedModule, error) {
	// Implementation would use HCL parser
	// For now, return skeleton
	return &ParsedModule{
		Path:        input.RootPath,
		Definitions: []*model.AssetDefinition{},
		Variables:   []*VariableBlock{},
		Locals:      []*LocalBlock{},
	}, nil
}

// Evaluator handles Phase 2: Evaluate
type Evaluator struct{}

func NewEvaluator() *Evaluator { return &Evaluator{} }

func (e *Evaluator) Evaluate(ctx context.Context, parsed *ParsedModule) (*EvaluatedModule, error) {
	result := &EvaluatedModule{
		ParsedModule:      parsed,
		ComputedLocals:    make(map[string]any),
		ResolvedProviders: make(map[string]ProviderConfig),
	}

	// Evaluate locals in dependency order
	// Resolve provider configurations

	return result, nil
}

// Resolver handles Phase 3: Resolve
type Resolver struct {
	inputVars map[string]any
}

func NewResolver(vars map[string]any) *Resolver {
	if vars == nil {
		vars = make(map[string]any)
	}
	return &Resolver{inputVars: vars}
}

func (r *Resolver) Resolve(ctx context.Context, evaluated *EvaluatedModule) (*ResolvedModule, error) {
	result := &ResolvedModule{
		EvaluatedModule:   evaluated,
		ResolvedVariables: make(map[string]any),
		ResolvedData:      make(map[string]ResolvedData),
	}

	// Resolve variables from inputs, defaults, environment
	for _, v := range evaluated.Variables {
		if val, ok := r.inputVars[v.Name]; ok {
			result.ResolvedVariables[v.Name] = val
		} else if v.Default != nil {
			result.ResolvedVariables[v.Name] = v.Default
		}
	}

	return result, nil
}

// Expander handles Phase 4: Expand
type Expander struct {
	defaultCount int
}

func NewExpander(defaultCount int) *Expander {
	return &Expander{defaultCount: defaultCount}
}

func (e *Expander) Expand(ctx context.Context, resolved *ResolvedModule, result *PipelineResult) (*ExpandedModule, error) {
	expanded := &ExpandedModule{
		ResolvedModule: resolved,
		Instances:      []*model.AssetInstance{},
	}

	idGen := determinism.NewIDGenerator("inst")

	for _, def := range resolved.Definitions {
		instances, warnings := e.expandDefinition(def, resolved, idGen)
		expanded.Instances = append(expanded.Instances, instances...)

		for _, w := range warnings {
			result.Warnings = append(result.Warnings, Warning{
				Phase:   PhaseExpand,
				Address: string(def.Address),
				Message: w,
			})
		}
	}

	// Sort instances for determinism
	sort.Slice(expanded.Instances, func(i, j int) bool {
		return expanded.Instances[i].Address < expanded.Instances[j].Address
	})

	return expanded, nil
}

func (e *Expander) expandDefinition(def *model.AssetDefinition, resolved *ResolvedModule, idGen *determinism.IDGenerator) ([]*model.AssetInstance, []string) {
	var warnings []string

	// Handle count
	if def.Count != nil {
		count, known := e.resolveCount(def.Count, resolved)
		if !known {
			warnings = append(warnings, fmt.Sprintf("count could not be determined, assuming %d", e.defaultCount))
			count = e.defaultCount
		}

		instances := make([]*model.AssetInstance, count)
		for i := 0; i < count; i++ {
			addr := model.InstanceAddress(fmt.Sprintf("%s[%d]", def.Address, i))
			instances[i] = &model.AssetInstance{
				ID:           model.InstanceID(idGen.Generate(string(def.ID), fmt.Sprintf("%d", i))),
				DefinitionID: def.ID,
				Address:      addr,
				Key:          model.InstanceKey{Type: model.KeyTypeInt, IntValue: i},
				Attributes:   e.resolveAttributes(def, i, "", resolved),
			}
		}
		return instances, warnings
	}

	// Handle for_each
	if def.ForEach != nil {
		keys, known := e.resolveForEach(def.ForEach, resolved)
		if !known {
			warnings = append(warnings, "for_each could not be determined")
			return []*model.AssetInstance{}, warnings
		}

		// Sort keys for determinism
		sort.Strings(keys)

		instances := make([]*model.AssetInstance, len(keys))
		for i, key := range keys {
			addr := model.InstanceAddress(fmt.Sprintf("%s[%q]", def.Address, key))
			instances[i] = &model.AssetInstance{
				ID:           model.InstanceID(idGen.Generate(string(def.ID), key)),
				DefinitionID: def.ID,
				Address:      addr,
				Key:          model.InstanceKey{Type: model.KeyTypeString, StrValue: key},
				Attributes:   e.resolveAttributes(def, 0, key, resolved),
			}
		}
		return instances, warnings
	}

	// No expansion - single instance
	return []*model.AssetInstance{
		{
			ID:           model.InstanceID(idGen.Generate(string(def.ID))),
			DefinitionID: def.ID,
			Address:      model.InstanceAddress(def.Address),
			Key:          model.InstanceKey{Type: model.KeyTypeNone},
			Attributes:   e.resolveAttributes(def, 0, "", resolved),
		},
	}, warnings
}

func (e *Expander) resolveCount(expr *model.Expression, resolved *ResolvedModule) (int, bool) {
	if expr.IsLiteral {
		if n, ok := expr.LiteralVal.(int); ok {
			return n, true
		}
		if f, ok := expr.LiteralVal.(float64); ok {
			return int(f), true
		}
	}
	// Would need full expression evaluation
	return 0, false
}

func (e *Expander) resolveForEach(expr *model.Expression, resolved *ResolvedModule) ([]string, bool) {
	if expr.IsLiteral {
		switch v := expr.LiteralVal.(type) {
		case map[string]any:
			keys := make([]string, 0, len(v))
			for k := range v {
				keys = append(keys, k)
			}
			return keys, true
		case []any:
			keys := make([]string, len(v))
			for i, item := range v {
				if s, ok := item.(string); ok {
					keys[i] = s
				}
			}
			return keys, true
		}
	}
	return nil, false
}

func (e *Expander) resolveAttributes(def *model.AssetDefinition, countIdx int, eachKey string, resolved *ResolvedModule) map[string]model.ResolvedAttribute {
	result := make(map[string]model.ResolvedAttribute)

	for name, expr := range def.Attributes {
		// Skip meta-arguments
		if name == "count" || name == "for_each" || name == "depends_on" || name == "lifecycle" || name == "provider" {
			continue
		}

		if expr.IsLiteral {
			result[name] = model.ResolvedAttribute{
				Value:     expr.LiteralVal,
				IsUnknown: false,
			}
		} else {
			// Mark as unknown for now
			result[name] = model.ResolvedAttribute{
				IsUnknown: true,
				Reason:    model.ReasonComputedAtApply,
			}
		}
	}

	return result
}

// GraphBuilder handles Phase 5: Build
type GraphBuilder struct{}

func NewGraphBuilder() *GraphBuilder { return &GraphBuilder{} }

func (b *GraphBuilder) Build(ctx context.Context, expanded *ExpandedModule) (*model.InstanceGraph, error) {
	graph := model.NewInstanceGraph()

	// Add all instances
	for _, inst := range expanded.Instances {
		graph.AddInstance(inst)
	}

	// Build dependency edges from depends_on and references
	// This requires analyzing instance dependencies

	return graph, nil
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\provider.go
# TYPE: go
# SIZE: 6912 bytes
################################################################################
// Package terraform - Provider configuration and alias resolution
package terraform

import (
	"fmt"
	"sort"
	"strings"

	"terraform-cost/core/model"
)

// ProviderResolver handles provider configuration and alias inheritance
type ProviderResolver struct {
	// Resolved providers by key (type.alias)
	providers map[string]ProviderConfig

	// Provider inheritance chain
	inheritance map[string]string // child -> parent

	// Default regions per provider type
	defaultRegions map[string]string
}

// NewProviderResolver creates a new resolver
func NewProviderResolver() *ProviderResolver {
	return &ProviderResolver{
		providers:   make(map[string]ProviderConfig),
		inheritance: make(map[string]string),
		defaultRegions: map[string]string{
			"aws":     "us-east-1",
			"azurerm": "eastus",
			"google":  "us-central1",
		},
	}
}

// AddProvider registers a provider configuration
func (r *ProviderResolver) AddProvider(cfg ProviderConfig) {
	key := r.providerKey(cfg.Type, cfg.Alias)
	r.providers[key] = cfg
}

// SetInheritance sets up module provider inheritance
// modulePath is the child module, providerMap maps child aliases to parent aliases
func (r *ProviderResolver) SetInheritance(modulePath string, providerMap map[string]string) {
	for childAlias, parentAlias := range providerMap {
		childKey := modulePath + ":" + childAlias
		r.inheritance[childKey] = parentAlias
	}
}

// Resolve determines the provider configuration for a resource
func (r *ProviderResolver) Resolve(
	resourceType string,
	explicitProvider string,
	modulePath string,
) (model.ResolvedProvider, error) {
	// Determine provider type from resource type
	providerType := r.providerTypeFromResource(resourceType)

	// Determine provider key
	providerKey := r.determineProviderKey(providerType, explicitProvider, modulePath)

	// Look up provider
	cfg, ok := r.providers[providerKey]
	if !ok {
		// Fall back to default provider
		cfg = r.defaultProvider(providerType)
	}

	return model.ResolvedProvider{
		Type:       cfg.Type,
		Alias:      cfg.Alias,
		Region:     cfg.Region,
		Attributes: cfg.Config,
	}, nil
}

// providerTypeFromResource extracts provider type from resource type
// e.g., "aws_instance" -> "aws", "google_compute_instance" -> "google"
func (r *ProviderResolver) providerTypeFromResource(resourceType string) string {
	parts := strings.SplitN(resourceType, "_", 2)
	if len(parts) < 1 {
		return ""
	}
	return parts[0]
}

// providerKey creates a unique key for a provider
func (r *ProviderResolver) providerKey(providerType, alias string) string {
	if alias == "" {
		return providerType
	}
	return providerType + "." + alias
}

// determineProviderKey determines which provider to use
func (r *ProviderResolver) determineProviderKey(
	providerType string,
	explicitProvider string,
	modulePath string,
) string {
	// If explicit provider specified, use it
	if explicitProvider != "" {
		// Check if it needs inheritance lookup
		if modulePath != "" {
			inheritKey := modulePath + ":" + explicitProvider
			if inherited, ok := r.inheritance[inheritKey]; ok {
				return inherited
			}
		}
		return explicitProvider
	}

	// Check module-level provider inheritance
	if modulePath != "" {
		// Walk up the module tree looking for provider
		for path := modulePath; path != ""; path = r.parentModule(path) {
			inheritKey := path + ":" + providerType
			if inherited, ok := r.inheritance[inheritKey]; ok {
				return inherited
			}
		}
	}

	// Default to un-aliased provider
	return providerType
}

// parentModule returns the parent module path
func (r *ProviderResolver) parentModule(path string) string {
	parts := strings.Split(path, ".")
	if len(parts) <= 1 {
		return ""
	}
	return strings.Join(parts[:len(parts)-1], ".")
}

// defaultProvider returns a default provider config
func (r *ProviderResolver) defaultProvider(providerType string) ProviderConfig {
	region := r.defaultRegions[providerType]
	if region == "" {
		region = "us-east-1" // Fallback
	}
	return ProviderConfig{
		Type:   providerType,
		Alias:  "",
		Region: region,
		Config: map[string]any{},
	}
}

// ResolveAllProviders resolves providers for all instances
func (r *ProviderResolver) ResolveAllProviders(
	instances []*model.AssetInstance,
	definitions map[model.DefinitionID]*model.AssetDefinition,
) error {
	for _, inst := range instances {
		def := definitions[inst.DefinitionID]
		if def == nil {
			continue
		}

		// Get explicit provider from definition
		explicitProvider := ""
		if provAttr, ok := def.Attributes["provider"]; ok && provAttr.IsLiteral {
			if s, ok := provAttr.LiteralVal.(string); ok {
				explicitProvider = s
			}
		}

		// Extract module path from address
		modulePath := r.modulePathFromAddress(string(def.Address))

		// Resolve provider
		resolved, err := r.Resolve(string(def.Type), explicitProvider, modulePath)
		if err != nil {
			return fmt.Errorf("failed to resolve provider for %s: %w", inst.Address, err)
		}

		inst.Provider = resolved
	}

	return nil
}

// modulePathFromAddress extracts module path from resource address
// e.g., "module.foo.module.bar.aws_instance.web" -> "module.foo.module.bar"
func (r *ProviderResolver) modulePathFromAddress(addr string) string {
	parts := strings.Split(addr, ".")
	var moduleParts []string

	for i := 0; i < len(parts)-2; i += 2 {
		if parts[i] == "module" {
			moduleParts = append(moduleParts, "module."+parts[i+1])
		} else {
			break
		}
	}

	return strings.Join(moduleParts, ".")
}

// Providers returns all registered providers in sorted order
func (r *ProviderResolver) Providers() []ProviderConfig {
	keys := make([]string, 0, len(r.providers))
	for k := range r.providers {
		keys = append(keys, k)
	}
	sort.Strings(keys)

	result := make([]ProviderConfig, len(keys))
	for i, k := range keys {
		result[i] = r.providers[k]
	}
	return result
}

// ExtractRegion extracts region from provider config or resource attributes
func (r *ProviderResolver) ExtractRegion(
	inst *model.AssetInstance,
	def *model.AssetDefinition,
) string {
	// First check instance provider
	if inst.Provider.Region != "" {
		return inst.Provider.Region
	}

	// Check resource attributes for region
	if regionAttr, ok := inst.Attributes["region"]; ok && !regionAttr.IsUnknown {
		if s, ok := regionAttr.Value.(string); ok {
			return s
		}
	}

	// Check availability_zone and derive region
	if azAttr, ok := inst.Attributes["availability_zone"]; ok && !azAttr.IsUnknown {
		if s, ok := azAttr.Value.(string); ok {
			// Remove the AZ suffix (e.g., "us-east-1a" -> "us-east-1")
			if len(s) > 1 {
				return s[:len(s)-1]
			}
		}
	}

	// Fall back to provider default
	return r.defaultRegions[inst.Provider.Type]
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\provider_binding.go
# TYPE: go
# SIZE: 8428 bytes
################################################################################
// Package terraform - Module provider binding resolution
// Provider aliases MUST propagate correctly through module boundaries.
package terraform

import (
	"fmt"
	"strings"
)

// ModuleProviderBinding represents how providers are passed to modules
type ModuleProviderBinding struct {
	// Module path (e.g., "module.vpc.module.subnet")
	ModulePath string

	// Provider mappings from parent to child
	// Key: local provider name in module (e.g., "aws")
	// Value: parent provider reference (e.g., "aws.us_east")
	Bindings map[string]string

	// Explicit providers block in module call
	ExplicitProviders map[string]string

	// Inherited from parent (not explicitly set)
	InheritedProviders map[string]string
}

// ModuleProviderResolver resolves provider bindings through module chains
type ModuleProviderResolver struct {
	// Root provider configs
	rootProviders map[string]*ProviderConfig

	// Per-module bindings
	moduleBindings map[string]*ModuleProviderBinding

	// Resolved cache
	resolvedCache map[string]*ProviderContext
}

// NewModuleProviderResolver creates a resolver
func NewModuleProviderResolver() *ModuleProviderResolver {
	return &ModuleProviderResolver{
		rootProviders:  make(map[string]*ProviderConfig),
		moduleBindings: make(map[string]*ModuleProviderBinding),
		resolvedCache:  make(map[string]*ProviderContext),
	}
}

// RegisterRootProvider registers a provider at root level
func (r *ModuleProviderResolver) RegisterRootProvider(config *ProviderConfig) {
	key := config.Type
	if config.Alias != "" {
		key = config.Type + "." + config.Alias
	}
	r.rootProviders[key] = config
}

// RegisterModuleCall registers a module call with its provider mappings
func (r *ModuleProviderResolver) RegisterModuleCall(parentPath, moduleName string, providers map[string]string) {
	childPath := moduleName
	if parentPath != "" {
		childPath = parentPath + "." + moduleName
	}

	binding := &ModuleProviderBinding{
		ModulePath:         childPath,
		Bindings:           make(map[string]string),
		ExplicitProviders:  providers,
		InheritedProviders: make(map[string]string),
	}

	// Process explicit providers
	for localName, parentRef := range providers {
		binding.Bindings[localName] = parentRef
	}

	r.moduleBindings[childPath] = binding
}

// ResolveProvider resolves the exact provider config for a resource
// Following Terraform's provider inheritance rules exactly
func (r *ModuleProviderResolver) ResolveProvider(modulePath, resourceType, explicitProvider string) (*ProviderContext, error) {
	// Cache key
	cacheKey := fmt.Sprintf("%s::%s::%s", modulePath, resourceType, explicitProvider)
	if cached, ok := r.resolvedCache[cacheKey]; ok {
		return cached, nil
	}

	// Extract provider type from resource
	providerType := extractProviderTypeFromResource(resourceType)

	// Determine which provider reference to resolve
	providerRef := providerType // default
	if explicitProvider != "" {
		providerRef = explicitProvider
	}

	// Resolve through module chain
	ctx, err := r.resolveProviderThroughChain(modulePath, providerRef, providerType)
	if err != nil {
		return nil, err
	}

	r.resolvedCache[cacheKey] = ctx
	return ctx, nil
}

// resolveProviderThroughChain walks the module chain to find the actual provider
func (r *ModuleProviderResolver) resolveProviderThroughChain(modulePath, providerRef, providerType string) (*ProviderContext, error) {
	// If at root, resolve directly
	if modulePath == "" {
		return r.resolveAtRoot(providerRef)
	}

	// Check if this module has explicit binding for this provider
	binding := r.moduleBindings[modulePath]

	// Extract just the provider name without alias for matching
	baseProviderName := providerType
	if idx := strings.Index(providerRef, "."); idx != -1 {
		baseProviderName = providerRef[:idx]
	}

	if binding != nil {
		// Check explicit providers first
		if parentRef, ok := binding.ExplicitProviders[baseProviderName]; ok {
			// This module maps this provider to a parent provider
			// Recurse to parent to resolve the actual config
			parentPath := getParentPath(modulePath)
			resolved, err := r.resolveProviderThroughChain(parentPath, parentRef, providerType)
			if err != nil {
				return nil, err
			}
			// Mark as inherited
			resolved.IsInherited = true
			resolved.DefinedInModule = parentPath
			return resolved, nil
		}

		// Check all bindings
		if parentRef, ok := binding.Bindings[providerRef]; ok {
			parentPath := getParentPath(modulePath)
			resolved, err := r.resolveProviderThroughChain(parentPath, parentRef, providerType)
			if err != nil {
				return nil, err
			}
			resolved.IsInherited = true
			return resolved, nil
		}
	}

	// No explicit binding - inherit from parent
	parentPath := getParentPath(modulePath)
	resolved, err := r.resolveProviderThroughChain(parentPath, providerRef, providerType)
	if err != nil {
		return nil, err
	}
	resolved.IsInherited = true
	return resolved, nil
}

// resolveAtRoot resolves a provider at the root module
func (r *ModuleProviderResolver) resolveAtRoot(providerRef string) (*ProviderContext, error) {
	// Look for exact match
	if config, ok := r.rootProviders[providerRef]; ok {
		return &ProviderContext{
			ProviderType:    config.Type,
			Alias:           config.Alias,
			Region:          config.Region,
			IsInherited:     false,
			DefinedInModule: "",
			FullAddress:     providerRef,
			Config:          config.Config,
		}, nil
	}

	// Try without alias (default provider)
	providerType := providerRef
	if idx := strings.Index(providerRef, "."); idx != -1 {
		providerType = providerRef[:idx]
	}

	if config, ok := r.rootProviders[providerType]; ok {
		return &ProviderContext{
			ProviderType:    config.Type,
			Alias:           config.Alias,
			Region:          config.Region,
			IsInherited:     false,
			DefinedInModule: "",
			FullAddress:     providerRef,
			Config:          config.Config,
		}, nil
	}

	// No provider found - return error, not a guess
	return nil, &ProviderNotFoundError{
		ProviderRef: providerRef,
		ModulePath:  "",
	}
}

// ProviderNotFoundError indicates a provider could not be resolved
type ProviderNotFoundError struct {
	ProviderRef string
	ModulePath  string
}

func (e *ProviderNotFoundError) Error() string {
	if e.ModulePath == "" {
		return fmt.Sprintf("provider %q not found in root module", e.ProviderRef)
	}
	return fmt.Sprintf("provider %q not found for module %q", e.ProviderRef, e.ModulePath)
}

func extractProviderTypeFromResource(resourceType string) string {
	if idx := strings.Index(resourceType, "_"); idx != -1 {
		return resourceType[:idx]
	}
	return resourceType
}

func getParentPath(modulePath string) string {
	if idx := strings.LastIndex(modulePath, "."); idx != -1 {
		return modulePath[:idx]
	}
	return ""
}

// ProviderBindingValidator validates that all resources have valid provider bindings
type ProviderBindingValidator struct {
	resolver *ModuleProviderResolver
	errors   []ProviderBindingError
}

// ProviderBindingError is a provider resolution error
type ProviderBindingError struct {
	ResourceAddress string
	ModulePath      string
	ProviderRef     string
	Reason          string
}

// NewProviderBindingValidator creates a validator
func NewProviderBindingValidator(resolver *ModuleProviderResolver) *ProviderBindingValidator {
	return &ProviderBindingValidator{
		resolver: resolver,
		errors:   []ProviderBindingError{},
	}
}

// Validate ensures all resources in a module have valid provider bindings
func (v *ProviderBindingValidator) Validate(resources []ResourceWithProvider) []ProviderBindingError {
	v.errors = []ProviderBindingError{}

	for _, res := range resources {
		_, err := v.resolver.ResolveProvider(res.ModulePath, res.ResourceType, res.ExplicitProvider)
		if err != nil {
			v.errors = append(v.errors, ProviderBindingError{
				ResourceAddress: res.Address,
				ModulePath:      res.ModulePath,
				ProviderRef:     res.ExplicitProvider,
				Reason:          err.Error(),
			})
		}
	}

	return v.errors
}

// ResourceWithProvider is a resource that needs provider resolution
type ResourceWithProvider struct {
	Address          string
	ModulePath       string
	ResourceType     string
	ExplicitProvider string
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\provider_context.go
# TYPE: go
# SIZE: 7293 bytes
################################################################################
// Package terraform - Provider context propagation
// Each instance MUST know exactly which provider config applies.
package terraform

import (
	"fmt"
	"strings"

	"terraform-cost/core/types"
)

// ProviderContext represents the resolved provider configuration for a resource
type ProviderContext struct {
	// Provider type (aws, google, azurerm)
	ProviderType string

	// Alias (empty for default)
	Alias string

	// Resolved region
	Region string

	// Is this inherited from module?
	IsInherited bool

	// Module path where this was defined
	DefinedInModule string

	// Full provider address
	FullAddress string

	// Additional configuration
	Config map[string]interface{}
}

// ProviderKey returns a unique key for this provider
func (p *ProviderContext) ProviderKey() string {
	if p.Alias == "" {
		return p.ProviderType
	}
	return p.ProviderType + "." + p.Alias
}

// ProviderRegistry tracks all provider configurations
type ProviderRegistry struct {
	// Provider configs by module path + alias
	configs map[string]*ProviderConfig

	// Default providers per type
	defaults map[string]*ProviderConfig

	// Module provider mappings (providers = { aws = aws.west })
	moduleMappings map[string]map[string]string
}

// ProviderConfig is defined in pipeline.go - using that definition

// NewProviderRegistry creates a new registry
func NewProviderRegistry() *ProviderRegistry {
	return &ProviderRegistry{
		configs:        make(map[string]*ProviderConfig),
		defaults:       make(map[string]*ProviderConfig),
		moduleMappings: make(map[string]map[string]string),
	}
}

// RegisterProvider registers a provider configuration
func (r *ProviderRegistry) RegisterProvider(modulePath string, config *ProviderConfig) {
	key := r.makeKey(modulePath, config.Type, config.Alias)
	r.configs[key] = config

	// Track default if no alias
	if config.Alias == "" {
		defaultKey := r.makeKey(modulePath, config.Type, "")
		r.defaults[defaultKey] = config
	}
}

// RegisterModuleMapping registers a module's provider mapping
func (r *ProviderRegistry) RegisterModuleMapping(modulePath string, mappings map[string]string) {
	r.moduleMappings[modulePath] = mappings
}

// ResolveForResource resolves the provider context for a resource
func (r *ProviderRegistry) ResolveForResource(modulePath, resourceType, providerAttr string) *ProviderContext {
	// Determine provider type from resource type
	providerType := r.extractProviderType(resourceType)

	// Check if resource has explicit provider attribute
	if providerAttr != "" {
		return r.resolveExplicitProvider(modulePath, providerAttr)
	}

	// Check module mappings
	if mapping, ok := r.moduleMappings[modulePath]; ok {
		if mapped, exists := mapping[providerType]; exists {
			return r.resolveExplicitProvider(modulePath, mapped)
		}
	}

	// Look for default provider in current module chain
	return r.resolveDefaultProvider(modulePath, providerType)
}

func (r *ProviderRegistry) resolveExplicitProvider(modulePath, providerRef string) *ProviderContext {
	// Parse provider reference (e.g., "aws.west")
	parts := strings.SplitN(providerRef, ".", 2)
	providerType := parts[0]
	alias := ""
	if len(parts) > 1 {
		alias = parts[1]
	}

	// Search from current module up to root
	currentPath := modulePath
	for {
		key := r.makeKey(currentPath, providerType, alias)
		if config, ok := r.configs[key]; ok {
			return &ProviderContext{
				ProviderType:    providerType,
				Alias:           alias,
				Region:          config.Region,
				IsInherited:     currentPath != modulePath,
				DefinedInModule: currentPath,
				FullAddress:     providerRef,
				Config:          config.Config,
			}
		}

		// Move up one module level
		if currentPath == "" {
			break
		}
		lastDot := strings.LastIndex(currentPath, ".")
		if lastDot == -1 {
			currentPath = ""
		} else {
			currentPath = currentPath[:lastDot]
		}
	}

	// Provider not found - return unknown context
	return &ProviderContext{
		ProviderType: providerType,
		Alias:        alias,
		Region:       "", // UNKNOWN - will need to be resolved or flagged
		FullAddress:  providerRef,
	}
}

func (r *ProviderRegistry) resolveDefaultProvider(modulePath, providerType string) *ProviderContext {
	// Search from current module up to root for default provider
	currentPath := modulePath
	for {
		key := r.makeKey(currentPath, providerType, "")
		if config, ok := r.defaults[key]; ok {
			return &ProviderContext{
				ProviderType:    providerType,
				Alias:           "",
				Region:          config.Region,
				IsInherited:     currentPath != modulePath,
				DefinedInModule: currentPath,
				FullAddress:     providerType,
				Config:          config.Config,
			}
		}

		// Move up one module level
		if currentPath == "" {
			break
		}
		lastDot := strings.LastIndex(currentPath, ".")
		if lastDot == -1 {
			currentPath = ""
		} else {
			currentPath = currentPath[:lastDot]
		}
	}

	// No provider found - use defaults
	return r.createDefaultContext(providerType)
}

func (r *ProviderRegistry) createDefaultContext(providerType string) *ProviderContext {
	// Default regions per provider
	defaultRegions := map[string]string{
		"aws":      "us-east-1",
		"google":   "us-central1",
		"azurerm":  "eastus",
	}

	region := defaultRegions[providerType]
	if region == "" {
		region = "unknown"
	}

	return &ProviderContext{
		ProviderType: providerType,
		Alias:        "",
		Region:       region,
		IsInherited:  false,
		FullAddress:  providerType,
	}
}

func (r *ProviderRegistry) extractProviderType(resourceType string) string {
	// aws_instance -> aws
	// google_compute_instance -> google
	// azurerm_virtual_machine -> azurerm
	idx := strings.Index(resourceType, "_")
	if idx == -1 {
		return resourceType
	}
	return resourceType[:idx]
}

func (r *ProviderRegistry) makeKey(modulePath, providerType, alias string) string {
	if alias != "" {
		return fmt.Sprintf("%s::%s.%s", modulePath, providerType, alias)
	}
	return fmt.Sprintf("%s::%s", modulePath, providerType)
}

// InstanceWithProvider binds an instance to its provider context
type InstanceWithProvider struct {
	InstanceAddress string
	InstanceKey     interface{}
	ProviderCtx     *ProviderContext // Resolved provider context

	// For cost estimation
	PricingRegion   types.Region   // Region for pricing lookups
	PricingProvider types.Provider // Provider for pricing lookups
}

// ResolveRegionForPricing returns the region to use for pricing lookups
func (i *InstanceWithProvider) ResolveRegionForPricing() types.Region {
	if i.ProviderCtx == nil || i.ProviderCtx.Region == "" {
		return types.Region("us-east-1") // Fallback
	}
	return types.Region(i.ProviderCtx.Region)
}

// GetPricingProvider returns the provider for pricing lookups
func (i *InstanceWithProvider) GetPricingProvider() types.Provider {
	if i.ProviderCtx == nil {
		return types.ProviderUnknown
	}
	switch i.ProviderCtx.ProviderType {
	case "aws":
		return types.ProviderAWS
	case "google":
		return types.ProviderGCP
	case "azurerm":
		return types.ProviderAzure
	default:
		return types.ProviderUnknown
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\provider_finalization.go
# TYPE: go
# SIZE: 7253 bytes
################################################################################
// Package terraform - Provider alias finalization
// Provider context MUST be frozen before pricing resolution.
// Alias + region + account is a first-class dimension.
package terraform

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
)

// FrozenProviderContext is an immutable provider binding
type FrozenProviderContext struct {
	// Canonical identity
	ProviderKey string // e.g., "aws.us_east"

	// Provider details
	Type   string
	Alias  string
	Region string

	// Account context
	AccountID string
	AssumeRole string

	// Content hash (immutable)
	ContentHash string

	// Is this frozen?
	frozen bool
}

// Freeze creates an immutable copy
func (p *ProviderContext) Freeze() *FrozenProviderContext {
	frozen := &FrozenProviderContext{
		ProviderKey: p.ProviderKey(),
		Type:        p.ProviderType,
		Alias:       p.Alias,
		Region:      p.Region,
		frozen:      true,
	}

	// Extract account from config if present
	if p.Config != nil {
		if accountID, ok := p.Config["account_id"].(string); ok {
			frozen.AccountID = accountID
		}
		if roleArn, ok := p.Config["assume_role"].(string); ok {
			frozen.AssumeRole = roleArn
		}
	}

	// Compute content hash
	frozen.ContentHash = frozen.computeHash()

	return frozen
}

func (f *FrozenProviderContext) computeHash() string {
	h := sha256.New()
	h.Write([]byte(f.Type))
	h.Write([]byte(f.Alias))
	h.Write([]byte(f.Region))
	h.Write([]byte(f.AccountID))
	h.Write([]byte(f.AssumeRole))
	return hex.EncodeToString(h.Sum(nil))[:12]
}

// RateKey returns the key for pricing lookup
func (f *FrozenProviderContext) RateKey(resourceType, sku string) string {
	// Format: provider:region:type:sku
	return fmt.Sprintf("%s:%s:%s:%s", f.Type, f.Region, resourceType, sku)
}

// PricingDimension returns all dimensions for pricing
func (f *FrozenProviderContext) PricingDimension() PricingDimension {
	return PricingDimension{
		Provider:  f.Type,
		Region:    f.Region,
		AccountID: f.AccountID,
		Alias:     f.Alias,
	}
}

// PricingDimension contains all provider dimensions for pricing
type PricingDimension struct {
	Provider  string
	Region    string
	AccountID string
	Alias     string
}

// Key returns a unique key for this dimension
func (d PricingDimension) Key() string {
	if d.AccountID != "" {
		return fmt.Sprintf("%s:%s:%s", d.Provider, d.Region, d.AccountID)
	}
	return fmt.Sprintf("%s:%s", d.Provider, d.Region)
}

// ProviderFinalizer ensures providers are frozen before use
type ProviderFinalizer struct {
	// All frozen providers
	frozen map[string]*FrozenProviderContext

	// Finalization order
	order []string

	// Is finalization complete?
	finalized bool
}

// NewProviderFinalizer creates a finalizer
func NewProviderFinalizer() *ProviderFinalizer {
	return &ProviderFinalizer{
		frozen:    make(map[string]*FrozenProviderContext),
		order:     []string{},
		finalized: false,
	}
}

// Freeze freezes a provider context
func (pf *ProviderFinalizer) Freeze(ctx *ProviderContext) (*FrozenProviderContext, error) {
	if pf.finalized {
		return nil, fmt.Errorf("provider finalization already complete")
	}

	frozen := ctx.Freeze()
	pf.frozen[frozen.ProviderKey] = frozen
	pf.order = append(pf.order, frozen.ProviderKey)

	return frozen, nil
}

// Finalize marks finalization complete - no more providers can be added
func (pf *ProviderFinalizer) Finalize() {
	pf.finalized = true
}

// Get returns a frozen provider
func (pf *ProviderFinalizer) Get(key string) (*FrozenProviderContext, bool) {
	frozen, ok := pf.frozen[key]
	return frozen, ok
}

// MustGet returns a frozen provider or panics
func (pf *ProviderFinalizer) MustGet(key string) *FrozenProviderContext {
	frozen, ok := pf.frozen[key]
	if !ok {
		panic(fmt.Sprintf("provider %s not frozen", key))
	}
	return frozen
}

// All returns all frozen providers
func (pf *ProviderFinalizer) All() []*FrozenProviderContext {
	result := make([]*FrozenProviderContext, 0, len(pf.frozen))
	for _, key := range pf.order {
		result = append(result, pf.frozen[key])
	}
	return result
}

// IsFinalized returns true if finalization is complete
func (pf *ProviderFinalizer) IsFinalized() bool {
	return pf.finalized
}

// InstanceProviderBinding binds an instance to its frozen provider
type InstanceProviderBinding struct {
	InstanceAddress string
	InstanceKey     interface{}
	Provider        *FrozenProviderContext
	BoundAt         string // When binding was established
}

// BindingRegistry tracks all instance-provider bindings
type BindingRegistry struct {
	bindings map[string]*InstanceProviderBinding
}

// NewBindingRegistry creates a registry
func NewBindingRegistry() *BindingRegistry {
	return &BindingRegistry{
		bindings: make(map[string]*InstanceProviderBinding),
	}
}

// Bind binds an instance to a provider
func (r *BindingRegistry) Bind(address string, key interface{}, provider *FrozenProviderContext) {
	r.bindings[address] = &InstanceProviderBinding{
		InstanceAddress: address,
		InstanceKey:     key,
		Provider:        provider,
		BoundAt:         "expansion",
	}
}

// Get returns the binding for an instance
func (r *BindingRegistry) Get(address string) (*InstanceProviderBinding, bool) {
	binding, ok := r.bindings[address]
	return binding, ok
}

// MustGet returns the binding or panics
func (r *BindingRegistry) MustGet(address string) *InstanceProviderBinding {
	binding, ok := r.bindings[address]
	if !ok {
		panic(fmt.Sprintf("no provider binding for %s", address))
	}
	return binding
}

// EnsureBound verifies an instance is bound before pricing
func (r *BindingRegistry) EnsureBound(address string) error {
	if _, ok := r.bindings[address]; !ok {
		return &UnboundInstanceError{Address: address}
	}
	return nil
}

// UnboundInstanceError indicates an instance has no provider binding
type UnboundInstanceError struct {
	Address string
}

func (e *UnboundInstanceError) Error() string {
	return fmt.Sprintf("instance %s has no provider binding - cannot price", e.Address)
}

// ProviderPricingGate ensures pricing only happens after provider finalization
type ProviderPricingGate struct {
	finalizer *ProviderFinalizer
	registry  *BindingRegistry
}

// NewProviderPricingGate creates a gate
func NewProviderPricingGate(finalizer *ProviderFinalizer, registry *BindingRegistry) *ProviderPricingGate {
	return &ProviderPricingGate{
		finalizer: finalizer,
		registry:  registry,
	}
}

// CanPrice checks if pricing is allowed for an instance
func (g *ProviderPricingGate) CanPrice(address string) error {
	// Check finalization
	if !g.finalizer.IsFinalized() {
		return fmt.Errorf("provider finalization not complete - cannot price %s", address)
	}

	// Check binding
	return g.registry.EnsureBound(address)
}

// GetPricingDimension returns the pricing dimension for an instance
func (g *ProviderPricingGate) GetPricingDimension(address string) (*PricingDimension, error) {
	if err := g.CanPrice(address); err != nil {
		return nil, err
	}

	binding := g.registry.MustGet(address)
	dim := binding.Provider.PricingDimension()
	return &dim, nil
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\safe_expansion.go
# TYPE: go
# SIZE: 8907 bytes
################################################################################
// Package terraform - Safe for_each handling
// When for_each keys are unknown: DO NOT EXPAND.
// Replace with symbolic range, surface warning, block in strict mode.
package terraform

import (
	"fmt"
)

// ForEachResult represents the result of for_each evaluation
type ForEachResult struct {
	// Is the for_each value known?
	IsKnown bool

	// Keys if known
	Keys []string

	// If unknown, symbolic range
	SymbolicRange *SymbolicRange

	// Warning to surface
	Warning string

	// Block estimation in strict mode?
	BlocksEstimation bool
}

// SymbolicRange represents an unknown cardinality
type SymbolicRange struct {
	// Minimum instances (conservative)
	Min int

	// Maximum instances (if bounded, -1 for unbounded)
	Max int

	// Expression that could not be evaluated
	Expression string

	// References that caused unknown
	UnknownReferences []string

	// Confidence impact
	ConfidenceImpact float64
}

// SafeForEachEvaluator evaluates for_each safely
type SafeForEachEvaluator struct {
	mode           EvaluationMode
	enforcer       *StrictModeEnforcer
	unknownHandler UnknownForEachHandler
}

// UnknownForEachHandler defines how to handle unknown for_each
type UnknownForEachHandler int

const (
	// HandlerBlock blocks estimation
	HandlerBlock UnknownForEachHandler = iota

	// HandlerSymbolic uses symbolic range
	HandlerSymbolic

	// HandlerMinimum uses minimum assumption (0 or 1)
	HandlerMinimum
)

// NewSafeForEachEvaluator creates an evaluator
func NewSafeForEachEvaluator(mode EvaluationMode) *SafeForEachEvaluator {
	handler := HandlerSymbolic
	if mode == ModeStrict {
		handler = HandlerBlock
	}

	return &SafeForEachEvaluator{
		mode:           mode,
		enforcer:       NewStrictModeEnforcer(mode),
		unknownHandler: handler,
	}
}

// Evaluate evaluates a for_each expression
func (e *SafeForEachEvaluator) Evaluate(address string, expr *ExpressionValue) *ForEachResult {
	result := &ForEachResult{
		IsKnown:          false,
		Keys:             []string{},
		BlocksEstimation: false,
	}

	// If expression is known, extract keys
	if expr != nil && expr.IsKnown {
		result.IsKnown = true
		result.Keys = extractForEachKeys(expr.Value)
		return result
	}

	// Unknown for_each - handle according to mode
	result.IsKnown = false

	// Check for blocking conditions
	if e.mode == ModeStrict {
		result.BlocksEstimation = true
		result.Warning = fmt.Sprintf("for_each at %s is unknown - blocking estimation in strict mode", address)
		return result
	}

	// Create symbolic range
	result.SymbolicRange = e.createSymbolicRange(address, expr)
	result.Warning = fmt.Sprintf(
		"for_each at %s has unknown cardinality (estimated %d-%d instances)",
		address, result.SymbolicRange.Min, result.SymbolicRange.Max,
	)

	return result
}

func (e *SafeForEachEvaluator) createSymbolicRange(address string, expr *ExpressionValue) *SymbolicRange {
	sr := &SymbolicRange{
		Min:              0,
		Max:              -1, // Unbounded
		ConfidenceImpact: 0.5,
	}

	if expr != nil {
		sr.Expression = expr.Expression
		sr.UnknownReferences = expr.References
	}

	// Infer bounds from expression type if possible
	if expr != nil && len(expr.References) > 0 {
		for _, ref := range expr.References {
			sr.UnknownReferences = append(sr.UnknownReferences, ref)

			// Data source references are fully unknown
			if isDataSourceRef(ref) {
				sr.Min = 0
				sr.Max = -1
				sr.ConfidenceImpact = 0.6
				continue
			}

			// Variable references might have bounds
			if isVariableRef(ref) {
				sr.Min = 1
				sr.Max = 10 // Conservative assumption
				sr.ConfidenceImpact = 0.4
			}
		}
	}

	return sr
}

func extractForEachKeys(value interface{}) []string {
	switch v := value.(type) {
	case map[string]interface{}:
		keys := make([]string, 0, len(v))
		for k := range v {
			keys = append(keys, k)
		}
		return keys
	case []interface{}:
		keys := make([]string, 0, len(v))
		for _, item := range v {
			if s, ok := item.(string); ok {
				keys = append(keys, s)
			}
		}
		return keys
	case []string:
		return v
	default:
		return []string{}
	}
}

func isDataSourceRef(ref string) bool {
	return len(ref) >= 5 && ref[:5] == "data."
}

func isVariableRef(ref string) bool {
	return len(ref) >= 4 && ref[:4] == "var."
}

// SafeCountEvaluator evaluates count safely
type SafeCountEvaluator struct {
	mode     EvaluationMode
	enforcer *StrictModeEnforcer
}

// CountResult represents the result of count evaluation
type CountResult struct {
	IsKnown          bool
	Value            int
	SymbolicRange    *SymbolicRange
	Warning          string
	BlocksEstimation bool
}

// NewSafeCountEvaluator creates an evaluator
func NewSafeCountEvaluator(mode EvaluationMode) *SafeCountEvaluator {
	return &SafeCountEvaluator{
		mode:     mode,
		enforcer: NewStrictModeEnforcer(mode),
	}
}

// Evaluate evaluates a count expression
func (e *SafeCountEvaluator) Evaluate(address string, expr *ExpressionValue) *CountResult {
	result := &CountResult{
		IsKnown:          false,
		Value:            0,
		BlocksEstimation: false,
	}

	// If expression is known, extract value
	if expr != nil && expr.IsKnown {
		result.IsKnown = true
		result.Value = extractCountValue(expr.Value)
		return result
	}

	// Unknown count
	if e.mode == ModeStrict {
		result.BlocksEstimation = true
		result.Warning = fmt.Sprintf("count at %s is unknown - blocking estimation in strict mode", address)
		return result
	}

	// Create symbolic range
	result.SymbolicRange = e.inferCountRange(address, expr)
	result.Warning = fmt.Sprintf(
		"count at %s has unknown value (estimated %d-%d instances)",
		address, result.SymbolicRange.Min, result.SymbolicRange.Max,
	)

	// Use minimum for estimation
	result.Value = result.SymbolicRange.Min

	return result
}

func (e *SafeCountEvaluator) inferCountRange(address string, expr *ExpressionValue) *SymbolicRange {
	sr := &SymbolicRange{
		Min:              0,
		Max:              10, // Conservative upper bound
		ConfidenceImpact: 0.4,
	}

	if expr != nil {
		sr.Expression = expr.Expression
		sr.UnknownReferences = expr.References

		// Check for common patterns
		if containsLengthCall(expr.Expression) {
			sr.Min = 0
			sr.Max = 20
			sr.ConfidenceImpact = 0.45
		}

		if containsConditional(expr.Expression) {
			sr.Min = 0
			sr.Max = 1
			sr.ConfidenceImpact = 0.3
		}
	}

	return sr
}

func extractCountValue(value interface{}) int {
	switch v := value.(type) {
	case int:
		return v
	case int64:
		return int(v)
	case float64:
		return int(v)
	default:
		return 1
	}
}

func containsLengthCall(expr string) bool {
	return len(expr) >= 6 && (contains(expr, "length(") || contains(expr, "len("))
}

func containsConditional(expr string) bool {
	return contains(expr, "?") || contains(expr, "if ")
}

func contains(s, substr string) bool {
	for i := 0; i <= len(s)-len(substr); i++ {
		if s[i:i+len(substr)] == substr {
			return true
		}
	}
	return false
}

// CardinalityWarning is a warning about unknown cardinality
type CardinalityWarning struct {
	Address          string
	Type             string // "count" or "for_each"
	Expression       string
	SymbolicRange    *SymbolicRange
	Message          string
	BlocksEstimation bool
}

// CardinalityWarnings collects cardinality warnings
type CardinalityWarnings struct {
	warnings []CardinalityWarning
}

// NewCardinalityWarnings creates a collector
func NewCardinalityWarnings() *CardinalityWarnings {
	return &CardinalityWarnings{
		warnings: []CardinalityWarning{},
	}
}

// AddForEach adds a for_each warning
func (w *CardinalityWarnings) AddForEach(address string, result *ForEachResult) {
	if result.IsKnown {
		return
	}
	w.warnings = append(w.warnings, CardinalityWarning{
		Address:          address,
		Type:             "for_each",
		SymbolicRange:    result.SymbolicRange,
		Message:          result.Warning,
		BlocksEstimation: result.BlocksEstimation,
	})
}

// AddCount adds a count warning
func (w *CardinalityWarnings) AddCount(address string, result *CountResult) {
	if result.IsKnown {
		return
	}
	w.warnings = append(w.warnings, CardinalityWarning{
		Address:          address,
		Type:             "count",
		SymbolicRange:    result.SymbolicRange,
		Message:          result.Warning,
		BlocksEstimation: result.BlocksEstimation,
	})
}

// All returns all warnings
func (w *CardinalityWarnings) All() []CardinalityWarning {
	return w.warnings
}

// HasBlocking returns true if any warning blocks estimation
func (w *CardinalityWarnings) HasBlocking() bool {
	for _, warn := range w.warnings {
		if warn.BlocksEstimation {
			return true
		}
	}
	return false
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\strict_mode.go
# TYPE: go
# SIZE: 8967 bytes
################################################################################
// Package terraform - Strict evaluation modes
// STRICT: block on unsafe unknowns
// PERMISSIVE: allow but degrade confidence
// ESTIMATE: best-effort (current behavior)
package terraform

import (
	"errors"
	"fmt"
)

// EvaluationMode controls how strictly unknowns are handled
type EvaluationMode int

const (
	// ModeEstimate - best effort, may guess (current default)
	ModeEstimate EvaluationMode = iota

	// ModePermissive - allows unknowns but degrades confidence
	ModePermissive

	// ModeStrict - blocks estimation on unsafe unknowns
	ModeStrict
)

// String returns the mode name
func (m EvaluationMode) String() string {
	switch m {
	case ModeEstimate:
		return "estimate"
	case ModePermissive:
		return "permissive"
	case ModeStrict:
		return "strict"
	default:
		return "unknown"
	}
}

// EvaluationModeFromString parses a mode string
func EvaluationModeFromString(s string) (EvaluationMode, error) {
	switch s {
	case "estimate", "":
		return ModeEstimate, nil
	case "permissive":
		return ModePermissive, nil
	case "strict":
		return ModeStrict, nil
	default:
		return ModeEstimate, fmt.Errorf("unknown evaluation mode: %s", s)
	}
}

// StrictModeEnforcer enforces strict mode rules
type StrictModeEnforcer struct {
	mode    EvaluationMode
	errors  []StrictModeError
	blocked bool
}

// StrictModeError is an error from strict mode enforcement
type StrictModeError struct {
	Address   string
	Attribute string
	Reason    string
	Category  ErrorCategory
	Blocking  bool // Does this error block estimation?
}

// ErrorCategory classifies the type of error
type ErrorCategory int

const (
	ErrorUnknownCount              ErrorCategory = iota // count is unknown
	ErrorUnknownForEach                                  // for_each is unknown
	ErrorUnknownProvider                                 // provider config unknown
	ErrorUnknownUsage                                    // usage value unknown
	ErrorDataSourceReference                             // data source in blocking position
	ErrorCircularDependency                              // cycle detected
	ErrorMissingRate                                     // no pricing rate found
	ErrorInvalidType                                     // type mismatch
)

// String returns the category name
func (c ErrorCategory) String() string {
	switch c {
	case ErrorUnknownCount:
		return "unknown_count"
	case ErrorUnknownForEach:
		return "unknown_for_each"
	case ErrorUnknownProvider:
		return "unknown_provider"
	case ErrorUnknownUsage:
		return "unknown_usage"
	case ErrorDataSourceReference:
		return "data_source_reference"
	case ErrorCircularDependency:
		return "circular_dependency"
	case ErrorMissingRate:
		return "missing_rate"
	case ErrorInvalidType:
		return "invalid_type"
	default:
		return "unknown"
	}
}

// NewStrictModeEnforcer creates an enforcer for the given mode
func NewStrictModeEnforcer(mode EvaluationMode) *StrictModeEnforcer {
	return &StrictModeEnforcer{
		mode:    mode,
		errors:  []StrictModeError{},
		blocked: false,
	}
}

// CheckUnknownCount checks if unknown count should block
func (e *StrictModeEnforcer) CheckUnknownCount(address string, reason string) error {
	err := StrictModeError{
		Address:  address,
		Reason:   reason,
		Category: ErrorUnknownCount,
		Blocking: e.mode == ModeStrict,
	}
	e.errors = append(e.errors, err)

	if e.mode == ModeStrict {
		e.blocked = true
		return &BlockedEstimationError{
			Address: address,
			Reason:  "unknown count blocks estimation in strict mode",
		}
	}
	return nil
}

// CheckUnknownForEach checks if unknown for_each should block
func (e *StrictModeEnforcer) CheckUnknownForEach(address string, reason string) error {
	err := StrictModeError{
		Address:  address,
		Reason:   reason,
		Category: ErrorUnknownForEach,
		Blocking: e.mode == ModeStrict,
	}
	e.errors = append(e.errors, err)

	if e.mode == ModeStrict {
		e.blocked = true
		return &BlockedEstimationError{
			Address: address,
			Reason:  "unknown for_each blocks estimation in strict mode",
		}
	}
	return nil
}

// CheckUnknownProvider checks if unknown provider should block
func (e *StrictModeEnforcer) CheckUnknownProvider(address, providerRef string) error {
	err := StrictModeError{
		Address:  address,
		Reason:   fmt.Sprintf("provider %s could not be resolved", providerRef),
		Category: ErrorUnknownProvider,
		Blocking: e.mode == ModeStrict,
	}
	e.errors = append(e.errors, err)

	if e.mode == ModeStrict {
		e.blocked = true
		return &BlockedEstimationError{
			Address: address,
			Reason:  "unknown provider blocks estimation in strict mode",
		}
	}
	return nil
}

// CheckDataSourceInBlockingPosition checks if data source ref is blocking
func (e *StrictModeEnforcer) CheckDataSourceInBlockingPosition(address, attribute, dataRef string) error {
	blocking := e.mode == ModeStrict

	err := StrictModeError{
		Address:   address,
		Attribute: attribute,
		Reason:    fmt.Sprintf("data source reference %s cannot be estimated", dataRef),
		Category:  ErrorDataSourceReference,
		Blocking:  blocking,
	}
	e.errors = append(e.errors, err)

	if blocking {
		e.blocked = true
		return &BlockedEstimationError{
			Address: address,
			Reason:  fmt.Sprintf("data source %s in blocking position", dataRef),
		}
	}
	return nil
}

// CheckMissingRate checks if missing rate should block
func (e *StrictModeEnforcer) CheckMissingRate(address, rateKey string) error {
	// Missing rates always block in strict mode
	blocking := e.mode == ModeStrict

	err := StrictModeError{
		Address:  address,
		Reason:   fmt.Sprintf("no pricing rate found for %s", rateKey),
		Category: ErrorMissingRate,
		Blocking: blocking,
	}
	e.errors = append(e.errors, err)

	if blocking {
		e.blocked = true
		return &BlockedEstimationError{
			Address: address,
			Reason:  fmt.Sprintf("missing rate %s blocks estimation", rateKey),
		}
	}
	return nil
}

// IsBlocked returns true if estimation is blocked
func (e *StrictModeEnforcer) IsBlocked() bool {
	return e.blocked
}

// GetErrors returns all errors
func (e *StrictModeEnforcer) GetErrors() []StrictModeError {
	return e.errors
}

// GetBlockingErrors returns only blocking errors
func (e *StrictModeEnforcer) GetBlockingErrors() []StrictModeError {
	var result []StrictModeError
	for _, err := range e.errors {
		if err.Blocking {
			result = append(result, err)
		}
	}
	return result
}

// BlockedEstimationError indicates estimation was blocked
type BlockedEstimationError struct {
	Address string
	Reason  string
}

func (e *BlockedEstimationError) Error() string {
	return fmt.Sprintf("estimation blocked for %s: %s", e.Address, e.Reason)
}

// IsBlockedEstimationError checks if an error is a blocked estimation error
func IsBlockedEstimationError(err error) bool {
	var blocked *BlockedEstimationError
	return errors.As(err, &blocked)
}

// ModeConfig configures behavior per mode
type ModeConfig struct {
	Mode EvaluationMode

	// What to do with unknown counts
	UnknownCountBehavior UnknownBehavior

	// What to do with unknown for_each
	UnknownForEachBehavior UnknownBehavior

	// What to do with data source references
	DataSourceBehavior DataSourceBehavior

	// Default count when unknown
	DefaultUnknownCount int
}

// UnknownBehavior defines how to handle unknowns
type UnknownBehavior int

const (
	UnknownBlock    UnknownBehavior = iota // Block estimation
	UnknownDegrade                          // Continue but degrade confidence
	UnknownDefault                          // Use default value
)

// DataSourceBehavior defines how to handle data sources
type DataSourceBehavior int

const (
	DataSourceBlock   DataSourceBehavior = iota // Block on data source refs
	DataSourceDegrade                            // Degrade confidence
	DataSourceIgnore                             // Treat as unknown value
)

// GetModeConfig returns the configuration for a mode
func GetModeConfig(mode EvaluationMode) ModeConfig {
	switch mode {
	case ModeStrict:
		return ModeConfig{
			Mode:                   ModeStrict,
			UnknownCountBehavior:   UnknownBlock,
			UnknownForEachBehavior: UnknownBlock,
			DataSourceBehavior:     DataSourceBlock,
			DefaultUnknownCount:    0,
		}
	case ModePermissive:
		return ModeConfig{
			Mode:                   ModePermissive,
			UnknownCountBehavior:   UnknownDegrade,
			UnknownForEachBehavior: UnknownDegrade,
			DataSourceBehavior:     DataSourceDegrade,
			DefaultUnknownCount:    1,
		}
	default: // ModeEstimate
		return ModeConfig{
			Mode:                   ModeEstimate,
			UnknownCountBehavior:   UnknownDefault,
			UnknownForEachBehavior: UnknownDefault,
			DataSourceBehavior:     DataSourceIgnore,
			DefaultUnknownCount:    1,
		}
	}
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\strict_module_output.go
# TYPE: go
# SIZE: 6157 bytes
################################################################################
// Package terraform - Module output strict handling
// Module outputs are NEVER like locals.
// They are: dependency edges, potentially unknown, cardinality-affecting.
package terraform

import (
	"fmt"
	"strings"
)

// StrictModuleOutput enforces correct module output handling
type StrictModuleOutput struct {
	// Always a dependency edge
	IsDependencyEdge bool // ALWAYS true

	// Output identity
	ModulePath string
	OutputName string
	Address    string

	// State
	IsKnown     bool
	IsComputed  bool // Runtime value
	IsSensitive bool

	// Value (only if known and not sensitive)
	Value interface{}

	// Expression (always captured)
	Expression string
	References []string

	// Cardinality impact
	AffectsCardinality    bool
	CardinalityExpression string

	// Confidence
	ConfidenceImpact float64
}

// NewStrictModuleOutput creates a strict module output
func NewStrictModuleOutput(modulePath, outputName string) *StrictModuleOutput {
	return &StrictModuleOutput{
		IsDependencyEdge: true, // ALWAYS
		ModulePath:       modulePath,
		OutputName:       outputName,
		Address:          modulePath + "." + outputName,
		IsKnown:          false, // Default to unknown
		ConfidenceImpact: 0.2,  // Default impact for module outputs
	}
}

// MarkKnown marks the output as known with a value
func (o *StrictModuleOutput) MarkKnown(value interface{}) {
	o.IsKnown = true
	o.Value = value

	// Check if value affects cardinality
	switch v := value.(type) {
	case []interface{}:
		o.AffectsCardinality = true
		o.CardinalityExpression = fmt.Sprintf("list with %d elements", len(v))
	case map[string]interface{}:
		o.AffectsCardinality = true
		o.CardinalityExpression = fmt.Sprintf("map with %d keys", len(v))
	}
}

// MarkUnknown marks the output as unknown
func (o *StrictModuleOutput) MarkUnknown(expression string, references []string) {
	o.IsKnown = false
	o.Expression = expression
	o.References = references
	o.ConfidenceImpact = 0.3 // Higher impact for unknown

	// Check if expression affects cardinality
	if o.expressionAffectsCardinality(expression) {
		o.AffectsCardinality = true
		o.ConfidenceImpact = 0.4
	}
}

func (o *StrictModuleOutput) expressionAffectsCardinality(expr string) bool {
	if expr == "" {
		return false
	}
	cardinalityFns := []string{"tolist", "toset", "tomap", "list", "set", "map", "keys", "values"}
	for _, fn := range cardinalityFns {
		if strings.Contains(expr, fn+"(") {
			return true
		}
	}
	return false
}

// StrictModuleOutputRegistry tracks all module outputs
type StrictModuleOutputRegistry struct {
	outputs map[string]*StrictModuleOutput
}

// NewStrictModuleOutputRegistry creates a registry
func NewStrictModuleOutputRegistry() *StrictModuleOutputRegistry {
	return &StrictModuleOutputRegistry{
		outputs: make(map[string]*StrictModuleOutput),
	}
}

// Register registers a module output
func (r *StrictModuleOutputRegistry) Register(output *StrictModuleOutput) {
	r.outputs[output.Address] = output
}

// Get gets an output by address
func (r *StrictModuleOutputRegistry) Get(address string) (*StrictModuleOutput, bool) {
	output, ok := r.outputs[address]
	return output, ok
}

// IsModuleOutputReference checks if a reference is to a module output
func (r *StrictModuleOutputRegistry) IsModuleOutputReference(ref string) bool {
	// module.name.output_name pattern
	if !strings.HasPrefix(ref, "module.") {
		return false
	}
	parts := strings.Split(ref, ".")
	return len(parts) >= 3
}

// ResolveReference resolves a module output reference
func (r *StrictModuleOutputRegistry) ResolveReference(ref string) (*StrictModuleOutput, error) {
	if !r.IsModuleOutputReference(ref) {
		return nil, fmt.Errorf("not a module output reference: %s", ref)
	}

	output, ok := r.Get(ref)
	if !ok {
		// Unknown module output - create a strict unknown entry
		parts := strings.Split(ref, ".")
		if len(parts) >= 3 {
			modulePath := strings.Join(parts[:2], ".")
			outputName := strings.Join(parts[2:], ".")
			output = NewStrictModuleOutput(modulePath, outputName)
			output.MarkUnknown("unknown_reference", []string{ref})
			r.Register(output)
		}
		return output, nil
	}

	return output, nil
}

// ValidateUsageInCardinality validates using module output for cardinality
func (r *StrictModuleOutputRegistry) ValidateUsageInCardinality(ref string, context string) *StrictModuleOutputWarning {
	output, _ := r.ResolveReference(ref)
	if output == nil {
		return nil
	}

	// If output is unknown or affects cardinality, this is dangerous
	if !output.IsKnown || output.AffectsCardinality {
		return &StrictModuleOutputWarning{
			Address:  ref,
			Context:  context,
			Warning:  fmt.Sprintf("module output %s used in cardinality context but is %s", ref, output.state()),
			Severity: WarningSevere,
			BlocksEstimation: !output.IsKnown,
		}
	}

	return nil
}

func (o *StrictModuleOutput) state() string {
	if !o.IsKnown {
		return "unknown"
	}
	if o.AffectsCardinality {
		return "cardinality-affecting"
	}
	return "known"
}

// StrictModuleOutputWarning is a warning about module output usage
type StrictModuleOutputWarning struct {
	Address          string
	Context          string
	Warning          string
	Severity         WarningSeverity
	BlocksEstimation bool
}

// WarningSeverity indicates warning severity
type WarningSeverity int

const (
	WarningInfo WarningSeverity = iota
	WarningModerate
	WarningSevere
)

// AllUnknown returns all unknown outputs
func (r *StrictModuleOutputRegistry) AllUnknown() []*StrictModuleOutput {
	var result []*StrictModuleOutput
	for _, output := range r.outputs {
		if !output.IsKnown {
			result = append(result, output)
		}
	}
	return result
}

// AllCardinalityAffecting returns outputs that affect cardinality
func (r *StrictModuleOutputRegistry) AllCardinalityAffecting() []*StrictModuleOutput {
	var result []*StrictModuleOutput
	for _, output := range r.outputs {
		if output.AffectsCardinality {
			result = append(result, output)
		}
	}
	return result
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\strict_unknown.go
# TYPE: go
# SIZE: 10833 bytes
################################################################################
// Package terraform - Strict unknown value semantics
// Unknowns NEVER collapse. They ALWAYS propagate. Cost ALWAYS degrades.
package terraform

import (
	"fmt"
)

// StrictUnknown represents an unknown value that CANNOT be collapsed.
// This is not a nil, not a zero, not an empty string - it is EXPLICITLY unknown.
type StrictUnknown struct {
	// Why this is unknown
	Reason UnknownReason

	// What type we expected
	ExpectedType ValueType

	// Where it came from
	Source string

	// What depends on this
	DependentCount int

	// How many levels deep (for debugging)
	PropagationDepth int
}

// IsUnknown always returns true for StrictUnknown
func (u *StrictUnknown) IsUnknown() bool { return true }

// String returns a debug representation
func (u *StrictUnknown) String() string {
	return fmt.Sprintf("(unknown: %s from %s)", u.Reason, u.Source)
}

// StrictValue is a value that is EITHER known OR unknown, never both, never nil.
type StrictValue struct {
	known   interface{}
	unknown *StrictUnknown
}

// MustBeKnown panics if the value is unknown - use for programming errors only
func (v StrictValue) MustBeKnown(context string) interface{} {
	if v.IsUnknown() {
		panic(fmt.Sprintf("BUG: expected known value but got unknown in %s: %s", context, v.unknown.String()))
	}
	return v.known
}

// StrictKnown creates a known value
func StrictKnown(val interface{}) StrictValue {
	if val == nil {
		// nil is a VALID known value (null)
		return StrictValue{known: nil, unknown: nil}
	}
	return StrictValue{known: val, unknown: nil}
}

// StrictUnknownValue creates an unknown value
func StrictUnknownValue(reason UnknownReason, expectedType ValueType, source string) StrictValue {
	return StrictValue{
		unknown: &StrictUnknown{
			Reason:       reason,
			ExpectedType: expectedType,
			Source:       source,
		},
	}
}

// IsKnown returns true ONLY if value is known
func (v StrictValue) IsKnown() bool {
	return v.unknown == nil
}

// IsUnknown returns true ONLY if value is unknown
func (v StrictValue) IsUnknown() bool {
	return v.unknown != nil
}

// Get returns the value if known, nil if unknown
// IMPORTANT: Check IsKnown() first!
func (v StrictValue) Get() interface{} {
	if v.IsUnknown() {
		return nil
	}
	return v.known
}

// GetUnknown returns the unknown info
func (v StrictValue) GetUnknown() *StrictUnknown {
	return v.unknown
}

// Propagate creates a NEW unknown that depends on this one
// The original unknown is preserved, depth is increased
func (v StrictValue) Propagate(newSource string) StrictValue {
	if v.IsKnown() {
		return v // Known values don't propagate
	}
	return StrictValue{
		unknown: &StrictUnknown{
			Reason:           ReasonDependsOnUnknown,
			ExpectedType:     v.unknown.ExpectedType,
			Source:           fmt.Sprintf("%s (via %s)", newSource, v.unknown.Source),
			PropagationDepth: v.unknown.PropagationDepth + 1,
		},
	}
}

// UnknownSet tracks all unresolved unknowns in a context
type UnknownSet struct {
	unknowns map[string]*StrictUnknown
}

// NewUnknownSet creates an empty unknown set
func NewUnknownSet() *UnknownSet {
	return &UnknownSet{
		unknowns: make(map[string]*StrictUnknown),
	}
}

// Add records an unknown
func (s *UnknownSet) Add(address string, u *StrictUnknown) {
	s.unknowns[address] = u
}

// Has checks if an address is unknown
func (s *UnknownSet) Has(address string) bool {
	_, ok := s.unknowns[address]
	return ok
}

// Get returns the unknown for an address
func (s *UnknownSet) Get(address string) *StrictUnknown {
	return s.unknowns[address]
}

// Merge combines two unknown sets
func (s *UnknownSet) Merge(other *UnknownSet) {
	if other == nil {
		return
	}
	for k, v := range other.unknowns {
		s.unknowns[k] = v
	}
}

// Count returns the number of unknowns
func (s *UnknownSet) Count() int {
	return len(s.unknowns)
}

// All returns all unknowns
func (s *UnknownSet) All() map[string]*StrictUnknown {
	result := make(map[string]*StrictUnknown)
	for k, v := range s.unknowns {
		result[k] = v
	}
	return result
}

// UnknownPropagator ensures unknowns propagate through operations
type UnknownPropagator struct {
	set *UnknownSet
}

// NewUnknownPropagator creates a propagator
func NewUnknownPropagator() *UnknownPropagator {
	return &UnknownPropagator{
		set: NewUnknownSet(),
	}
}

// CheckAndPropagate checks if any input is unknown, and if so returns propagated unknown
func (p *UnknownPropagator) CheckAndPropagate(inputs []StrictValue, operation string) (StrictValue, bool) {
	for _, input := range inputs {
		if input.IsUnknown() {
			// Any unknown input â†’ entire result is unknown
			propagated := input.Propagate(operation)
			return propagated, true
		}
	}
	return StrictValue{}, false
}

// Set returns the underlying unknown set
func (p *UnknownPropagator) Set() *UnknownSet {
	return p.set
}

// StrictArithmetic performs arithmetic that respects unknowns
type StrictArithmetic struct{}

// Add adds two values - if either is unknown, result is unknown
func (StrictArithmetic) Add(a, b StrictValue) StrictValue {
	if a.IsUnknown() {
		return a.Propagate("add.left")
	}
	if b.IsUnknown() {
		return b.Propagate("add.right")
	}

	// Both known - do arithmetic
	aNum, aOk := toFloat(a.Get())
	bNum, bOk := toFloat(b.Get())
	if !aOk || !bOk {
		return StrictUnknownValue(ReasonExpressionError, TypeNumber, "add: non-numeric operand")
	}
	return StrictKnown(aNum + bNum)
}

// Mul multiplies two values - if either is unknown, result is unknown
func (StrictArithmetic) Mul(a, b StrictValue) StrictValue {
	if a.IsUnknown() {
		return a.Propagate("mul.left")
	}
	if b.IsUnknown() {
		return b.Propagate("mul.right")
	}

	aNum, aOk := toFloat(a.Get())
	bNum, bOk := toFloat(b.Get())
	if !aOk || !bOk {
		return StrictUnknownValue(ReasonExpressionError, TypeNumber, "mul: non-numeric operand")
	}
	return StrictKnown(aNum * bNum)
}

// Div divides two values - if either is unknown, result is unknown
func (StrictArithmetic) Div(a, b StrictValue) StrictValue {
	if a.IsUnknown() {
		return a.Propagate("div.left")
	}
	if b.IsUnknown() {
		return b.Propagate("div.right")
	}

	aNum, aOk := toFloat(a.Get())
	bNum, bOk := toFloat(b.Get())
	if !aOk || !bOk {
		return StrictUnknownValue(ReasonExpressionError, TypeNumber, "div: non-numeric operand")
	}
	if bNum == 0 {
		return StrictUnknownValue(ReasonExpressionError, TypeNumber, "div: division by zero")
	}
	return StrictKnown(aNum / bNum)
}

func toFloat(v interface{}) (float64, bool) {
	switch n := v.(type) {
	case float64:
		return n, true
	case float32:
		return float64(n), true
	case int:
		return float64(n), true
	case int64:
		return float64(n), true
	case int32:
		return float64(n), true
	default:
		return 0, false
	}
}

// StrictCondition evaluates conditions respecting unknowns
type StrictCondition struct{}

// IfThenElse evaluates a conditional - if condition is unknown, result is unknown
func (StrictCondition) IfThenElse(condition, thenVal, elseVal StrictValue) StrictValue {
	if condition.IsUnknown() {
		// Unknown condition â†’ result is unknown
		return condition.Propagate("condition")
	}

	// Condition is known - evaluate
	cond, ok := condition.Get().(bool)
	if !ok {
		return StrictUnknownValue(ReasonExpressionError, TypeUnknown, "if: non-boolean condition")
	}

	if cond {
		return thenVal
	}
	return elseVal
}

// Equals compares two values - if either is unknown, result is unknown
func (StrictCondition) Equals(a, b StrictValue) StrictValue {
	if a.IsUnknown() {
		return a.Propagate("equals.left")
	}
	if b.IsUnknown() {
		return b.Propagate("equals.right")
	}
	return StrictKnown(a.Get() == b.Get())
}

// StrictList handles list operations with unknown propagation
type StrictList struct{}

// Index gets an element - if list or index is unknown, result is unknown
func (StrictList) Index(list StrictValue, index StrictValue) StrictValue {
	if list.IsUnknown() {
		return list.Propagate("list.index")
	}
	if index.IsUnknown() {
		return index.Propagate("list.index")
	}

	l, ok := list.Get().([]interface{})
	if !ok {
		return StrictUnknownValue(ReasonExpressionError, TypeUnknown, "index: not a list")
	}

	idx, ok := toInt(index.Get())
	if !ok {
		return StrictUnknownValue(ReasonExpressionError, TypeUnknown, "index: non-integer index")
	}

	if idx < 0 || idx >= len(l) {
		return StrictUnknownValue(ReasonExpressionError, TypeUnknown, "index: out of bounds")
	}

	return StrictKnown(l[idx])
}

// Length gets list length - if list is unknown, result is unknown
func (StrictList) Length(list StrictValue) StrictValue {
	if list.IsUnknown() {
		return list.Propagate("list.length")
	}

	switch v := list.Get().(type) {
	case []interface{}:
		return StrictKnown(len(v))
	case string:
		return StrictKnown(len(v))
	case map[string]interface{}:
		return StrictKnown(len(v))
	default:
		return StrictUnknownValue(ReasonExpressionError, TypeNumber, "length: unsupported type")
	}
}

func toInt(v interface{}) (int, bool) {
	switch n := v.(type) {
	case int:
		return n, true
	case int64:
		return int(n), true
	case float64:
		return int(n), true
	default:
		return 0, false
	}
}

// CostDegradation tracks how costs are degraded due to unknowns
type CostDegradation struct {
	IsDegraded bool
	Confidence float64 // 0.0 - 1.0

	Reasons []DegradationReason
}

// DegradationReason explains why cost is degraded
type DegradationReason struct {
	Component string
	Reason    string
	Impact    float64 // How much this reduces confidence
	IsUnknown bool    // Is this due to an unknown value?
}

// NewCostDegradation creates a fresh (non-degraded) state
func NewCostDegradation() *CostDegradation {
	return &CostDegradation{
		IsDegraded: false,
		Confidence: 1.0,
		Reasons:    []DegradationReason{},
	}
}

// RecordUnknown records that an unknown caused degradation
func (d *CostDegradation) RecordUnknown(component, source string, impact float64) {
	d.IsDegraded = true
	d.Confidence *= (1.0 - impact)
	d.Reasons = append(d.Reasons, DegradationReason{
		Component: component,
		Reason:    fmt.Sprintf("unknown value: %s", source),
		Impact:    impact,
		IsUnknown: true,
	})
}

// RecordMissing records that a missing value caused degradation
func (d *CostDegradation) RecordMissing(component, what string, impact float64) {
	d.IsDegraded = true
	d.Confidence *= (1.0 - impact)
	d.Reasons = append(d.Reasons, DegradationReason{
		Component: component,
		Reason:    fmt.Sprintf("missing: %s", what),
		Impact:    impact,
		IsUnknown: false,
	})
}

################################################################################
# FILE: :\good projects\cost estimation\core\terraform\unknown.go
# TYPE: go
# SIZE: 13736 bytes
################################################################################
// Package terraform - Unknown value propagation
// Implements correct Terraform unknown semantics: unknowns MUST propagate, never collapse.
package terraform

import (
	"fmt"

	"terraform-cost/core/model"
)

// UnknownValue represents a value that cannot be determined at plan time.
// This is a FIRST-CLASS type, not a nil or empty value.
type UnknownValue struct {
	// Type hint for the expected type
	ExpectedType ValueType

	// Why this value is unknown
	Reason UnknownReason

	// Source of the unknown (for debugging)
	Source string

	// Depth tracks how many levels of unknowns we've propagated through
	Depth int
}

// ValueType indicates the expected type of an unknown value
type ValueType int

const (
	TypeUnknown ValueType = iota
	TypeString
	TypeNumber
	TypeBool
	TypeList
	TypeMap
	TypeObject
)

// UnknownReason explains WHY a value is unknown
type UnknownReason int

const (
	// ReasonComputedAtApply - value computed during terraform apply
	ReasonComputedAtApply UnknownReason = iota

	// ReasonDataSourcePending - data source not yet evaluated
	ReasonDataSourcePending

	// ReasonVariableNotProvided - required variable with no default
	ReasonVariableNotProvided

	// ReasonDependsOnUnknown - depends on another unknown value
	ReasonDependsOnUnknown

	// ReasonExpressionError - expression couldn't be evaluated
	ReasonExpressionError

	// ReasonResourceNotCreated - resource doesn't exist yet
	ReasonResourceNotCreated
)

// String returns human-readable reason
func (r UnknownReason) String() string {
	switch r {
	case ReasonComputedAtApply:
		return "computed at apply time"
	case ReasonDataSourcePending:
		return "data source not yet evaluated"
	case ReasonVariableNotProvided:
		return "required variable not provided"
	case ReasonDependsOnUnknown:
		return "depends on unknown value"
	case ReasonExpressionError:
		return "expression evaluation failed"
	case ReasonResourceNotCreated:
		return "resource not yet created"
	default:
		return "unknown reason"
	}
}

// Value is a wrapper that can hold either a known value or an unknown
type Value struct {
	known   interface{}
	unknown *UnknownValue
}

// Known creates a known value
func Known(v interface{}) Value {
	return Value{known: v}
}

// Unknown creates an unknown value
func Unknown(reason UnknownReason, source string) Value {
	return Value{
		unknown: &UnknownValue{
			Reason: reason,
			Source: source,
			Depth:  0,
		},
	}
}

// UnknownWithType creates a typed unknown
func UnknownWithType(t ValueType, reason UnknownReason, source string) Value {
	return Value{
		unknown: &UnknownValue{
			ExpectedType: t,
			Reason:       reason,
			Source:       source,
			Depth:        0,
		},
	}
}

// IsKnown returns true if value is known
func (v Value) IsKnown() bool {
	return v.unknown == nil
}

// IsUnknown returns true if value is unknown
func (v Value) IsUnknown() bool {
	return v.unknown != nil
}

// Get returns the known value or nil
func (v Value) Get() interface{} {
	if v.IsUnknown() {
		return nil
	}
	return v.known
}

// GetUnknown returns the unknown info
func (v Value) GetUnknown() *UnknownValue {
	return v.unknown
}

// PropagateUnknown creates a new unknown that depends on this one
func (v Value) PropagateUnknown(newSource string) Value {
	if v.IsKnown() {
		return v // Nothing to propagate
	}

	return Value{
		unknown: &UnknownValue{
			ExpectedType: v.unknown.ExpectedType,
			Reason:       ReasonDependsOnUnknown,
			Source:       fmt.Sprintf("%s (from %s)", newSource, v.unknown.Source),
			Depth:        v.unknown.Depth + 1,
		},
	}
}

// UnknownAwareAttribute wraps an attribute that may be unknown
type UnknownAwareAttribute struct {
	Value     Value
	Sensitive bool
	Source    model.SourceLocation
}

// UnknownTracker tracks unknowns throughout the evaluation pipeline
type UnknownTracker struct {
	unknowns map[string]*UnknownValue
}

// NewUnknownTracker creates a new tracker
func NewUnknownTracker() *UnknownTracker {
	return &UnknownTracker{
		unknowns: make(map[string]*UnknownValue),
	}
}

// Track records an unknown value
func (t *UnknownTracker) Track(address string, u *UnknownValue) {
	t.unknowns[address] = u
}

// IsUnknown checks if an address is unknown
func (t *UnknownTracker) IsUnknown(address string) bool {
	_, ok := t.unknowns[address]
	return ok
}

// Get returns unknown info for an address
func (t *UnknownTracker) Get(address string) *UnknownValue {
	return t.unknowns[address]
}

// All returns all tracked unknowns
func (t *UnknownTracker) All() map[string]*UnknownValue {
	// Return copy
	result := make(map[string]*UnknownValue)
	for k, v := range t.unknowns {
		result[k] = v
	}
	return result
}

// Count returns the number of unknowns
func (t *UnknownTracker) Count() int {
	return len(t.unknowns)
}

// UnknownAwareExpander expands resources with proper unknown handling
type UnknownAwareExpander struct {
	tracker *UnknownTracker

	// What to do when count/for_each is unknown
	behavior UnknownExpansionBehavior
}

// UnknownExpansionBehavior defines how to handle unknown count/for_each
type UnknownExpansionBehavior int

const (
	// BehaviorPlaceholder creates a single placeholder instance
	BehaviorPlaceholder UnknownExpansionBehavior = iota

	// BehaviorSkip skips the resource entirely
	BehaviorSkip

	// BehaviorError returns an error
	BehaviorError
)

// NewUnknownAwareExpander creates a new expander
func NewUnknownAwareExpander(behavior UnknownExpansionBehavior) *UnknownAwareExpander {
	return &UnknownAwareExpander{
		tracker:  NewUnknownTracker(),
		behavior: behavior,
	}
}

// ExpandWithUnknowns expands a definition, properly handling unknowns
func (e *UnknownAwareExpander) ExpandWithUnknowns(
	def *model.AssetDefinition,
	ctx *EvalContext,
) ([]*model.AssetInstance, *ExpansionResult) {
	result := &ExpansionResult{
		Warnings: []string{},
		Unknowns: []*UnknownValue{},
	}

	// Check for count
	if def.Count != nil {
		countVal := e.evaluateExpression(*def.Count, ctx)

		if countVal.IsUnknown() {
			// UNKNOWN COUNT: do not guess!
			e.tracker.Track(string(def.Address)+".count", countVal.GetUnknown())
			result.Unknowns = append(result.Unknowns, countVal.GetUnknown())
			result.Warnings = append(result.Warnings,
				fmt.Sprintf("count is unknown: %s", countVal.GetUnknown().Reason))

			switch e.behavior {
			case BehaviorPlaceholder:
				return e.createPlaceholderInstance(def, countVal.GetUnknown()), result
			case BehaviorSkip:
				return []*model.AssetInstance{}, result
			case BehaviorError:
				result.Error = fmt.Errorf("unknown count not allowed")
				return nil, result
			}
		}

		// Known count
		count, ok := countVal.Get().(int)
		if !ok {
			if f, ok := countVal.Get().(float64); ok {
				count = int(f)
			}
		}
		return e.expandCount(def, count, ctx), result
	}

	// Check for for_each
	if def.ForEach != nil {
		forEachVal := e.evaluateExpression(*def.ForEach, ctx)

		if forEachVal.IsUnknown() {
			// UNKNOWN FOR_EACH: do not guess!
			e.tracker.Track(string(def.Address)+".for_each", forEachVal.GetUnknown())
			result.Unknowns = append(result.Unknowns, forEachVal.GetUnknown())
			result.Warnings = append(result.Warnings,
				fmt.Sprintf("for_each is unknown: %s", forEachVal.GetUnknown().Reason))

			switch e.behavior {
			case BehaviorPlaceholder:
				return e.createPlaceholderInstance(def, forEachVal.GetUnknown()), result
			case BehaviorSkip:
				return []*model.AssetInstance{}, result
			case BehaviorError:
				result.Error = fmt.Errorf("unknown for_each not allowed")
				return nil, result
			}
		}

		return e.expandForEach(def, forEachVal.Get(), ctx), result
	}

	// No expansion
	return []*model.AssetInstance{e.createSingleInstance(def, ctx)}, result
}

// ExpansionResult contains the result of expansion
type ExpansionResult struct {
	Warnings []string
	Unknowns []*UnknownValue
	Error    error
}

func (e *UnknownAwareExpander) evaluateExpression(expr model.Expression, ctx *EvalContext) Value {
	if expr.IsLiteral {
		return Known(expr.LiteralVal)
	}

	// Check if any references are unknown
	for _, ref := range expr.References {
		if u := e.tracker.Get(ref); u != nil {
			return Unknown(ReasonDependsOnUnknown, ref)
		}
	}

	// Try to evaluate
	if ctx != nil {
		val, err := ctx.Evaluate(expr)
		if err != nil {
			return Unknown(ReasonExpressionError, expr.Raw)
		}
		return Known(val)
	}

	return Unknown(ReasonExpressionError, expr.Raw)
}

func (e *UnknownAwareExpander) createPlaceholderInstance(
	def *model.AssetDefinition,
	u *UnknownValue,
) []*model.AssetInstance {
	inst := &model.AssetInstance{
		ID:           model.InstanceID(fmt.Sprintf("%s:placeholder", def.ID)),
		DefinitionID: def.ID,
		Address:      model.InstanceAddress(fmt.Sprintf("%s[?]", def.Address)),
		Key:          model.InstanceKey{Type: model.KeyTypeNone},
		Attributes:   make(map[string]model.ResolvedAttribute),
		Metadata: model.InstanceMetadata{
			IsPlaceholder: true,
			Warning:       fmt.Sprintf("placeholder for unknown expansion: %s", u.Reason),
		},
	}

	// Mark all attributes as unknown
	for name := range def.Attributes {
		inst.Attributes[name] = model.ResolvedAttribute{
			IsUnknown: true,
			Reason:    model.ReasonComputedAtApply,
		}
	}

	return []*model.AssetInstance{inst}
}

func (e *UnknownAwareExpander) createSingleInstance(
	def *model.AssetDefinition,
	ctx *EvalContext,
) *model.AssetInstance {
	inst := &model.AssetInstance{
		ID:           model.InstanceID(def.ID),
		DefinitionID: def.ID,
		Address:      model.InstanceAddress(def.Address),
		Key:          model.InstanceKey{Type: model.KeyTypeNone},
		Attributes:   e.resolveAttributes(def, ctx),
	}
	return inst
}

func (e *UnknownAwareExpander) expandCount(
	def *model.AssetDefinition,
	count int,
	ctx *EvalContext,
) []*model.AssetInstance {
	instances := make([]*model.AssetInstance, count)
	for i := 0; i < count; i++ {
		instances[i] = &model.AssetInstance{
			ID:           model.InstanceID(fmt.Sprintf("%s:%d", def.ID, i)),
			DefinitionID: def.ID,
			Address:      model.InstanceAddress(fmt.Sprintf("%s[%d]", def.Address, i)),
			Key:          model.InstanceKey{Type: model.KeyTypeInt, IntValue: i},
			Attributes:   e.resolveAttributesWithCount(def, i, ctx),
		}
	}
	return instances
}

func (e *UnknownAwareExpander) expandForEach(
	def *model.AssetDefinition,
	forEach interface{},
	ctx *EvalContext,
) []*model.AssetInstance {
	var instances []*model.AssetInstance

	switch v := forEach.(type) {
	case map[string]interface{}:
		for key, value := range v {
			instances = append(instances, &model.AssetInstance{
				ID:           model.InstanceID(fmt.Sprintf("%s:%s", def.ID, key)),
				DefinitionID: def.ID,
				Address:      model.InstanceAddress(fmt.Sprintf("%s[%q]", def.Address, key)),
				Key:          model.InstanceKey{Type: model.KeyTypeString, StrValue: key},
				Attributes:   e.resolveAttributesWithEach(def, key, value, ctx),
			})
		}
	case []interface{}:
		for i, item := range v {
			if key, ok := item.(string); ok {
				instances = append(instances, &model.AssetInstance{
					ID:           model.InstanceID(fmt.Sprintf("%s:%s", def.ID, key)),
					DefinitionID: def.ID,
					Address:      model.InstanceAddress(fmt.Sprintf("%s[%q]", def.Address, key)),
					Key:          model.InstanceKey{Type: model.KeyTypeString, StrValue: key},
					Attributes:   e.resolveAttributesWithEach(def, key, item, ctx),
				})
			} else {
				// Use index as fallback
				instances = append(instances, &model.AssetInstance{
					ID:           model.InstanceID(fmt.Sprintf("%s:%d", def.ID, i)),
					DefinitionID: def.ID,
					Address:      model.InstanceAddress(fmt.Sprintf("%s[%d]", def.Address, i)),
					Key:          model.InstanceKey{Type: model.KeyTypeInt, IntValue: i},
					Attributes:   e.resolveAttributesWithEach(def, i, item, ctx),
				})
			}
		}
	}

	return instances
}

func (e *UnknownAwareExpander) resolveAttributes(
	def *model.AssetDefinition,
	ctx *EvalContext,
) map[string]model.ResolvedAttribute {
	result := make(map[string]model.ResolvedAttribute)

	for name, expr := range def.Attributes {
		if name == "count" || name == "for_each" || name == "depends_on" || name == "lifecycle" || name == "provider" {
			continue
		}

		val := e.evaluateExpression(expr, ctx)
		if val.IsUnknown() {
			result[name] = model.ResolvedAttribute{
				IsUnknown: true,
				Reason:    model.UnknownReason(val.GetUnknown().Reason),
			}
		} else {
			result[name] = model.ResolvedAttribute{
				Value:     val.Get(),
				IsUnknown: false,
			}
		}
	}

	return result
}

func (e *UnknownAwareExpander) resolveAttributesWithCount(
	def *model.AssetDefinition,
	index int,
	ctx *EvalContext,
) map[string]model.ResolvedAttribute {
	// Clone context and add count.index
	childCtx := ctx.Clone()
	childCtx.SetLocal("count.index", index)
	return e.resolveAttributes(def, childCtx)
}

func (e *UnknownAwareExpander) resolveAttributesWithEach(
	def *model.AssetDefinition,
	key interface{},
	value interface{},
	ctx *EvalContext,
) map[string]model.ResolvedAttribute {
	childCtx := ctx.Clone()
	childCtx.SetLocal("each.key", key)
	childCtx.SetLocal("each.value", value)
	return e.resolveAttributes(def, childCtx)
}

// Tracker returns the unknown tracker
func (e *UnknownAwareExpander) Tracker() *UnknownTracker {
	return e.tracker
}

################################################################################
# FILE: :\good projects\cost estimation\core\types\asset.go
# TYPE: go
# SIZE: 6162 bytes
################################################################################
// Package types - Asset domain types
package types

// RawAsset represents a parsed infrastructure resource before graph construction.
// This is the output of scanners - no pricing or cost information here.
type RawAsset struct {
	// Address is the Terraform resource address
	Address ResourceAddress `json:"address"`

	// Provider is the cloud provider (aws, azure, gcp)
	Provider Provider `json:"provider"`

	// Type is the resource type (e.g., "aws_instance", "aws_s3_bucket")
	Type string `json:"type"`

	// Name is the resource name from the Terraform configuration
	Name string `json:"name"`

	// Attributes contains all resource attributes
	Attributes Attributes `json:"attributes"`

	// Module is the module path (empty for root module)
	Module string `json:"module,omitempty"`

	// Count is the count value if using count meta-argument
	Count int `json:"count,omitempty"`

	// ForEach contains the for_each keys if using for_each meta-argument
	ForEach []string `json:"for_each,omitempty"`

	// IsDataSource indicates if this is a data source, not a resource
	IsDataSource bool `json:"is_data_source"`

	// SourceFile is the file where this resource is defined
	SourceFile string `json:"source_file,omitempty"`

	// SourceLine is the line number in the source file
	SourceLine int `json:"source_line,omitempty"`
}

// Asset represents a node in the Asset Graph.
// This is the normalized, provider-agnostic representation of infrastructure.
type Asset struct {
	// ID is a unique identifier for this asset
	ID string `json:"id"`

	// Address is the original Terraform resource address
	Address ResourceAddress `json:"address"`

	// Provider is the cloud provider
	Provider Provider `json:"provider"`

	// Category groups assets by function (compute, storage, network, etc.)
	Category AssetCategory `json:"category"`

	// Type is the resource type
	Type string `json:"type"`

	// Name is the resource name
	Name string `json:"name"`

	// Attributes contains normalized resource attributes
	Attributes Attributes `json:"attributes"`

	// Children contains child assets (e.g., EBS volumes attached to an EC2 instance)
	Children []*Asset `json:"children,omitempty"`

	// Parent is the parent asset (nil for root-level assets)
	Parent *Asset `json:"-"`

	// Dependencies lists assets this asset depends on
	Dependencies []*Asset `json:"-"`

	// Metadata contains additional information about the asset
	Metadata AssetMetadata `json:"metadata"`

	// Region is the deployment region
	Region Region `json:"region,omitempty"`

	// Tags are resource tags
	Tags map[string]string `json:"tags,omitempty"`
}

// AssetCategory groups assets by their primary function
type AssetCategory string

const (
	CategoryCompute    AssetCategory = "compute"
	CategoryStorage    AssetCategory = "storage"
	CategoryNetwork    AssetCategory = "network"
	CategoryDatabase   AssetCategory = "database"
	CategoryContainer  AssetCategory = "container"
	CategoryServerless AssetCategory = "serverless"
	CategorySecurity   AssetCategory = "security"
	CategoryMonitoring AssetCategory = "monitoring"
	CategoryAI         AssetCategory = "ai_ml"
	CategoryOther      AssetCategory = "other"
)

// String returns the string representation
func (c AssetCategory) String() string {
	return string(c)
}

// AssetMetadata contains asset-specific metadata
type AssetMetadata struct {
	// Source is the file path where the asset is defined
	Source string `json:"source,omitempty"`

	// Line is the line number in the source file
	Line int `json:"line,omitempty"`

	// IsDataSource indicates if this originated from a data source
	IsDataSource bool `json:"is_data_source"`

	// ModulePath is the module path
	ModulePath string `json:"module_path,omitempty"`

	// Index is the count or for_each index
	Index string `json:"index,omitempty"`
}

// AssetGraph represents the complete infrastructure as a directed acyclic graph
type AssetGraph struct {
	// Roots contains top-level assets (no parent)
	Roots []*Asset `json:"roots"`

	// ByID provides O(1) lookup by asset ID
	ByID map[string]*Asset `json:"-"`

	// ByAddress provides lookup by Terraform address
	ByAddress map[ResourceAddress]*Asset `json:"-"`

	// ByProvider groups assets by cloud provider
	ByProvider map[Provider][]*Asset `json:"-"`

	// ByCategory groups assets by category
	ByCategory map[AssetCategory][]*Asset `json:"-"`

	// Metadata contains graph-level metadata
	Metadata GraphMetadata `json:"metadata"`
}

// GraphMetadata contains metadata about the asset graph
type GraphMetadata struct {
	// TotalAssets is the total count of assets
	TotalAssets int `json:"total_assets"`

	// Providers lists all providers in the graph
	Providers []Provider `json:"providers"`

	// Modules lists all module paths
	Modules []string `json:"modules,omitempty"`
}

// NewAssetGraph creates a new empty asset graph
func NewAssetGraph() *AssetGraph {
	return &AssetGraph{
		Roots:      make([]*Asset, 0),
		ByID:       make(map[string]*Asset),
		ByAddress:  make(map[ResourceAddress]*Asset),
		ByProvider: make(map[Provider][]*Asset),
		ByCategory: make(map[AssetCategory][]*Asset),
	}
}

// Add adds an asset to the graph
func (g *AssetGraph) Add(asset *Asset) {
	g.ByID[asset.ID] = asset
	g.ByAddress[asset.Address] = asset
	g.ByProvider[asset.Provider] = append(g.ByProvider[asset.Provider], asset)
	g.ByCategory[asset.Category] = append(g.ByCategory[asset.Category], asset)

	if asset.Parent == nil {
		g.Roots = append(g.Roots, asset)
	}

	g.Metadata.TotalAssets++
}

// Walk traverses all assets in the graph, calling fn for each
func (g *AssetGraph) Walk(fn func(*Asset) error) error {
	for _, root := range g.Roots {
		if err := walkAsset(root, fn); err != nil {
			return err
		}
	}
	return nil
}

func walkAsset(asset *Asset, fn func(*Asset) error) error {
	if err := fn(asset); err != nil {
		return err
	}
	for _, child := range asset.Children {
		if err := walkAsset(child, fn); err != nil {
			return err
		}
	}
	return nil
}

################################################################################
# FILE: :\good projects\cost estimation\core\types\cost.go
# TYPE: go
# SIZE: 7583 bytes
################################################################################
// Package types - Cost graph types
package types

import "github.com/shopspring/decimal"

// Currency represents a currency code
type Currency string

const (
	CurrencyUSD Currency = "USD"
	CurrencyEUR Currency = "EUR"
	CurrencyGBP Currency = "GBP"
)

// String returns the string representation
func (c Currency) String() string {
	return string(c)
}

// RateKey uniquely identifies a pricing rate
type RateKey struct {
	// Provider is the cloud provider
	Provider Provider `json:"provider"`

	// Service is the cloud service (e.g., "EC2", "S3")
	Service string `json:"service"`

	// ProductFamily is the product family (e.g., "Compute Instance", "Storage")
	ProductFamily string `json:"product_family"`

	// Region is the cloud region
	Region string `json:"region"`

	// Attributes contains SKU-specific attributes
	Attributes map[string]string `json:"attributes,omitempty"`
}

// String returns a string representation for caching/lookup
func (k RateKey) String() string {
	return string(k.Provider) + "/" + k.Service + "/" + k.ProductFamily + "/" + k.Region
}

// CostUnit represents a single billable line item
type CostUnit struct {
	// ID uniquely identifies this cost unit
	ID string `json:"id"`

	// Label is a human-readable label
	Label string `json:"label"`

	// Description provides additional context
	Description string `json:"description,omitempty"`

	// Measure is the billing unit (e.g., "GB-month", "hours", "requests")
	Measure string `json:"measure"`

	// Quantity is the usage quantity
	Quantity decimal.Decimal `json:"quantity"`

	// RateKey identifies the pricing rate
	RateKey RateKey `json:"rate_key"`

	// Rate is the unit price
	Rate decimal.Decimal `json:"rate"`

	// Amount is the calculated cost (Quantity * Rate)
	Amount decimal.Decimal `json:"amount"`

	// Currency is the cost currency
	Currency Currency `json:"currency"`

	// Lineage tracks why this cost exists
	Lineage CostLineage `json:"lineage"`

	// IsSubcost indicates if this is a sub-component of a larger cost
	IsSubcost bool `json:"is_subcost,omitempty"`
}

// CostLineage tracks the origin and calculation of a cost
type CostLineage struct {
	// AssetID links to the source asset
	AssetID string `json:"asset_id"`

	// AssetAddress is the Terraform resource address
	AssetAddress ResourceAddress `json:"asset_address"`

	// Formula describes how the cost was calculated
	Formula string `json:"formula"`

	// UsageVector is the usage data used in calculation
	UsageVector *UsageVector `json:"usage_vector,omitempty"`

	// Assumptions lists assumptions made during calculation
	Assumptions []string `json:"assumptions,omitempty"`
}

// CostAggregate groups cost units by a dimension
type CostAggregate struct {
	// ID uniquely identifies this aggregate
	ID string `json:"id"`

	// Label is a human-readable label
	Label string `json:"label"`

	// Description provides additional context
	Description string `json:"description,omitempty"`

	// Units contains the cost units in this aggregate
	Units []*CostUnit `json:"units,omitempty"`

	// Children contains child aggregates
	Children []*CostAggregate `json:"children,omitempty"`

	// MonthlyCost is the calculated monthly total
	MonthlyCost decimal.Decimal `json:"monthly_cost"`

	// HourlyCost is the calculated hourly cost
	HourlyCost decimal.Decimal `json:"hourly_cost"`

	// Currency is the cost currency
	Currency Currency `json:"currency"`
}

// Add adds a cost unit to the aggregate
func (a *CostAggregate) Add(unit *CostUnit) {
	a.Units = append(a.Units, unit)
	a.MonthlyCost = a.MonthlyCost.Add(unit.Amount)
}

// Total returns the total monthly cost
func (a *CostAggregate) Total() decimal.Decimal {
	total := a.MonthlyCost
	for _, child := range a.Children {
		total = total.Add(child.Total())
	}
	return total
}

// CostGraph represents the complete cost model as a graph
type CostGraph struct {
	// Root is the top-level aggregate
	Root *CostAggregate `json:"root"`

	// ByAsset groups costs by asset ID
	ByAsset map[string]*CostAggregate `json:"by_asset,omitempty"`

	// ByProvider groups costs by cloud provider
	ByProvider map[Provider]*CostAggregate `json:"by_provider,omitempty"`

	// ByService groups costs by service
	ByService map[string]*CostAggregate `json:"by_service,omitempty"`

	// ByCategory groups costs by asset category
	ByCategory map[AssetCategory]*CostAggregate `json:"by_category,omitempty"`

	// TotalMonthlyCost is the overall monthly total
	TotalMonthlyCost decimal.Decimal `json:"total_monthly_cost"`

	// TotalHourlyCost is the overall hourly total
	TotalHourlyCost decimal.Decimal `json:"total_hourly_cost"`

	// Currency is the primary currency
	Currency Currency `json:"currency"`

	// Metadata contains graph-level information
	Metadata CostGraphMetadata `json:"metadata"`
}

// CostGraphMetadata contains metadata about the cost graph
type CostGraphMetadata struct {
	// PricingSnapshotID is the pricing snapshot used
	PricingSnapshotID string `json:"pricing_snapshot_id"`

	// CreatedAt is when the graph was created
	CreatedAt string `json:"created_at"`

	// AssetCount is the number of priced assets
	AssetCount int `json:"asset_count"`

	// CostUnitCount is the total number of cost units
	CostUnitCount int `json:"cost_unit_count"`

	// MissingPrices lists rate keys that couldn't be resolved
	MissingPrices []RateKey `json:"missing_prices,omitempty"`
}

// NewCostGraph creates a new empty cost graph
func NewCostGraph(currency Currency) *CostGraph {
	return &CostGraph{
		Root: &CostAggregate{
			ID:       "root",
			Label:    "Total",
			Currency: currency,
		},
		ByAsset:    make(map[string]*CostAggregate),
		ByProvider: make(map[Provider]*CostAggregate),
		ByService:  make(map[string]*CostAggregate),
		ByCategory: make(map[AssetCategory]*CostAggregate),
		Currency:   currency,
	}
}

// AddCostUnit adds a cost unit to the graph with proper indexing
func (g *CostGraph) AddCostUnit(unit *CostUnit, asset *Asset) {
	// Add to root
	g.Root.Add(unit)

	// Add to by-asset index
	if _, ok := g.ByAsset[asset.ID]; !ok {
		g.ByAsset[asset.ID] = &CostAggregate{
			ID:       asset.ID,
			Label:    string(asset.Address),
			Currency: g.Currency,
		}
	}
	g.ByAsset[asset.ID].Add(unit)

	// Add to by-provider index
	if _, ok := g.ByProvider[asset.Provider]; !ok {
		g.ByProvider[asset.Provider] = &CostAggregate{
			ID:       string(asset.Provider),
			Label:    string(asset.Provider),
			Currency: g.Currency,
		}
	}
	g.ByProvider[asset.Provider].Add(unit)

	// Add to by-service index
	service := unit.RateKey.Service
	if _, ok := g.ByService[service]; !ok {
		g.ByService[service] = &CostAggregate{
			ID:       service,
			Label:    service,
			Currency: g.Currency,
		}
	}
	g.ByService[service].Add(unit)

	// Add to by-category index
	if _, ok := g.ByCategory[asset.Category]; !ok {
		g.ByCategory[asset.Category] = &CostAggregate{
			ID:       string(asset.Category),
			Label:    string(asset.Category),
			Currency: g.Currency,
		}
	}
	g.ByCategory[asset.Category].Add(unit)

	// Update totals
	g.TotalMonthlyCost = g.TotalMonthlyCost.Add(unit.Amount)
	g.Metadata.CostUnitCount++
}

// Summarize recalculates all totals in the graph
func (g *CostGraph) Summarize() {
	g.TotalMonthlyCost = g.Root.Total()
	// Convert to hourly (730 hours/month)
	g.TotalHourlyCost = g.TotalMonthlyCost.Div(decimal.NewFromInt(730))
}

################################################################################
# FILE: :\good projects\cost estimation\core\types\pricing.go
# TYPE: go
# SIZE: 4299 bytes
################################################################################
// Package types - Pricing types
package types

import (
	"time"

	"github.com/shopspring/decimal"
)

// PricingSnapshot represents a point-in-time pricing dataset
type PricingSnapshot struct {
	// ID uniquely identifies this snapshot
	ID string `json:"id"`

	// Provider is the cloud provider
	Provider Provider `json:"provider"`

	// Region is the pricing region
	Region string `json:"region"`

	// Timestamp is when the snapshot was taken
	Timestamp time.Time `json:"timestamp"`

	// Hash is a content hash for validation
	Hash string `json:"hash"`

	// Source indicates where the pricing came from
	Source string `json:"source"`

	// Version is the pricing data version
	Version string `json:"version,omitempty"`
}

// Rate represents a pricing rate for a specific SKU
type Rate struct {
	// Key uniquely identifies what this rate applies to
	Key RateKey `json:"key"`

	// Price is the unit price
	Price decimal.Decimal `json:"price"`

	// Unit is the billing unit (e.g., "hour", "GB-month")
	Unit string `json:"unit"`

	// Currency is the price currency
	Currency Currency `json:"currency"`

	// EffectiveFrom is when this rate became effective
	EffectiveFrom time.Time `json:"effective_from"`

	// EffectiveTo is when this rate expires (nil = current)
	EffectiveTo *time.Time `json:"effective_to,omitempty"`

	// SnapshotID links to the pricing snapshot
	SnapshotID string `json:"snapshot_id"`

	// Description provides additional context
	Description string `json:"description,omitempty"`

	// Tiers contains tiered pricing information
	Tiers []PricingTier `json:"tiers,omitempty"`
}

// PricingTier represents a tier in tiered pricing
type PricingTier struct {
	// StartQuantity is the tier start (inclusive)
	StartQuantity decimal.Decimal `json:"start_quantity"`

	// EndQuantity is the tier end (exclusive, nil = unlimited)
	EndQuantity *decimal.Decimal `json:"end_quantity,omitempty"`

	// Price is the unit price for this tier
	Price decimal.Decimal `json:"price"`

	// Unit is the billing unit
	Unit string `json:"unit"`
}

// CalculateTieredCost calculates cost for tiered pricing
func (r *Rate) CalculateTieredCost(quantity decimal.Decimal) decimal.Decimal {
	if len(r.Tiers) == 0 {
		return quantity.Mul(r.Price)
	}

	total := decimal.Zero
	remaining := quantity

	for _, tier := range r.Tiers {
		if remaining.LessThanOrEqual(decimal.Zero) {
			break
		}

		var tierQuantity decimal.Decimal
		if tier.EndQuantity == nil {
			tierQuantity = remaining
		} else {
			tierRange := tier.EndQuantity.Sub(tier.StartQuantity)
			if remaining.LessThan(tierRange) {
				tierQuantity = remaining
			} else {
				tierQuantity = tierRange
			}
		}

		total = total.Add(tierQuantity.Mul(tier.Price))
		remaining = remaining.Sub(tierQuantity)
	}

	return total
}

// PricingResult contains resolved pricing for a set of rate keys
type PricingResult struct {
	// Rates maps rate keys to their resolved rates
	Rates map[string]Rate `json:"rates"`

	// Snapshot is the pricing snapshot used
	Snapshot PricingSnapshot `json:"snapshot"`

	// Missing lists rate keys that couldn't be resolved
	Missing []RateKey `json:"missing,omitempty"`

	// FromCache indicates how many rates were from cache
	FromCache int `json:"from_cache"`

	// FromDB indicates how many rates were from database
	FromDB int `json:"from_db"`

	// FromAPI indicates how many rates were from API
	FromAPI int `json:"from_api"`
}

// GetRate retrieves a rate by its key
func (r *PricingResult) GetRate(key RateKey) (Rate, bool) {
	if r == nil || r.Rates == nil {
		return Rate{}, false
	}
	rate, ok := r.Rates[key.String()]
	return rate, ok
}

// PricingFilter specifies criteria for pricing lookups
type PricingFilter struct {
	// Provider filters by cloud provider
	Provider Provider `json:"provider,omitempty"`

	// Service filters by service name
	Service string `json:"service,omitempty"`

	// Region filters by region
	Region string `json:"region,omitempty"`

	// ProductFamily filters by product family
	ProductFamily string `json:"product_family,omitempty"`

	// Attributes filters by specific attributes
	Attributes map[string]string `json:"attributes,omitempty"`
}

################################################################################
# FILE: :\good projects\cost estimation\core\types\project.go
# TYPE: go
# SIZE: 3240 bytes
################################################################################
// Package types - Project input types
package types

import "time"

// ProjectInput represents a normalized input for estimation
type ProjectInput struct {
	// ID uniquely identifies this input
	ID string `json:"id"`

	// Path is the filesystem path to the project
	Path string `json:"path"`

	// Type is the detected project type
	Type ProjectType `json:"type"`

	// Source indicates where the input came from
	Source InputSource `json:"source"`

	// Metadata contains additional context
	Metadata InputMetadata `json:"metadata"`
}

// ProjectType identifies the type of infrastructure project
type ProjectType string

const (
	ProjectTypeTerraformHCL    ProjectType = "terraform-hcl"
	ProjectTypeTerraformPlan   ProjectType = "terraform-plan"
	ProjectTypeTerragrunt      ProjectType = "terragrunt"
	ProjectTypeCloudFormation  ProjectType = "cloudformation"
	ProjectTypeUnknown         ProjectType = "unknown"
)

// String returns the string representation
func (t ProjectType) String() string {
	return string(t)
}

// InputSource indicates the origin of the input
type InputSource string

const (
	SourceCLI      InputSource = "cli"
	SourceWeb      InputSource = "web"
	SourceGit      InputSource = "git"
	SourceCICD     InputSource = "cicd"
	SourceAPI      InputSource = "api"
)

// String returns the string representation
func (s InputSource) String() string {
	return string(s)
}

// InputMetadata contains metadata about the input
type InputMetadata struct {
	// Repository is the Git repository URL
	Repository string `json:"repository,omitempty"`

	// Branch is the Git branch
	Branch string `json:"branch,omitempty"`

	// Commit is the Git commit SHA
	Commit string `json:"commit,omitempty"`

	// User is the authenticated user
	User string `json:"user,omitempty"`

	// Timestamp is when the input was received
	Timestamp time.Time `json:"timestamp"`

	// Files lists the input files
	Files []string `json:"files,omitempty"`

	// Hash is a content hash for caching
	Hash string `json:"hash,omitempty"`

	// Environment is the target environment
	Environment string `json:"environment,omitempty"`

	// Tags are user-provided tags
	Tags map[string]string `json:"tags,omitempty"`
}

// DetectedProject contains detection results
type DetectedProject struct {
	// Type is the project type
	Type ProjectType `json:"type"`

	// Roots are the Terraform root modules
	Roots []string `json:"roots"`

	// Confidence is the detection confidence (0.0 to 1.0)
	Confidence float64 `json:"confidence"`

	// Files are the detected IaC files
	Files []DetectedFile `json:"files"`
}

// DetectedFile represents a detected infrastructure file
type DetectedFile struct {
	// Path is the file path relative to project root
	Path string `json:"path"`

	// Type is the file type
	Type FileType `json:"type"`
}

// FileType identifies the type of infrastructure file
type FileType string

const (
	FileTypeTerraform      FileType = "terraform"
	FileTypeTerraformVars  FileType = "tfvars"
	FileTypeTerraformPlan  FileType = "tfplan"
	FileTypeTerragrunt     FileType = "terragrunt"
	FileTypeCloudFormation FileType = "cloudformation"
)

################################################################################
# FILE: :\good projects\cost estimation\core\types\types.go
# TYPE: go
# SIZE: 3456 bytes
################################################################################
// Package types defines core domain types shared across all layers.
// This package contains NO business logic - only type definitions.
package types

import "time"

// Provider represents a cloud provider
type Provider string

const (
	ProviderAWS     Provider = "aws"
	ProviderAzure   Provider = "azure"
	ProviderGCP     Provider = "gcp"
	ProviderUnknown Provider = "unknown"
)

// String returns the string representation of the provider
func (p Provider) String() string {
	return string(p)
}

// IsValid checks if the provider is a known provider
func (p Provider) IsValid() bool {
	switch p {
	case ProviderAWS, ProviderAzure, ProviderGCP:
		return true
	default:
		return false
	}
}

// ResourceAddress uniquely identifies a resource in Terraform
// Format: module.name.resource_type.resource_name or resource_type.resource_name
type ResourceAddress string

// String returns the string representation
func (r ResourceAddress) String() string {
	return string(r)
}

// Attribute represents a resource attribute value
// CRITICAL: Attribute may be UNEVALUATED if it depends on context
type Attribute struct {
	Value       interface{} `json:"value"`
	IsComputed  bool        `json:"is_computed"`
	IsSensitive bool        `json:"is_sensitive"`
	IsUnknown   bool        `json:"is_unknown"` // True if value cannot be determined

	// Expression tracking for deferred evaluation
	Expression       string   `json:"expression,omitempty"`        // Source expression
	ExpressionType   string   `json:"expression_type,omitempty"`   // "literal", "variable", "local", etc
	References       []string `json:"references,omitempty"`        // Referenced addresses
	ConfidenceImpact float64  `json:"confidence_impact,omitempty"` // 0.0-1.0 impact on confidence

	Type string `json:"type,omitempty"`
}

// Attributes is a map of attribute names to values
type Attributes map[string]Attribute

// Get retrieves an attribute value, returning nil if not found
func (a Attributes) Get(key string) interface{} {
	if attr, ok := a[key]; ok {
		return attr.Value
	}
	return nil
}

// GetString retrieves a string attribute value
func (a Attributes) GetString(key string) string {
	if v := a.Get(key); v != nil {
		if s, ok := v.(string); ok {
			return s
		}
	}
	return ""
}

// GetInt retrieves an integer attribute value
func (a Attributes) GetInt(key string) int {
	if v := a.Get(key); v != nil {
		switch n := v.(type) {
		case int:
			return n
		case int64:
			return int(n)
		case float64:
			return int(n)
		}
	}
	return 0
}

// GetBool retrieves a boolean attribute value
func (a Attributes) GetBool(key string) bool {
	if v := a.Get(key); v != nil {
		if b, ok := v.(bool); ok {
			return b
		}
	}
	return false
}

// GetFloat retrieves a float64 attribute value
func (a Attributes) GetFloat(key string) float64 {
	if v := a.Get(key); v != nil {
		switch n := v.(type) {
		case float64:
			return n
		case int:
			return float64(n)
		case int64:
			return float64(n)
		}
	}
	return 0
}

// Metadata contains common metadata fields
type Metadata struct {
	CreatedAt time.Time `json:"created_at"`
	UpdatedAt time.Time `json:"updated_at"`
	Version   string    `json:"version"`
}

// Region represents a cloud region
type Region string

// String returns the string representation
func (r Region) String() string {
	return string(r)
}

################################################################################
# FILE: :\good projects\cost estimation\core\types\usage.go
# TYPE: go
# SIZE: 6309 bytes
################################################################################
// Package types - Usage estimation types
package types

// UsageMetric identifies a measurable usage dimension
type UsageMetric string

// Common usage metrics across all providers
const (
	// Time-based metrics
	MetricMonthlyHours UsageMetric = "monthly_hours"
	MetricDailyHours   UsageMetric = "daily_hours"

	// Storage metrics
	MetricMonthlyGB        UsageMetric = "monthly_gb"
	MetricMonthlyGBStorage UsageMetric = "monthly_gb_storage"
	MetricMonthlySnapshots UsageMetric = "monthly_snapshots"

	// Transfer metrics
	MetricMonthlyGBTransferOut   UsageMetric = "monthly_gb_transfer_out"
	MetricMonthlyGBTransferIn    UsageMetric = "monthly_gb_transfer_in"
	MetricMonthlyGBInterRegion   UsageMetric = "monthly_gb_inter_region"
	MetricMonthlyGBInterAZ       UsageMetric = "monthly_gb_inter_az"

	// Request metrics
	MetricMonthlyRequests       UsageMetric = "monthly_requests"
	MetricMonthlyReadRequests   UsageMetric = "monthly_read_requests"
	MetricMonthlyWriteRequests  UsageMetric = "monthly_write_requests"
	MetricMonthlyAPIRequests    UsageMetric = "monthly_api_requests"

	// Operation metrics
	MetricMonthlyOperations     UsageMetric = "monthly_operations"
	MetricMonthlyGetOperations  UsageMetric = "monthly_get_operations"
	MetricMonthlyPutOperations  UsageMetric = "monthly_put_operations"
	MetricMonthlyListOperations UsageMetric = "monthly_list_operations"

	// Compute metrics
	MetricMonthlyCPUCredits UsageMetric = "monthly_cpu_credits"
	MetricMonthlyVCPUHours  UsageMetric = "monthly_vcpu_hours"
	MetricMonthlyGBHours    UsageMetric = "monthly_gb_hours"

	// Database metrics
	MetricMonthlyIORequests       UsageMetric = "monthly_io_requests"
	MetricMonthlyBackupStorageGB  UsageMetric = "monthly_backup_storage_gb"

	// Serverless metrics
	MetricMonthlyInvocations   UsageMetric = "monthly_invocations"
	MetricMonthlyGBSeconds     UsageMetric = "monthly_gb_seconds"
	MetricMonthlyDurationMs    UsageMetric = "monthly_duration_ms"
)

// String returns the string representation
func (m UsageMetric) String() string {
	return string(m)
}

// UsageVector represents estimated usage for a specific metric
type UsageVector struct {
	// Metric is the usage dimension being measured
	Metric UsageMetric `json:"metric"`

	// Value is the estimated usage amount
	Value float64 `json:"value"`

	// Confidence is the confidence level (0.0 to 1.0)
	Confidence float64 `json:"confidence"`

	// Source indicates where this estimate came from
	Source UsageSource `json:"source"`

	// Min is the minimum expected value (for range estimates)
	Min *float64 `json:"min,omitempty"`

	// Max is the maximum expected value (for range estimates)
	Max *float64 `json:"max,omitempty"`

	// Description explains the usage estimate
	Description string `json:"description,omitempty"`
}

// UsageSource indicates the origin of usage data
type UsageSource string

const (
	// SourceDefault uses built-in default values
	SourceDefault UsageSource = "default"

	// SourceOverride uses user-provided values
	SourceOverride UsageSource = "override"

	// SourceProfile uses a pre-defined usage profile
	SourceProfile UsageSource = "profile"

	// SourceHistorical uses historical data analysis
	SourceHistorical UsageSource = "historical"

	// SourceML uses machine learning predictions
	SourceML UsageSource = "ml"

	// SourceTerraform uses values from Terraform configuration
	SourceTerraform UsageSource = "terraform"
)

// String returns the string representation
func (s UsageSource) String() string {
	return string(s)
}

// UsageProfile represents a complete usage configuration for an estimation
type UsageProfile struct {
	// Name is the profile identifier
	Name string `json:"name"`

	// Description explains the profile
	Description string `json:"description,omitempty"`

	// Environment is the target environment (dev, staging, prod)
	Environment string `json:"environment,omitempty"`

	// Defaults are default usage values by resource type
	Defaults map[string][]UsageVector `json:"defaults,omitempty"`

	// Overrides are resource-specific usage overrides
	Overrides map[ResourceAddress][]UsageVector `json:"overrides,omitempty"`

	// Multipliers scale usage values for scenario analysis
	Multipliers map[UsageMetric]float64 `json:"multipliers,omitempty"`
}

// NewUsageProfile creates a new usage profile with the given name
func NewUsageProfile(name string) *UsageProfile {
	return &UsageProfile{
		Name:        name,
		Defaults:    make(map[string][]UsageVector),
		Overrides:   make(map[ResourceAddress][]UsageVector),
		Multipliers: make(map[UsageMetric]float64),
	}
}

// GetOverrides returns usage overrides for a specific resource
func (p *UsageProfile) GetOverrides(addr ResourceAddress) []UsageVector {
	if p == nil {
		return nil
	}
	return p.Overrides[addr]
}

// GetDefaults returns default usage for a resource type
func (p *UsageProfile) GetDefaults(resourceType string) []UsageVector {
	if p == nil {
		return nil
	}
	return p.Defaults[resourceType]
}

// ApplyMultiplier applies a multiplier to usage vectors
func (p *UsageProfile) ApplyMultiplier(vectors []UsageVector) []UsageVector {
	if p == nil || len(p.Multipliers) == 0 {
		return vectors
	}

	result := make([]UsageVector, len(vectors))
	for i, v := range vectors {
		result[i] = v
		if multiplier, ok := p.Multipliers[v.Metric]; ok {
			result[i].Value = v.Value * multiplier
			if v.Min != nil {
				min := *v.Min * multiplier
				result[i].Min = &min
			}
			if v.Max != nil {
				max := *v.Max * multiplier
				result[i].Max = &max
			}
		}
	}
	return result
}

// UsageContext provides context for usage estimation
type UsageContext struct {
	// Profile is the active usage profile
	Profile *UsageProfile

	// Environment is the target environment
	Environment string

	// Region is the deployment region
	Region Region

	// Scenario is the estimation scenario (min, typical, max)
	Scenario UsageScenario
}

// UsageScenario represents different usage estimation scenarios
type UsageScenario string

const (
	ScenarioMin     UsageScenario = "min"
	ScenarioTypical UsageScenario = "typical"
	ScenarioMax     UsageScenario = "max"
)

################################################################################
# FILE: :\good projects\cost estimation\core\ui\runner.go
# TYPE: go
# SIZE: 5520 bytes
################################################################################
// Package ui - Interactive estimation runner with live progress
package ui

import (
	"context"
	"fmt"
	"time"

	"terraform-cost/core/graph"
)

// EstimationRunner runs estimation with live UI feedback
type EstimationRunner struct {
	w           *Writer
	executor    *graph.ConcurrentExecutor
	showSpinner bool
	showTable   bool
}

// NewEstimationRunner creates a runner
func NewEstimationRunner(w *Writer, workers int) *EstimationRunner {
	return &EstimationRunner{
		w:           w,
		executor:    graph.NewConcurrentExecutor(workers),
		showSpinner: true,
		showTable:   true,
	}
}

// EstimationResult is the result of an estimation run
type EstimationResult struct {
	TotalMonthly    string
	TotalHourly     string
	Resources       int
	Instances       int
	Confidence      float64
	Duration        time.Duration
	Warnings        []string
	LowConfidence   []LowConfidenceItem
	TopCosts        []TopCostItem
	ByService       map[string]string
}

// LowConfidenceItem is a resource with low confidence
type LowConfidenceItem struct {
	Address    string
	Confidence float64
	Reason     string
}

// TopCostItem is a high-cost resource
type TopCostItem struct {
	Address string
	Monthly string
	Percent float64
}

// Run executes estimation and displays results
func (r *EstimationRunner) Run(ctx context.Context, infraGraph *graph.InfrastructureGraph, estimator graph.NodeExecutor) (*EstimationResult, error) {
	result := &EstimationResult{
		Warnings:    []string{},
		LowConfidence: []LowConfidenceItem{},
		TopCosts:    []TopCostItem{},
		ByService:   make(map[string]string),
	}

	start := time.Now()

	// Show header
	r.w.Header("Terraform Cost Estimation")
	r.w.Info("Analyzing infrastructure...")
	r.w.Println("")

	// Phase 1: Scanning
	spinner := r.w.NewSpinner("Scanning resources...")
	spinner.Start()
	time.Sleep(500 * time.Millisecond) // Simulate work
	spinner.Stop(true)

	// Phase 2: Resolving
	spinner = r.w.NewSpinner("Resolving dependencies...")
	spinner.Start()
	time.Sleep(300 * time.Millisecond)
	spinner.Stop(true)

	// Phase 3: Estimation with progress
	r.w.Println("")
	r.w.SubHeader("Estimating costs...")
	
	bar := r.w.NewProgressBar(infraGraph.Size(), "Progress")
	
	err := r.executor.ExecuteWithProgress(ctx, infraGraph, estimator, func(p graph.ExecutionProgress) {
		bar.Update(int(p.Completed + p.Failed))
	}, 100*time.Millisecond)

	bar.Done()

	if err != nil {
		r.w.Error("Estimation failed: %v", err)
		return nil, err
	}

	// Get stats
	stats := r.executor.GetStats()
	result.Duration = time.Since(start)
	result.Instances = int(stats.CompletedNodes)

	// Show errors if any
	errors := r.executor.GetErrors()
	if len(errors) > 0 {
		r.w.Println("")
		r.w.Warning("%d resources failed to estimate", len(errors))
		for _, e := range errors {
			r.w.Debug("  %s: %s", e.NodeID, e.Message)
		}
	}

	return result, nil
}

// DisplayResult shows the estimation result
func (r *EstimationRunner) DisplayResult(result *EstimationResult) {
	// Cost summary
	summary := r.w.NewCostSummary()
	summary.TotalMonthly = result.TotalMonthly
	summary.TotalHourly = result.TotalHourly
	summary.Confidence = result.Confidence
	summary.Resources = result.Instances
	summary.Warnings = len(result.Warnings)
	summary.Render()

	// Top costs table
	if len(result.TopCosts) > 0 {
		r.w.Println("")
		r.w.SubHeader("Top Costs")
		table := r.w.NewTable("Resource", "Monthly Cost", "% of Total")
		for _, item := range result.TopCosts {
			table.AddRow(item.Address, item.Monthly, fmt.Sprintf("%.1f%%", item.Percent))
		}
		table.Render()
	}

	// By service breakdown
	if len(result.ByService) > 0 {
		r.w.Println("")
		r.w.SubHeader("By Service")
		table := r.w.NewTable("Service", "Monthly Cost")
		for service, cost := range result.ByService {
			table.AddRow(service, cost)
		}
		table.Render()
	}

	// Low confidence warnings
	if len(result.LowConfidence) > 0 {
		r.w.Println("")
		r.w.Warning("Low Confidence Resources")
		for _, item := range result.LowConfidence {
			r.w.Println("  %s: %.0f%% - %s", 
				r.w.color(Yellow, item.Address), 
				item.Confidence*100, 
				item.Reason)
		}
	}

	// Duration
	r.w.Println("")
	r.w.Println(r.w.color(Dim, fmt.Sprintf("Completed in %s", result.Duration.Round(time.Millisecond))))
}

// DisplayDiff shows cost comparison
func (r *EstimationRunner) DisplayDiff(before, after *EstimationResult) {
	diff := r.w.NewResourceDiff()
	
	// Calculate total change
	// This would parse the actual values in real implementation
	diff.TotalChange = "$50.00/month"
	diff.IsIncrease = true

	// Add sample items (real implementation would compare)
	diff.Added = []DiffItem{
		{Address: "aws_instance.new", NewCost: "$100.00/month"},
	}
	diff.Changed = []DiffItem{
		{Address: "aws_rds_instance.main", OldCost: "$200.00", NewCost: "$250.00", Change: "$50.00", IsIncrease: true},
	}

	diff.Render()
}

// JSONOutput outputs results as JSON
func (r *EstimationRunner) JSONOutput(result *EstimationResult) {
	// In real implementation, use encoding/json
	r.w.Println(`{`)
	r.w.Println(`  "totalMonthly": "%s",`, result.TotalMonthly)
	r.w.Println(`  "totalHourly": "%s",`, result.TotalHourly)
	r.w.Println(`  "confidence": %.2f,`, result.Confidence)
	r.w.Println(`  "resources": %d,`, result.Instances)
	r.w.Println(`  "duration": "%s"`, result.Duration)
	r.w.Println(`}`)
}

################################################################################
# FILE: :\good projects\cost estimation\core\ui\terminal.go
# TYPE: go
# SIZE: 10160 bytes
################################################################################
// Package ui - Terminal user interface
// Rich CLI output with progress bars, tables, and colors.
package ui

import (
	"fmt"
	"io"
	"os"
	"strings"
	"time"
)

// Colors for terminal output
const (
	Reset   = "\033[0m"
	Bold    = "\033[1m"
	Dim     = "\033[2m"
	Red     = "\033[31m"
	Green   = "\033[32m"
	Yellow  = "\033[33m"
	Blue    = "\033[34m"
	Magenta = "\033[35m"
	Cyan    = "\033[36m"
	White   = "\033[37m"
)

// Writer is the UI output destination
type Writer struct {
	out       io.Writer
	noColor   bool
	verbosity int
}

// NewWriter creates a UI writer
func NewWriter(out io.Writer, noColor bool) *Writer {
	if out == nil {
		out = os.Stdout
	}
	return &Writer{
		out:       out,
		noColor:   noColor,
		verbosity: 1,
	}
}

// SetVerbosity sets output verbosity (0=quiet, 1=normal, 2=verbose)
func (w *Writer) SetVerbosity(level int) {
	w.verbosity = level
}

// color applies color if enabled
func (w *Writer) color(c, text string) string {
	if w.noColor {
		return text
	}
	return c + text + Reset
}

// Print writes a line
func (w *Writer) Print(format string, args ...interface{}) {
	fmt.Fprintf(w.out, format, args...)
}

// Println writes a line with newline
func (w *Writer) Println(format string, args ...interface{}) {
	fmt.Fprintf(w.out, format+"\n", args...)
}

// Header prints a section header
func (w *Writer) Header(title string) {
	w.Println("")
	w.Println(w.color(Bold+Cyan, "â”â”â” "+title+" â”â”â”"))
	w.Println("")
}

// SubHeader prints a subsection header
func (w *Writer) SubHeader(title string) {
	w.Println(w.color(Bold, "â–¸ "+title))
}

// Success prints a success message
func (w *Writer) Success(format string, args ...interface{}) {
	msg := fmt.Sprintf(format, args...)
	w.Println(w.color(Green, "âœ“ ")+msg)
}

// Warning prints a warning
func (w *Writer) Warning(format string, args ...interface{}) {
	msg := fmt.Sprintf(format, args...)
	w.Println(w.color(Yellow, "âš  ")+msg)
}

// Error prints an error
func (w *Writer) Error(format string, args ...interface{}) {
	msg := fmt.Sprintf(format, args...)
	w.Println(w.color(Red, "âœ— ")+msg)
}

// Info prints an info message
func (w *Writer) Info(format string, args ...interface{}) {
	if w.verbosity < 1 {
		return
	}
	msg := fmt.Sprintf(format, args...)
	w.Println(w.color(Blue, "â„¹ ")+msg)
}

// Debug prints a debug message
func (w *Writer) Debug(format string, args ...interface{}) {
	if w.verbosity < 2 {
		return
	}
	msg := fmt.Sprintf(format, args...)
	w.Println(w.color(Dim, "  "+msg))
}

// ProgressBar renders a progress bar
type ProgressBar struct {
	w         *Writer
	total     int
	current   int
	width     int
	label     string
	startTime time.Time
}

// NewProgressBar creates a progress bar
func (w *Writer) NewProgressBar(total int, label string) *ProgressBar {
	return &ProgressBar{
		w:         w,
		total:     total,
		width:     40,
		label:     label,
		startTime: time.Now(),
	}
}

// Update updates the progress bar
func (p *ProgressBar) Update(current int) {
	p.current = current
	p.render()
}

// Increment increments the progress bar
func (p *ProgressBar) Increment() {
	p.current++
	p.render()
}

func (p *ProgressBar) render() {
	if p.total == 0 {
		return
	}

	percent := float64(p.current) / float64(p.total)
	filled := int(percent * float64(p.width))
	
	bar := strings.Repeat("â–ˆ", filled) + strings.Repeat("â–‘", p.width-filled)
	
	// Calculate ETA
	elapsed := time.Since(p.startTime)
	eta := ""
	if p.current > 0 {
		remaining := time.Duration(float64(elapsed) / float64(p.current) * float64(p.total-p.current))
		eta = fmt.Sprintf(" ETA: %s", formatDuration(remaining))
	}

	fmt.Fprintf(p.w.out, "\r%s [%s] %3.0f%% (%d/%d)%s", 
		p.label, bar, percent*100, p.current, p.total, eta)
}

// Done completes the progress bar
func (p *ProgressBar) Done() {
	fmt.Fprintln(p.w.out)
}

// Table renders a table
type Table struct {
	w       *Writer
	headers []string
	rows    [][]string
	widths  []int
}

// NewTable creates a table
func (w *Writer) NewTable(headers ...string) *Table {
	widths := make([]int, len(headers))
	for i, h := range headers {
		widths[i] = len(h)
	}
	return &Table{
		w:       w,
		headers: headers,
		rows:    [][]string{},
		widths:  widths,
	}
}

// AddRow adds a row to the table
func (t *Table) AddRow(cells ...string) {
	// Pad or truncate cells to match header count
	row := make([]string, len(t.headers))
	for i := range row {
		if i < len(cells) {
			row[i] = cells[i]
		}
		if len(row[i]) > t.widths[i] {
			t.widths[i] = len(row[i])
		}
	}
	t.rows = append(t.rows, row)
}

// Render prints the table
func (t *Table) Render() {
	// Build format string
	format := ""
	for i, w := range t.widths {
		if i > 0 {
			format += " â”‚ "
		}
		format += fmt.Sprintf("%%-%ds", w)
	}
	format += "\n"

	// Header
	headerArgs := make([]interface{}, len(t.headers))
	for i, h := range t.headers {
		headerArgs[i] = h
	}
	t.w.Print(t.w.color(Bold, fmt.Sprintf(format, headerArgs...)))

	// Separator
	sep := ""
	for i, w := range t.widths {
		if i > 0 {
			sep += "â”€â”¼â”€"
		}
		sep += strings.Repeat("â”€", w)
	}
	t.w.Println(sep)

	// Rows
	for _, row := range t.rows {
		args := make([]interface{}, len(row))
		for i, cell := range row {
			args[i] = cell
		}
		t.w.Print(format, args...)
	}
}

// CostSummary renders a cost summary
type CostSummary struct {
	w           *Writer
	TotalMonthly string
	TotalHourly  string
	Confidence   float64
	Resources    int
	Warnings     int
}

// NewCostSummary creates a cost summary
func (w *Writer) NewCostSummary() *CostSummary {
	return &CostSummary{w: w}
}

// Render prints the cost summary
func (s *CostSummary) Render() {
	s.w.Header("Cost Estimation Summary")

	// Main cost box
	s.w.Println(s.w.color(Bold, "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®"))
	s.w.Println(s.w.color(Bold, "â”‚")+s.w.color(Green, fmt.Sprintf("  Monthly Cost: %-20s", s.TotalMonthly))+s.w.color(Bold, "â”‚"))
	s.w.Println(s.w.color(Bold, "â”‚")+s.w.color(Dim, fmt.Sprintf("  Hourly Cost:  %-20s", s.TotalHourly))+s.w.color(Bold, "â”‚"))
	s.w.Println(s.w.color(Bold, "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯"))

	s.w.Println("")

	// Confidence indicator
	confColor := Green
	confIcon := "â—"
	if s.Confidence < 0.8 {
		confColor = Yellow
		confIcon = "â—"
	}
	if s.Confidence < 0.5 {
		confColor = Red
		confIcon = "â—‹"
	}
	s.w.Println(s.w.color(confColor, fmt.Sprintf("%s Confidence: %.0f%%", confIcon, s.Confidence*100)))

	// Stats
	s.w.Println(s.w.color(Dim, fmt.Sprintf("  Resources: %d", s.Resources)))
	if s.Warnings > 0 {
		s.w.Warning("%d warnings", s.Warnings)
	}
}

// Spinner shows a loading spinner
type Spinner struct {
	w       *Writer
	label   string
	frames  []string
	current int
	stop    chan struct{}
	done    chan struct{}
}

// NewSpinner creates a spinner
func (w *Writer) NewSpinner(label string) *Spinner {
	return &Spinner{
		w:      w,
		label:  label,
		frames: []string{"â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "},
		stop:   make(chan struct{}),
		done:   make(chan struct{}),
	}
}

// Start starts the spinner
func (s *Spinner) Start() {
	go func() {
		ticker := time.NewTicker(80 * time.Millisecond)
		defer ticker.Stop()
		for {
			select {
			case <-s.stop:
				close(s.done)
				return
			case <-ticker.C:
				s.current = (s.current + 1) % len(s.frames)
				fmt.Fprintf(s.w.out, "\r%s %s", s.w.color(Cyan, s.frames[s.current]), s.label)
			}
		}
	}()
}

// Stop stops the spinner
func (s *Spinner) Stop(success bool) {
	close(s.stop)
	<-s.done
	
	icon := s.w.color(Green, "âœ“")
	if !success {
		icon = s.w.color(Red, "âœ—")
	}
	fmt.Fprintf(s.w.out, "\r%s %s\n", icon, s.label)
}

// ResourceDiff shows resource cost diff
type ResourceDiff struct {
	w           *Writer
	Added       []DiffItem
	Removed     []DiffItem
	Changed     []DiffItem
	TotalChange string
	IsIncrease  bool
}

// DiffItem is a single diff item
type DiffItem struct {
	Address    string
	OldCost    string
	NewCost    string
	Change     string
	IsIncrease bool
}

// NewResourceDiff creates a diff view
func (w *Writer) NewResourceDiff() *ResourceDiff {
	return &ResourceDiff{w: w}
}

// Render prints the diff
func (d *ResourceDiff) Render() {
	d.w.Header("Cost Changes")

	// Added
	if len(d.Added) > 0 {
		d.w.SubHeader(fmt.Sprintf("Added (%d)", len(d.Added)))
		for _, item := range d.Added {
			d.w.Println(d.w.color(Green, "+ ")+"%s: %s", item.Address, item.NewCost)
		}
		d.w.Println("")
	}

	// Removed
	if len(d.Removed) > 0 {
		d.w.SubHeader(fmt.Sprintf("Removed (%d)", len(d.Removed)))
		for _, item := range d.Removed {
			d.w.Println(d.w.color(Red, "- ")+"%s: %s", item.Address, item.OldCost)
		}
		d.w.Println("")
	}

	// Changed
	if len(d.Changed) > 0 {
		d.w.SubHeader(fmt.Sprintf("Changed (%d)", len(d.Changed)))
		for _, item := range d.Changed {
			arrow := d.w.color(Yellow, "â†’")
			change := item.Change
			if item.IsIncrease {
				change = d.w.color(Red, "+"+change)
			} else {
				change = d.w.color(Green, change)
			}
			d.w.Println("  %s: %s %s %s (%s)", item.Address, item.OldCost, arrow, item.NewCost, change)
		}
		d.w.Println("")
	}

	// Total
	d.w.Println(strings.Repeat("â”€", 40))
	changeColor := Green
	changePrefix := ""
	if d.IsIncrease {
		changeColor = Red
		changePrefix = "+"
	}
	d.w.Println(d.w.color(Bold, "Total Change: ")+d.w.color(changeColor, changePrefix+d.TotalChange))
}

func formatDuration(d time.Duration) string {
	if d < time.Second {
		return "< 1s"
	}
	if d < time.Minute {
		return fmt.Sprintf("%ds", int(d.Seconds()))
	}
	return fmt.Sprintf("%dm %ds", int(d.Minutes()), int(d.Seconds())%60)
}

################################################################################
# FILE: :\good projects\cost estimation\core\usage\assumptions.go
# TYPE: go
# SIZE: 6400 bytes
################################################################################
// Package usage - Tracked assumptions
// Every default MUST be recorded as an assumption and reduce confidence.
package usage

import (
	"fmt"
	"terraform-cost/core/confidence"
)

// Assumption represents a usage assumption made during estimation
type Assumption struct {
	// What was assumed
	Component string
	Attribute string

	// What value was used
	Value     interface{}
	Unit      string

	// Why this was assumed
	Source    AssumptionSource
	Reason    string

	// Confidence impact
	ConfidenceImpact float64

	// Is this overrideable?
	Overrideable     bool
	OverrideKey      string // Key to use in usage file
}

// AssumptionSource indicates where the assumption came from
type AssumptionSource int

const (
	AssumptionFromDefault    AssumptionSource = iota // Hardcoded default
	AssumptionFromHeuristic                           // Calculated from other attributes
	AssumptionFromProfile                             // Usage profile
	AssumptionFromHistorical                          // Historical data
)

// String returns the source name
func (s AssumptionSource) String() string {
	switch s {
	case AssumptionFromDefault:
		return "default"
	case AssumptionFromHeuristic:
		return "heuristic"
	case AssumptionFromProfile:
		return "profile"
	case AssumptionFromHistorical:
		return "historical"
	default:
		return "unknown"
	}
}

// AssumptionTracker tracks all assumptions made during estimation
type AssumptionTracker struct {
	assumptions []*Assumption
	byComponent map[string][]*Assumption
}

// NewAssumptionTracker creates a new tracker
func NewAssumptionTracker() *AssumptionTracker {
	return &AssumptionTracker{
		assumptions: []*Assumption{},
		byComponent: make(map[string][]*Assumption),
	}
}

// RecordDefault records a default value assumption
// This ALWAYS reduces confidence
func (t *AssumptionTracker) RecordDefault(component, attribute string, value interface{}, unit string, impact float64) *Assumption {
	a := &Assumption{
		Component:        component,
		Attribute:        attribute,
		Value:            value,
		Unit:             unit,
		Source:           AssumptionFromDefault,
		Reason:           "using default value",
		ConfidenceImpact: impact,
		Overrideable:     true,
		OverrideKey:      fmt.Sprintf("%s.%s", component, attribute),
	}

	t.assumptions = append(t.assumptions, a)
	t.byComponent[component] = append(t.byComponent[component], a)
	return a
}

// RecordHeuristic records a heuristic-based assumption
func (t *AssumptionTracker) RecordHeuristic(component, attribute string, value interface{}, unit, reason string, impact float64) *Assumption {
	a := &Assumption{
		Component:        component,
		Attribute:        attribute,
		Value:            value,
		Unit:             unit,
		Source:           AssumptionFromHeuristic,
		Reason:           reason,
		ConfidenceImpact: impact,
		Overrideable:     true,
		OverrideKey:      fmt.Sprintf("%s.%s", component, attribute),
	}

	t.assumptions = append(t.assumptions, a)
	t.byComponent[component] = append(t.byComponent[component], a)
	return a
}

// All returns all assumptions
func (t *AssumptionTracker) All() []*Assumption {
	return t.assumptions
}

// ForComponent returns assumptions for a component
func (t *AssumptionTracker) ForComponent(component string) []*Assumption {
	return t.byComponent[component]
}

// TotalConfidenceImpact returns the total confidence impact
func (t *AssumptionTracker) TotalConfidenceImpact() float64 {
	total := 0.0
	for _, a := range t.assumptions {
		total += a.ConfidenceImpact
	}
	return total
}

// ApplyToTracker applies all assumptions to a confidence tracker
func (t *AssumptionTracker) ApplyToTracker(ct *confidence.ConfidenceTracker) {
	for _, a := range t.assumptions {
		ct.Apply("default_usage", fmt.Sprintf("%s: %v %s", a.OverrideKey, a.Value, a.Unit))
	}
}

// Count returns the number of assumptions
func (t *AssumptionTracker) Count() int {
	return len(t.assumptions)
}

// DefaultAssumptionImpacts defines standard confidence impacts
var DefaultAssumptionImpacts = map[string]float64{
	// Compute
	"lambda.memory_size":         0.05,
	"lambda.invocations":         0.20, // High impact - very variable
	"lambda.duration":            0.15,
	"ec2.cpu_utilization":        0.10,
	"ec2.data_transfer_gb":       0.20,
	"ecs.desired_count":          0.10,
	
	// Storage
	"s3.storage_gb":              0.25, // High impact - very variable
	"s3.requests":                0.20,
	"ebs.iops":                   0.10,
	"rds.storage_gb":             0.15,
	
	// Network
	"nat.data_processed_gb":      0.25, // High impact
	"lb.processed_bytes":         0.20,
	"data_transfer.egress_gb":    0.25,
	
	// Cache
	"elasticache.data_tiering":   0.05,
	
	// Default for unknown
	"default":                    0.15,
}

// GetDefaultImpact returns the standard impact for an assumption
func GetDefaultImpact(key string) float64 {
	if impact, ok := DefaultAssumptionImpacts[key]; ok {
		return impact
	}
	return DefaultAssumptionImpacts["default"]
}

// CommonDefaults defines common default values
var CommonDefaults = map[string]interface{}{
	// Lambda
	"aws_lambda_function.memory_size":  128,
	"aws_lambda_function.timeout":      3,
	"aws_lambda_function.invocations":  1000000, // 1M/month
	"aws_lambda_function.duration_ms":  100,

	// EC2
	"aws_instance.cpu_utilization":     50.0,  // %
	"aws_instance.data_transfer_gb":    100.0, // GB/month

	// ECS
	"aws_ecs_service.desired_count":    1,
	"aws_ecs_task.cpu_utilization":     50.0,

	// S3
	"aws_s3_bucket.storage_gb":         100.0, // GB
	"aws_s3_bucket.put_requests":       10000,
	"aws_s3_bucket.get_requests":       100000,

	// RDS
	"aws_db_instance.storage_gb":       20.0,
	"aws_db_instance.iops":             1000,

	// NAT
	"aws_nat_gateway.data_processed_gb": 100.0,

	// ALB
	"aws_lb.processed_bytes":           1000000000, // 1 GB
	"aws_lb.new_connections":           1000,
	"aws_lb.active_connections":        100,
}

// GetDefault returns a default value for a resource attribute
func GetDefault(resourceType, attribute string) (interface{}, bool) {
	key := resourceType + "." + attribute
	if val, ok := CommonDefaults[key]; ok {
		return val, true
	}
	return nil, false
}

################################################################################
# FILE: :\good projects\cost estimation\core\usage\estimator.go
# TYPE: go
# SIZE: 2653 bytes
################################################################################
// Package usage provides usage estimation interfaces.
// This package estimates how infrastructure will be used.
// Usage is decoupled from resource definitions to enable scenario modeling.
package usage

import (
	"context"

	"terraform-cost/core/types"
)

// Estimator estimates usage for a specific resource type
type Estimator interface {
	// Provider returns the cloud provider
	Provider() types.Provider

	// ResourceType returns the resource type this estimator handles
	ResourceType() string

	// Estimate produces usage vectors for an asset
	Estimate(ctx context.Context, asset *types.Asset, uctx *Context) ([]types.UsageVector, error)
}

// Context provides context for usage estimation
type Context struct {
	// Profile is the active usage profile
	Profile *types.UsageProfile

	// Environment is the target environment (dev, staging, prod)
	Environment string

	// Region is the deployment region
	Region types.Region

	// Scenario is the estimation scenario
	Scenario types.UsageScenario

	// Now is the current time (for time-based calculations)
	Now string

	// CustomDefaults are additional default values
	CustomDefaults map[types.UsageMetric]float64
}

// DefaultContext creates a new usage context with defaults
func DefaultContext() *Context {
	return &Context{
		Environment: "production",
		Scenario:    types.ScenarioTypical,
	}
}

// EstimatorRegistry manages usage estimator registration
type EstimatorRegistry interface {
	// Register adds an estimator to the registry
	Register(estimator Estimator) error

	// GetEstimator returns an estimator for a provider and resource type
	GetEstimator(provider types.Provider, resourceType string) (Estimator, bool)

	// GetProviderEstimators returns all estimators for a provider
	GetProviderEstimators(provider types.Provider) []Estimator
}

// EstimationResult contains usage estimation output
type EstimationResult struct {
	// AssetID is the asset this estimation is for
	AssetID string

	// Vectors are the usage estimates
	Vectors []types.UsageVector

	// Confidence is the overall confidence level
	Confidence float64

	// Assumptions lists assumptions made
	Assumptions []string
}

// Manager orchestrates usage estimation across all assets
type Manager interface {
	// EstimateAll estimates usage for all assets in a graph
	EstimateAll(ctx context.Context, graph *types.AssetGraph, uctx *Context) (map[string]*EstimationResult, error)

	// EstimateAsset estimates usage for a single asset
	EstimateAsset(ctx context.Context, asset *types.Asset, uctx *Context) (*EstimationResult, error)
}

################################################################################
# FILE: :\good projects\cost estimation\core\usage\registry.go
# TYPE: go
# SIZE: 2268 bytes
################################################################################
// Package usage - Usage estimator registry
package usage

import (
	"fmt"
	"sync"

	"terraform-cost/core/types"
)

// DefaultEstimatorRegistry is the default implementation
type DefaultEstimatorRegistry struct {
	mu         sync.RWMutex
	estimators map[string]Estimator // key: provider/resource_type
}

// NewEstimatorRegistry creates a new estimator registry
func NewEstimatorRegistry() *DefaultEstimatorRegistry {
	return &DefaultEstimatorRegistry{
		estimators: make(map[string]Estimator),
	}
}

// Register adds an estimator to the registry
func (r *DefaultEstimatorRegistry) Register(estimator Estimator) error {
	r.mu.Lock()
	defer r.mu.Unlock()

	key := makeEstimatorKey(estimator.Provider(), estimator.ResourceType())
	if _, exists := r.estimators[key]; exists {
		return fmt.Errorf("estimator already registered: %s", key)
	}

	r.estimators[key] = estimator
	return nil
}

// GetEstimator returns an estimator for a provider and resource type
func (r *DefaultEstimatorRegistry) GetEstimator(provider types.Provider, resourceType string) (Estimator, bool) {
	r.mu.RLock()
	defer r.mu.RUnlock()

	key := makeEstimatorKey(provider, resourceType)
	estimator, ok := r.estimators[key]
	return estimator, ok
}

// GetProviderEstimators returns all estimators for a provider
func (r *DefaultEstimatorRegistry) GetProviderEstimators(provider types.Provider) []Estimator {
	r.mu.RLock()
	defer r.mu.RUnlock()

	var estimators []Estimator
	prefix := string(provider) + "/"
	for key, estimator := range r.estimators {
		if len(key) > len(prefix) && key[:len(prefix)] == prefix {
			estimators = append(estimators, estimator)
		}
	}
	return estimators
}

func makeEstimatorKey(provider types.Provider, resourceType string) string {
	return string(provider) + "/" + resourceType
}

// Global default registry
var defaultEstimatorRegistry = NewEstimatorRegistry()

// RegisterEstimator adds an estimator to the default registry
func RegisterEstimator(estimator Estimator) error {
	return defaultEstimatorRegistry.Register(estimator)
}

// GetDefaultEstimatorRegistry returns the default registry
func GetDefaultEstimatorRegistry() *DefaultEstimatorRegistry {
	return defaultEstimatorRegistry
}

################################################################################
# FILE: :\good projects\cost estimation\core\usage\strict_defaults.go
# TYPE: go
# SIZE: 11167 bytes
################################################################################
// Package usage - Strict default enforcement
// Defaults MUST bias toward over-estimation, not under-estimation.
// Every default MUST make users uncomfortable if they don't override.
package usage

import (
	"fmt"
	"terraform-cost/core/confidence"
	"terraform-cost/core/determinism"
)

// StrictDefaultPolicy enforces that all defaults are visible and conservative
type StrictDefaultPolicy struct {
	// Defaults that are known to bias low
	lowBiasDefaults map[string]DefaultRisk

	// Minimum confidence impacts per category
	minImpacts map[string]float64
}

// DefaultRisk describes the risk of a default value
type DefaultRisk struct {
	DefaultValue     interface{}
	RiskLevel        RiskLevel
	ProductionTypical interface{} // What production usually sees
	ConfidenceImpact float64
	Warning          string
}

// RiskLevel indicates how risky a default is
type RiskLevel int

const (
	RiskLow    RiskLevel = iota // Default is conservative
	RiskMedium                   // Default may underestimate
	RiskHigh                     // Default likely underestimates
	RiskCritical                 // Default almost certainly underestimates
)

// String returns the risk level name
func (r RiskLevel) String() string {
	switch r {
	case RiskLow:
		return "low"
	case RiskMedium:
		return "medium"
	case RiskHigh:
		return "high"
	case RiskCritical:
		return "critical"
	default:
		return "unknown"
	}
}

// NewStrictDefaultPolicy creates a strict policy
func NewStrictDefaultPolicy() *StrictDefaultPolicy {
	return &StrictDefaultPolicy{
		lowBiasDefaults: map[string]DefaultRisk{
			// Lambda - invocations are typically MUCH higher
			"aws_lambda_function.invocations": {
				DefaultValue:     1000000,            // 1M
				RiskLevel:        RiskCritical,
				ProductionTypical: 100000000,          // 100M
				ConfidenceImpact: 0.35,
				Warning:          "Lambda invocations default (1M) is typically 100x lower than production",
			},
			"aws_lambda_function.duration_ms": {
				DefaultValue:     100,
				RiskLevel:        RiskHigh,
				ProductionTypical: 500,
				ConfidenceImpact: 0.25,
				Warning:          "Lambda duration default (100ms) may underestimate cold starts",
			},

			// S3 - storage grows rapidly
			"aws_s3_bucket.storage_gb": {
				DefaultValue:     100,
				RiskLevel:        RiskCritical,
				ProductionTypical: 10000,             // 10TB
				ConfidenceImpact: 0.40,
				Warning:          "S3 storage default (100GB) is typically 100x lower than production",
			},
			"aws_s3_bucket.put_requests": {
				DefaultValue:     10000,
				RiskLevel:        RiskHigh,
				ProductionTypical: 10000000,
				ConfidenceImpact: 0.30,
				Warning:          "S3 PUT requests often 1000x higher in production",
			},

			// NAT Gateway - data transfer is expensive
			"aws_nat_gateway.data_processed_gb": {
				DefaultValue:     100,
				RiskLevel:        RiskCritical,
				ProductionTypical: 5000,
				ConfidenceImpact: 0.40,
				Warning:          "NAT data default (100GB) is typically 50x lower - this is expensive",
			},

			// Data transfer - egress is expensive
			"data_transfer.egress_gb": {
				DefaultValue:     100,
				RiskLevel:        RiskCritical,
				ProductionTypical: 10000,
				ConfidenceImpact: 0.45,
				Warning:          "Egress default (100GB) is typically 100x lower in production",
			},

			// EC2 hours - assume full month
			"aws_instance.monthly_hours": {
				DefaultValue:     730,
				RiskLevel:        RiskLow, // This is actually correct
				ProductionTypical: 730,
				ConfidenceImpact: 0.05,
				Warning:          "",
			},

			// RDS storage
			"aws_db_instance.storage_gb": {
				DefaultValue:     20,
				RiskLevel:        RiskHigh,
				ProductionTypical: 500,
				ConfidenceImpact: 0.30,
				Warning:          "RDS storage default (20GB) is typically 25x lower",
			},

			// ECS
			"aws_ecs_service.desired_count": {
				DefaultValue:     1,
				RiskLevel:        RiskHigh,
				ProductionTypical: 5,
				ConfidenceImpact: 0.25,
				Warning:          "ECS desired_count default (1) is typically 5x lower",
			},
		},
		minImpacts: map[string]float64{
			"storage":       0.25,
			"compute":       0.15,
			"network":       0.30,
			"data_transfer": 0.35,
			"requests":      0.25,
		},
	}
}

// ValidateDefault checks if a default is acceptable and returns warnings
func (p *StrictDefaultPolicy) ValidateDefault(resourceType, attribute string, value interface{}) *DefaultValidation {
	key := resourceType + "." + attribute
	
	validation := &DefaultValidation{
		Key:      key,
		Value:    value,
		Acceptable: true,
		Warnings:   []string{},
	}

	if risk, ok := p.lowBiasDefaults[key]; ok {
		validation.Risk = risk.RiskLevel
		validation.ConfidenceImpact = risk.ConfidenceImpact
		
		if risk.Warning != "" {
			validation.Warnings = append(validation.Warnings, risk.Warning)
		}

		if risk.RiskLevel >= RiskHigh {
			validation.Acceptable = false
			validation.Warnings = append(validation.Warnings, 
				fmt.Sprintf("Consider using production-typical value: %v", risk.ProductionTypical))
		}
	}

	return validation
}

// DefaultValidation is the result of validating a default
type DefaultValidation struct {
	Key              string
	Value            interface{}
	Acceptable       bool
	Risk             RiskLevel
	ConfidenceImpact float64
	Warnings         []string
}

// ApplyToTracker applies the default's confidence impact
func (v *DefaultValidation) ApplyToTracker(tracker *confidence.ConfidenceTracker) {
	if v.ConfidenceImpact > 0 {
		tracker.Apply("usage_default", fmt.Sprintf("%s uses default value", v.Key))
	}
}

// StrictUsageResolver resolves usage with explicit tracking
type StrictUsageResolver struct {
	policy     *StrictDefaultPolicy
	tracker    *AssumptionTracker
	confidence *confidence.ConfidenceTracker
	warnings   []UsageWarning
}

// UsageWarning is a warning about usage estimation
type UsageWarning struct {
	ResourceType string
	Attribute    string
	Value        interface{}
	Risk         RiskLevel
	Message      string
}

// NewStrictUsageResolver creates a resolver
func NewStrictUsageResolver() *StrictUsageResolver {
	return &StrictUsageResolver{
		policy:     NewStrictDefaultPolicy(),
		tracker:    NewAssumptionTracker(),
		confidence: confidence.NewConfidenceTracker(),
		warnings:   []UsageWarning{},
	}
}

// ResolveUsage resolves a usage value, either from overrides or defaults
func (r *StrictUsageResolver) ResolveUsage(
	resourceType, attribute string,
	override interface{},
	defaultValue interface{},
) *ResolvedUsage {
	
	result := &ResolvedUsage{
		Attribute: attribute,
	}

	// If override provided, use it
	if override != nil {
		result.Value = override
		result.Source = UsageSourceOverride
		result.Confidence = 1.0
		return result
	}

	// Using default - validate it
	validation := r.policy.ValidateDefault(resourceType, attribute, defaultValue)
	
	result.Value = defaultValue
	result.Source = UsageSourceDefault
	result.Confidence = 1.0 - validation.ConfidenceImpact
	result.Risk = validation.Risk
	result.Warnings = validation.Warnings

	// Track the assumption
	r.tracker.RecordDefault(
		resourceType,
		attribute,
		defaultValue,
		"",
		validation.ConfidenceImpact,
	)

	// Record warning if high risk
	if validation.Risk >= RiskHigh {
		r.warnings = append(r.warnings, UsageWarning{
			ResourceType: resourceType,
			Attribute:    attribute,
			Value:        defaultValue,
			Risk:         validation.Risk,
			Message:      validation.Warnings[0],
		})
	}

	return result
}

// ResolvedUsage is a resolved usage value
type ResolvedUsage struct {
	Attribute  string
	Value      interface{}
	Source     UsageSource
	Confidence float64
	Risk       RiskLevel
	Warnings   []string
}

// UsageSource indicates where usage came from
type UsageSource int

const (
	UsageSourceOverride   UsageSource = iota // User provided
	UsageSourceDefault                        // Using default
	UsageSourceHistorical                     // From historical data
	UsageSourceInferred                       // Inferred from config
)

// AsFloat returns the value as float64
func (u *ResolvedUsage) AsFloat() float64 {
	switch v := u.Value.(type) {
	case float64:
		return v
	case int:
		return float64(v)
	case int64:
		return float64(v)
	default:
		return 0
	}
}

// GetWarnings returns all warnings from resolution
func (r *StrictUsageResolver) GetWarnings() []UsageWarning {
	return r.warnings
}

// GetAssumptions returns all assumptions made
func (r *StrictUsageResolver) GetAssumptions() []*Assumption {
	return r.tracker.All()
}

// GetConfidenceTracker returns the confidence tracker
func (r *StrictUsageResolver) GetConfidenceTracker() *confidence.ConfidenceTracker {
	return r.confidence
}

// FormatWarnings returns human-readable warnings
func (r *StrictUsageResolver) FormatWarnings() string {
	if len(r.warnings) == 0 {
		return "No usage warnings"
	}

	result := fmt.Sprintf("âš ï¸ %d Usage Warnings:\n", len(r.warnings))
	for i, w := range r.warnings {
		result += fmt.Sprintf("  %d. [%s] %s.%s = %v\n", 
			i+1, w.Risk.String(), w.ResourceType, w.Attribute, w.Value)
		result += fmt.Sprintf("     %s\n", w.Message)
	}
	return result
}

// CalculateTotalRisk returns aggregate risk information
func (r *StrictUsageResolver) CalculateTotalRisk() *AggregateRisk {
	risk := &AggregateRisk{}

	for _, w := range r.warnings {
		switch w.Risk {
		case RiskCritical:
			risk.CriticalCount++
		case RiskHigh:
			risk.HighCount++
		case RiskMedium:
			risk.MediumCount++
		}
	}

	risk.ConfidenceLoss = r.tracker.TotalConfidenceImpact()
	risk.EstimatedBias = r.estimateBias()

	return risk
}

func (r *StrictUsageResolver) estimateBias() determinism.Money {
	// Rough estimate of how much we might be underestimating
	// This is a heuristic based on typical production vs default ratios
	biasMultiplier := 1.0
	for _, w := range r.warnings {
		switch w.Risk {
		case RiskCritical:
			biasMultiplier *= 2.0
		case RiskHigh:
			biasMultiplier *= 1.5
		case RiskMedium:
			biasMultiplier *= 1.2
		}
	}
	// Return estimate that we might be X% low
	// This is informational only
	return determinism.Zero("USD")
}

// AggregateRisk summarizes overall usage risk
type AggregateRisk struct {
	CriticalCount  int
	HighCount      int
	MediumCount    int
	ConfidenceLoss float64
	EstimatedBias  determinism.Money
}

// IsAcceptable returns true if risk is acceptable for production
func (r *AggregateRisk) IsAcceptable() bool {
	return r.CriticalCount == 0 && r.HighCount <= 2
}

// Summary returns a summary string
func (r *AggregateRisk) Summary() string {
	if r.CriticalCount == 0 && r.HighCount == 0 {
		return "Usage defaults are acceptable"
	}
	return fmt.Sprintf("âš ï¸ %d critical, %d high risk defaults - estimate may be significantly low",
		r.CriticalCount, r.HighCount)
}

################################################################################
# FILE: :\good projects\cost estimation\db\postgres.go
# TYPE: go
# SIZE: 15223 bytes
################################################################################
// Package db - PostgreSQL implementation of PricingStore
package db

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"time"

	"github.com/google/uuid"
	"github.com/shopspring/decimal"
	_ "github.com/lib/pq"
)

// PostgresStore implements PricingStore using PostgreSQL
type PostgresStore struct {
	db *sql.DB
}

// Config holds database configuration
type Config struct {
	Host     string
	Port     int
	User     string
	Password string
	Database string
	SSLMode  string
}

// NewPostgresStore creates a new PostgreSQL pricing store
func NewPostgresStore(cfg Config) (*PostgresStore, error) {
	connStr := fmt.Sprintf(
		"host=%s port=%d user=%s password=%s dbname=%s sslmode=%s",
		cfg.Host, cfg.Port, cfg.User, cfg.Password, cfg.Database, cfg.SSLMode,
	)

	db, err := sql.Open("postgres", connStr)
	if err != nil {
		return nil, fmt.Errorf("failed to open database: %w", err)
	}

	// Configure connection pool
	db.SetMaxOpenConns(25)
	db.SetMaxIdleConns(5)
	db.SetConnMaxLifetime(5 * time.Minute)

	// Verify connection
	if err := db.Ping(); err != nil {
		return nil, fmt.Errorf("failed to ping database: %w", err)
	}

	return &PostgresStore{db: db}, nil
}

// Ping checks database connectivity
func (s *PostgresStore) Ping(ctx context.Context) error {
	return s.db.PingContext(ctx)
}

// Close closes the database connection
func (s *PostgresStore) Close() error {
	return s.db.Close()
}

// CreateSnapshot inserts a new pricing snapshot
func (s *PostgresStore) CreateSnapshot(ctx context.Context, snapshot *PricingSnapshot) error {
	query := `
		INSERT INTO pricing_snapshots 
		(id, cloud, region, provider_alias, source, fetched_at, valid_from, valid_to, hash, version, is_active)
		VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
	`
	_, err := s.db.ExecContext(ctx, query,
		snapshot.ID, snapshot.Cloud, snapshot.Region, snapshot.ProviderAlias,
		snapshot.Source, snapshot.FetchedAt, snapshot.ValidFrom, snapshot.ValidTo,
		snapshot.Hash, snapshot.Version, snapshot.IsActive,
	)
	return err
}

// GetSnapshot retrieves a snapshot by ID
func (s *PostgresStore) GetSnapshot(ctx context.Context, id uuid.UUID) (*PricingSnapshot, error) {
	query := `
		SELECT id, cloud, region, provider_alias, source, fetched_at, valid_from, valid_to, hash, version, is_active, created_at
		FROM pricing_snapshots WHERE id = $1
	`
	snapshot := &PricingSnapshot{}
	err := s.db.QueryRowContext(ctx, query, id).Scan(
		&snapshot.ID, &snapshot.Cloud, &snapshot.Region, &snapshot.ProviderAlias,
		&snapshot.Source, &snapshot.FetchedAt, &snapshot.ValidFrom, &snapshot.ValidTo,
		&snapshot.Hash, &snapshot.Version, &snapshot.IsActive, &snapshot.CreatedAt,
	)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	return snapshot, err
}

// GetActiveSnapshot retrieves the active snapshot for a cloud/region/alias
func (s *PostgresStore) GetActiveSnapshot(ctx context.Context, cloud CloudProvider, region, alias string) (*PricingSnapshot, error) {
	query := `
		SELECT id, cloud, region, provider_alias, source, fetched_at, valid_from, valid_to, hash, version, is_active, created_at
		FROM pricing_snapshots 
		WHERE cloud = $1 AND region = $2 AND provider_alias = $3 AND is_active = TRUE
	`
	snapshot := &PricingSnapshot{}
	err := s.db.QueryRowContext(ctx, query, cloud, region, alias).Scan(
		&snapshot.ID, &snapshot.Cloud, &snapshot.Region, &snapshot.ProviderAlias,
		&snapshot.Source, &snapshot.FetchedAt, &snapshot.ValidFrom, &snapshot.ValidTo,
		&snapshot.Hash, &snapshot.Version, &snapshot.IsActive, &snapshot.CreatedAt,
	)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	return snapshot, err
}

// ActivateSnapshot activates a snapshot (deactivates others)
func (s *PostgresStore) ActivateSnapshot(ctx context.Context, id uuid.UUID) error {
	_, err := s.db.ExecContext(ctx, "SELECT activate_snapshot($1)", id)
	return err
}

// ListSnapshots lists snapshots for a cloud/region
func (s *PostgresStore) ListSnapshots(ctx context.Context, cloud CloudProvider, region string) ([]*PricingSnapshot, error) {
	query := `
		SELECT id, cloud, region, provider_alias, source, fetched_at, valid_from, valid_to, hash, version, is_active, created_at
		FROM pricing_snapshots 
		WHERE cloud = $1 AND region = $2
		ORDER BY created_at DESC
	`
	rows, err := s.db.QueryContext(ctx, query, cloud, region)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var snapshots []*PricingSnapshot
	for rows.Next() {
		s := &PricingSnapshot{}
		err := rows.Scan(
			&s.ID, &s.Cloud, &s.Region, &s.ProviderAlias,
			&s.Source, &s.FetchedAt, &s.ValidFrom, &s.ValidTo,
			&s.Hash, &s.Version, &s.IsActive, &s.CreatedAt,
		)
		if err != nil {
			return nil, err
		}
		snapshots = append(snapshots, s)
	}
	return snapshots, nil
}

// UpsertRateKey inserts or returns existing rate key
func (s *PostgresStore) UpsertRateKey(ctx context.Context, key *RateKey) (*RateKey, error) {
	attrsJSON, err := json.Marshal(key.Attributes)
	if err != nil {
		return nil, err
	}

	query := `
		INSERT INTO pricing_rate_keys (id, cloud, service, product_family, region, attributes)
		VALUES ($1, $2, $3, $4, $5, $6)
		ON CONFLICT (cloud, service, product_family, region, attributes) 
		DO UPDATE SET id = pricing_rate_keys.id
		RETURNING id, created_at
	`
	err = s.db.QueryRowContext(ctx, query,
		key.ID, key.Cloud, key.Service, key.ProductFamily, key.Region, attrsJSON,
	).Scan(&key.ID, &key.CreatedAt)
	return key, err
}

// GetRateKey retrieves a rate key
func (s *PostgresStore) GetRateKey(ctx context.Context, cloud CloudProvider, service, productFamily, region string, attrs map[string]string) (*RateKey, error) {
	attrsJSON, err := json.Marshal(attrs)
	if err != nil {
		return nil, err
	}

	query := `
		SELECT id, cloud, service, product_family, region, attributes, created_at
		FROM pricing_rate_keys
		WHERE cloud = $1 AND service = $2 AND product_family = $3 AND region = $4 AND attributes = $5
	`
	key := &RateKey{}
	var attrsBytes []byte
	err = s.db.QueryRowContext(ctx, query, cloud, service, productFamily, region, attrsJSON).Scan(
		&key.ID, &key.Cloud, &key.Service, &key.ProductFamily, &key.Region, &attrsBytes, &key.CreatedAt,
	)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, err
	}
	json.Unmarshal(attrsBytes, &key.Attributes)
	return key, nil
}

// CreateRate inserts a pricing rate
func (s *PostgresStore) CreateRate(ctx context.Context, rate *PricingRate) error {
	query := `
		INSERT INTO pricing_rates 
		(id, snapshot_id, rate_key_id, unit, price, currency, confidence, tier_min, tier_max, effective_date)
		VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
	`
	_, err := s.db.ExecContext(ctx, query,
		rate.ID, rate.SnapshotID, rate.RateKeyID, rate.Unit,
		rate.Price, rate.Currency, rate.Confidence,
		rate.TierMin, rate.TierMax, rate.EffectiveDate,
	)
	return err
}

// BulkCreateRates inserts multiple rates efficiently
func (s *PostgresStore) BulkCreateRates(ctx context.Context, rates []*PricingRate) error {
	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return err
	}
	defer tx.Rollback()

	stmt, err := tx.PrepareContext(ctx, `
		INSERT INTO pricing_rates 
		(id, snapshot_id, rate_key_id, unit, price, currency, confidence, tier_min, tier_max, effective_date)
		VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
	`)
	if err != nil {
		return err
	}
	defer stmt.Close()

	for _, rate := range rates {
		_, err := stmt.ExecContext(ctx,
			rate.ID, rate.SnapshotID, rate.RateKeyID, rate.Unit,
			rate.Price, rate.Currency, rate.Confidence,
			rate.TierMin, rate.TierMax, rate.EffectiveDate,
		)
		if err != nil {
			return err
		}
	}

	return tx.Commit()
}

// ResolveRate looks up a rate from the active snapshot
func (s *PostgresStore) ResolveRate(ctx context.Context, cloud CloudProvider, service, productFamily, region string, attrs map[string]string, unit, alias string) (*ResolvedRate, error) {
	attrsJSON, err := json.Marshal(attrs)
	if err != nil {
		return nil, err
	}

	query := `
		SELECT pr.price, pr.currency, pr.confidence, pr.tier_min, pr.tier_max, ps.id, ps.source
		FROM pricing_snapshots ps
		JOIN pricing_rate_keys rk ON rk.cloud = ps.cloud AND rk.region = ps.region
		JOIN pricing_rates pr ON pr.snapshot_id = ps.id AND pr.rate_key_id = rk.id
		WHERE ps.cloud = $1
		  AND ps.region = $2
		  AND ps.provider_alias = $3
		  AND ps.is_active = TRUE
		  AND rk.service = $4
		  AND rk.product_family = $5
		  AND rk.attributes @> $6
		  AND pr.unit = $7
		ORDER BY pr.tier_min NULLS FIRST
		LIMIT 1
	`
	
	rate := &ResolvedRate{}
	err = s.db.QueryRowContext(ctx, query, cloud, region, alias, service, productFamily, attrsJSON, unit).Scan(
		&rate.Price, &rate.Currency, &rate.Confidence, &rate.TierMin, &rate.TierMax, &rate.SnapshotID, &rate.Source,
	)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	return rate, err
}

// ResolveTieredRates returns all tiers for a rate
func (s *PostgresStore) ResolveTieredRates(ctx context.Context, cloud CloudProvider, service, productFamily, region string, attrs map[string]string, unit, alias string) ([]TieredRate, error) {
	attrsJSON, err := json.Marshal(attrs)
	if err != nil {
		return nil, err
	}

	query := `
		SELECT pr.price, pr.confidence, pr.tier_min, pr.tier_max
		FROM pricing_snapshots ps
		JOIN pricing_rate_keys rk ON rk.cloud = ps.cloud AND rk.region = ps.region
		JOIN pricing_rates pr ON pr.snapshot_id = ps.id AND pr.rate_key_id = rk.id
		WHERE ps.cloud = $1
		  AND ps.region = $2
		  AND ps.provider_alias = $3
		  AND ps.is_active = TRUE
		  AND rk.service = $4
		  AND rk.product_family = $5
		  AND rk.attributes @> $6
		  AND pr.unit = $7
		ORDER BY pr.tier_min NULLS FIRST
	`
	
	rows, err := s.db.QueryContext(ctx, query, cloud, region, alias, service, productFamily, attrsJSON, unit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var tiers []TieredRate
	for rows.Next() {
		var t TieredRate
		var tierMin, tierMax *decimal.Decimal
		err := rows.Scan(&t.Price, &t.Confidence, &tierMin, &tierMax)
		if err != nil {
			return nil, err
		}
		if tierMin != nil {
			t.Min = *tierMin
		}
		t.Max = tierMax
		tiers = append(tiers, t)
	}
	return tiers, nil
}

// Transaction interface for atomic operations
type Tx interface {
	CreateSnapshot(ctx context.Context, snapshot *PricingSnapshot) error
	UpsertRateKey(ctx context.Context, key *RateKey) (*RateKey, error)
	CreateRate(ctx context.Context, rate *PricingRate) error
	ActivateSnapshot(ctx context.Context, id uuid.UUID) error
	Commit() error
	Rollback() error
}

// PostgresTx wraps a database transaction
type PostgresTx struct {
	tx *sql.Tx
}

// BeginTx starts a new transaction
func (s *PostgresStore) BeginTx(ctx context.Context) (Tx, error) {
	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return nil, err
	}
	return &PostgresTx{tx: tx}, nil
}

// CreateSnapshot creates a snapshot within a transaction
func (t *PostgresTx) CreateSnapshot(ctx context.Context, snapshot *PricingSnapshot) error {
	query := `
		INSERT INTO pricing_snapshots 
		(id, cloud, region, provider_alias, source, fetched_at, valid_from, valid_to, hash, version, is_active)
		VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
	`
	_, err := t.tx.ExecContext(ctx, query,
		snapshot.ID, snapshot.Cloud, snapshot.Region, snapshot.ProviderAlias,
		snapshot.Source, snapshot.FetchedAt, snapshot.ValidFrom, snapshot.ValidTo,
		snapshot.Hash, snapshot.Version, snapshot.IsActive,
	)
	return err
}

// UpsertRateKey inserts or returns existing rate key within a transaction
func (t *PostgresTx) UpsertRateKey(ctx context.Context, key *RateKey) (*RateKey, error) {
	attrsJSON, err := json.Marshal(key.Attributes)
	if err != nil {
		return nil, err
	}

	query := `
		INSERT INTO pricing_rate_keys (id, cloud, service, product_family, region, attributes)
		VALUES ($1, $2, $3, $4, $5, $6)
		ON CONFLICT (cloud, service, product_family, region, attributes) 
		DO UPDATE SET id = pricing_rate_keys.id
		RETURNING id, created_at
	`
	err = t.tx.QueryRowContext(ctx, query,
		key.ID, key.Cloud, key.Service, key.ProductFamily, key.Region, attrsJSON,
	).Scan(&key.ID, &key.CreatedAt)
	return key, err
}

// CreateRate creates a rate within a transaction
func (t *PostgresTx) CreateRate(ctx context.Context, rate *PricingRate) error {
	query := `
		INSERT INTO pricing_rates 
		(id, snapshot_id, rate_key_id, unit, price, currency, confidence, tier_min, tier_max, effective_date)
		VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
	`
	_, err := t.tx.ExecContext(ctx, query,
		rate.ID, rate.SnapshotID, rate.RateKeyID, rate.Unit,
		rate.Price, rate.Currency, rate.Confidence,
		rate.TierMin, rate.TierMax, rate.EffectiveDate,
	)
	return err
}

// ActivateSnapshot activates a snapshot within a transaction
func (t *PostgresTx) ActivateSnapshot(ctx context.Context, id uuid.UUID) error {
	// Deactivate existing snapshots for same cloud/region/alias
	_, err := t.tx.ExecContext(ctx, `
		UPDATE pricing_snapshots SET is_active = FALSE 
		WHERE id IN (
			SELECT ps2.id FROM pricing_snapshots ps2 
			JOIN pricing_snapshots ps1 ON ps1.cloud = ps2.cloud 
				AND ps1.region = ps2.region 
				AND ps1.provider_alias = ps2.provider_alias
			WHERE ps1.id = $1 AND ps2.id != $1 AND ps2.is_active = TRUE
		)
	`, id)
	if err != nil {
		return err
	}
	
	// Activate the new snapshot
	_, err = t.tx.ExecContext(ctx, `
		UPDATE pricing_snapshots SET is_active = TRUE WHERE id = $1
	`, id)
	return err
}

// Commit commits the transaction
func (t *PostgresTx) Commit() error {
	return t.tx.Commit()
}

// Rollback rolls back the transaction
func (t *PostgresTx) Rollback() error {
	return t.tx.Rollback()
}

// FindSnapshotByHash finds a snapshot with matching content hash
func (s *PostgresStore) FindSnapshotByHash(ctx context.Context, cloud CloudProvider, region, alias, hash string) (*PricingSnapshot, error) {
	query := `
		SELECT id, cloud, region, provider_alias, source, fetched_at, valid_from, valid_to, hash, version, is_active, created_at
		FROM pricing_snapshots 
		WHERE cloud = $1 AND region = $2 AND provider_alias = $3 AND hash = $4
		ORDER BY created_at DESC
		LIMIT 1
	`
	snapshot := &PricingSnapshot{}
	err := s.db.QueryRowContext(ctx, query, cloud, region, alias, hash).Scan(
		&snapshot.ID, &snapshot.Cloud, &snapshot.Region, &snapshot.ProviderAlias,
		&snapshot.Source, &snapshot.FetchedAt, &snapshot.ValidFrom, &snapshot.ValidTo,
		&snapshot.Hash, &snapshot.Version, &snapshot.IsActive, &snapshot.CreatedAt,
	)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	return snapshot, err
}

// CountRates returns the count of rates in a snapshot
func (s *PostgresStore) CountRates(ctx context.Context, snapshotID uuid.UUID) (int, error) {
	var count int
	err := s.db.QueryRowContext(ctx, 
		"SELECT COUNT(*) FROM pricing_rates WHERE snapshot_id = $1", 
		snapshotID,
	).Scan(&count)
	return count, err
}

################################################################################
# FILE: :\good projects\cost estimation\db\resolver.go
# TYPE: go
# SIZE: 3935 bytes
################################################################################
// Package db - Pricing resolver that integrates with mappers
package db

import (
	"context"
	"fmt"

	"github.com/shopspring/decimal"
)

// Resolver provides pricing resolution for the estimation engine
type Resolver struct {
	store        PricingStore
	defaultAlias string
	strictMode   bool
}

// NewResolver creates a new pricing resolver
func NewResolver(store PricingStore) *Resolver {
	return &Resolver{
		store:        store,
		defaultAlias: "default",
		strictMode:   false,
	}
}

// WithStrictMode enables strict mode (fails on missing rates)
func (r *Resolver) WithStrictMode(strict bool) *Resolver {
	r.strictMode = strict
	return r
}

// WithDefaultAlias sets the default provider alias
func (r *Resolver) WithDefaultAlias(alias string) *Resolver {
	r.defaultAlias = alias
	return r
}

// ResolveRequest contains all parameters for rate resolution
type ResolveRequest struct {
	Cloud         CloudProvider
	Service       string
	ProductFamily string
	Region        string
	Attributes    map[string]string
	Unit          string
	Alias         string // Optional, uses default if empty
}

// ResolveResult contains the resolved rate or error info
type ResolveResult struct {
	Rate       *ResolvedRate
	IsSymbolic bool
	Reason     string
}

// Resolve attempts to resolve a pricing rate
func (r *Resolver) Resolve(ctx context.Context, req ResolveRequest) (*ResolveResult, error) {
	alias := req.Alias
	if alias == "" {
		alias = r.defaultAlias
	}

	// Check for active snapshot
	snapshot, err := r.store.GetActiveSnapshot(ctx, req.Cloud, req.Region, alias)
	if err != nil {
		return nil, fmt.Errorf("failed to get active snapshot: %w", err)
	}
	if snapshot == nil {
		if r.strictMode {
			return nil, fmt.Errorf("strict mode: no active snapshot for %s/%s/%s", req.Cloud, req.Region, alias)
		}
		return &ResolveResult{
			IsSymbolic: true,
			Reason:     fmt.Sprintf("no pricing snapshot for %s/%s", req.Cloud, req.Region),
		}, nil
	}

	// Resolve the rate
	rate, err := r.store.ResolveRate(ctx, req.Cloud, req.Service, req.ProductFamily, req.Region, req.Attributes, req.Unit, alias)
	if err != nil {
		return nil, fmt.Errorf("failed to resolve rate: %w", err)
	}
	if rate == nil {
		if r.strictMode {
			return nil, fmt.Errorf("strict mode: no rate found for %s/%s/%s", req.Service, req.ProductFamily, req.Unit)
		}
		return &ResolveResult{
			IsSymbolic: true,
			Reason:     fmt.Sprintf("rate not found: %s/%s/%s", req.Service, req.ProductFamily, req.Unit),
		}, nil
	}

	return &ResolveResult{
		Rate:       rate,
		IsSymbolic: false,
	}, nil
}

// ResolveTiered resolves tiered pricing (S3, data transfer, etc.)
func (r *Resolver) ResolveTiered(ctx context.Context, req ResolveRequest) ([]TieredRate, error) {
	alias := req.Alias
	if alias == "" {
		alias = r.defaultAlias
	}

	return r.store.ResolveTieredRates(ctx, req.Cloud, req.Service, req.ProductFamily, req.Region, req.Attributes, req.Unit, alias)
}

// CalculateTieredCost computes cost for tiered pricing
func CalculateTieredCost(usage decimal.Decimal, tiers []TieredRate) (decimal.Decimal, float64) {
	if len(tiers) == 0 {
		return decimal.Zero, 0
	}

	totalCost := decimal.Zero
	remaining := usage
	minConfidence := 1.0

	for _, tier := range tiers {
		if remaining.LessThanOrEqual(decimal.Zero) {
			break
		}

		var tierUsage decimal.Decimal
		if tier.Max == nil {
			// Unlimited tier
			tierUsage = remaining
		} else {
			tierSize := tier.Max.Sub(tier.Min)
			if remaining.GreaterThan(tierSize) {
				tierUsage = tierSize
			} else {
				tierUsage = remaining
			}
		}

		tierCost := tierUsage.Mul(tier.Price)
		totalCost = totalCost.Add(tierCost)
		remaining = remaining.Sub(tierUsage)

		if tier.Confidence < minConfidence {
			minConfidence = tier.Confidence
		}
	}

	return totalCost, minConfidence
}

################################################################################
# FILE: :\good projects\cost estimation\db\strict_resolver.go
# TYPE: go
# SIZE: 6703 bytes
################################################################################
// Package db - Strict resolver with coverage integration
package db

import (
	"context"
	"fmt"

	"github.com/google/uuid"
	"github.com/shopspring/decimal"
)

// StrictMode defines resolver behavior
type StrictMode int

const (
	// Permissive - missing rates become symbolic
	Permissive StrictMode = iota
	// Strict - missing rates cause errors
	Strict
)

// StrictResolver provides strict-mode pricing resolution
type StrictResolver struct {
	store        PricingStore
	defaultAlias string
	mode         StrictMode
	usedSnapshot map[string]uuid.UUID // Track snapshots used for auditability
}

// NewStrictResolver creates a new strict resolver
func NewStrictResolver(store PricingStore) *StrictResolver {
	return &StrictResolver{
		store:        store,
		defaultAlias: "default",
		mode:         Permissive,
		usedSnapshot: make(map[string]uuid.UUID),
	}
}

// WithMode sets the strict mode
func (r *StrictResolver) WithMode(mode StrictMode) *StrictResolver {
	r.mode = mode
	return r
}

// WithAlias sets the default provider alias
func (r *StrictResolver) WithAlias(alias string) *StrictResolver {
	r.defaultAlias = alias
	return r
}

// ResolutionRequest contains rate resolution parameters
type ResolutionRequest struct {
	Cloud         CloudProvider
	Service       string
	ProductFamily string
	Region        string
	Attributes    map[string]string
	Unit          string
	Alias         string
}

// ResolutionResult contains resolution outcome
type ResolutionResult struct {
	// Rate info (nil if symbolic)
	Price      *decimal.Decimal
	Currency   string
	Confidence float64
	SnapshotID uuid.UUID
	Source     string
	
	// Symbolic info
	IsSymbolic bool
	Reason     string
}

// Resolve resolves a rate with strict mode enforcement
func (r *StrictResolver) Resolve(ctx context.Context, req ResolutionRequest) (*ResolutionResult, error) {
	alias := req.Alias
	if alias == "" {
		alias = r.defaultAlias
	}
	
	// 1. Validate provider alias (MANDATORY)
	if alias == "" {
		return nil, fmt.Errorf("provider alias cannot be empty")
	}
	
	// 2. Get active snapshot (MANDATORY - fails in both modes)
	snapshot, err := r.store.GetActiveSnapshot(ctx, req.Cloud, req.Region, alias)
	if err != nil {
		return nil, fmt.Errorf("snapshot lookup failed: %w", err)
	}
	if snapshot == nil {
		// Alias mismatch or missing snapshot - always fail
		return nil, fmt.Errorf("no active pricing snapshot for %s/%s/%s", req.Cloud, req.Region, alias)
	}
	
	// Track snapshot for audit
	key := fmt.Sprintf("%s:%s:%s", req.Cloud, req.Region, alias)
	r.usedSnapshot[key] = snapshot.ID
	
	// 3. Resolve rate
	rate, err := r.store.ResolveRate(
		ctx, req.Cloud, req.Service, req.ProductFamily,
		req.Region, req.Attributes, req.Unit, alias,
	)
	if err != nil {
		return nil, fmt.Errorf("rate resolution failed: %w", err)
	}
	
	// 4. Handle missing rate
	if rate == nil {
		if r.mode == Strict {
			return nil, fmt.Errorf("strict mode: no rate for %s/%s/%s unit=%s",
				req.Service, req.ProductFamily, req.Region, req.Unit)
		}
		
		// Permissive mode - return symbolic
		return &ResolutionResult{
			IsSymbolic: true,
			Reason:     fmt.Sprintf("rate not found: %s/%s/%s", req.Service, req.ProductFamily, req.Unit),
			SnapshotID: snapshot.ID,
			Source:     snapshot.Source,
		}, nil
	}
	
	// 5. Success
	return &ResolutionResult{
		Price:      &rate.Price,
		Currency:   rate.Currency,
		Confidence: rate.Confidence,
		SnapshotID: rate.SnapshotID,
		Source:     rate.Source,
		IsSymbolic: false,
	}, nil
}

// ResolveTiered resolves tiered pricing
func (r *StrictResolver) ResolveTiered(ctx context.Context, req ResolutionRequest) (*TieredResolutionResult, error) {
	alias := req.Alias
	if alias == "" {
		alias = r.defaultAlias
	}
	
	// Validate snapshot exists
	snapshot, err := r.store.GetActiveSnapshot(ctx, req.Cloud, req.Region, alias)
	if err != nil {
		return nil, fmt.Errorf("snapshot lookup failed: %w", err)
	}
	if snapshot == nil {
		return nil, fmt.Errorf("no active pricing snapshot for %s/%s/%s", req.Cloud, req.Region, alias)
	}
	
	// Get tiers
	tiers, err := r.store.ResolveTieredRates(
		ctx, req.Cloud, req.Service, req.ProductFamily,
		req.Region, req.Attributes, req.Unit, alias,
	)
	if err != nil {
		return nil, fmt.Errorf("tiered rate resolution failed: %w", err)
	}
	
	if len(tiers) == 0 {
		if r.mode == Strict {
			return nil, fmt.Errorf("strict mode: no tiered rates for %s/%s/%s unit=%s",
				req.Service, req.ProductFamily, req.Region, req.Unit)
		}
		
		return &TieredResolutionResult{
			IsSymbolic: true,
			Reason:     fmt.Sprintf("tiered rates not found: %s/%s", req.Service, req.ProductFamily),
			SnapshotID: snapshot.ID,
		}, nil
	}
	
	return &TieredResolutionResult{
		Tiers:      tiers,
		SnapshotID: snapshot.ID,
		IsSymbolic: false,
	}, nil
}

// TieredResolutionResult contains tiered resolution outcome
type TieredResolutionResult struct {
	Tiers      []TieredRate
	SnapshotID uuid.UUID
	IsSymbolic bool
	Reason     string
}

// CalculateCost computes cost from tiered rates and usage
func (r *TieredResolutionResult) CalculateCost(usage decimal.Decimal) (decimal.Decimal, float64) {
	return CalculateTieredCost(usage, r.Tiers)
}

// GetUsedSnapshots returns all snapshots used during resolution
func (r *StrictResolver) GetUsedSnapshots() map[string]uuid.UUID {
	result := make(map[string]uuid.UUID)
	for k, v := range r.usedSnapshot {
		result[k] = v
	}
	return result
}

// ResetSnapshots resets the snapshot tracking
func (r *StrictResolver) ResetSnapshots() {
	r.usedSnapshot = make(map[string]uuid.UUID)
}

// SnapshotAudit returns audit info for reproducibility
type SnapshotAudit struct {
	Cloud      CloudProvider `json:"cloud"`
	Region     string        `json:"region"`
	Alias      string        `json:"alias"`
	SnapshotID uuid.UUID     `json:"snapshot_id"`
}

// GetAuditInfo returns audit information for all used snapshots
func (r *StrictResolver) GetAuditInfo() []SnapshotAudit {
	var audits []SnapshotAudit
	for key, id := range r.usedSnapshot {
		parts := splitKey(key)
		if len(parts) == 3 {
			audits = append(audits, SnapshotAudit{
				Cloud:      CloudProvider(parts[0]),
				Region:     parts[1],
				Alias:      parts[2],
				SnapshotID: id,
			})
		}
	}
	return audits
}

func splitKey(key string) []string {
	var parts []string
	start := 0
	for i := 0; i < len(key); i++ {
		if key[i] == ':' {
			parts = append(parts, key[start:i])
			start = i + 1
		}
	}
	parts = append(parts, key[start:])
	return parts
}

################################################################################
# FILE: :\good projects\cost estimation\db\types.go
# TYPE: go
# SIZE: 5512 bytes
################################################################################
// Package db - Pricing database types and interface
// Provides snapshot-based, immutable pricing storage.
package db

import (
	"context"
	"time"

	"github.com/google/uuid"
	"github.com/shopspring/decimal"
)

// CloudProvider represents a cloud provider
type CloudProvider string

const (
	AWS   CloudProvider = "aws"
	Azure CloudProvider = "azure"
	GCP   CloudProvider = "gcp"
)

// PricingSnapshot represents a point-in-time pricing capture
type PricingSnapshot struct {
	ID            uuid.UUID     `db:"id" json:"id"`
	Cloud         CloudProvider `db:"cloud" json:"cloud"`
	Region        string        `db:"region" json:"region"`
	ProviderAlias string        `db:"provider_alias" json:"provider_alias"`
	Source        string        `db:"source" json:"source"`
	FetchedAt     time.Time     `db:"fetched_at" json:"fetched_at"`
	ValidFrom     time.Time     `db:"valid_from" json:"valid_from"`
	ValidTo       *time.Time    `db:"valid_to" json:"valid_to,omitempty"`
	Hash          string        `db:"hash" json:"hash"`
	Version       string        `db:"version" json:"version"`
	IsActive      bool          `db:"is_active" json:"is_active"`
	CreatedAt     time.Time     `db:"created_at" json:"created_at"`
}

// RateKey represents a unique pricing lookup key
type RateKey struct {
	ID            uuid.UUID         `db:"id" json:"id"`
	Cloud         CloudProvider     `db:"cloud" json:"cloud"`
	Service       string            `db:"service" json:"service"`
	ProductFamily string            `db:"product_family" json:"product_family"`
	Region        string            `db:"region" json:"region"`
	Attributes    map[string]string `db:"attributes" json:"attributes"`
	CreatedAt     time.Time         `db:"created_at" json:"created_at"`
}

// PricingRate represents a price for a rate key within a snapshot
type PricingRate struct {
	ID            uuid.UUID       `db:"id" json:"id"`
	SnapshotID    uuid.UUID       `db:"snapshot_id" json:"snapshot_id"`
	RateKeyID     uuid.UUID       `db:"rate_key_id" json:"rate_key_id"`
	Unit          string          `db:"unit" json:"unit"`
	Price         decimal.Decimal `db:"price" json:"price"`
	Currency      string          `db:"currency" json:"currency"`
	Confidence    float64         `db:"confidence" json:"confidence"`
	TierMin       *decimal.Decimal `db:"tier_min" json:"tier_min,omitempty"`
	TierMax       *decimal.Decimal `db:"tier_max" json:"tier_max,omitempty"`
	EffectiveDate *time.Time      `db:"effective_date" json:"effective_date,omitempty"`
	CreatedAt     time.Time       `db:"created_at" json:"created_at"`
}

// ResolvedRate is the result of a pricing lookup
type ResolvedRate struct {
	Price      decimal.Decimal
	Currency   string
	Confidence float64
	TierMin    *decimal.Decimal
	TierMax    *decimal.Decimal
	SnapshotID uuid.UUID
	Source     string
}

// TieredRate represents a pricing tier
type TieredRate struct {
	Min        decimal.Decimal
	Max        *decimal.Decimal // nil = unlimited
	Price      decimal.Decimal
	Confidence float64
}

// PricingStore is the interface for pricing database operations
type PricingStore interface {
	// Snapshots
	CreateSnapshot(ctx context.Context, snapshot *PricingSnapshot) error
	GetSnapshot(ctx context.Context, id uuid.UUID) (*PricingSnapshot, error)
	GetActiveSnapshot(ctx context.Context, cloud CloudProvider, region, alias string) (*PricingSnapshot, error)
	ActivateSnapshot(ctx context.Context, id uuid.UUID) error
	ListSnapshots(ctx context.Context, cloud CloudProvider, region string) ([]*PricingSnapshot, error)

	// Rate Keys
	UpsertRateKey(ctx context.Context, key *RateKey) (*RateKey, error)
	GetRateKey(ctx context.Context, cloud CloudProvider, service, productFamily, region string, attrs map[string]string) (*RateKey, error)

	// Rates
	CreateRate(ctx context.Context, rate *PricingRate) error
	BulkCreateRates(ctx context.Context, rates []*PricingRate) error
	
	// Resolution
	ResolveRate(ctx context.Context, cloud CloudProvider, service, productFamily, region string, attrs map[string]string, unit, alias string) (*ResolvedRate, error)
	ResolveTieredRates(ctx context.Context, cloud CloudProvider, service, productFamily, region string, attrs map[string]string, unit, alias string) ([]TieredRate, error)

	// Health
	Ping(ctx context.Context) error
	Close() error
}

// SnapshotBuilder helps construct pricing snapshots
type SnapshotBuilder struct {
	snapshot *PricingSnapshot
	rates    []*RateKey
}

// NewSnapshotBuilder creates a new snapshot builder
func NewSnapshotBuilder(cloud CloudProvider, region, source string) *SnapshotBuilder {
	return &SnapshotBuilder{
		snapshot: &PricingSnapshot{
			ID:            uuid.New(),
			Cloud:         cloud,
			Region:        region,
			ProviderAlias: "default",
			Source:        source,
			FetchedAt:     time.Now(),
			ValidFrom:     time.Now(),
			Version:       "1.0",
		},
		rates: make([]*RateKey, 0),
	}
}

// WithAlias sets the provider alias
func (b *SnapshotBuilder) WithAlias(alias string) *SnapshotBuilder {
	b.snapshot.ProviderAlias = alias
	return b
}

// WithValidRange sets the validity period
func (b *SnapshotBuilder) WithValidRange(from, to time.Time) *SnapshotBuilder {
	b.snapshot.ValidFrom = from
	b.snapshot.ValidTo = &to
	return b
}

// Build finalizes the snapshot
func (b *SnapshotBuilder) Build(hash string) *PricingSnapshot {
	b.snapshot.Hash = hash
	return b.snapshot
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\aws.go
# TYPE: go
# SIZE: 36895 bytes
################################################################################
// Package ingestion - AWS pricing fetcher and normalizer
package ingestion

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"strings"

	"terraform-cost/db"

	"github.com/shopspring/decimal"
)

// AWSFetcher fetches pricing from AWS
type AWSFetcher struct {
	httpClient *http.Client
	regions    []string
}

// NewAWSFetcher creates a new AWS pricing fetcher
func NewAWSFetcher() *AWSFetcher {
	return &AWSFetcher{
		httpClient: &http.Client{},
		regions: []string{
			"us-east-1", "us-east-2", "us-west-1", "us-west-2",
			"eu-west-1", "eu-west-2", "eu-central-1",
			"ap-southeast-1", "ap-southeast-2", "ap-northeast-1",
		},
	}
}

func (f *AWSFetcher) Cloud() db.CloudProvider {
	return db.AWS
}

func (f *AWSFetcher) SupportedRegions() []string {
	return f.regions
}

// SupportedServices returns services this fetcher covers
func (f *AWSFetcher) SupportedServices() []string {
	return []string{
		"AmazonEC2",
		"AmazonRDS",
		"AmazonS3",
		"AWSLambda",
		"ElasticLoadBalancing",
		"AmazonDynamoDB",
		"AmazonECS",
		"AmazonElastiCache",
		"AWSSecretsManager",
		"AmazonCloudWatch",
		"AmazonVPC",
		"AWSDataTransfer",
		"AWSQueueService",
		"AmazonSNS",
		"awskms",
		"AWSCertificateManager",
		"AmazonRoute53",
	}
}

// FetchRegion fetches AWS pricing for a region
// Note: In production, use AWS Pricing API or bulk price list files
func (f *AWSFetcher) FetchRegion(ctx context.Context, region string) ([]RawPrice, error) {
	// AWS Pricing API endpoint (simplified)
	// In production, use: https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/AmazonEC2/current/index.json
	
	// For now, return stub data for development
	return f.getStubPrices(region), nil
}

// getStubPrices returns development stub prices for ALL supported AWS services
func (f *AWSFetcher) getStubPrices(region string) []RawPrice {
	return []RawPrice{
		// ============================================================
		// EC2 INSTANCES - aws_instance
		// ============================================================
		// T3 Series (Burstable)
		{SKU: "ec2-t3-nano", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.0052", Currency: "USD",
			Attributes: map[string]string{"instanceType": "t3.nano", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-t3-micro", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.0104", Currency: "USD",
			Attributes: map[string]string{"instanceType": "t3.micro", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-t3-small", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.0208", Currency: "USD",
			Attributes: map[string]string{"instanceType": "t3.small", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-t3-medium", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.0416", Currency: "USD",
			Attributes: map[string]string{"instanceType": "t3.medium", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-t3-large", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.0832", Currency: "USD",
			Attributes: map[string]string{"instanceType": "t3.large", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-t3-xlarge", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.1664", Currency: "USD",
			Attributes: map[string]string{"instanceType": "t3.xlarge", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-t3-2xlarge", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.3328", Currency: "USD",
			Attributes: map[string]string{"instanceType": "t3.2xlarge", "operatingSystem": "Linux", "tenancy": "Shared"}},

		// M5 Series (General Purpose)
		{SKU: "ec2-m5-large", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.096", Currency: "USD",
			Attributes: map[string]string{"instanceType": "m5.large", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-m5-xlarge", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.192", Currency: "USD",
			Attributes: map[string]string{"instanceType": "m5.xlarge", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-m5-2xlarge", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.384", Currency: "USD",
			Attributes: map[string]string{"instanceType": "m5.2xlarge", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-m5-4xlarge", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.768", Currency: "USD",
			Attributes: map[string]string{"instanceType": "m5.4xlarge", "operatingSystem": "Linux", "tenancy": "Shared"}},

		// C5 Series (Compute Optimized)
		{SKU: "ec2-c5-large", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.085", Currency: "USD",
			Attributes: map[string]string{"instanceType": "c5.large", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-c5-xlarge", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.17", Currency: "USD",
			Attributes: map[string]string{"instanceType": "c5.xlarge", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-c5-2xlarge", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.34", Currency: "USD",
			Attributes: map[string]string{"instanceType": "c5.2xlarge", "operatingSystem": "Linux", "tenancy": "Shared"}},

		// R5 Series (Memory Optimized)
		{SKU: "ec2-r5-large", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.126", Currency: "USD",
			Attributes: map[string]string{"instanceType": "r5.large", "operatingSystem": "Linux", "tenancy": "Shared"}},
		{SKU: "ec2-r5-xlarge", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.252", Currency: "USD",
			Attributes: map[string]string{"instanceType": "r5.xlarge", "operatingSystem": "Linux", "tenancy": "Shared"}},

		// Windows Instances
		{SKU: "ec2-t3-micro-win", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.0208", Currency: "USD",
			Attributes: map[string]string{"instanceType": "t3.micro", "operatingSystem": "Windows", "tenancy": "Shared"}},
		{SKU: "ec2-m5-large-win", ServiceCode: "AmazonEC2", ProductFamily: "Compute Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.188", Currency: "USD",
			Attributes: map[string]string{"instanceType": "m5.large", "operatingSystem": "Windows", "tenancy": "Shared"}},

		// ============================================================
		// EBS VOLUMES - aws_ebs_volume
		// ============================================================
		{SKU: "ebs-gp3", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.08", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "gp3", "volumeType": "General Purpose"}},
		{SKU: "ebs-gp3-iops", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "IOPS-Mo", PricePerUnit: "0.005", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "gp3", "usagetype": "IOPS"}},
		{SKU: "ebs-gp3-throughput", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "MiBps-Mo", PricePerUnit: "0.04", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "gp3", "usagetype": "Throughput"}},
		{SKU: "ebs-gp2", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.10", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "gp2", "volumeType": "General Purpose"}},
		{SKU: "ebs-io1", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.125", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "io1", "volumeType": "Provisioned IOPS"}},
		{SKU: "ebs-io1-iops", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "IOPS-Mo", PricePerUnit: "0.065", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "io1", "usagetype": "IOPS"}},
		{SKU: "ebs-io2", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.125", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "io2", "volumeType": "Provisioned IOPS"}},
		{SKU: "ebs-st1", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.045", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "st1", "volumeType": "Throughput Optimized"}},
		{SKU: "ebs-sc1", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.025", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "sc1", "volumeType": "Cold HDD"}},
		{SKU: "ebs-standard", ServiceCode: "AmazonEC2", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.05", Currency: "USD",
			Attributes: map[string]string{"volumeApiName": "standard", "volumeType": "Magnetic"}},

		// EBS Snapshots
		{SKU: "ebs-snapshot", ServiceCode: "AmazonEC2", ProductFamily: "Storage Snapshot", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.05", Currency: "USD",
			Attributes: map[string]string{"usagetype": "EBS:SnapshotUsage"}},

		// ============================================================
		// RDS - aws_db_instance
		// ============================================================
		// MySQL
		{SKU: "rds-mysql-db.t3.micro", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.017", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.t3.micro", "databaseEngine": "MySQL"}},
		{SKU: "rds-mysql-db.t3.small", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.034", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.t3.small", "databaseEngine": "MySQL"}},
		{SKU: "rds-mysql-db.t3.medium", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.068", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.t3.medium", "databaseEngine": "MySQL"}},
		{SKU: "rds-mysql-db.m5.large", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.171", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.m5.large", "databaseEngine": "MySQL"}},
		{SKU: "rds-mysql-db.r5.large", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.24", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.r5.large", "databaseEngine": "MySQL"}},

		// PostgreSQL
		{SKU: "rds-postgres-db.t3.micro", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.018", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.t3.micro", "databaseEngine": "PostgreSQL"}},
		{SKU: "rds-postgres-db.t3.small", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.036", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.t3.small", "databaseEngine": "PostgreSQL"}},
		{SKU: "rds-postgres-db.m5.large", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.178", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.m5.large", "databaseEngine": "PostgreSQL"}},

		// Aurora MySQL
		{SKU: "rds-aurora-mysql-db.t3.small", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.041", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.t3.small", "databaseEngine": "Aurora MySQL"}},
		{SKU: "rds-aurora-mysql-db.r5.large", ServiceCode: "AmazonRDS", ProductFamily: "Database Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.29", Currency: "USD",
			Attributes: map[string]string{"instanceType": "db.r5.large", "databaseEngine": "Aurora MySQL"}},

		// RDS Storage
		{SKU: "rds-storage-gp2", ServiceCode: "AmazonRDS", ProductFamily: "Database Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.115", Currency: "USD",
			Attributes: map[string]string{"volumeType": "General Purpose (SSD)"}},
		{SKU: "rds-storage-io1", ServiceCode: "AmazonRDS", ProductFamily: "Database Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.125", Currency: "USD",
			Attributes: map[string]string{"volumeType": "Provisioned IOPS (SSD)"}},
		{SKU: "rds-iops", ServiceCode: "AmazonRDS", ProductFamily: "Provisioned IOPS", Region: region,
			Unit: "IOPS-Mo", PricePerUnit: "0.10", Currency: "USD",
			Attributes: map[string]string{"usagetype": "RDS:PIOPS"}},

		// ============================================================
		// S3 - aws_s3_bucket
		// ============================================================
		// Storage Classes
		{SKU: "s3-standard", ServiceCode: "AmazonS3", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.023", Currency: "USD",
			Attributes: map[string]string{"storageClass": "General Purpose", "volumeType": "Standard"}},
		{SKU: "s3-intelligent-tiering", ServiceCode: "AmazonS3", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.023", Currency: "USD",
			Attributes: map[string]string{"storageClass": "Intelligent-Tiering"}},
		{SKU: "s3-standard-ia", ServiceCode: "AmazonS3", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.0125", Currency: "USD",
			Attributes: map[string]string{"storageClass": "Infrequent Access"}},
		{SKU: "s3-onezone-ia", ServiceCode: "AmazonS3", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.01", Currency: "USD",
			Attributes: map[string]string{"storageClass": "One Zone - Infrequent Access"}},
		{SKU: "s3-glacier-instant", ServiceCode: "AmazonS3", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.004", Currency: "USD",
			Attributes: map[string]string{"storageClass": "Glacier Instant Retrieval"}},
		{SKU: "s3-glacier-flexible", ServiceCode: "AmazonS3", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.0036", Currency: "USD",
			Attributes: map[string]string{"storageClass": "Glacier Flexible Retrieval"}},
		{SKU: "s3-glacier-deep", ServiceCode: "AmazonS3", ProductFamily: "Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.00099", Currency: "USD",
			Attributes: map[string]string{"storageClass": "Glacier Deep Archive"}},

		// S3 Requests
		{SKU: "s3-put-requests", ServiceCode: "AmazonS3", ProductFamily: "API Requests", Region: region,
			Unit: "Requests", PricePerUnit: "0.000005", Currency: "USD",
			Attributes: map[string]string{"operation": "PUT", "storageClass": "Standard"}},
		{SKU: "s3-get-requests", ServiceCode: "AmazonS3", ProductFamily: "API Requests", Region: region,
			Unit: "Requests", PricePerUnit: "0.0000004", Currency: "USD",
			Attributes: map[string]string{"operation": "GET", "storageClass": "Standard"}},
		{SKU: "s3-list-requests", ServiceCode: "AmazonS3", ProductFamily: "API Requests", Region: region,
			Unit: "Requests", PricePerUnit: "0.000005", Currency: "USD",
			Attributes: map[string]string{"operation": "LIST", "storageClass": "Standard"}},

		// S3 Data Transfer
		{SKU: "s3-data-transfer-out", ServiceCode: "AmazonS3", ProductFamily: "Data Transfer", Region: region,
			Unit: "GB", PricePerUnit: "0.09", Currency: "USD",
			Attributes: map[string]string{"transferType": "AWS Outbound", "fromLocation": region}},

		// ============================================================
		// NAT GATEWAY - aws_nat_gateway
		// ============================================================
		{SKU: "nat-gateway-hour", ServiceCode: "AmazonEC2", ProductFamily: "NAT Gateway", Region: region,
			Unit: "Hrs", PricePerUnit: "0.045", Currency: "USD",
			Attributes: map[string]string{"usagetype": "NatGateway-Hours"}},
		{SKU: "nat-gateway-data", ServiceCode: "AmazonEC2", ProductFamily: "NAT Gateway", Region: region,
			Unit: "GB", PricePerUnit: "0.045", Currency: "USD",
			Attributes: map[string]string{"usagetype": "NatGateway-Bytes"}},

		// ============================================================
		// LAMBDA - aws_lambda_function
		// ============================================================
		{SKU: "lambda-requests", ServiceCode: "AWSLambda", ProductFamily: "Serverless", Region: region,
			Unit: "Requests", PricePerUnit: "0.0000002", Currency: "USD",
			Attributes: map[string]string{"group": "AWS-Lambda-Requests"}},
		{SKU: "lambda-duration-128", ServiceCode: "AWSLambda", ProductFamily: "Serverless", Region: region,
			Unit: "GB-Second", PricePerUnit: "0.0000166667", Currency: "USD",
			Attributes: map[string]string{"group": "AWS-Lambda-Duration", "memorySize": "128"}},
		{SKU: "lambda-duration-512", ServiceCode: "AWSLambda", ProductFamily: "Serverless", Region: region,
			Unit: "GB-Second", PricePerUnit: "0.0000166667", Currency: "USD",
			Attributes: map[string]string{"group": "AWS-Lambda-Duration", "memorySize": "512"}},
		{SKU: "lambda-duration-1024", ServiceCode: "AWSLambda", ProductFamily: "Serverless", Region: region,
			Unit: "GB-Second", PricePerUnit: "0.0000166667", Currency: "USD",
			Attributes: map[string]string{"group": "AWS-Lambda-Duration", "memorySize": "1024"}},
		{SKU: "lambda-provisioned-concurrency", ServiceCode: "AWSLambda", ProductFamily: "Serverless", Region: region,
			Unit: "GB-Second", PricePerUnit: "0.000004", Currency: "USD",
			Attributes: map[string]string{"group": "AWS-Lambda-Provisioned-Concurrency"}},

		// ============================================================
		// LOAD BALANCERS - aws_lb, aws_alb, aws_nlb
		// ============================================================
		{SKU: "alb-hour", ServiceCode: "ElasticLoadBalancing", ProductFamily: "Load Balancer", Region: region,
			Unit: "Hrs", PricePerUnit: "0.0225", Currency: "USD",
			Attributes: map[string]string{"productFamily": "Load Balancer-Application", "usagetype": "LoadBalancerUsage"}},
		{SKU: "alb-lcu", ServiceCode: "ElasticLoadBalancing", ProductFamily: "Load Balancer", Region: region,
			Unit: "LCU-Hrs", PricePerUnit: "0.008", Currency: "USD",
			Attributes: map[string]string{"productFamily": "Load Balancer-Application", "usagetype": "LCUUsage"}},
		{SKU: "nlb-hour", ServiceCode: "ElasticLoadBalancing", ProductFamily: "Load Balancer", Region: region,
			Unit: "Hrs", PricePerUnit: "0.0225", Currency: "USD",
			Attributes: map[string]string{"productFamily": "Load Balancer-Network"}},
		{SKU: "nlb-lcu", ServiceCode: "ElasticLoadBalancing", ProductFamily: "Load Balancer", Region: region,
			Unit: "NLCU-Hrs", PricePerUnit: "0.006", Currency: "USD",
			Attributes: map[string]string{"productFamily": "Load Balancer-Network", "usagetype": "NLCUUsage"}},
		{SKU: "clb-hour", ServiceCode: "ElasticLoadBalancing", ProductFamily: "Load Balancer", Region: region,
			Unit: "Hrs", PricePerUnit: "0.025", Currency: "USD",
			Attributes: map[string]string{"productFamily": "Load Balancer-Classic"}},
		{SKU: "clb-data", ServiceCode: "ElasticLoadBalancing", ProductFamily: "Load Balancer", Region: region,
			Unit: "GB", PricePerUnit: "0.008", Currency: "USD",
			Attributes: map[string]string{"productFamily": "Load Balancer-Classic", "usagetype": "DataProcessing"}},

		// ============================================================
		// ECS / FARGATE - aws_ecs_service, aws_ecs_task_definition
		// ============================================================
		{SKU: "fargate-vcpu", ServiceCode: "AmazonECS", ProductFamily: "Compute", Region: region,
			Unit: "vCPU-Hours", PricePerUnit: "0.04048", Currency: "USD",
			Attributes: map[string]string{"cputype": "ARM", "usagetype": "Fargate-vCPU-Hours"}},
		{SKU: "fargate-vcpu-x86", ServiceCode: "AmazonECS", ProductFamily: "Compute", Region: region,
			Unit: "vCPU-Hours", PricePerUnit: "0.04048", Currency: "USD",
			Attributes: map[string]string{"cputype": "x86", "usagetype": "Fargate-vCPU-Hours"}},
		{SKU: "fargate-memory", ServiceCode: "AmazonECS", ProductFamily: "Compute", Region: region,
			Unit: "GB-Hours", PricePerUnit: "0.004445", Currency: "USD",
			Attributes: map[string]string{"usagetype": "Fargate-GB-Hours"}},
		{SKU: "fargate-spot-vcpu", ServiceCode: "AmazonECS", ProductFamily: "Compute", Region: region,
			Unit: "vCPU-Hours", PricePerUnit: "0.01334384", Currency: "USD",
			Attributes: map[string]string{"usagetype": "Fargate-SpotUsage-vCPU-Hours"}},
		{SKU: "fargate-spot-memory", ServiceCode: "AmazonECS", ProductFamily: "Compute", Region: region,
			Unit: "GB-Hours", PricePerUnit: "0.00146489", Currency: "USD",
			Attributes: map[string]string{"usagetype": "Fargate-SpotUsage-GB-Hours"}},

		// ============================================================
		// DYNAMODB - aws_dynamodb_table
		// ============================================================
		{SKU: "dynamodb-wcu", ServiceCode: "AmazonDynamoDB", ProductFamily: "Provisioned Throughput", Region: region,
			Unit: "WriteCapacityUnit-Hrs", PricePerUnit: "0.00065", Currency: "USD",
			Attributes: map[string]string{"group": "DDB-WriteUnits"}},
		{SKU: "dynamodb-rcu", ServiceCode: "AmazonDynamoDB", ProductFamily: "Provisioned Throughput", Region: region,
			Unit: "ReadCapacityUnit-Hrs", PricePerUnit: "0.00013", Currency: "USD",
			Attributes: map[string]string{"group": "DDB-ReadUnits"}},
		{SKU: "dynamodb-ondemand-write", ServiceCode: "AmazonDynamoDB", ProductFamily: "Amazon DynamoDB PayPerRequest Throughput", Region: region,
			Unit: "WriteRequestUnits", PricePerUnit: "0.00000125", Currency: "USD",
			Attributes: map[string]string{"group": "DDB-WriteUnits", "usagetype": "PayPerRequest"}},
		{SKU: "dynamodb-ondemand-read", ServiceCode: "AmazonDynamoDB", ProductFamily: "Amazon DynamoDB PayPerRequest Throughput", Region: region,
			Unit: "ReadRequestUnits", PricePerUnit: "0.00000025", Currency: "USD",
			Attributes: map[string]string{"group": "DDB-ReadUnits", "usagetype": "PayPerRequest"}},
		{SKU: "dynamodb-storage", ServiceCode: "AmazonDynamoDB", ProductFamily: "Database Storage", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.25", Currency: "USD",
			Attributes: map[string]string{"usagetype": "TimedStorage-ByteHrs"}},
		{SKU: "dynamodb-gsi-wcu", ServiceCode: "AmazonDynamoDB", ProductFamily: "Provisioned Throughput", Region: region,
			Unit: "WriteCapacityUnit-Hrs", PricePerUnit: "0.00065", Currency: "USD",
			Attributes: map[string]string{"group": "DDB-WriteUnits", "indexType": "GSI"}},
		{SKU: "dynamodb-gsi-rcu", ServiceCode: "AmazonDynamoDB", ProductFamily: "Provisioned Throughput", Region: region,
			Unit: "ReadCapacityUnit-Hrs", PricePerUnit: "0.00013", Currency: "USD",
			Attributes: map[string]string{"group": "DDB-ReadUnits", "indexType": "GSI"}},

		// ============================================================
		// ELASTICACHE - aws_elasticache_cluster
		// ============================================================
		{SKU: "elasticache-redis-t3.micro", ServiceCode: "AmazonElastiCache", ProductFamily: "Cache Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.017", Currency: "USD",
			Attributes: map[string]string{"instanceType": "cache.t3.micro", "cacheEngine": "Redis"}},
		{SKU: "elasticache-redis-t3.small", ServiceCode: "AmazonElastiCache", ProductFamily: "Cache Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.034", Currency: "USD",
			Attributes: map[string]string{"instanceType": "cache.t3.small", "cacheEngine": "Redis"}},
		{SKU: "elasticache-redis-m5.large", ServiceCode: "AmazonElastiCache", ProductFamily: "Cache Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.156", Currency: "USD",
			Attributes: map[string]string{"instanceType": "cache.m5.large", "cacheEngine": "Redis"}},
		{SKU: "elasticache-redis-r5.large", ServiceCode: "AmazonElastiCache", ProductFamily: "Cache Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.224", Currency: "USD",
			Attributes: map[string]string{"instanceType": "cache.r5.large", "cacheEngine": "Redis"}},
		{SKU: "elasticache-memcached-t3.micro", ServiceCode: "AmazonElastiCache", ProductFamily: "Cache Instance", Region: region,
			Unit: "Hrs", PricePerUnit: "0.017", Currency: "USD",
			Attributes: map[string]string{"instanceType": "cache.t3.micro", "cacheEngine": "Memcached"}},

		// ============================================================
		// SECRETS MANAGER - aws_secretsmanager_secret
		// ============================================================
		{SKU: "secrets-manager-secret", ServiceCode: "AWSSecretsManager", ProductFamily: "Secret", Region: region,
			Unit: "Secrets", PricePerUnit: "0.40", Currency: "USD",
			Attributes: map[string]string{"usagetype": "SecretMonth"}},
		{SKU: "secrets-manager-api", ServiceCode: "AWSSecretsManager", ProductFamily: "API Request", Region: region,
			Unit: "Requests", PricePerUnit: "0.05", Currency: "USD",
			Attributes: map[string]string{"usagetype": "API-Requests-Per10K"}},

		// ============================================================
		// CLOUDWATCH - aws_cloudwatch_metric_alarm, aws_cloudwatch_log_group
		// ============================================================
		{SKU: "cloudwatch-metric", ServiceCode: "AmazonCloudWatch", ProductFamily: "Metric", Region: region,
			Unit: "Metrics", PricePerUnit: "0.30", Currency: "USD",
			Attributes: map[string]string{"usagetype": "CW:MetricMonitorUsage"}},
		{SKU: "cloudwatch-alarm", ServiceCode: "AmazonCloudWatch", ProductFamily: "Alarm", Region: region,
			Unit: "Alarms", PricePerUnit: "0.10", Currency: "USD",
			Attributes: map[string]string{"usagetype": "CW:AlarmMonitorUsage", "alarmType": "Standard"}},
		{SKU: "cloudwatch-alarm-highres", ServiceCode: "AmazonCloudWatch", ProductFamily: "Alarm", Region: region,
			Unit: "Alarms", PricePerUnit: "0.30", Currency: "USD",
			Attributes: map[string]string{"usagetype": "CW:AlarmMonitorUsage", "alarmType": "High Resolution"}},
		{SKU: "cloudwatch-logs-ingest", ServiceCode: "AmazonCloudWatch", ProductFamily: "Logs", Region: region,
			Unit: "GB", PricePerUnit: "0.50", Currency: "USD",
			Attributes: map[string]string{"usagetype": "DataProcessing-Bytes"}},
		{SKU: "cloudwatch-logs-storage", ServiceCode: "AmazonCloudWatch", ProductFamily: "Logs", Region: region,
			Unit: "GB-Mo", PricePerUnit: "0.03", Currency: "USD",
			Attributes: map[string]string{"usagetype": "TimedStorage-ByteHrs"}},

		// ============================================================
		// VPC - aws_vpc, aws_subnet, aws_internet_gateway
		// ============================================================
		{SKU: "vpc-endpoint-hour", ServiceCode: "AmazonVPC", ProductFamily: "VpcEndpoint", Region: region,
			Unit: "Hrs", PricePerUnit: "0.01", Currency: "USD",
			Attributes: map[string]string{"usagetype": "VpcEndpoint-Hours"}},
		{SKU: "vpc-endpoint-data", ServiceCode: "AmazonVPC", ProductFamily: "VpcEndpoint", Region: region,
			Unit: "GB", PricePerUnit: "0.01", Currency: "USD",
			Attributes: map[string]string{"usagetype": "VpcEndpoint-Bytes"}},
		{SKU: "vpn-connection-hour", ServiceCode: "AmazonVPC", ProductFamily: "VPN Connection", Region: region,
			Unit: "Hrs", PricePerUnit: "0.05", Currency: "USD",
			Attributes: map[string]string{"usagetype": "VPN-Hours"}},

		// ============================================================
		// DATA TRANSFER (Cross-region, Internet)
		// ============================================================
		{SKU: "data-transfer-out-internet", ServiceCode: "AWSDataTransfer", ProductFamily: "Data Transfer", Region: region,
			Unit: "GB", PricePerUnit: "0.09", Currency: "USD",
			Attributes: map[string]string{"transferType": "AWS Outbound", "toLocation": "External"}},
		{SKU: "data-transfer-in-internet", ServiceCode: "AWSDataTransfer", ProductFamily: "Data Transfer", Region: region,
			Unit: "GB", PricePerUnit: "0.00", Currency: "USD",
			Attributes: map[string]string{"transferType": "AWS Inbound", "fromLocation": "External"}},
		{SKU: "data-transfer-inter-region", ServiceCode: "AWSDataTransfer", ProductFamily: "Data Transfer", Region: region,
			Unit: "GB", PricePerUnit: "0.02", Currency: "USD",
			Attributes: map[string]string{"transferType": "InterRegion Outbound"}},
		{SKU: "data-transfer-inter-az", ServiceCode: "AWSDataTransfer", ProductFamily: "Data Transfer", Region: region,
			Unit: "GB", PricePerUnit: "0.01", Currency: "USD",
			Attributes: map[string]string{"transferType": "IntraRegion"}},

		// ============================================================
		// SQS - aws_sqs_queue
		// ============================================================
		{SKU: "sqs-standard", ServiceCode: "AWSQueueService", ProductFamily: "Queue", Region: region,
			Unit: "Requests", PricePerUnit: "0.0000004", Currency: "USD",
			Attributes: map[string]string{"queueType": "Standard", "usagetype": "Requests"}},
		{SKU: "sqs-fifo", ServiceCode: "AWSQueueService", ProductFamily: "Queue", Region: region,
			Unit: "Requests", PricePerUnit: "0.00000050", Currency: "USD",
			Attributes: map[string]string{"queueType": "FIFO", "usagetype": "Requests"}},

		// ============================================================
		// SNS - aws_sns_topic
		// ============================================================
		{SKU: "sns-publish", ServiceCode: "AmazonSNS", ProductFamily: "Notification", Region: region,
			Unit: "Requests", PricePerUnit: "0.50", Currency: "USD",
			Attributes: map[string]string{"usagetype": "PublishAPI-Requests-Per1M"}},
		{SKU: "sns-delivery-http", ServiceCode: "AmazonSNS", ProductFamily: "Notification", Region: region,
			Unit: "Notifications", PricePerUnit: "0.06", Currency: "USD",
			Attributes: map[string]string{"usagetype": "DeliveryAttempts-HTTP-Per100K"}},

		// ============================================================
		// KMS - aws_kms_key
		// ============================================================
		{SKU: "kms-key", ServiceCode: "awskms", ProductFamily: "Key Management", Region: region,
			Unit: "Keys", PricePerUnit: "1.00", Currency: "USD",
			Attributes: map[string]string{"usagetype": "KMS-Keys"}},
		{SKU: "kms-requests", ServiceCode: "awskms", ProductFamily: "Key Management", Region: region,
			Unit: "Requests", PricePerUnit: "0.03", Currency: "USD",
			Attributes: map[string]string{"usagetype": "KMS-Requests-Per10K"}},

		// ============================================================
		// ACM - aws_acm_certificate (Free for public certs)
		// ============================================================
		{SKU: "acm-private-ca", ServiceCode: "AWSCertificateManager", ProductFamily: "Certificate Authority", Region: region,
			Unit: "CA", PricePerUnit: "400.00", Currency: "USD",
			Attributes: map[string]string{"usagetype": "PrivateCA"}},
		{SKU: "acm-private-cert", ServiceCode: "AWSCertificateManager", ProductFamily: "Certificate", Region: region,
			Unit: "Certificates", PricePerUnit: "0.75", Currency: "USD",
			Attributes: map[string]string{"usagetype": "PrivateCertificate"}},

		// ============================================================
		// ROUTE53 - aws_route53_zone, aws_route53_record
		// ============================================================
		{SKU: "route53-hosted-zone", ServiceCode: "AmazonRoute53", ProductFamily: "Hosted Zone", Region: region,
			Unit: "HostedZone", PricePerUnit: "0.50", Currency: "USD",
			Attributes: map[string]string{"usagetype": "HostedZone"}},
		{SKU: "route53-queries", ServiceCode: "AmazonRoute53", ProductFamily: "DNS Query", Region: region,
			Unit: "Queries", PricePerUnit: "0.40", Currency: "USD",
			Attributes: map[string]string{"usagetype": "DNS-Queries-Per1M"}},
		{SKU: "route53-health-check", ServiceCode: "AmazonRoute53", ProductFamily: "Health Check", Region: region,
			Unit: "HealthCheck", PricePerUnit: "0.50", Currency: "USD",
			Attributes: map[string]string{"usagetype": "HealthCheck-Basic"}},
	}
}

// AWSNormalizer normalizes AWS pricing data
type AWSNormalizer struct{}

func NewAWSNormalizer() *AWSNormalizer {
	return &AWSNormalizer{}
}

func (n *AWSNormalizer) Cloud() db.CloudProvider {
	return db.AWS
}

// Normalize converts raw AWS prices to normalized rates
func (n *AWSNormalizer) Normalize(raw []RawPrice) ([]NormalizedRate, error) {
	var rates []NormalizedRate
	
	for _, r := range raw {
		price, err := ParsePrice(r.PricePerUnit)
		if err != nil {
			continue // Skip unparseable prices
		}
		
		// Normalize attributes
		attrs := n.normalizeAttributes(r.Attributes)
		
		// Create rate key
		rateKey := db.RateKey{
			Cloud:         db.AWS,
			Service:       r.ServiceCode,
			ProductFamily: r.ProductFamily,
			Region:        r.Region,
			Attributes:    attrs,
		}
		
		// Create normalized rate
		nr := NormalizedRate{
			RateKey:    rateKey,
			Unit:       n.normalizeUnit(r.Unit),
			Price:      price,
			Currency:   r.Currency,
			Confidence: 1.0, // Direct from AWS API
		}
		
		// Handle tiers
		if r.TierStart != nil {
			d := decimal.NewFromFloat(*r.TierStart)
			nr.TierMin = &d
		}
		if r.TierEnd != nil {
			d := decimal.NewFromFloat(*r.TierEnd)
			nr.TierMax = &d
		}
		
		rates = append(rates, nr)
	}
	
	return rates, nil
}

func (n *AWSNormalizer) normalizeAttributes(raw map[string]string) map[string]string {
	result := make(map[string]string)
	
	for k, v := range raw {
		// Normalize key names
		key := n.normalizeKey(k)
		// Normalize values
		val := strings.ToLower(strings.TrimSpace(v))
		result[key] = val
	}
	
	return result
}

func (n *AWSNormalizer) normalizeKey(k string) string {
	// Map AWS attribute names to canonical names
	mapping := map[string]string{
		"instanceType":     "instance_type",
		"operatingSystem":  "os",
		"tenancy":          "tenancy",
		"volumeApiName":    "volume_type",
		"databaseEngine":   "engine",
		"usagetype":        "usage_type",
		"productFamily":    "product_family",
		"group":            "group",
	}
	
	if canonical, ok := mapping[k]; ok {
		return canonical
	}
	return strings.ToLower(strings.ReplaceAll(k, " ", "_"))
}

func (n *AWSNormalizer) normalizeUnit(unit string) string {
	// Normalize unit names
	mapping := map[string]string{
		"Hrs":        "hours",
		"GB-Mo":      "GB-month",
		"GB":         "GB",
		"Requests":   "requests",
		"GB-Second":  "GB-seconds",
	}
	
	if normalized, ok := mapping[unit]; ok {
		return normalized
	}
	return strings.ToLower(unit)
}

// fetchFromAWSAPI is the production implementation (placeholder)
func fetchFromAWSAPI(ctx context.Context, region, service string) ([]byte, error) {
	// In production:
	// 1. Use AWS Pricing API: pricing.GetProducts()
	// 2. Or download bulk price list: https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/{service}/current/index.json
	return nil, fmt.Errorf("not implemented: use AWS SDK in production")
}

// parseAWSPriceList parses AWS bulk price list JSON
func parseAWSPriceList(data []byte) ([]RawPrice, error) {
	var result struct {
		Products map[string]struct {
			SKU           string            `json:"sku"`
			ProductFamily string            `json:"productFamily"`
			Attributes    map[string]string `json:"attributes"`
		} `json:"products"`
		Terms struct {
			OnDemand map[string]map[string]struct {
				PriceDimensions map[string]struct {
					Unit         string `json:"unit"`
					PricePerUnit struct {
						USD string `json:"USD"`
					} `json:"pricePerUnit"`
				} `json:"priceDimensions"`
			} `json:"OnDemand"`
		} `json:"terms"`
	}
	
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, err
	}
	
	// Parse would continue here...
	return nil, nil
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\aws_api.go
# TYPE: go
# SIZE: 14373 bytes
################################################################################
// Package ingestion - Real AWS Pricing API integration
package ingestion

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strings"
	"time"

	"terraform-cost/db"

	"github.com/shopspring/decimal"
)

// AWSPricingAPIFetcher fetches real pricing data from AWS Pricing API
type AWSPricingAPIFetcher struct {
	httpClient *http.Client
	regions    []string
	baseURL    string
}

// NewAWSPricingAPIFetcher creates a new AWS Pricing API fetcher
func NewAWSPricingAPIFetcher() *AWSPricingAPIFetcher {
	return &AWSPricingAPIFetcher{
		httpClient: &http.Client{Timeout: 60 * time.Second},
		baseURL:    "https://pricing.us-east-1.amazonaws.com",
		regions: []string{
			"us-east-1", "us-east-2", "us-west-1", "us-west-2",
			"eu-west-1", "eu-west-2", "eu-west-3", "eu-central-1", "eu-north-1",
			"ap-southeast-1", "ap-southeast-2", "ap-northeast-1", "ap-northeast-2", "ap-south-1",
			"sa-east-1", "ca-central-1",
		},
	}
}

func (f *AWSPricingAPIFetcher) Cloud() db.CloudProvider {
	return db.AWS
}

func (f *AWSPricingAPIFetcher) SupportedRegions() []string {
	return f.regions
}

// AWSPriceListIndex represents the top-level price list index
type AWSPriceListIndex struct {
	FormatVersion string `json:"formatVersion"`
	Disclaimer    string `json:"disclaimer"`
	Offers        map[string]struct {
		OfferCode     string `json:"offerCode"`
		CurrentVersion string `json:"currentVersionUrl"`
		RegionIndex   string `json:"currentRegionIndexUrl"`
	} `json:"offers"`
}

// AWSRegionIndex represents regional price index
type AWSRegionIndex struct {
	Regions map[string]struct {
		CurrentVersionURL string `json:"currentVersionUrl"`
	} `json:"regions"`
}

// AWSPriceList represents the full price list for a service
type AWSPriceList struct {
	FormatVersion string `json:"formatVersion"`
	Disclaimer    string `json:"disclaimer"`
	PublicationDate string `json:"publicationDate"`
	Products      map[string]AWSProduct `json:"products"`
	Terms         struct {
		OnDemand map[string]map[string]AWSTerm `json:"OnDemand"`
		Reserved map[string]map[string]AWSTerm `json:"Reserved,omitempty"`
	} `json:"terms"`
}

// AWSProduct represents a product in the price list
type AWSProduct struct {
	SKU           string            `json:"sku"`
	ProductFamily string            `json:"productFamily"`
	Attributes    map[string]string `json:"attributes"`
}

// AWSTerm represents a pricing term
type AWSTerm struct {
	OfferTermCode   string `json:"offerTermCode"`
	SKU             string `json:"sku"`
	EffectiveDate   string `json:"effectiveDate"`
	PriceDimensions map[string]AWSPriceDimension `json:"priceDimensions"`
	TermAttributes  map[string]string `json:"termAttributes,omitempty"`
}

// AWSPriceDimension represents a price dimension
type AWSPriceDimension struct {
	RateCode     string `json:"rateCode"`
	Description  string `json:"description"`
	BeginRange   string `json:"beginRange"`
	EndRange     string `json:"endRange"`
	Unit         string `json:"unit"`
	PricePerUnit struct {
		USD string `json:"USD"`
	} `json:"pricePerUnit"`
	AppliesTo []string `json:"appliesTo"`
}

// FetchRegion fetches all prices for a region from AWS Pricing API
func (f *AWSPricingAPIFetcher) FetchRegion(ctx context.Context, region string) ([]RawPrice, error) {
	var allPrices []RawPrice

	// Fetch EC2 pricing
	ec2Prices, err := f.fetchServicePricing(ctx, "AmazonEC2", region)
	if err != nil {
		return nil, fmt.Errorf("failed to fetch EC2 pricing: %w", err)
	}
	allPrices = append(allPrices, ec2Prices...)

	// Fetch RDS pricing
	rdsPrices, err := f.fetchServicePricing(ctx, "AmazonRDS", region)
	if err != nil {
		return nil, fmt.Errorf("failed to fetch RDS pricing: %w", err)
	}
	allPrices = append(allPrices, rdsPrices...)

	// Fetch Lambda pricing
	lambdaPrices, err := f.fetchServicePricing(ctx, "AWSLambda", region)
	if err != nil {
		return nil, fmt.Errorf("failed to fetch Lambda pricing: %w", err)
	}
	allPrices = append(allPrices, lambdaPrices...)

	// Fetch S3 pricing
	s3Prices, err := f.fetchServicePricing(ctx, "AmazonS3", region)
	if err != nil {
		return nil, fmt.Errorf("failed to fetch S3 pricing: %w", err)
	}
	allPrices = append(allPrices, s3Prices...)

	// Fetch ELB pricing
	elbPrices, err := f.fetchServicePricing(ctx, "ElasticLoadBalancing", region)
	if err != nil {
		return nil, fmt.Errorf("failed to fetch ELB pricing: %w", err)
	}
	allPrices = append(allPrices, elbPrices...)

	return allPrices, nil
}

// fetchServicePricing fetches pricing for a specific service
func (f *AWSPricingAPIFetcher) fetchServicePricing(ctx context.Context, service, region string) ([]RawPrice, error) {
	// Construct URL for regional pricing
	// AWS provides regional price list files
	priceListURL := fmt.Sprintf("%s/offers/v1.0/aws/%s/current/%s/index.json",
		f.baseURL, service, mapRegionToAWSName(region))

	req, err := http.NewRequestWithContext(ctx, "GET", priceListURL, nil)
	if err != nil {
		return nil, err
	}

	resp, err := f.httpClient.Do(req)
	if err != nil {
		return nil, fmt.Errorf("HTTP request failed: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		// Try bulk file format
		return f.fetchBulkPricing(ctx, service, region)
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to read response: %w", err)
	}

	return f.parsePriceList(body, service, region)
}

// fetchBulkPricing fetches from bulk price list files
func (f *AWSPricingAPIFetcher) fetchBulkPricing(ctx context.Context, service, region string) ([]RawPrice, error) {
	// Get the index first
	indexURL := fmt.Sprintf("%s/offers/v1.0/aws/%s/current/region_index.json", f.baseURL, service)
	
	req, err := http.NewRequestWithContext(ctx, "GET", indexURL, nil)
	if err != nil {
		return nil, err
	}

	resp, err := f.httpClient.Do(req)
	if err != nil {
		return nil, fmt.Errorf("index request failed: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("index not found: %d", resp.StatusCode)
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}

	var regionIndex AWSRegionIndex
	if err := json.Unmarshal(body, &regionIndex); err != nil {
		return nil, fmt.Errorf("failed to parse region index: %w", err)
	}

	// Find the region-specific URL
	regionData, ok := regionIndex.Regions[region]
	if !ok {
		return nil, fmt.Errorf("region %s not found in index", region)
	}

	// Fetch region-specific pricing
	regionURL := f.baseURL + regionData.CurrentVersionURL
	req, err = http.NewRequestWithContext(ctx, "GET", regionURL, nil)
	if err != nil {
		return nil, err
	}

	resp, err = f.httpClient.Do(req)
	if err != nil {
		return nil, fmt.Errorf("region pricing request failed: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("region pricing not found: %d", resp.StatusCode)
	}

	body, err = io.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}

	return f.parsePriceList(body, service, region)
}

// parsePriceList parses AWS price list JSON
func (f *AWSPricingAPIFetcher) parsePriceList(data []byte, service, region string) ([]RawPrice, error) {
	var priceList AWSPriceList
	if err := json.Unmarshal(data, &priceList); err != nil {
		return nil, fmt.Errorf("failed to parse price list: %w", err)
	}

	var prices []RawPrice

	// Process on-demand terms
	for sku, productTerms := range priceList.Terms.OnDemand {
		product, ok := priceList.Products[sku]
		if !ok {
			continue
		}

		// Filter by region
		if prodRegion := product.Attributes["regionCode"]; prodRegion != "" && prodRegion != region {
			continue
		}
		if prodLocation := product.Attributes["location"]; prodLocation != "" && !matchesRegion(prodLocation, region) {
			continue
		}

		for _, term := range productTerms {
			for _, dim := range term.PriceDimensions {
				price := RawPrice{
					SKU:           sku,
					ServiceCode:   service,
					ProductFamily: product.ProductFamily,
					Region:        region,
					Unit:          dim.Unit,
					PricePerUnit:  dim.PricePerUnit.USD,
					Currency:      "USD",
					Attributes:    product.Attributes,
				}

				// Parse tiers
				if dim.BeginRange != "0" && dim.BeginRange != "" {
					if val, err := parseFloat(dim.BeginRange); err == nil {
						price.TierStart = &val
					}
				}
				if dim.EndRange != "Inf" && dim.EndRange != "" {
					if val, err := parseFloat(dim.EndRange); err == nil {
						price.TierEnd = &val
					}
				}

				// Parse effective date
				if term.EffectiveDate != "" {
					if t, err := time.Parse("2006-01-02T15:04:05Z", term.EffectiveDate); err == nil {
						price.EffectiveDate = &t
					}
				}

				prices = append(prices, price)
			}
		}
	}

	return prices, nil
}

// mapRegionToAWSName maps region codes to AWS naming convention
func mapRegionToAWSName(region string) string {
	// AWS uses different naming in some cases
	mapping := map[string]string{
		"us-east-1": "US East (N. Virginia)",
		"us-east-2": "US East (Ohio)",
		"us-west-1": "US West (N. California)",
		"us-west-2": "US West (Oregon)",
		"eu-west-1": "EU (Ireland)",
		"eu-west-2": "EU (London)",
		"eu-central-1": "EU (Frankfurt)",
		"ap-southeast-1": "Asia Pacific (Singapore)",
		"ap-southeast-2": "Asia Pacific (Sydney)",
		"ap-northeast-1": "Asia Pacific (Tokyo)",
	}
	if name, ok := mapping[region]; ok {
		return url.PathEscape(name)
	}
	return region
}

// matchesRegion checks if a location string matches a region
func matchesRegion(location, region string) bool {
	mapping := map[string][]string{
		"us-east-1": {"US East (N. Virginia)", "US-East"},
		"us-east-2": {"US East (Ohio)"},
		"us-west-1": {"US West (N. California)"},
		"us-west-2": {"US West (Oregon)"},
		"eu-west-1": {"EU (Ireland)", "EU-West"},
		"eu-west-2": {"EU (London)"},
		"eu-central-1": {"EU (Frankfurt)"},
		"ap-southeast-1": {"Asia Pacific (Singapore)"},
		"ap-southeast-2": {"Asia Pacific (Sydney)"},
		"ap-northeast-1": {"Asia Pacific (Tokyo)"},
	}
	
	candidates, ok := mapping[region]
	if !ok {
		return false
	}
	
	for _, c := range candidates {
		if strings.Contains(location, c) || c == location {
			return true
		}
	}
	return false
}

func parseFloat(s string) (float64, error) {
	var f float64
	_, err := fmt.Sscanf(s, "%f", &f)
	return f, err
}

// AWSPricingAPINormalizer normalizes real AWS pricing data
type AWSPricingAPINormalizer struct {
	dimensionMapping map[string]string
}

// NewAWSPricingAPINormalizer creates a new normalizer for AWS Pricing API data
func NewAWSPricingAPINormalizer() *AWSPricingAPINormalizer {
	return &AWSPricingAPINormalizer{
		dimensionMapping: map[string]string{
			"instanceType":        "instance_type",
			"instanceFamily":      "instance_family",
			"operatingSystem":     "os",
			"tenancy":             "tenancy",
			"preInstalledSw":      "software",
			"licenseModel":        "license",
			"capacitystatus":      "capacity_status",
			"volumeApiName":       "volume_type",
			"volumeType":          "volume_class",
			"storageClass":        "storage_class",
			"databaseEngine":      "engine",
			"databaseEdition":     "edition",
			"deploymentOption":    "deployment",
			"productFamily":       "product_family",
			"usagetype":           "usage_type",
			"memory":              "memory",
			"vcpu":                "vcpu",
			"physicalProcessor":   "processor",
			"clockSpeed":          "clock_speed",
			"networkPerformance":  "network",
		},
	}
}

func (n *AWSPricingAPINormalizer) Cloud() db.CloudProvider {
	return db.AWS
}

// Normalize converts raw AWS Pricing API data to normalized rates
func (n *AWSPricingAPINormalizer) Normalize(raw []RawPrice) ([]NormalizedRate, error) {
	var rates []NormalizedRate

	for _, r := range raw {
		// Skip zero/empty prices
		if r.PricePerUnit == "" || r.PricePerUnit == "0" || r.PricePerUnit == "0.0000000000" {
			continue
		}

		price, err := decimal.NewFromString(r.PricePerUnit)
		if err != nil {
			continue
		}

		// Skip zero prices
		if price.IsZero() {
			continue
		}

		// Normalize attributes
		attrs := n.normalizeAttributes(r.Attributes)

		// Create rate key
		rateKey := db.RateKey{
			Cloud:         db.AWS,
			Service:       r.ServiceCode,
			ProductFamily: r.ProductFamily,
			Region:        r.Region,
			Attributes:    attrs,
		}

		// Create normalized rate
		nr := NormalizedRate{
			RateKey:    rateKey,
			Unit:       n.normalizeUnit(r.Unit),
			Price:      price,
			Currency:   r.Currency,
			Confidence: 1.0, // Direct from AWS API = full confidence
		}

		// Handle tiers
		if r.TierStart != nil {
			d := decimal.NewFromFloat(*r.TierStart)
			nr.TierMin = &d
		}
		if r.TierEnd != nil {
			d := decimal.NewFromFloat(*r.TierEnd)
			nr.TierMax = &d
		}

		rates = append(rates, nr)
	}

	return rates, nil
}

func (n *AWSPricingAPINormalizer) normalizeAttributes(raw map[string]string) map[string]string {
	result := make(map[string]string)

	for k, v := range raw {
		// Map to canonical key name
		key := k
		if canonical, ok := n.dimensionMapping[k]; ok {
			key = canonical
		} else {
			key = strings.ToLower(strings.ReplaceAll(k, " ", "_"))
		}

		// Normalize value
		val := strings.ToLower(strings.TrimSpace(v))
		
		// Skip empty or NA values
		if val == "" || val == "na" || val == "n/a" {
			continue
		}

		result[key] = val
	}

	return result
}

func (n *AWSPricingAPINormalizer) normalizeUnit(unit string) string {
	mapping := map[string]string{
		"Hrs":           "hours",
		"hrs":           "hours",
		"GB-Mo":         "GB-month",
		"GB-month":      "GB-month",
		"GB":            "GB",
		"Requests":      "requests",
		"requests":      "requests",
		"GB-Second":     "GB-seconds",
		"GB-Seconds":    "GB-seconds",
		"Lambda-GB-Second": "GB-seconds",
		"Quantity":      "units",
		"LCU-Hrs":       "LCU-hours",
		"NLCU-Hrs":      "NLCU-hours",
	}

	if normalized, ok := mapping[unit]; ok {
		return normalized
	}
	return strings.ToLower(unit)
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\azure.go
# TYPE: go
# SIZE: 1921 bytes
################################################################################
// Package ingestion - Azure pricing fetcher and normalizer (placeholder)
package ingestion

import (
	"context"
	"fmt"

	"terraform-cost/db"
)

// AzurePriceFetcher fetches pricing from Azure Retail Prices API
type AzurePriceFetcher struct{}

// NewAzurePriceFetcher creates an Azure price fetcher
func NewAzurePriceFetcher() *AzurePriceFetcher {
	return &AzurePriceFetcher{}
}

// Cloud returns the cloud provider
func (f *AzurePriceFetcher) Cloud() db.CloudProvider {
	return db.Azure
}

// FetchRegion fetches all prices for a region
func (f *AzurePriceFetcher) FetchRegion(ctx context.Context, region string) ([]RawPrice, error) {
	// Placeholder - needs Azure Retail Prices API implementation
	return nil, fmt.Errorf("Azure pricing fetcher not yet implemented")
}

// SupportedRegions returns supported regions
func (f *AzurePriceFetcher) SupportedRegions() []string {
	return []string{
		"eastus",
		"eastus2",
		"westus",
		"westus2",
		"centralus",
		"northeurope",
		"westeurope",
	}
}

// SupportedServices returns supported services
func (f *AzurePriceFetcher) SupportedServices() []string {
	return []string{
		"Virtual Machines",
		"Storage",
		"Azure SQL Database",
		"Azure Cosmos DB",
		"Azure Functions",
	}
}

// AzurePriceNormalizer normalizes Azure pricing
type AzurePriceNormalizer struct{}

// NewAzurePriceNormalizer creates an Azure price normalizer
func NewAzurePriceNormalizer() *AzurePriceNormalizer {
	return &AzurePriceNormalizer{}
}

// Cloud returns the cloud provider
func (n *AzurePriceNormalizer) Cloud() db.CloudProvider {
	return db.Azure
}

// Normalize converts raw prices to normalized rates
func (n *AzurePriceNormalizer) Normalize(raw []RawPrice) ([]NormalizedRate, error) {
	// Placeholder - needs Azure-specific normalization logic
	return nil, fmt.Errorf("Azure pricing normalizer not yet implemented")
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\backup.go
# TYPE: go
# SIZE: 5218 bytes
################################################################################
// Package ingestion - Backup and restore for pricing snapshots
package ingestion

import (
	"compress/gzip"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"time"

	"terraform-cost/db"
)

// SnapshotBackup is a complete snapshot dump for backup/restore
type SnapshotBackup struct {
	// Provider is the cloud provider
	Provider db.CloudProvider `json:"provider"`

	// Region
	Region string `json:"region"`

	// Alias for multi-account
	Alias string `json:"alias"`

	// Timestamp when backup was created
	Timestamp time.Time `json:"timestamp"`

	// ContentHash of the rates
	ContentHash string `json:"content_hash"`

	// RateCount for quick validation
	RateCount int `json:"rate_count"`

	// SchemaVersion for compatibility
	SchemaVersion string `json:"schema_version"`

	// Rates is the complete set of normalized rates
	Rates []NormalizedRate `json:"rates"`
}

// BackupManager handles backup creation and reading
type BackupManager struct{}

// NewBackupManager creates a backup manager
func NewBackupManager() *BackupManager {
	return &BackupManager{}
}

// WriteBackup writes a snapshot backup to disk
func (m *BackupManager) WriteBackup(baseDir string, backup *SnapshotBackup) (string, error) {
	// Create directory structure: baseDir/provider/timestamp.json.gz
	providerDir := filepath.Join(baseDir, string(backup.Provider))
	if err := os.MkdirAll(providerDir, 0755); err != nil {
		return "", fmt.Errorf("failed to create backup directory: %w", err)
	}

	// Generate filename with timestamp
	filename := fmt.Sprintf("%s_%s.json.gz",
		backup.Region,
		backup.Timestamp.Format("2006-01-02T15-04-05"),
	)
	fullPath := filepath.Join(providerDir, filename)

	// Create file
	file, err := os.Create(fullPath)
	if err != nil {
		return "", fmt.Errorf("failed to create backup file: %w", err)
	}
	defer file.Close()

	// Write gzipped JSON
	gzWriter := gzip.NewWriter(file)
	defer gzWriter.Close()

	encoder := json.NewEncoder(gzWriter)
	encoder.SetIndent("", "  ")
	if err := encoder.Encode(backup); err != nil {
		return "", fmt.Errorf("failed to write backup: %w", err)
	}

	return fullPath, nil
}

// ReadBackup reads a snapshot backup from disk
func (m *BackupManager) ReadBackup(path string) (*SnapshotBackup, error) {
	file, err := os.Open(path)
	if err != nil {
		return nil, fmt.Errorf("failed to open backup file: %w", err)
	}
	defer file.Close()

	var reader io.Reader = file

	// Handle gzipped files
	if strings.HasSuffix(path, ".gz") {
		gzReader, err := gzip.NewReader(file)
		if err != nil {
			return nil, fmt.Errorf("failed to create gzip reader: %w", err)
		}
		defer gzReader.Close()
		reader = gzReader
	}

	var backup SnapshotBackup
	if err := json.NewDecoder(reader).Decode(&backup); err != nil {
		return nil, fmt.Errorf("failed to decode backup: %w", err)
	}

	// Validate
	if err := m.ValidateBackup(&backup); err != nil {
		return nil, fmt.Errorf("backup validation failed: %w", err)
	}

	return &backup, nil
}

// ValidateBackup validates a backup file
func (m *BackupManager) ValidateBackup(backup *SnapshotBackup) error {
	if backup.Provider == "" {
		return fmt.Errorf("backup missing provider")
	}
	if backup.Region == "" {
		return fmt.Errorf("backup missing region")
	}
	if backup.ContentHash == "" {
		return fmt.Errorf("backup missing content hash")
	}
	if backup.RateCount == 0 {
		return fmt.Errorf("backup has 0 rates")
	}
	if len(backup.Rates) != backup.RateCount {
		return fmt.Errorf("backup rate count mismatch: header says %d, actual %d", backup.RateCount, len(backup.Rates))
	}

	// Verify hash
	actualHash := calculateHash(backup.Rates)
	if actualHash != backup.ContentHash {
		return fmt.Errorf("backup content hash mismatch: expected %s, got %s", backup.ContentHash, actualHash)
	}

	return nil
}

// ListBackups lists all backups in a directory
func (m *BackupManager) ListBackups(baseDir string) ([]BackupInfo, error) {
	var backups []BackupInfo

	providers := []string{"aws", "azure", "gcp"}
	for _, provider := range providers {
		providerDir := filepath.Join(baseDir, provider)
		if _, err := os.Stat(providerDir); os.IsNotExist(err) {
			continue
		}

		entries, err := os.ReadDir(providerDir)
		if err != nil {
			continue
		}

		for _, entry := range entries {
			if entry.IsDir() {
				continue
			}
			if !strings.HasSuffix(entry.Name(), ".json") && !strings.HasSuffix(entry.Name(), ".json.gz") {
				continue
			}

			info, err := entry.Info()
			if err != nil {
				continue
			}

			backups = append(backups, BackupInfo{
				Provider:  db.CloudProvider(provider),
				Path:      filepath.Join(providerDir, entry.Name()),
				Filename:  entry.Name(),
				Size:      info.Size(),
				CreatedAt: info.ModTime(),
			})
		}
	}

	return backups, nil
}

// BackupInfo is metadata about a backup file
type BackupInfo struct {
	Provider  db.CloudProvider `json:"provider"`
	Path      string           `json:"path"`
	Filename  string           `json:"filename"`
	Size      int64            `json:"size"`
	CreatedAt time.Time        `json:"created_at"`
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\coverage.go
# TYPE: go
# SIZE: 6594 bytes
################################################################################
// Package ingestion - Snapshot coverage tracking
package ingestion

import (
	"fmt"

	"terraform-cost/db"

	"github.com/google/uuid"
)

// SnapshotCoverage tracks completeness of a snapshot
type SnapshotCoverage struct {
	SnapshotID      uuid.UUID
	Services        map[string]*ServiceCoverage
	TotalRates      int
	TotalDimensions int
	IsComplete      bool
	MinCoverage     float64
}

// ServiceCoverage tracks coverage for a single service
type ServiceCoverage struct {
	Service           string
	RateCount         int
	RequiredCount     int
	DimensionCount    int
	CoveragePercent   float64
	MissingDimensions []string
	IsComplete        bool
}

// CoverageTracker tracks and enforces snapshot completeness
type CoverageTracker struct {
	contracts  map[string]IngestionContract
	allowlists *DimensionAllowlist
}

// NewCoverageTracker creates a new coverage tracker
func NewCoverageTracker() *CoverageTracker {
	ct := &CoverageTracker{
		contracts:  make(map[string]IngestionContract),
		allowlists: NewDimensionAllowlist(),
	}
	for _, c := range DefaultContracts() {
		key := fmt.Sprintf("%s:%s", c.Cloud, c.Service)
		ct.contracts[key] = c
	}
	return ct
}

// CalculateCoverage calculates coverage for a set of rates
func (ct *CoverageTracker) CalculateCoverage(snapshotID uuid.UUID, cloud db.CloudProvider, rates []NormalizedRate) *SnapshotCoverage {
	coverage := &SnapshotCoverage{
		SnapshotID:  snapshotID,
		Services:    make(map[string]*ServiceCoverage),
		TotalRates:  len(rates),
		IsComplete:  true,
		MinCoverage: 100,
	}

	// Group rates by service
	byService := make(map[string][]NormalizedRate)
	for _, r := range rates {
		byService[r.RateKey.Service] = append(byService[r.RateKey.Service], r)
	}

	// Calculate coverage for each contracted service
	for key, contract := range ct.contracts {
		if contract.Cloud != cloud {
			continue
		}

		serviceRates := byService[contract.Service]
		sc := ct.calculateServiceCoverage(contract, serviceRates)
		coverage.Services[key] = sc

		if !sc.IsComplete {
			coverage.IsComplete = false
		}
		if sc.CoveragePercent < coverage.MinCoverage {
			coverage.MinCoverage = sc.CoveragePercent
		}
	}

	// Track total dimensions
	dims := make(map[string]bool)
	for _, r := range rates {
		for k := range r.RateKey.Attributes {
			dims[k] = true
		}
	}
	coverage.TotalDimensions = len(dims)

	return coverage
}

func (ct *CoverageTracker) calculateServiceCoverage(contract IngestionContract, rates []NormalizedRate) *ServiceCoverage {
	sc := &ServiceCoverage{
		Service:       contract.Service,
		RateCount:     len(rates),
		RequiredCount: contract.MinRateCount,
		IsComplete:    true,
	}

	// Calculate coverage percent
	if contract.MinRateCount > 0 {
		sc.CoveragePercent = float64(len(rates)) / float64(contract.MinRateCount) * 100
		if sc.CoveragePercent > 100 {
			sc.CoveragePercent = 100
		}
	} else {
		sc.CoveragePercent = 100
	}

	// Check rate count
	if len(rates) < contract.MinRateCount {
		sc.IsComplete = false
	}

	// Check required dimensions
	presentDims := make(map[string]bool)
	for _, r := range rates {
		for k := range r.RateKey.Attributes {
			presentDims[k] = true
		}
	}
	sc.DimensionCount = len(presentDims)

	for _, reqDim := range contract.RequiredDimensions {
		if !presentDims[reqDim] {
			sc.MissingDimensions = append(sc.MissingDimensions, reqDim)
			sc.IsComplete = false
		}
	}

	return sc
}

// EnforceCoverage checks if coverage meets minimum thresholds
func (ct *CoverageTracker) EnforceCoverage(coverage *SnapshotCoverage, minPercent float64) error {
	if coverage.MinCoverage < minPercent {
		return fmt.Errorf("snapshot coverage %.1f%% below minimum %.1f%%", 
			coverage.MinCoverage, minPercent)
	}

	var incompleteServices []string
	for key, sc := range coverage.Services {
		if !sc.IsComplete {
			incompleteServices = append(incompleteServices, key)
		}
	}

	if len(incompleteServices) > 0 {
		return fmt.Errorf("incomplete services: %v", incompleteServices)
	}

	return nil
}

// CoverageReport generates a human-readable coverage report
type CoverageReport struct {
	SnapshotID       uuid.UUID
	Cloud            db.CloudProvider
	Region           string
	TotalRates       int
	TotalDimensions  int
	OverallCoverage  float64
	IsComplete       bool
	ServiceReports   []ServiceReport
	MissingServices  []string
}

// ServiceReport is a per-service coverage summary
type ServiceReport struct {
	Service           string
	RateCount         int
	RequiredCount     int
	CoveragePercent   float64
	DimensionCount    int
	MissingDimensions []string
	Status            string // "complete", "partial", "missing"
}

// GenerateReport creates a detailed coverage report
func (ct *CoverageTracker) GenerateReport(snapshot *db.PricingSnapshot, rates []NormalizedRate) *CoverageReport {
	coverage := ct.CalculateCoverage(snapshot.ID, snapshot.Cloud, rates)

	report := &CoverageReport{
		SnapshotID:      snapshot.ID,
		Cloud:           snapshot.Cloud,
		Region:          snapshot.Region,
		TotalRates:      coverage.TotalRates,
		TotalDimensions: coverage.TotalDimensions,
		OverallCoverage: coverage.MinCoverage,
		IsComplete:      coverage.IsComplete,
		ServiceReports:  make([]ServiceReport, 0),
	}

	// Generate service reports
	for _, contract := range ct.contracts {
		if contract.Cloud != snapshot.Cloud {
			continue
		}

		key := fmt.Sprintf("%s:%s", contract.Cloud, contract.Service)
		sc, ok := coverage.Services[key]
		
		sr := ServiceReport{
			Service:       contract.Service,
			RequiredCount: contract.MinRateCount,
		}

		if !ok || sc.RateCount == 0 {
			sr.Status = "missing"
			report.MissingServices = append(report.MissingServices, contract.Service)
		} else {
			sr.RateCount = sc.RateCount
			sr.CoveragePercent = sc.CoveragePercent
			sr.DimensionCount = sc.DimensionCount
			sr.MissingDimensions = sc.MissingDimensions
			
			if sc.IsComplete {
				sr.Status = "complete"
			} else {
				sr.Status = "partial"
			}
		}

		report.ServiceReports = append(report.ServiceReports, sr)
	}

	return report
}

// String returns a summary string
func (r *CoverageReport) String() string {
	status := "INCOMPLETE"
	if r.IsComplete {
		status = "COMPLETE"
	}
	return fmt.Sprintf(
		"[%s] %s/%s: %d rates, %d dimensions, %.1f%% coverage (%s)",
		status, r.Cloud, r.Region,
		r.TotalRates, r.TotalDimensions, r.OverallCoverage,
		r.SnapshotID,
	)
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\dimension_filter.go
# TYPE: go
# SIZE: 6268 bytes
################################################################################
// Package ingestion - Dimension filtering to prevent explosion
package ingestion

import (
	"terraform-cost/db"
)

// DimensionAllowlist defines which dimensions to keep per service
type DimensionAllowlist struct {
	dimensions map[string]map[string]DimensionConfig // cloud:service -> dimension -> config
}

// DimensionConfig holds configuration for a dimension
type DimensionConfig struct {
	Key        string
	IsRequired bool
	Priority   int
}

// NewDimensionAllowlist creates a new allowlist with defaults
func NewDimensionAllowlist() *DimensionAllowlist {
	al := &DimensionAllowlist{
		dimensions: make(map[string]map[string]DimensionConfig),
	}
	al.loadDefaults()
	return al
}

// loadDefaults populates default allowlists for high-impact services
func (al *DimensionAllowlist) loadDefaults() {
	// AWS EC2
	al.Add(db.AWS, "AmazonEC2", "instance_type", true, 100)
	al.Add(db.AWS, "AmazonEC2", "os", true, 90)
	al.Add(db.AWS, "AmazonEC2", "tenancy", false, 80)
	al.Add(db.AWS, "AmazonEC2", "volume_type", false, 70)
	al.Add(db.AWS, "AmazonEC2", "capacity_status", false, 50)
	al.Add(db.AWS, "AmazonEC2", "product_family", false, 60)

	// AWS RDS
	al.Add(db.AWS, "AmazonRDS", "instance_type", true, 100)
	al.Add(db.AWS, "AmazonRDS", "engine", true, 90)
	al.Add(db.AWS, "AmazonRDS", "deployment", false, 70)
	al.Add(db.AWS, "AmazonRDS", "license", false, 60)

	// AWS Lambda
	al.Add(db.AWS, "AWSLambda", "memory_size", false, 80)
	al.Add(db.AWS, "AWSLambda", "architecture", false, 60)
	al.Add(db.AWS, "AWSLambda", "group", false, 70)

	// AWS S3
	al.Add(db.AWS, "AmazonS3", "storage_class", true, 100)
	al.Add(db.AWS, "AmazonS3", "volume_type", false, 80)

	// AWS ELB
	al.Add(db.AWS, "ElasticLoadBalancing", "product_family", true, 100)
	al.Add(db.AWS, "ElasticLoadBalancing", "usage_type", false, 70)

	// AWS DynamoDB
	al.Add(db.AWS, "AmazonDynamoDB", "group", false, 80)
	al.Add(db.AWS, "AmazonDynamoDB", "usage_type", false, 70)

	// AWS NAT Gateway
	al.Add(db.AWS, "AmazonEC2", "usage_type", false, 60)
}

// Add adds a dimension to the allowlist
func (al *DimensionAllowlist) Add(cloud db.CloudProvider, service, dimension string, required bool, priority int) {
	key := string(cloud) + ":" + service
	if _, ok := al.dimensions[key]; !ok {
		al.dimensions[key] = make(map[string]DimensionConfig)
	}
	al.dimensions[key][dimension] = DimensionConfig{
		Key:        dimension,
		IsRequired: required,
		Priority:   priority,
	}
}

// GetAllowed returns allowed dimensions for a service
func (al *DimensionAllowlist) GetAllowed(cloud db.CloudProvider, service string) map[string]DimensionConfig {
	key := string(cloud) + ":" + service
	if dims, ok := al.dimensions[key]; ok {
		return dims
	}
	return nil
}

// GetRequired returns required dimensions for a service
func (al *DimensionAllowlist) GetRequired(cloud db.CloudProvider, service string) []string {
	key := string(cloud) + ":" + service
	dims, ok := al.dimensions[key]
	if !ok {
		return nil
	}

	var required []string
	for k, cfg := range dims {
		if cfg.IsRequired {
			required = append(required, k)
		}
	}
	return required
}

// Filter filters attributes to only allowed dimensions
func (al *DimensionAllowlist) Filter(cloud db.CloudProvider, service string, attrs map[string]string) map[string]string {
	allowed := al.GetAllowed(cloud, service)
	if allowed == nil {
		// No allowlist = accept all (for unconfigured services)
		return attrs
	}

	filtered := make(map[string]string)
	for k, v := range attrs {
		if _, ok := allowed[k]; ok {
			filtered[k] = v
		}
	}
	return filtered
}

// IsAllowed checks if a dimension is allowed
func (al *DimensionAllowlist) IsAllowed(cloud db.CloudProvider, service, dimension string) bool {
	allowed := al.GetAllowed(cloud, service)
	if allowed == nil {
		return true // No list = allow all
	}
	_, ok := allowed[dimension]
	return ok
}

// FilteredNormalizer wraps a normalizer with dimension filtering
type FilteredNormalizer struct {
	inner     PriceNormalizer
	allowlist *DimensionAllowlist
}

// NewFilteredNormalizer creates a normalizer that filters dimensions
func NewFilteredNormalizer(inner PriceNormalizer) *FilteredNormalizer {
	return &FilteredNormalizer{
		inner:     inner,
		allowlist: NewDimensionAllowlist(),
	}
}

func (n *FilteredNormalizer) Cloud() db.CloudProvider {
	return n.inner.Cloud()
}

// Normalize normalizes and filters dimensions
func (n *FilteredNormalizer) Normalize(raw []RawPrice) ([]NormalizedRate, error) {
	// First normalize with inner normalizer
	rates, err := n.inner.Normalize(raw)
	if err != nil {
		return nil, err
	}

	// Then filter dimensions
	for i := range rates {
		rates[i].RateKey.Attributes = n.allowlist.Filter(
			rates[i].RateKey.Cloud,
			rates[i].RateKey.Service,
			rates[i].RateKey.Attributes,
		)
	}

	// Deduplicate after filtering (same rate key might now match)
	return n.deduplicate(rates), nil
}

// deduplicate removes duplicate rates (keeping first)
func (n *FilteredNormalizer) deduplicate(rates []NormalizedRate) []NormalizedRate {
	seen := make(map[string]bool)
	var result []NormalizedRate

	for _, r := range rates {
		key := rateKeyString(r.RateKey) + "|" + r.Unit
		if !seen[key] {
			seen[key] = true
			result = append(result, r)
		}
	}

	return result
}

// Stats returns filtering statistics
type FilteringStats struct {
	TotalRates    int
	FilteredRates int
	DroppedRates  int
	ByService     map[string]int
}

// WithStats normalizes and returns stats
func (n *FilteredNormalizer) WithStats(raw []RawPrice) ([]NormalizedRate, *FilteringStats, error) {
	// Normalize without filtering first
	allRates, err := n.inner.Normalize(raw)
	if err != nil {
		return nil, nil, err
	}

	// Then filter
	filtered, err := n.Normalize(raw)
	if err != nil {
		return nil, nil, err
	}

	stats := &FilteringStats{
		TotalRates:    len(allRates),
		FilteredRates: len(filtered),
		DroppedRates:  len(allRates) - len(filtered),
		ByService:     make(map[string]int),
	}

	for _, r := range filtered {
		stats.ByService[r.RateKey.Service]++
	}

	return filtered, stats, nil
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\drift.go
# TYPE: go
# SIZE: 7805 bytes
################################################################################
// Package ingestion - Pricing drift detection
package ingestion

import (
	"context"
	"fmt"

	"terraform-cost/db"

	"github.com/google/uuid"
	"github.com/shopspring/decimal"
)

// DriftDetector compares snapshots and identifies price changes
type DriftDetector struct {
	store                  db.PricingStore
	significanceThreshold  float64 // Percent change considered significant
}

// NewDriftDetector creates a new drift detector
func NewDriftDetector(store db.PricingStore) *DriftDetector {
	return &DriftDetector{
		store:                 store,
		significanceThreshold: 0.05, // 5% default
	}
}

// WithThreshold sets the significance threshold
func (d *DriftDetector) WithThreshold(pct float64) *DriftDetector {
	d.significanceThreshold = pct
	return d
}

// DriftRecord represents a single price change
type DriftRecord struct {
	Service        string
	ProductFamily  string
	DimensionKey   string
	DimensionValue string
	OldPrice       decimal.Decimal
	NewPrice       decimal.Decimal
	PriceDelta     decimal.Decimal
	PercentChange  float64
	Unit           string
	DriftType      DriftType
	IsSignificant  bool
}

// DriftType categorizes the type of drift
type DriftType string

const (
	DriftIncrease DriftType = "increase"
	DriftDecrease DriftType = "decrease"
	DriftNew      DriftType = "new"
	DriftRemoved  DriftType = "removed"
)

// DriftSummary summarizes drift between two snapshots
type DriftSummary struct {
	OldSnapshotID     uuid.UUID
	NewSnapshotID     uuid.UUID
	Cloud             db.CloudProvider
	TotalChanges      int
	PriceIncreases    int
	PriceDecreases    int
	NewRates          int
	RemovedRates      int
	AvgPercentChange  float64
	MaxPercentChange  float64
	SignificantChanges int
	Records           []DriftRecord
}

// DetectDrift compares two snapshots and returns drift summary
func (d *DriftDetector) DetectDrift(ctx context.Context, oldSnapshotID, newSnapshotID uuid.UUID) (*DriftSummary, error) {
	// Get snapshots
	oldSnapshot, err := d.store.GetSnapshot(ctx, oldSnapshotID)
	if err != nil {
		return nil, fmt.Errorf("failed to get old snapshot: %w", err)
	}
	if oldSnapshot == nil {
		return nil, fmt.Errorf("old snapshot not found: %s", oldSnapshotID)
	}

	newSnapshot, err := d.store.GetSnapshot(ctx, newSnapshotID)
	if err != nil {
		return nil, fmt.Errorf("failed to get new snapshot: %w", err)
	}
	if newSnapshot == nil {
		return nil, fmt.Errorf("new snapshot not found: %s", newSnapshotID)
	}

	// Verify same cloud/region
	if oldSnapshot.Cloud != newSnapshot.Cloud || oldSnapshot.Region != newSnapshot.Region {
		return nil, fmt.Errorf("snapshots must be for same cloud/region")
	}

	summary := &DriftSummary{
		OldSnapshotID: oldSnapshotID,
		NewSnapshotID: newSnapshotID,
		Cloud:         oldSnapshot.Cloud,
		Records:       make([]DriftRecord, 0),
	}

	// This would typically query the database for rate comparisons
	// For now, we'll create the structure for the comparison

	return summary, nil
}

// DetectDriftFromRates compares two sets of rates directly
func (d *DriftDetector) DetectDriftFromRates(oldRates, newRates []NormalizedRate) *DriftSummary {
	summary := &DriftSummary{
		Records: make([]DriftRecord, 0),
	}

	// Index old rates by key
	oldIndex := make(map[string]NormalizedRate)
	for _, r := range oldRates {
		key := rateKeyString(r.RateKey) + "|" + r.Unit
		oldIndex[key] = r
	}

	// Index new rates by key
	newIndex := make(map[string]NormalizedRate)
	for _, r := range newRates {
		key := rateKeyString(r.RateKey) + "|" + r.Unit
		newIndex[key] = r
	}

	// Find changes and additions
	for key, newRate := range newIndex {
		if oldRate, exists := oldIndex[key]; exists {
			// Compare prices
			if !oldRate.Price.Equal(newRate.Price) {
				record := d.createDriftRecord(oldRate, newRate)
				summary.Records = append(summary.Records, record)
				summary.TotalChanges++
				
				if record.IsSignificant {
					summary.SignificantChanges++
				}
				
				switch record.DriftType {
				case DriftIncrease:
					summary.PriceIncreases++
				case DriftDecrease:
					summary.PriceDecreases++
				}
			}
		} else {
			// New rate
			record := DriftRecord{
				Service:       newRate.RateKey.Service,
				ProductFamily: newRate.RateKey.ProductFamily,
				OldPrice:      decimal.Zero,
				NewPrice:      newRate.Price,
				PriceDelta:    newRate.Price,
				PercentChange: 100,
				Unit:          newRate.Unit,
				DriftType:     DriftNew,
				IsSignificant: true,
			}
			summary.Records = append(summary.Records, record)
			summary.TotalChanges++
			summary.NewRates++
			summary.SignificantChanges++
		}
	}

	// Find removals
	for key, oldRate := range oldIndex {
		if _, exists := newIndex[key]; !exists {
			record := DriftRecord{
				Service:       oldRate.RateKey.Service,
				ProductFamily: oldRate.RateKey.ProductFamily,
				OldPrice:      oldRate.Price,
				NewPrice:      decimal.Zero,
				PriceDelta:    oldRate.Price.Neg(),
				PercentChange: -100,
				Unit:          oldRate.Unit,
				DriftType:     DriftRemoved,
				IsSignificant: true,
			}
			summary.Records = append(summary.Records, record)
			summary.TotalChanges++
			summary.RemovedRates++
			summary.SignificantChanges++
		}
	}

	// Calculate averages
	if summary.TotalChanges > 0 {
		var totalPct float64
		var maxPct float64
		for _, r := range summary.Records {
			absPct := r.PercentChange
			if absPct < 0 {
				absPct = -absPct
			}
			totalPct += absPct
			if absPct > maxPct {
				maxPct = absPct
			}
		}
		summary.AvgPercentChange = totalPct / float64(summary.TotalChanges)
		summary.MaxPercentChange = maxPct
	}

	return summary
}

func (d *DriftDetector) createDriftRecord(oldRate, newRate NormalizedRate) DriftRecord {
	delta := newRate.Price.Sub(oldRate.Price)
	
	var pctChange float64
	if !oldRate.Price.IsZero() {
		pctChange = delta.Div(oldRate.Price).Mul(decimal.NewFromInt(100)).InexactFloat64()
	}

	driftType := DriftDecrease
	if delta.IsPositive() {
		driftType = DriftIncrease
	}

	isSignificant := false
	absPct := pctChange
	if absPct < 0 {
		absPct = -absPct
	}
	if absPct >= d.significanceThreshold*100 {
		isSignificant = true
	}

	return DriftRecord{
		Service:       newRate.RateKey.Service,
		ProductFamily: newRate.RateKey.ProductFamily,
		OldPrice:      oldRate.Price,
		NewPrice:      newRate.Price,
		PriceDelta:    delta,
		PercentChange: pctChange,
		Unit:          newRate.Unit,
		DriftType:     driftType,
		IsSignificant: isSignificant,
	}
}

// HasSignificantDrift returns true if there are significant price changes
func (s *DriftSummary) HasSignificantDrift() bool {
	return s.SignificantChanges > 0
}

// String returns a human-readable summary
func (s *DriftSummary) String() string {
	return fmt.Sprintf(
		"Pricing Drift: %d changes (%d significant) - %d increases, %d decreases, %d new, %d removed - avg %.2f%%, max %.2f%%",
		s.TotalChanges, s.SignificantChanges,
		s.PriceIncreases, s.PriceDecreases, s.NewRates, s.RemovedRates,
		s.AvgPercentChange, s.MaxPercentChange,
	)
}

// GetSignificantRecords returns only significant drift records
func (s *DriftSummary) GetSignificantRecords() []DriftRecord {
	var significant []DriftRecord
	for _, r := range s.Records {
		if r.IsSignificant {
			significant = append(significant, r)
		}
	}
	return significant
}

// GroupByService groups drift records by service
func (s *DriftSummary) GroupByService() map[string][]DriftRecord {
	byService := make(map[string][]DriftRecord)
	for _, r := range s.Records {
		byService[r.Service] = append(byService[r.Service], r)
	}
	return byService
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\gcp.go
# TYPE: go
# SIZE: 1828 bytes
################################################################################
// Package ingestion - GCP pricing fetcher and normalizer (placeholder)
package ingestion

import (
	"context"
	"fmt"

	"terraform-cost/db"
)

// GCPPriceFetcher fetches pricing from GCP Cloud Billing API
type GCPPriceFetcher struct{}

// NewGCPPriceFetcher creates a GCP price fetcher
func NewGCPPriceFetcher() *GCPPriceFetcher {
	return &GCPPriceFetcher{}
}

// Cloud returns the cloud provider
func (f *GCPPriceFetcher) Cloud() db.CloudProvider {
	return db.GCP
}

// FetchRegion fetches all prices for a region
func (f *GCPPriceFetcher) FetchRegion(ctx context.Context, region string) ([]RawPrice, error) {
	// Placeholder - needs GCP Cloud Billing API implementation
	return nil, fmt.Errorf("GCP pricing fetcher not yet implemented")
}

// SupportedRegions returns supported regions
func (f *GCPPriceFetcher) SupportedRegions() []string {
	return []string{
		"us-central1",
		"us-east1",
		"us-west1",
		"europe-west1",
		"asia-east1",
	}
}

// SupportedServices returns supported services
func (f *GCPPriceFetcher) SupportedServices() []string {
	return []string{
		"Compute Engine",
		"Cloud Storage",
		"Cloud SQL",
		"BigQuery",
		"Cloud Functions",
	}
}

// GCPPriceNormalizer normalizes GCP pricing
type GCPPriceNormalizer struct{}

// NewGCPPriceNormalizer creates a GCP price normalizer
func NewGCPPriceNormalizer() *GCPPriceNormalizer {
	return &GCPPriceNormalizer{}
}

// Cloud returns the cloud provider
func (n *GCPPriceNormalizer) Cloud() db.CloudProvider {
	return db.GCP
}

// Normalize converts raw prices to normalized rates
func (n *GCPPriceNormalizer) Normalize(raw []RawPrice) ([]NormalizedRate, error) {
	// Placeholder - needs GCP-specific normalization logic
	return nil, fmt.Errorf("GCP pricing normalizer not yet implemented")
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\governance.go
# TYPE: go
# SIZE: 10909 bytes
################################################################################
// Package ingestion - Ingestion governance and validation
package ingestion

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"time"

	"terraform-cost/db"

	"github.com/google/uuid"
)

// IngestionContract defines requirements for service ingestion
type IngestionContract struct {
	Cloud              db.CloudProvider
	Service            string
	RequiredDimensions []string
	MinRateCount       int
}

// DefaultContracts returns the default ingestion contracts
func DefaultContracts() []IngestionContract {
	return []IngestionContract{
		{db.AWS, "AmazonEC2", []string{"instance_type", "os", "tenancy"}, 100},
		{db.AWS, "AmazonRDS", []string{"instance_type", "engine"}, 50},
		{db.AWS, "AmazonS3", []string{"storage_class"}, 10},
		{db.AWS, "AWSLambda", []string{"memory_size"}, 5},
		{db.AWS, "ElasticLoadBalancing", []string{"product_family"}, 5},
		{db.AWS, "AmazonDynamoDB", []string{"read_capacity"}, 5},
		{db.Azure, "Virtual Machines", []string{"vm_size", "os"}, 100},
		{db.Azure, "Storage", []string{"redundancy", "tier"}, 20},
		{db.GCP, "Compute Engine", []string{"machine_type"}, 100},
		{db.GCP, "Cloud Storage", []string{"storage_class"}, 10},
	}
}

// IngestionState tracks ingestion progress
type IngestionState struct {
	ID            uuid.UUID
	SnapshotID    uuid.UUID
	Provider      string
	Status        IngestionStatus
	RecordCount   int
	DimensionCount int
	Checksum      string
	ErrorMessage  string
	StartedAt     time.Time
	CompletedAt   *time.Time
}

// IngestionStatus represents the state of an ingestion
type IngestionStatus string

const (
	IngestionStarted    IngestionStatus = "started"
	IngestionInProgress IngestionStatus = "in_progress"
	IngestionCompleted  IngestionStatus = "completed"
	IngestionFailed     IngestionStatus = "failed"
)

// IngestionValidator validates ingestion against contracts
type IngestionValidator struct {
	contracts          map[string]IngestionContract
	minCoveragePercent float64
}

// NewIngestionValidator creates a new validator with default contracts
func NewIngestionValidator() *IngestionValidator {
	v := &IngestionValidator{
		contracts:          make(map[string]IngestionContract),
		minCoveragePercent: 95.0, // Very high coverage required
	}
	for _, c := range DefaultContracts() {
		key := fmt.Sprintf("%s:%s", c.Cloud, c.Service)
		v.contracts[key] = c
	}
	return v
}

// SetMinCoveragePercent sets the minimum coverage percentage
func (v *IngestionValidator) SetMinCoveragePercent(pct float64) {
	v.minCoveragePercent = pct
}

// AddContract adds a custom contract
func (v *IngestionValidator) AddContract(contract IngestionContract) {
	key := fmt.Sprintf("%s:%s", contract.Cloud, contract.Service)
	v.contracts[key] = contract
}

// ValidationResult contains validation outcome
type ValidationResult struct {
	IsValid           bool
	ServiceResults    map[string]ServiceValidation
	TotalRates        int
	TotalDimensions   int
	MissingServices   []string
	Errors            []string
}

// ServiceValidation contains per-service validation
type ServiceValidation struct {
	Service           string
	RateCount         int
	RequiredCount     int
	HasRequiredDims   bool
	MissingDimensions []string
	IsValid           bool
}

// Validate validates ingested rates against contracts
func (v *IngestionValidator) Validate(cloud db.CloudProvider, rates []NormalizedRate) *ValidationResult {
	result := &ValidationResult{
		IsValid:        true,
		ServiceResults: make(map[string]ServiceValidation),
	}

	// Group rates by service
	byService := make(map[string][]NormalizedRate)
	for _, r := range rates {
		byService[r.RateKey.Service] = append(byService[r.RateKey.Service], r)
	}

	result.TotalRates = len(rates)

	// Collect unique dimensions
	dims := make(map[string]bool)
	for _, r := range rates {
		for k := range r.RateKey.Attributes {
			dims[k] = true
		}
	}
	result.TotalDimensions = len(dims)

	// Validate each contracted service
	for key, contract := range v.contracts {
		if contract.Cloud != cloud {
			continue
		}

		serviceRates := byService[contract.Service]
		sv := ServiceValidation{
			Service:       contract.Service,
			RateCount:     len(serviceRates),
			RequiredCount: contract.MinRateCount,
			IsValid:       true,
		}

		// Check minimum rate count
		if len(serviceRates) < contract.MinRateCount {
			sv.IsValid = false
			result.Errors = append(result.Errors, 
				fmt.Sprintf("%s: only %d rates, need %d", contract.Service, len(serviceRates), contract.MinRateCount))
		}

		// Check required dimensions
		presentDims := make(map[string]bool)
		for _, r := range serviceRates {
			for k := range r.RateKey.Attributes {
				presentDims[k] = true
			}
		}

		for _, reqDim := range contract.RequiredDimensions {
			if !presentDims[reqDim] {
				sv.MissingDimensions = append(sv.MissingDimensions, reqDim)
				sv.HasRequiredDims = false
				sv.IsValid = false
				result.Errors = append(result.Errors,
					fmt.Sprintf("%s: missing required dimension '%s'", contract.Service, reqDim))
			}
		}

		if len(sv.MissingDimensions) == 0 {
			sv.HasRequiredDims = true
		}

		if !sv.IsValid {
			result.IsValid = false
		}

		result.ServiceResults[key] = sv
	}

	// Check for missing services
	for _, contract := range v.contracts {
		if contract.Cloud != cloud {
			continue
		}
		if _, ok := byService[contract.Service]; !ok {
			result.MissingServices = append(result.MissingServices, contract.Service)
			result.IsValid = false
		}
	}

	return result
}

// GovernedPipeline wraps Pipeline with governance
type GovernedPipeline struct {
	*Pipeline
	validator *IngestionValidator
}

// NewGovernedPipeline creates a governed ingestion pipeline
func NewGovernedPipeline(fetcher PriceFetcher, normalizer PriceNormalizer, store db.PricingStore) *GovernedPipeline {
	return &GovernedPipeline{
		Pipeline:  NewPipeline(fetcher, normalizer, store),
		validator: NewIngestionValidator(),
	}
}

// IngestWithValidation runs ingestion with contract validation
func (p *GovernedPipeline) IngestWithValidation(ctx context.Context, region, alias string) (*db.PricingSnapshot, *ValidationResult, error) {
	// Fetch
	raw, err := p.fetcher.FetchRegion(ctx, region)
	if err != nil {
		return nil, nil, fmt.Errorf("fetch failed: %w", err)
	}

	// Normalize
	normalized, err := p.normalizer.Normalize(raw)
	if err != nil {
		return nil, nil, fmt.Errorf("normalization failed: %w", err)
	}

	// Validate against contracts
	validation := p.validator.Validate(p.fetcher.Cloud(), normalized)
	if !validation.IsValid {
		// Still build snapshot but mark as partial
		// In strict mode, this would fail
	}

	// Build snapshot
	snapshot, err := p.builder.BuildSnapshot(
		ctx,
		p.fetcher.Cloud(),
		region,
		alias,
		fmt.Sprintf("ingestion_pipeline_%s", p.fetcher.Cloud()),
		normalized,
	)
	if err != nil {
		return nil, validation, fmt.Errorf("snapshot build failed: %w", err)
	}

	// Only activate if validation passed
	if validation.IsValid {
		if err := p.builder.ActivateSnapshot(ctx, snapshot.ID); err != nil {
			return snapshot, validation, fmt.Errorf("activation failed: %w", err)
		}
	}

	return snapshot, validation, nil
}

// CalculateChecksum computes checksum for rates
func CalculateChecksum(rates []NormalizedRate) string {
	hasher := sha256.New()
	for _, r := range rates {
		hasher.Write([]byte(r.RateKey.Service))
		hasher.Write([]byte(r.RateKey.ProductFamily))
		hasher.Write([]byte(r.RateKey.Region))
		hasher.Write([]byte(r.Unit))
		hasher.Write([]byte(r.Price.String()))
	}
	return hex.EncodeToString(hasher.Sum(nil))
}

// ValidateAll runs all pre-commit validations (abort on failure)
func (v *IngestionValidator) ValidateAll(rates []NormalizedRate, prevRateCount int) error {
	// 1. Validate no negative prices
	if err := v.ValidatePricesPositive(rates); err != nil {
		return err
	}

	// 2. Validate required dimensions exist
	if err := v.ValidateDimensionsComplete(rates); err != nil {
		return err
	}

	// 3. Validate no duplicate rate keys
	if err := v.ValidateNoDuplicates(rates); err != nil {
		return err
	}

	// 4. Validate coverage not decreased (if previous exists)
	if prevRateCount > 0 {
		if err := v.ValidateCoverageNotDecreased(len(rates), prevRateCount); err != nil {
			return err
		}
	}

	return nil
}

// ValidatePricesPositive ensures no negative prices
func (v *IngestionValidator) ValidatePricesPositive(rates []NormalizedRate) error {
	for _, r := range rates {
		if r.Price.IsNegative() {
			return fmt.Errorf("negative price found: %s = %s", 
				fmt.Sprintf("%s/%s/%s", r.RateKey.Service, r.RateKey.ProductFamily, r.RateKey.Region),
				r.Price.String())
		}
	}
	return nil
}

// ValidateDimensionsComplete ensures required dimensions exist
func (v *IngestionValidator) ValidateDimensionsComplete(rates []NormalizedRate) error {
	// Group by service
	byService := make(map[string]map[string]bool)
	for _, r := range rates {
		if byService[r.RateKey.Service] == nil {
			byService[r.RateKey.Service] = make(map[string]bool)
		}
		for k := range r.RateKey.Attributes {
			byService[r.RateKey.Service][k] = true
		}
	}

	// Check contracts
	for _, contract := range v.contracts {
		presentDims := byService[contract.Service]
		if presentDims == nil {
			continue // Service not in this ingestion
		}
		for _, reqDim := range contract.RequiredDimensions {
			if !presentDims[reqDim] {
				return fmt.Errorf("service %s missing required dimension: %s", contract.Service, reqDim)
			}
		}
	}

	return nil
}

// ValidateNoDuplicates ensures no duplicate rate keys
func (v *IngestionValidator) ValidateNoDuplicates(rates []NormalizedRate) error {
	seen := make(map[string]bool)
	for _, r := range rates {
		key := rateKeyForDedupe(r.RateKey)
		if seen[key] {
			return fmt.Errorf("duplicate rate key found: %s", key)
		}
		seen[key] = true
	}
	return nil
}

func rateKeyForDedupe(k db.RateKey) string {
	return fmt.Sprintf("%s|%s|%s|%s|%v", k.Cloud, k.Service, k.ProductFamily, k.Region, k.Attributes)
}

// ValidateCoverageNotDecreased ensures coverage >= previous snapshot
func (v *IngestionValidator) ValidateCoverageNotDecreased(newCount, prevCount int) error {
	if newCount == 0 {
		return fmt.Errorf("new snapshot has 0 rates, previous had %d", prevCount)
	}

	// Calculate coverage percentage
	coveragePercent := float64(newCount) / float64(prevCount) * 100

	if coveragePercent < v.minCoveragePercent {
		return fmt.Errorf("coverage decreased: new has %d rates (%.1f%%) vs previous %d rates, minimum %.1f%% required",
			newCount, coveragePercent, prevCount, v.minCoveragePercent)
	}

	return nil
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\pipeline.go
# TYPE: go
# SIZE: 14448 bytes
################################################################################
// Package ingestion - Pricing data ingestion pipeline
// Strictly separated from estimation: fetch â†’ normalize â†’ validate â†’ backup â†’ commit
package ingestion

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"sort"
	"strings"
	"time"

	"terraform-cost/db"

	"github.com/google/uuid"
	"github.com/shopspring/decimal"
)

// Phase represents a pipeline execution phase
type Phase string

const (
	PhaseFetch     Phase = "fetch"
	PhaseNormalize Phase = "normalize"
	PhaseValidate  Phase = "validate"
	PhaseBackup    Phase = "backup"
	PhaseCommit    Phase = "commit"
)

// PipelineConfig configures the ingestion pipeline
type PipelineConfig struct {
	// Provider is the cloud provider (aws, azure, gcp)
	Provider db.CloudProvider

	// Region to ingest
	Region string

	// Alias for multi-account (default if empty)
	Alias string

	// DryRun validates only, no DB writes
	DryRun bool

	// BackupDir is where to write backups
	BackupDir string

	// MinCoveragePercent is the minimum required coverage (default 95%)
	MinCoveragePercent float64

	// Timeout for the entire pipeline
	Timeout time.Duration
}

// DefaultPipelineConfig returns production defaults
func DefaultPipelineConfig() *PipelineConfig {
	return &PipelineConfig{
		Alias:              "default",
		DryRun:             false,
		BackupDir:          "./pricing-backups",
		MinCoveragePercent: 95.0, // Very high coverage required
		Timeout:            30 * time.Minute,
	}
}

// PipelineResult contains the outcome of a pipeline run
type PipelineResult struct {
	// Success indicates all phases completed
	Success bool `json:"success"`

	// SnapshotID of the created snapshot (nil if dry-run or failure)
	SnapshotID *uuid.UUID `json:"snapshot_id,omitempty"`

	// Phases completed
	PhasesCompleted []Phase `json:"phases_completed"`

	// FailedPhase if any
	FailedPhase Phase `json:"failed_phase,omitempty"`

	// Error message if failed
	Error string `json:"error,omitempty"`

	// Stats from the run
	Stats PipelineStats `json:"stats"`

	// BackupPath where backup was written
	BackupPath string `json:"backup_path,omitempty"`

	// Duration of the run
	Duration time.Duration `json:"duration"`
}

// PipelineStats contains statistics from a run
type PipelineStats struct {
	RawPricesCount       int     `json:"raw_prices_count"`
	NormalizedRatesCount int     `json:"normalized_rates_count"`
	UniqueServicesCount  int     `json:"unique_services_count"`
	CoveragePercent      float64 `json:"coverage_percent"`
	ContentHash          string  `json:"content_hash"`
}

// RawPrice represents a raw price record from a cloud API
type RawPrice struct {
	SKU           string            `json:"sku"`
	ServiceCode   string            `json:"service_code"`
	ProductFamily string            `json:"product_family"`
	Region        string            `json:"region"`
	Unit          string            `json:"unit"`
	PricePerUnit  string            `json:"price_per_unit"`
	Currency      string            `json:"currency"`
	Attributes    map[string]string `json:"attributes"`
	TierStart     *float64          `json:"tier_start,omitempty"`
	TierEnd       *float64          `json:"tier_end,omitempty"`
	EffectiveDate *time.Time        `json:"effective_date,omitempty"`
}

// NormalizedRate is the output of normalization
type NormalizedRate struct {
	RateKey    db.RateKey      `json:"rate_key"`
	Unit       string          `json:"unit"`
	Price      decimal.Decimal `json:"price"`
	Currency   string          `json:"currency"`
	Confidence float64         `json:"confidence"`
	TierMin    *decimal.Decimal `json:"tier_min,omitempty"`
	TierMax    *decimal.Decimal `json:"tier_max,omitempty"`
}

// PriceFetcher fetches raw prices from a cloud API
type PriceFetcher interface {
	// Cloud returns the cloud provider
	Cloud() db.CloudProvider

	// FetchRegion fetches all prices for a region (NO DB WRITES)
	FetchRegion(ctx context.Context, region string) ([]RawPrice, error)

	// SupportedRegions returns supported regions
	SupportedRegions() []string

	// SupportedServices returns services this fetcher covers
	SupportedServices() []string
}

// PriceNormalizer converts raw prices to normalized rates
type PriceNormalizer interface {
	// Cloud returns the cloud provider
	Cloud() db.CloudProvider

	// Normalize converts raw prices to normalized rates
	Normalize(raw []RawPrice) ([]NormalizedRate, error)
}

// Pipeline orchestrates the full ingestion flow with 5 strict phases
type Pipeline struct {
	fetcher    PriceFetcher
	normalizer PriceNormalizer
	validator  *IngestionValidator
	backupMgr  *BackupManager
	store      db.PricingStore
}

// NewPipeline creates a new ingestion pipeline
func NewPipeline(
	fetcher PriceFetcher,
	normalizer PriceNormalizer,
	store db.PricingStore,
) *Pipeline {
	return &Pipeline{
		fetcher:    fetcher,
		normalizer: normalizer,
		validator:  NewIngestionValidator(),
		backupMgr:  NewBackupManager(),
		store:      store,
	}
}

// Execute runs the full 5-phase ingestion pipeline
func (p *Pipeline) Execute(ctx context.Context, config *PipelineConfig) (*PipelineResult, error) {
	if config == nil {
		config = DefaultPipelineConfig()
	}

	start := time.Now()
	result := &PipelineResult{
		PhasesCompleted: make([]Phase, 0, 5),
	}

	// Apply timeout
	if config.Timeout > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, config.Timeout)
		defer cancel()
	}

	// ========================================
	// PHASE A: FETCH (NO DB WRITES)
	// ========================================
	rawPrices, err := p.phaseFetch(ctx, config)
	if err != nil {
		result.FailedPhase = PhaseFetch
		result.Error = err.Error()
		result.Duration = time.Since(start)
		return result, nil
	}
	result.PhasesCompleted = append(result.PhasesCompleted, PhaseFetch)
	result.Stats.RawPricesCount = len(rawPrices)

	// ========================================
	// PHASE B: NORMALIZE
	// ========================================
	normalizedRates, err := p.phaseNormalize(ctx, rawPrices)
	if err != nil {
		result.FailedPhase = PhaseNormalize
		result.Error = err.Error()
		result.Duration = time.Since(start)
		return result, nil
	}
	result.PhasesCompleted = append(result.PhasesCompleted, PhaseNormalize)
	result.Stats.NormalizedRatesCount = len(normalizedRates)
	result.Stats.UniqueServicesCount = countUniqueServices(normalizedRates)
	result.Stats.ContentHash = calculateHash(normalizedRates)

	// ========================================
	// PHASE C: VALIDATE (NON-NEGOTIABLE)
	// ========================================
	validationErr := p.phaseValidate(ctx, config, normalizedRates)
	if validationErr != nil {
		result.FailedPhase = PhaseValidate
		result.Error = validationErr.Error()
		result.Duration = time.Since(start)
		return result, nil
	}
	result.PhasesCompleted = append(result.PhasesCompleted, PhaseValidate)

	// ========================================
	// PHASE D: BACKUP (MANDATORY)
	// ========================================
	backupPath, err := p.phaseBackup(ctx, config, normalizedRates, result.Stats)
	if err != nil {
		result.FailedPhase = PhaseBackup
		result.Error = err.Error()
		result.Duration = time.Since(start)
		return result, nil
	}
	result.PhasesCompleted = append(result.PhasesCompleted, PhaseBackup)
	result.BackupPath = backupPath

	// ========================================
	// DRY-RUN CHECK
	// ========================================
	if config.DryRun {
		result.Success = true
		result.Duration = time.Since(start)
		return result, nil
	}

	// ========================================
	// PHASE E: ATOMIC DATABASE COMMIT
	// ========================================
	snapshotID, err := p.phaseCommit(ctx, config, normalizedRates, result.Stats.ContentHash)
	if err != nil {
		result.FailedPhase = PhaseCommit
		result.Error = err.Error()
		result.Duration = time.Since(start)
		return result, nil
	}
	result.PhasesCompleted = append(result.PhasesCompleted, PhaseCommit)
	result.SnapshotID = &snapshotID

	result.Success = true
	result.Duration = time.Since(start)
	return result, nil
}

// phaseFetch downloads raw pricing (NO DB WRITES)
func (p *Pipeline) phaseFetch(ctx context.Context, config *PipelineConfig) ([]RawPrice, error) {
	rawPrices, err := p.fetcher.FetchRegion(ctx, config.Region)
	if err != nil {
		return nil, fmt.Errorf("fetch failed for %s/%s: %w", config.Provider, config.Region, err)
	}

	if len(rawPrices) == 0 {
		return nil, fmt.Errorf("fetch returned 0 prices for %s/%s", config.Provider, config.Region)
	}

	return rawPrices, nil
}

// phaseNormalize transforms raw prices to canonical rates
func (p *Pipeline) phaseNormalize(ctx context.Context, rawPrices []RawPrice) ([]NormalizedRate, error) {
	normalized, err := p.normalizer.Normalize(rawPrices)
	if err != nil {
		return nil, fmt.Errorf("normalization failed: %w", err)
	}

	if len(normalized) == 0 {
		return nil, fmt.Errorf("normalization produced 0 rates")
	}

	return normalized, nil
}

// phaseValidate runs governance checks (abort on failure)
func (p *Pipeline) phaseValidate(ctx context.Context, config *PipelineConfig, rates []NormalizedRate) error {
	// Configure validator
	p.validator.SetMinCoveragePercent(config.MinCoveragePercent)

	// Get previous snapshot for coverage comparison
	prevSnapshot, _ := p.store.GetActiveSnapshot(ctx, config.Provider, config.Region, config.Alias)
	var prevRateCount int
	if prevSnapshot != nil {
		prevRateCount, _ = p.store.CountRates(ctx, prevSnapshot.ID)
	}

	// Run all validations
	return p.validator.ValidateAll(rates, prevRateCount)
}

// phaseBackup writes snapshot dump to local file
func (p *Pipeline) phaseBackup(ctx context.Context, config *PipelineConfig, rates []NormalizedRate, stats PipelineStats) (string, error) {
	backup := &SnapshotBackup{
		Provider:      config.Provider,
		Region:        config.Region,
		Alias:         config.Alias,
		Timestamp:     time.Now(),
		ContentHash:   stats.ContentHash,
		RateCount:     len(rates),
		SchemaVersion: "1.0",
		Rates:         rates,
	}

	return p.backupMgr.WriteBackup(config.BackupDir, backup)
}

// phaseCommit atomically writes to database
func (p *Pipeline) phaseCommit(ctx context.Context, config *PipelineConfig, rates []NormalizedRate, contentHash string) (uuid.UUID, error) {
	// Check for existing snapshot with same hash (idempotency)
	existing, _ := p.store.FindSnapshotByHash(ctx, config.Provider, config.Region, config.Alias, contentHash)
	if existing != nil {
		// Already ingested, return existing
		return existing.ID, nil
	}

	// Create snapshot in a single transaction
	snapshot := &db.PricingSnapshot{
		ID:            uuid.New(),
		Cloud:         config.Provider,
		Region:        config.Region,
		ProviderAlias: config.Alias,
		Source:        "manual_ingestion_pipeline",
		FetchedAt:     time.Now(),
		ValidFrom:     time.Now(),
		Hash:          contentHash,
		Version:       "1.0",
		IsActive:      false, // Not active until commit succeeds
	}

	// Begin transaction
	tx, err := p.store.BeginTx(ctx)
	if err != nil {
		return uuid.Nil, fmt.Errorf("failed to begin transaction: %w", err)
	}

	// Rollback on any error
	defer func() {
		if err != nil {
			tx.Rollback()
		}
	}()

	// Insert snapshot
	if err = tx.CreateSnapshot(ctx, snapshot); err != nil {
		return uuid.Nil, fmt.Errorf("failed to create snapshot: %w", err)
	}

	// Insert all rates
	for _, nr := range rates {
		nr.RateKey.ID = uuid.New()
		key, err := tx.UpsertRateKey(ctx, &nr.RateKey)
		if err != nil {
			return uuid.Nil, fmt.Errorf("failed to upsert rate key: %w", err)
		}

		rate := &db.PricingRate{
			ID:         uuid.New(),
			SnapshotID: snapshot.ID,
			RateKeyID:  key.ID,
			Unit:       nr.Unit,
			Price:      nr.Price,
			Currency:   nr.Currency,
			Confidence: nr.Confidence,
			TierMin:    nr.TierMin,
			TierMax:    nr.TierMax,
		}
		if err = tx.CreateRate(ctx, rate); err != nil {
			return uuid.Nil, fmt.Errorf("failed to create rate: %w", err)
		}
	}

	// Mark snapshot as ready and activate
	if err = tx.ActivateSnapshot(ctx, snapshot.ID); err != nil {
		return uuid.Nil, fmt.Errorf("failed to activate snapshot: %w", err)
	}

	// Commit transaction
	if err = tx.Commit(); err != nil {
		return uuid.Nil, fmt.Errorf("commit failed: %w", err)
	}

	return snapshot.ID, nil
}

// calculateHash computes a deterministic hash of rates
func calculateHash(rates []NormalizedRate) string {
	// Sort for determinism
	sorted := make([]NormalizedRate, len(rates))
	copy(sorted, rates)
	sort.Slice(sorted, func(i, j int) bool {
		ki := rateKeyString(sorted[i].RateKey)
		kj := rateKeyString(sorted[j].RateKey)
		return ki < kj
	})

	hasher := sha256.New()
	for _, r := range sorted {
		hasher.Write([]byte(rateKeyString(r.RateKey)))
		hasher.Write([]byte(r.Unit))
		hasher.Write([]byte(r.Price.String()))
	}

	return hex.EncodeToString(hasher.Sum(nil))
}

func rateKeyString(k db.RateKey) string {
	attrs := make([]string, 0, len(k.Attributes))
	for k, v := range k.Attributes {
		attrs = append(attrs, k+"="+v)
	}
	sort.Strings(attrs)
	return fmt.Sprintf("%s|%s|%s|%s|%s", k.Cloud, k.Service, k.ProductFamily, k.Region, strings.Join(attrs, ","))
}

func countUniqueServices(rates []NormalizedRate) int {
	services := make(map[string]bool)
	for _, r := range rates {
		services[r.RateKey.Service] = true
	}
	return len(services)
}

// NormalizeAttributes canonicalizes attribute keys and values
func NormalizeAttributes(raw map[string]string) map[string]string {
	result := make(map[string]string)
	for k, v := range raw {
		key := strings.ToLower(strings.ReplaceAll(k, " ", "_"))
		val := strings.ToLower(strings.TrimSpace(v))
		result[key] = val
	}
	return result
}

// ParsePrice parses a price string to decimal
func ParsePrice(s string) (decimal.Decimal, error) {
	s = strings.TrimSpace(s)
	if s == "" {
		return decimal.Zero, nil
	}
	return decimal.NewFromString(s)
}

// MarshalRateKey converts a RateKey to JSON for storage
func MarshalRateKey(k db.RateKey) ([]byte, error) {
	return json.Marshal(k.Attributes)
}

################################################################################
# FILE: :\good projects\cost estimation\db\ingestion\pipeline_test.go
# TYPE: go
# SIZE: 4606 bytes
################################################################################
// Package ingestion - Pipeline tests
package ingestion

import (
	"testing"

	"terraform-cost/db"

	"github.com/shopspring/decimal"
)

func TestValidatePricesPositive(t *testing.T) {
	validator := NewIngestionValidator()

	// Valid prices
	validRates := []NormalizedRate{
		{Price: decimal.NewFromFloat(0.10)},
		{Price: decimal.NewFromFloat(0.0)},
		{Price: decimal.NewFromFloat(100.00)},
	}
	if err := validator.ValidatePricesPositive(validRates); err != nil {
		t.Errorf("expected valid prices to pass, got: %v", err)
	}

	// Invalid negative price
	invalidRates := []NormalizedRate{
		{Price: decimal.NewFromFloat(-0.10)},
	}
	if err := validator.ValidatePricesPositive(invalidRates); err == nil {
		t.Error("expected negative price to fail validation")
	}
}

func TestValidateNoDuplicates(t *testing.T) {
	validator := NewIngestionValidator()

	// Unique rates
	uniqueRates := []NormalizedRate{
		{RateKey: db.RateKey{Cloud: db.AWS, Service: "EC2", Region: "us-east-1", Attributes: map[string]string{"type": "t3.micro"}}},
		{RateKey: db.RateKey{Cloud: db.AWS, Service: "EC2", Region: "us-east-1", Attributes: map[string]string{"type": "t3.small"}}},
	}
	if err := validator.ValidateNoDuplicates(uniqueRates); err != nil {
		t.Errorf("expected unique rates to pass, got: %v", err)
	}

	// Duplicate rates
	duplicateRates := []NormalizedRate{
		{RateKey: db.RateKey{Cloud: db.AWS, Service: "EC2", Region: "us-east-1", Attributes: map[string]string{"type": "t3.micro"}}},
		{RateKey: db.RateKey{Cloud: db.AWS, Service: "EC2", Region: "us-east-1", Attributes: map[string]string{"type": "t3.micro"}}},
	}
	if err := validator.ValidateNoDuplicates(duplicateRates); err == nil {
		t.Error("expected duplicate rates to fail validation")
	}
}

func TestValidateCoverageNotDecreased(t *testing.T) {
	validator := NewIngestionValidator()
	validator.SetMinCoveragePercent(95.0)

	// Coverage maintained
	if err := validator.ValidateCoverageNotDecreased(100, 100); err != nil {
		t.Errorf("expected same coverage to pass, got: %v", err)
	}

	// Coverage increased
	if err := validator.ValidateCoverageNotDecreased(110, 100); err != nil {
		t.Errorf("expected increased coverage to pass, got: %v", err)
	}

	// Coverage slightly decreased (still above 95%)
	if err := validator.ValidateCoverageNotDecreased(96, 100); err != nil {
		t.Errorf("expected 96%% coverage to pass, got: %v", err)
	}

	// Coverage decreased below threshold
	if err := validator.ValidateCoverageNotDecreased(90, 100); err == nil {
		t.Error("expected 90%% coverage to fail validation")
	}
}

func TestBackupWriteRead(t *testing.T) {
	backup := &SnapshotBackup{
		Provider:      db.AWS,
		Region:        "us-east-1",
		Alias:         "default",
		ContentHash:   "abc123",
		RateCount:     2,
		SchemaVersion: "1.0",
		Rates: []NormalizedRate{
			{
				RateKey: db.RateKey{
					Cloud:   db.AWS,
					Service: "EC2",
					Region:  "us-east-1",
				},
				Price: decimal.NewFromFloat(0.10),
			},
			{
				RateKey: db.RateKey{
					Cloud:   db.AWS,
					Service: "RDS",
					Region:  "us-east-1",
				},
				Price: decimal.NewFromFloat(0.20),
			},
		},
	}

	// Recalculate hash to match
	backup.ContentHash = calculateHash(backup.Rates)

	mgr := NewBackupManager()
	
	// Write to temp directory
	path, err := mgr.WriteBackup(t.TempDir(), backup)
	if err != nil {
		t.Fatalf("failed to write backup: %v", err)
	}

	// Read back
	readBackup, err := mgr.ReadBackup(path)
	if err != nil {
		t.Fatalf("failed to read backup: %v", err)
	}

	// Verify
	if readBackup.Provider != backup.Provider {
		t.Errorf("provider mismatch: got %s, want %s", readBackup.Provider, backup.Provider)
	}
	if readBackup.RateCount != backup.RateCount {
		t.Errorf("rate count mismatch: got %d, want %d", readBackup.RateCount, backup.RateCount)
	}
	if len(readBackup.Rates) != len(backup.Rates) {
		t.Errorf("rates length mismatch: got %d, want %d", len(readBackup.Rates), len(backup.Rates))
	}
}

func TestPipelineResult(t *testing.T) {
	// Verify PipelineResult structure
	result := &PipelineResult{
		Success:         true,
		PhasesCompleted: []Phase{PhaseFetch, PhaseNormalize, PhaseValidate, PhaseBackup, PhaseCommit},
		Stats: PipelineStats{
			RawPricesCount:       100,
			NormalizedRatesCount: 95,
			UniqueServicesCount:  5,
		},
	}

	if !result.Success {
		t.Error("expected success")
	}
	if len(result.PhasesCompleted) != 5 {
		t.Errorf("expected 5 phases, got %d", len(result.PhasesCompleted))
	}
}

################################################################################
# FILE: :\good projects\cost estimation\db\migrations\001_pricing_schema.sql
# TYPE: sql
# SIZE: 8957 bytes
################################################################################
-- Terraform Cost Estimation - Pricing Database Schema
-- PostgreSQL 16+

-- =============================================================================
-- PRICING SNAPSHOTS (IMMUTABLE)
-- =============================================================================
-- Each snapshot represents a point-in-time capture of pricing data.
-- Snapshots are immutable once created - no updates allowed.

CREATE TABLE pricing_snapshots (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    cloud           TEXT NOT NULL CHECK (cloud IN ('aws', 'azure', 'gcp')),
    region          TEXT NOT NULL,
    provider_alias  TEXT NOT NULL DEFAULT 'default',
    source          TEXT NOT NULL,  -- aws_pricing_api, azure_retail, gcp_catalog
    fetched_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    valid_from      TIMESTAMPTZ NOT NULL,
    valid_to        TIMESTAMPTZ,
    hash            TEXT NOT NULL,  -- SHA256 content hash for deduplication
    version         TEXT NOT NULL DEFAULT '1.0',
    is_active       BOOLEAN NOT NULL DEFAULT FALSE,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_snapshot UNIQUE (cloud, region, provider_alias, hash)
);

-- Ensure only one active snapshot per cloud/region/alias combination
CREATE UNIQUE INDEX idx_active_snapshot 
ON pricing_snapshots (cloud, region, provider_alias) 
WHERE is_active = TRUE;

CREATE INDEX idx_snapshots_lookup ON pricing_snapshots (cloud, region, provider_alias, is_active);

-- =============================================================================
-- RATE KEYS (NORMALIZED)
-- =============================================================================
-- RateKeys are the unique identifiers for pricing lookups.
-- Matches the RateKey struct in Go exactly.

CREATE TABLE pricing_rate_keys (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    cloud           TEXT NOT NULL CHECK (cloud IN ('aws', 'azure', 'gcp')),
    service         TEXT NOT NULL,        -- AmazonEC2, AmazonRDS, etc.
    product_family  TEXT NOT NULL,        -- Compute Instance, Storage, etc.
    region          TEXT NOT NULL,
    attributes      JSONB NOT NULL,       -- {instanceType, os, tenancy, tier, etc.}
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_rate_key UNIQUE (cloud, service, product_family, region, attributes)
);

CREATE INDEX idx_rate_keys_lookup 
ON pricing_rate_keys (cloud, service, product_family, region);

CREATE INDEX idx_rate_keys_attributes 
ON pricing_rate_keys USING GIN (attributes);

-- =============================================================================
-- PRICING RATES (THE MONEY)
-- =============================================================================
-- Actual prices tied to snapshots and rate keys.
-- Supports tiered pricing (S3, data transfer, free tiers).

CREATE TABLE pricing_rates (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    snapshot_id     UUID NOT NULL REFERENCES pricing_snapshots(id) ON DELETE CASCADE,
    rate_key_id     UUID NOT NULL REFERENCES pricing_rate_keys(id) ON DELETE CASCADE,
    unit            TEXT NOT NULL,        -- hours, GB-month, requests, GB
    price           NUMERIC(20, 10) NOT NULL,
    currency        TEXT NOT NULL DEFAULT 'USD',
    confidence      FLOAT NOT NULL DEFAULT 1.0 CHECK (confidence > 0 AND confidence <= 1),
    tier_min        NUMERIC,              -- NULL for non-tiered pricing
    tier_max        NUMERIC,              -- NULL for unlimited tier
    effective_date  DATE,                 -- When this price became effective
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_rate UNIQUE (snapshot_id, rate_key_id, unit, tier_min, tier_max)
);

CREATE INDEX idx_rates_snapshot ON pricing_rates (snapshot_id);
CREATE INDEX idx_rates_rate_key ON pricing_rates (rate_key_id);
CREATE INDEX idx_rates_lookup ON pricing_rates (snapshot_id, rate_key_id);

-- =============================================================================
-- PRICING METADATA
-- =============================================================================
-- Optional key-value metadata for snapshots.

CREATE TABLE pricing_metadata (
    snapshot_id     UUID NOT NULL REFERENCES pricing_snapshots(id) ON DELETE CASCADE,
    key             TEXT NOT NULL,
    value           TEXT NOT NULL,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    PRIMARY KEY (snapshot_id, key)
);

-- =============================================================================
-- SERVICE CATALOG (Reference Data)
-- =============================================================================
-- Maps service names to product families for validation.

CREATE TABLE service_catalog (
    cloud           TEXT NOT NULL CHECK (cloud IN ('aws', 'azure', 'gcp')),
    service         TEXT NOT NULL,
    product_family  TEXT NOT NULL,
    description     TEXT,
    is_billable     BOOLEAN NOT NULL DEFAULT TRUE,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    PRIMARY KEY (cloud, service, product_family)
);

-- =============================================================================
-- FUNCTIONS
-- =============================================================================

-- Activate a snapshot (deactivates all others for same cloud/region/alias)
CREATE OR REPLACE FUNCTION activate_snapshot(p_snapshot_id UUID)
RETURNS VOID AS $$
DECLARE
    v_cloud TEXT;
    v_region TEXT;
    v_alias TEXT;
BEGIN
    -- Get snapshot details
    SELECT cloud, region, provider_alias 
    INTO v_cloud, v_region, v_alias
    FROM pricing_snapshots 
    WHERE id = p_snapshot_id;
    
    IF NOT FOUND THEN
        RAISE EXCEPTION 'Snapshot not found: %', p_snapshot_id;
    END IF;
    
    -- Deactivate existing
    UPDATE pricing_snapshots
    SET is_active = FALSE
    WHERE cloud = v_cloud 
      AND region = v_region 
      AND provider_alias = v_alias
      AND is_active = TRUE;
    
    -- Activate new
    UPDATE pricing_snapshots
    SET is_active = TRUE
    WHERE id = p_snapshot_id;
END;
$$ LANGUAGE plpgsql;

-- Get rate for a rate key from active snapshot
CREATE OR REPLACE FUNCTION get_active_rate(
    p_cloud TEXT,
    p_service TEXT,
    p_product_family TEXT,
    p_region TEXT,
    p_attributes JSONB,
    p_unit TEXT,
    p_provider_alias TEXT DEFAULT 'default'
)
RETURNS TABLE (
    price NUMERIC,
    currency TEXT,
    confidence FLOAT,
    tier_min NUMERIC,
    tier_max NUMERIC,
    snapshot_id UUID
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        pr.price,
        pr.currency,
        pr.confidence,
        pr.tier_min,
        pr.tier_max,
        ps.id as snapshot_id
    FROM pricing_snapshots ps
    JOIN pricing_rate_keys rk ON rk.cloud = ps.cloud AND rk.region = ps.region
    JOIN pricing_rates pr ON pr.snapshot_id = ps.id AND pr.rate_key_id = rk.id
    WHERE ps.cloud = p_cloud
      AND ps.region = p_region
      AND ps.provider_alias = p_provider_alias
      AND ps.is_active = TRUE
      AND rk.service = p_service
      AND rk.product_family = p_product_family
      AND rk.attributes @> p_attributes
      AND pr.unit = p_unit
    ORDER BY pr.tier_min NULLS FIRST;
END;
$$ LANGUAGE plpgsql;

-- =============================================================================
-- SEED DATA - Common Services
-- =============================================================================

INSERT INTO service_catalog (cloud, service, product_family, description, is_billable) VALUES
-- AWS
('aws', 'AmazonEC2', 'Compute Instance', 'EC2 On-Demand Instances', true),
('aws', 'AmazonEC2', 'Storage', 'EBS Volumes', true),
('aws', 'AmazonEC2', 'Data Transfer', 'EC2 Data Transfer', true),
('aws', 'AmazonRDS', 'Database Instance', 'RDS Instances', true),
('aws', 'AmazonRDS', 'Database Storage', 'RDS Storage', true),
('aws', 'AmazonS3', 'Storage', 'S3 Standard Storage', true),
('aws', 'AmazonS3', 'Data Transfer', 'S3 Data Transfer', true),
('aws', 'AWSLambda', 'Serverless', 'Lambda Functions', true),
('aws', 'AmazonDynamoDB', 'Database', 'DynamoDB Tables', true),
('aws', 'AmazonVPC', 'Networking', 'NAT Gateway', true),
('aws', 'ElasticLoadBalancing', 'Networking', 'Load Balancers', true),
-- Azure
('azure', 'Virtual Machines', 'Compute', 'Azure VMs', true),
('azure', 'Storage', 'Storage', 'Managed Disks', true),
('azure', 'SQL Database', 'Database', 'Azure SQL', true),
('azure', 'Cosmos DB', 'Database', 'CosmosDB', true),
-- GCP
('gcp', 'Compute Engine', 'Compute', 'GCE Instances', true),
('gcp', 'Cloud Storage', 'Storage', 'GCS Buckets', true),
('gcp', 'Cloud SQL', 'Database', 'Cloud SQL Instances', true),
('gcp', 'BigQuery', 'Analytics', 'BigQuery', true)
ON CONFLICT DO NOTHING;

################################################################################
# FILE: :\good projects\cost estimation\db\migrations\002_pricing_dimensions.sql
# TYPE: sql
# SIZE: 9576 bytes
################################################################################
-- Terraform Cost Estimation - Pricing Dimensions Schema
-- Phase 2: First-class dimension tables for scalable pricing

-- =============================================================================
-- PRICING DIMENSIONS (FIRST-CLASS)
-- =============================================================================
-- Dimensions are independently queryable, not embedded in JSONB.
-- This enables exact matching, partial fallback, and dimension evolution.

CREATE TABLE pricing_dimensions (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    key             TEXT NOT NULL,              -- "instance_type", "storage_class", "os"
    value           TEXT NOT NULL,              -- "t3.medium", "STANDARD_IA", "linux"
    normalized_value TEXT NOT NULL,             -- Canonical lowercase form
    cloud           TEXT NOT NULL CHECK (cloud IN ('aws', 'azure', 'gcp')),
    category        TEXT,                       -- "compute", "storage", "network"
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_dimension UNIQUE (cloud, key, value)
);

CREATE INDEX idx_dimensions_lookup ON pricing_dimensions (cloud, key, normalized_value);
CREATE INDEX idx_dimensions_category ON pricing_dimensions (cloud, category, key);

-- =============================================================================
-- PRICING RATE DIMENSIONS (JOIN TABLE)
-- =============================================================================
-- Maps rates to their dimensions for exact and partial matching.

CREATE TABLE pricing_rate_dimensions (
    rate_id         UUID NOT NULL REFERENCES pricing_rates(id) ON DELETE CASCADE,
    dimension_id    UUID NOT NULL REFERENCES pricing_dimensions(id) ON DELETE CASCADE,
    is_primary      BOOLEAN NOT NULL DEFAULT TRUE,  -- Primary vs fallback dimension
    
    PRIMARY KEY (rate_id, dimension_id)
);

CREATE INDEX idx_rate_dimensions_rate ON pricing_rate_dimensions (rate_id);
CREATE INDEX idx_rate_dimensions_dim ON pricing_rate_dimensions (dimension_id);

-- =============================================================================
-- INGESTION GOVERNANCE
-- =============================================================================
-- Tracks ingestion state to prevent partial/corrupted snapshots.

CREATE TABLE pricing_snapshot_ingestion (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    snapshot_id     UUID NOT NULL REFERENCES pricing_snapshots(id) ON DELETE CASCADE,
    provider        TEXT NOT NULL,
    status          TEXT NOT NULL CHECK (status IN ('started', 'in_progress', 'completed', 'failed')),
    record_count    INT NOT NULL DEFAULT 0,
    dimension_count INT NOT NULL DEFAULT 0,
    checksum        TEXT,
    error_message   TEXT,
    started_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    completed_at    TIMESTAMPTZ,
    
    CONSTRAINT unique_snapshot_ingestion UNIQUE (snapshot_id)
);

CREATE INDEX idx_ingestion_status ON pricing_snapshot_ingestion (status);
CREATE INDEX idx_ingestion_snapshot ON pricing_snapshot_ingestion (snapshot_id);

-- =============================================================================
-- INGESTION CONTRACTS
-- =============================================================================
-- Defines required dimensions and minimum rates per service.

CREATE TABLE ingestion_contracts (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    cloud           TEXT NOT NULL CHECK (cloud IN ('aws', 'azure', 'gcp')),
    service         TEXT NOT NULL,
    required_dimensions TEXT[] NOT NULL,        -- {"instance_type", "os", "region"}
    min_rate_count  INT NOT NULL DEFAULT 1,
    is_active       BOOLEAN NOT NULL DEFAULT TRUE,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_contract UNIQUE (cloud, service)
);

-- Seed contracts for high-impact services
INSERT INTO ingestion_contracts (cloud, service, required_dimensions, min_rate_count) VALUES
('aws', 'AmazonEC2', ARRAY['instance_type', 'os', 'tenancy'], 100),
('aws', 'AmazonRDS', ARRAY['instance_type', 'engine'], 50),
('aws', 'AmazonS3', ARRAY['storage_class'], 10),
('aws', 'AWSLambda', ARRAY['memory_size'], 5),
('aws', 'ElasticLoadBalancing', ARRAY['product_family'], 5),
('azure', 'Virtual Machines', ARRAY['vm_size', 'os'], 100),
('azure', 'Storage', ARRAY['redundancy', 'tier'], 20),
('gcp', 'Compute Engine', ARRAY['machine_type'], 100),
('gcp', 'Cloud Storage', ARRAY['storage_class'], 10)
ON CONFLICT DO NOTHING;

-- =============================================================================
-- SNAPSHOT VERSIONING METADATA
-- =============================================================================
-- Tracks source information for audits.

CREATE TABLE pricing_snapshot_source (
    snapshot_id     UUID PRIMARY KEY REFERENCES pricing_snapshots(id) ON DELETE CASCADE,
    api_version     TEXT,                       -- AWS Pricing API version
    source_url      TEXT,                       -- Bulk file URL or API endpoint
    extraction_time TIMESTAMPTZ NOT NULL,
    pricing_date    DATE,                       -- Effective pricing date
    currency        TEXT NOT NULL DEFAULT 'USD',
    notes           TEXT,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- =============================================================================
-- DIMENSION FALLBACK RULES
-- =============================================================================
-- Defines fallback hierarchy for dimension matching.

CREATE TABLE dimension_fallback_rules (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    cloud           TEXT NOT NULL CHECK (cloud IN ('aws', 'azure', 'gcp')),
    dimension_key   TEXT NOT NULL,              -- "instance_type"
    fallback_key    TEXT NOT NULL,              -- "instance_family"
    confidence_penalty FLOAT NOT NULL DEFAULT 0.1,
    priority        INT NOT NULL DEFAULT 0,
    
    CONSTRAINT unique_fallback UNIQUE (cloud, dimension_key, fallback_key)
);

-- Seed fallback rules
INSERT INTO dimension_fallback_rules (cloud, dimension_key, fallback_key, confidence_penalty, priority) VALUES
('aws', 'instance_type', 'instance_family', 0.15, 1),
('aws', 'tenancy', 'default_tenancy', 0.05, 1),
('azure', 'vm_size', 'vm_family', 0.15, 1),
('gcp', 'machine_type', 'machine_family', 0.15, 1)
ON CONFLICT DO NOTHING;

-- =============================================================================
-- FUNCTIONS
-- =============================================================================

-- Validate ingestion against contract
CREATE OR REPLACE FUNCTION validate_ingestion(p_snapshot_id UUID)
RETURNS TABLE (
    is_valid BOOLEAN,
    missing_dimensions TEXT[],
    rate_count INT,
    required_count INT
) AS $$
DECLARE
    v_cloud TEXT;
    v_service TEXT;
BEGIN
    -- Get snapshot info
    SELECT cloud INTO v_cloud FROM pricing_snapshots WHERE id = p_snapshot_id;
    
    -- Get rate counts and validate against contracts
    RETURN QUERY
    SELECT 
        CASE WHEN COUNT(*) >= c.min_rate_count THEN TRUE ELSE FALSE END as is_valid,
        ARRAY[]::TEXT[] as missing_dimensions,
        COUNT(*)::INT as rate_count,
        c.min_rate_count as required_count
    FROM pricing_rates pr
    JOIN pricing_snapshots ps ON pr.snapshot_id = ps.id
    LEFT JOIN ingestion_contracts c ON c.cloud = ps.cloud
    WHERE pr.snapshot_id = p_snapshot_id
    GROUP BY c.min_rate_count;
END;
$$ LANGUAGE plpgsql;

-- Mark ingestion complete
CREATE OR REPLACE FUNCTION complete_ingestion(
    p_snapshot_id UUID,
    p_checksum TEXT
) RETURNS VOID AS $$
DECLARE
    v_rate_count INT;
    v_dim_count INT;
BEGIN
    -- Get counts
    SELECT COUNT(*) INTO v_rate_count FROM pricing_rates WHERE snapshot_id = p_snapshot_id;
    SELECT COUNT(DISTINCT dimension_id) INTO v_dim_count 
    FROM pricing_rate_dimensions prd
    JOIN pricing_rates pr ON prd.rate_id = pr.id
    WHERE pr.snapshot_id = p_snapshot_id;
    
    -- Update ingestion status
    UPDATE pricing_snapshot_ingestion
    SET status = 'completed',
        record_count = v_rate_count,
        dimension_count = v_dim_count,
        checksum = p_checksum,
        completed_at = NOW()
    WHERE snapshot_id = p_snapshot_id;
END;
$$ LANGUAGE plpgsql;

-- Get rate with dimension fallback
CREATE OR REPLACE FUNCTION get_rate_with_fallback(
    p_cloud TEXT,
    p_service TEXT,
    p_region TEXT,
    p_dimensions JSONB,
    p_unit TEXT,
    p_alias TEXT DEFAULT 'default'
)
RETURNS TABLE (
    price NUMERIC,
    confidence FLOAT,
    is_fallback BOOLEAN,
    matched_dimensions JSONB
) AS $$
BEGIN
    -- Try exact match first
    RETURN QUERY
    SELECT 
        pr.price,
        pr.confidence,
        FALSE as is_fallback,
        rk.attributes as matched_dimensions
    FROM pricing_snapshots ps
    JOIN pricing_rate_keys rk ON rk.cloud = ps.cloud AND rk.region = ps.region
    JOIN pricing_rates pr ON pr.snapshot_id = ps.id AND pr.rate_key_id = rk.id
    WHERE ps.cloud = p_cloud
      AND ps.region = p_region
      AND ps.provider_alias = p_alias
      AND ps.is_active = TRUE
      AND rk.service = p_service
      AND rk.attributes @> p_dimensions
      AND pr.unit = p_unit
    LIMIT 1;
    
    -- If no exact match, fallback logic would go here
    -- (simplified for initial implementation)
END;
$$ LANGUAGE plpgsql;

################################################################################
# FILE: :\good projects\cost estimation\db\migrations\003_scale_hardening.sql
# TYPE: sql
# SIZE: 12839 bytes
################################################################################
-- Terraform Cost Estimation - Scale Hardening Schema
-- Phase 3: Coverage tracking, dimension filtering, drift detection

-- =============================================================================
-- SNAPSHOT COVERAGE TRACKING
-- =============================================================================
-- Tracks completeness per service to prevent partial ingestion.

CREATE TABLE pricing_snapshot_coverage (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    snapshot_id     UUID NOT NULL REFERENCES pricing_snapshots(id) ON DELETE CASCADE,
    service         TEXT NOT NULL,
    rate_count      INT NOT NULL DEFAULT 0,
    dimension_count INT NOT NULL DEFAULT 0,
    coverage_percent FLOAT NOT NULL DEFAULT 0,
    missing_dimensions TEXT[] DEFAULT '{}',
    is_complete     BOOLEAN NOT NULL DEFAULT FALSE,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_snapshot_service_coverage UNIQUE (snapshot_id, service)
);

CREATE INDEX idx_coverage_snapshot ON pricing_snapshot_coverage (snapshot_id);
CREATE INDEX idx_coverage_complete ON pricing_snapshot_coverage (snapshot_id, is_complete);

-- =============================================================================
-- DIMENSION ALLOW-LISTS
-- =============================================================================
-- Prevents dimension explosion by filtering at ingestion time.

CREATE TABLE dimension_allowlists (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    cloud           TEXT NOT NULL CHECK (cloud IN ('aws', 'azure', 'gcp')),
    service         TEXT NOT NULL,
    dimension_key   TEXT NOT NULL,
    is_required     BOOLEAN NOT NULL DEFAULT FALSE,
    priority        INT NOT NULL DEFAULT 0,  -- Higher = more important
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_dimension_allowlist UNIQUE (cloud, service, dimension_key)
);

CREATE INDEX idx_allowlist_service ON dimension_allowlists (cloud, service);

-- Seed dimension allow-lists for AWS high-impact services
INSERT INTO dimension_allowlists (cloud, service, dimension_key, is_required, priority) VALUES
-- EC2
('aws', 'AmazonEC2', 'instance_type', TRUE, 100),
('aws', 'AmazonEC2', 'os', TRUE, 90),
('aws', 'AmazonEC2', 'tenancy', FALSE, 80),
('aws', 'AmazonEC2', 'region', TRUE, 100),
('aws', 'AmazonEC2', 'volume_type', FALSE, 70),
('aws', 'AmazonEC2', 'capacity_status', FALSE, 50),
-- RDS
('aws', 'AmazonRDS', 'instance_type', TRUE, 100),
('aws', 'AmazonRDS', 'engine', TRUE, 90),
('aws', 'AmazonRDS', 'deployment', FALSE, 70),
('aws', 'AmazonRDS', 'region', TRUE, 100),
-- Lambda
('aws', 'AWSLambda', 'memory_size', FALSE, 80),
('aws', 'AWSLambda', 'architecture', FALSE, 60),
('aws', 'AWSLambda', 'region', TRUE, 100),
-- S3
('aws', 'AmazonS3', 'storage_class', TRUE, 100),
('aws', 'AmazonS3', 'region', TRUE, 100),
-- ELB
('aws', 'ElasticLoadBalancing', 'product_family', TRUE, 100),
('aws', 'ElasticLoadBalancing', 'region', TRUE, 100),
-- DynamoDB
('aws', 'AmazonDynamoDB', 'read_capacity', FALSE, 80),
('aws', 'AmazonDynamoDB', 'write_capacity', FALSE, 80),
('aws', 'AmazonDynamoDB', 'region', TRUE, 100)
ON CONFLICT DO NOTHING;

-- =============================================================================
-- PRICING DRIFT DETECTION
-- =============================================================================
-- Stores differences between snapshots for alerting.

CREATE TABLE pricing_drift_records (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    old_snapshot_id UUID NOT NULL REFERENCES pricing_snapshots(id) ON DELETE CASCADE,
    new_snapshot_id UUID NOT NULL REFERENCES pricing_snapshots(id) ON DELETE CASCADE,
    cloud           TEXT NOT NULL,
    service         TEXT NOT NULL,
    product_family  TEXT NOT NULL,
    dimension_key   TEXT,
    dimension_value TEXT,
    old_price       NUMERIC(20,10) NOT NULL,
    new_price       NUMERIC(20,10) NOT NULL,
    price_delta     NUMERIC(20,10) NOT NULL,
    percent_change  FLOAT NOT NULL,
    unit            TEXT NOT NULL,
    drift_type      TEXT NOT NULL CHECK (drift_type IN ('increase', 'decrease', 'new', 'removed')),
    is_significant  BOOLEAN NOT NULL DEFAULT FALSE,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_drift_record UNIQUE (old_snapshot_id, new_snapshot_id, service, dimension_key, dimension_value, unit)
);

CREATE INDEX idx_drift_snapshots ON pricing_drift_records (old_snapshot_id, new_snapshot_id);
CREATE INDEX idx_drift_significant ON pricing_drift_records (is_significant) WHERE is_significant = TRUE;
CREATE INDEX idx_drift_service ON pricing_drift_records (service, drift_type);

-- Drift summary per snapshot comparison
CREATE TABLE pricing_drift_summary (
    id                  UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    old_snapshot_id     UUID NOT NULL REFERENCES pricing_snapshots(id) ON DELETE CASCADE,
    new_snapshot_id     UUID NOT NULL REFERENCES pricing_snapshots(id) ON DELETE CASCADE,
    cloud               TEXT NOT NULL,
    total_changes       INT NOT NULL DEFAULT 0,
    price_increases     INT NOT NULL DEFAULT 0,
    price_decreases     INT NOT NULL DEFAULT 0,
    new_rates           INT NOT NULL DEFAULT 0,
    removed_rates       INT NOT NULL DEFAULT 0,
    avg_percent_change  FLOAT,
    max_percent_change  FLOAT,
    significant_changes INT NOT NULL DEFAULT 0,
    created_at          TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_drift_summary UNIQUE (old_snapshot_id, new_snapshot_id)
);

-- =============================================================================
-- FUNCTIONS
-- =============================================================================

-- Calculate snapshot coverage for a service
CREATE OR REPLACE FUNCTION calculate_service_coverage(
    p_snapshot_id UUID,
    p_service TEXT
) RETURNS TABLE (
    rate_count INT,
    dimension_count INT, 
    coverage_percent FLOAT,
    missing_dimensions TEXT[],
    is_complete BOOLEAN
) AS $$
DECLARE
    v_cloud TEXT;
    v_required_dims TEXT[];
    v_present_dims TEXT[];
    v_missing TEXT[];
    v_rate_count INT;
    v_min_rates INT;
BEGIN
    -- Get cloud from snapshot
    SELECT cloud INTO v_cloud FROM pricing_snapshots WHERE id = p_snapshot_id;
    
    -- Get required dimensions
    SELECT ARRAY_AGG(dimension_key) INTO v_required_dims
    FROM dimension_allowlists
    WHERE cloud = v_cloud AND service = p_service AND is_required = TRUE;
    
    -- Get present dimensions from rates
    SELECT ARRAY_AGG(DISTINCT key) INTO v_present_dims
    FROM pricing_rates pr
    JOIN pricing_rate_keys rk ON pr.rate_key_id = rk.id
    CROSS JOIN LATERAL jsonb_object_keys(rk.attributes) AS key
    WHERE pr.snapshot_id = p_snapshot_id AND rk.service = p_service;
    
    -- Count rates
    SELECT COUNT(*) INTO v_rate_count
    FROM pricing_rates pr
    JOIN pricing_rate_keys rk ON pr.rate_key_id = rk.id
    WHERE pr.snapshot_id = p_snapshot_id AND rk.service = p_service;
    
    -- Get minimum rate requirement
    SELECT min_rate_count INTO v_min_rates
    FROM ingestion_contracts
    WHERE cloud = v_cloud AND service = p_service;
    
    v_min_rates := COALESCE(v_min_rates, 1);
    
    -- Calculate missing dimensions
    IF v_required_dims IS NOT NULL AND v_present_dims IS NOT NULL THEN
        SELECT ARRAY_AGG(dim) INTO v_missing
        FROM unnest(v_required_dims) AS dim
        WHERE dim != ALL(v_present_dims);
    ELSE
        v_missing := v_required_dims;
    END IF;
    
    v_missing := COALESCE(v_missing, '{}');
    
    RETURN QUERY SELECT
        v_rate_count,
        COALESCE(array_length(v_present_dims, 1), 0),
        CASE WHEN v_min_rates > 0 THEN LEAST(v_rate_count::FLOAT / v_min_rates * 100, 100) ELSE 100.0 END,
        v_missing,
        v_rate_count >= v_min_rates AND array_length(v_missing, 1) IS NULL;
END;
$$ LANGUAGE plpgsql;

-- Detect drift between two snapshots
CREATE OR REPLACE FUNCTION detect_pricing_drift(
    p_old_snapshot_id UUID,
    p_new_snapshot_id UUID,
    p_significance_threshold FLOAT DEFAULT 0.05  -- 5% change is significant
) RETURNS INT AS $$
DECLARE
    v_changes_count INT := 0;
    v_cloud TEXT;
BEGIN
    -- Get cloud
    SELECT cloud INTO v_cloud FROM pricing_snapshots WHERE id = p_old_snapshot_id;
    
    -- Insert price changes
    INSERT INTO pricing_drift_records (
        old_snapshot_id, new_snapshot_id, cloud, service, product_family,
        dimension_key, dimension_value, old_price, new_price, price_delta,
        percent_change, unit, drift_type, is_significant
    )
    SELECT 
        p_old_snapshot_id,
        p_new_snapshot_id,
        v_cloud,
        COALESCE(old_rk.service, new_rk.service),
        COALESCE(old_rk.product_family, new_rk.product_family),
        NULL, NULL,
        COALESCE(old_pr.price, 0),
        COALESCE(new_pr.price, 0),
        COALESCE(new_pr.price, 0) - COALESCE(old_pr.price, 0),
        CASE 
            WHEN old_pr.price IS NULL OR old_pr.price = 0 THEN 100
            WHEN new_pr.price IS NULL THEN -100
            ELSE ((new_pr.price - old_pr.price) / old_pr.price * 100)::FLOAT
        END,
        COALESCE(old_pr.unit, new_pr.unit),
        CASE 
            WHEN old_pr.price IS NULL THEN 'new'
            WHEN new_pr.price IS NULL THEN 'removed'
            WHEN new_pr.price > old_pr.price THEN 'increase'
            ELSE 'decrease'
        END,
        ABS(CASE 
            WHEN old_pr.price IS NULL OR old_pr.price = 0 THEN 1
            WHEN new_pr.price IS NULL THEN 1
            ELSE ((new_pr.price - old_pr.price) / old_pr.price)::FLOAT
        END) >= p_significance_threshold
    FROM (
        SELECT pr.*, rk.service, rk.product_family, rk.attributes
        FROM pricing_rates pr
        JOIN pricing_rate_keys rk ON pr.rate_key_id = rk.id
        WHERE pr.snapshot_id = p_old_snapshot_id
    ) old_pr
    FULL OUTER JOIN (
        SELECT pr.*, rk.service, rk.product_family, rk.attributes
        FROM pricing_rates pr
        JOIN pricing_rate_keys rk ON pr.rate_key_id = rk.id
        WHERE pr.snapshot_id = p_new_snapshot_id
    ) new_pr ON old_pr.service = new_pr.service 
        AND old_pr.product_family = new_pr.product_family
        AND old_pr.attributes = new_pr.attributes
        AND old_pr.unit = new_pr.unit
    CROSS JOIN LATERAL (
        SELECT old_pr.service, old_pr.product_family AS old_rk_service
    ) AS old_rk
    CROSS JOIN LATERAL (
        SELECT new_pr.service, new_pr.product_family AS new_rk_service
    ) AS new_rk
    WHERE old_pr.price IS DISTINCT FROM new_pr.price
    ON CONFLICT DO NOTHING;
    
    GET DIAGNOSTICS v_changes_count = ROW_COUNT;
    
    -- Create summary
    INSERT INTO pricing_drift_summary (
        old_snapshot_id, new_snapshot_id, cloud,
        total_changes, price_increases, price_decreases,
        new_rates, removed_rates, avg_percent_change,
        max_percent_change, significant_changes
    )
    SELECT
        p_old_snapshot_id,
        p_new_snapshot_id,
        v_cloud,
        COUNT(*),
        COUNT(*) FILTER (WHERE drift_type = 'increase'),
        COUNT(*) FILTER (WHERE drift_type = 'decrease'),
        COUNT(*) FILTER (WHERE drift_type = 'new'),
        COUNT(*) FILTER (WHERE drift_type = 'removed'),
        AVG(percent_change),
        MAX(ABS(percent_change)),
        COUNT(*) FILTER (WHERE is_significant)
    FROM pricing_drift_records
    WHERE old_snapshot_id = p_old_snapshot_id AND new_snapshot_id = p_new_snapshot_id
    ON CONFLICT (old_snapshot_id, new_snapshot_id) DO UPDATE SET
        total_changes = EXCLUDED.total_changes,
        price_increases = EXCLUDED.price_increases,
        price_decreases = EXCLUDED.price_decreases,
        new_rates = EXCLUDED.new_rates,
        removed_rates = EXCLUDED.removed_rates,
        avg_percent_change = EXCLUDED.avg_percent_change,
        max_percent_change = EXCLUDED.max_percent_change,
        significant_changes = EXCLUDED.significant_changes;
    
    RETURN v_changes_count;
END;
$$ LANGUAGE plpgsql;

-- Check if snapshot is complete for strict mode
CREATE OR REPLACE FUNCTION is_snapshot_complete(
    p_snapshot_id UUID,
    p_min_coverage FLOAT DEFAULT 80.0
) RETURNS BOOLEAN AS $$
DECLARE
    v_all_complete BOOLEAN;
BEGIN
    SELECT bool_and(is_complete AND coverage_percent >= p_min_coverage)
    INTO v_all_complete
    FROM pricing_snapshot_coverage
    WHERE snapshot_id = p_snapshot_id;
    
    RETURN COALESCE(v_all_complete, FALSE);
END;
$$ LANGUAGE plpgsql;

################################################################################
# FILE: :\good projects\cost estimation\docs\COST_FORMULA_EXTRACTION.md
# TYPE: markdown
# SIZE: 6854 bytes
################################################################################
# Cost Formula Extraction Guide

This document explains how to extract pricing knowledge from `combined-resources.txt` (Infracost reference)
WITHOUT copying code.

## The Extraction Process

For each service, extract ONLY:

1. **Pricing Drivers** - Which Terraform attributes affect cost
2. **Usage Dependencies** - Which metrics are needed
3. **Pricing Products** - AWS/Azure/GCP product codes
4. **Cost Formulas** - How quantities map to billing units

## Template: Service Cost Formula

```yaml
service: aws_db_instance
cloud: aws

pricing_drivers:
  - attribute: instance_class
    example: "db.t3.medium"
    affects: hourly_rate
  - attribute: engine
    example: "mysql"
    affects: pricing_product
  - attribute: multi_az
    example: true
    affects: rate_multiplier (2x)
  - attribute: storage_type
    example: "gp2"
    affects: storage_rate
  - attribute: allocated_storage
    example: 100
    affects: storage_quantity
  - attribute: iops
    example: 3000
    affects: iops_quantity (io1 only)

usage_dependencies:
  - metric: monthly_hours
    default: 730
    confidence: 0.95
  - metric: storage_gb
    source: allocated_storage
    confidence: 1.0

cost_units:
  - name: instance
    measure: hours
    formula: monthly_hours
    rate_key:
      service: AmazonRDS
      product: Database Instance
      filters:
        instanceType: {instance_class}
        databaseEngine: {engine}
        deploymentOption: {multi_az ? "Multi-AZ" : "Single-AZ"}

  - name: storage
    measure: GB-months
    formula: allocated_storage
    rate_key:
      service: AmazonRDS
      product: Database Storage
      filters:
        volumeType: {storage_type}

  - name: iops (conditional: storage_type == "io1")
    measure: IOPS-months
    formula: iops
    rate_key:
      service: AmazonRDS
      product: Provisioned IOPS
```

---

## Extracted Formulas

### AWS EC2 (aws_instance)

```yaml
pricing_drivers:
  - instance_type: affects hourly_rate
  - tenancy: "default" | "dedicated" | "host"
  - ami: infers operating_system
  - ebs_optimized: adds surcharge for some types

cost_units:
  - name: compute
    measure: hours
    rate_key: AmazonEC2 / instance_type / os / tenancy

  - name: root_storage
    measure: GB-months
    source: root_block_device.volume_size
    rate_key: AmazonEC2 / EBS:VolumeUsage.{volume_type}
```

### AWS RDS (aws_db_instance)

```yaml
pricing_drivers:
  - instance_class: db.t3.micro, db.r5.large, etc.
  - engine: mysql, postgres, aurora-mysql, oracle-se2, sqlserver-se
  - multi_az: doubles instance cost
  - storage_type: gp2, gp3, io1, magnetic
  - allocated_storage: GB
  - iops: only for io1

cost_units:
  - name: instance
    rate_key: AmazonRDS / {engine} / {instance_class} / {deployment}

  - name: storage
    rate_key: AmazonRDS / {storage_type}

  - name: iops (io1 only)
    rate_key: AmazonRDS / PIOPS

  - name: backup
    rate_key: AmazonRDS / ChargedBackupUsage
```

### AWS S3 (aws_s3_bucket)

```yaml
pricing_drivers:
  - storage_class: STANDARD, INTELLIGENT_TIERING, GLACIER, etc.

usage_dependencies:
  - storage_gb: highly variable
  - put_requests: per 1000
  - get_requests: per 1000
  - data_transfer_out_gb: tiered

cost_units:
  - name: storage
    measure: GB-months
    rate_key: AmazonS3 / TimedStorage-{storage_class}

  - name: put_requests
    measure: requests/1000
    rate_key: AmazonS3 / Requests-Tier1

  - name: get_requests
    measure: requests/1000
    rate_key: AmazonS3 / Requests-Tier2

  - name: data_transfer
    measure: GB
    rate_key: AWSDataTransfer / AWS Outbound
```

### AWS Lambda (aws_lambda_function)

```yaml
pricing_drivers:
  - memory_size: 128-10240 MB
  - architectures: x86_64 | arm64 (20% cheaper)
  - ephemeral_storage.size: >512 MB has cost

usage_dependencies:
  - monthly_requests: symbolic if unknown
  - average_duration_ms: symbolic if unknown

cost_units:
  - name: requests
    measure: requests
    formula: monthly_requests
    rate_key: AWSLambda / Request
    free_tier: 1M requests

  - name: duration
    measure: GB-seconds
    formula: requests * (duration_ms/1000) * (memory_mb/1024)
    rate_key: AWSLambda / {architecture}
    free_tier: 400K GB-seconds

  - name: ephemeral_storage (if >512MB)
    measure: GB-seconds
    rate_key: AWSLambda / Lambda-Provisioned-GB-Second
```

### AWS NAT Gateway (aws_nat_gateway)

```yaml
pricing_drivers:
  - none (fixed pricing per region)

usage_dependencies:
  - monthly_hours: 730
  - data_processed_gb: highly variable

cost_units:
  - name: hourly
    measure: hours
    rate_key: AmazonEC2 / NatGateway-Hours

  - name: data_processed
    measure: GB
    rate_key: AmazonEC2 / NatGateway-Bytes
```

### AWS EKS (aws_eks_cluster)

```yaml
pricing_drivers:
  - none (fixed $0.10/hour per cluster)

cost_units:
  - name: control_plane
    measure: hours
    formula: 730
    rate: $0.10/hour (fixed)
    rate_key: AmazonEKS / AmazonEKS-Hours:perkubernetes
```

### AWS ElastiCache (aws_elasticache_cluster)

```yaml
pricing_drivers:
  - node_type: cache.t3.micro, cache.r5.large, etc.
  - engine: redis | memcached
  - num_cache_nodes: count

cost_units:
  - name: cache_nodes
    measure: node-hours
    formula: num_cache_nodes * monthly_hours
    rate_key: AmazonElastiCache / NodeUsage:{node_type}
```

### AWS DynamoDB (aws_dynamodb_table)

```yaml
pricing_drivers:
  - billing_mode: PROVISIONED | PAY_PER_REQUEST
  - read_capacity: RCU (provisioned only)
  - write_capacity: WCU (provisioned only)

usage_dependencies:
  - storage_gb: grows with data
  - read_request_units: on-demand only
  - write_request_units: on-demand only

cost_units:
  # Provisioned mode
  - name: read_capacity
    measure: RCU-hours
    formula: read_capacity * 730
    rate_key: AmazonDynamoDB / ReadCapacityUnit-Hrs

  - name: write_capacity
    measure: WCU-hours
    formula: write_capacity * 730
    rate_key: AmazonDynamoDB / WriteCapacityUnit-Hrs

  # On-demand mode
  - name: read_requests
    measure: RRU
    rate_key: AmazonDynamoDB / ReadRequestUnit

  - name: write_requests
    measure: WRU
    rate_key: AmazonDynamoDB / WriteRequestUnit

  # Both modes
  - name: storage
    measure: GB-months
    rate_key: AmazonDynamoDB / TimedStorage-ByteHrs
```

---

## What NOT To Copy From Infracost

1. **Struct definitions** - Use our own
2. **Registry patterns** - We have our own
3. **Usage population** - We use explicit UsageContext
4. **Default assumptions** - We emit symbolic costs
5. **Pricing API calls** - We use RateKey abstraction
6. **Error suppression** - We panic on invariant violations

################################################################################
# FILE: :\good projects\cost estimation\examples\aws-simple\main.tf
# TYPE: hcl
# SIZE: 1876 bytes
################################################################################
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = "us-east-1"
}

# EC2 Instance
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.medium"

  root_block_device {
    volume_type = "gp3"
    volume_size = 30
  }

  tags = {
    Name        = "web-server"
    Environment = "production"
  }
}

# RDS Database
resource "aws_db_instance" "main" {
  identifier        = "main-database"
  engine            = "postgres"
  engine_version    = "15.4"
  instance_class    = "db.t3.medium"
  allocated_storage = 100
  storage_type      = "gp2"

  db_name  = "myapp"
  username = "admin"
  password = "changeme123"

  multi_az            = false
  skip_final_snapshot = true

  tags = {
    Name        = "main-database"
    Environment = "production"
  }
}

# NAT Gateway
resource "aws_nat_gateway" "main" {
  allocation_id = "eipalloc-12345678"
  subnet_id     = "subnet-12345678"

  tags = {
    Name = "main-nat"
  }
}

# EBS Volume
resource "aws_ebs_volume" "data" {
  availability_zone = "us-east-1a"
  size              = 500
  type              = "gp3"
  iops              = 3000
  throughput        = 125

  tags = {
    Name = "data-volume"
  }
}

# Lambda Function
resource "aws_lambda_function" "api" {
  function_name = "api-handler"
  role          = "arn:aws:iam::123456789012:role/lambda-role"
  handler       = "index.handler"
  runtime       = "nodejs18.x"
  memory_size   = 256
  timeout       = 30

  filename = "function.zip"

  tags = {
    Name = "api-lambda"
  }
}

# S3 Bucket
resource "aws_s3_bucket" "assets" {
  bucket = "my-app-assets-bucket"

  tags = {
    Name        = "assets"
    Environment = "production"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\frontend\Dockerfile
# TYPE: text
# SIZE: 633 bytes
################################################################################
# Build stage
FROM node:20-alpine AS builder

WORKDIR /app

# Copy package files
COPY package.json package-lock.json ./

# Install dependencies
RUN npm ci

# Copy source
COPY . .

# Build for production
RUN npm run build

# Runtime stage
FROM nginx:alpine

# Copy built assets
COPY --from=builder /app/dist /usr/share/nginx/html

# Copy nginx config
COPY nginx.conf /etc/nginx/conf.d/default.conf

# Expose port
EXPOSE 80

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD wget -q --spider http://localhost/ || exit 1

CMD ["nginx", "-g", "daemon off;"]

################################################################################
# FILE: :\good projects\cost estimation\frontend\package.json
# TYPE: json
# SIZE: 900 bytes
################################################################################
{
  "name": "terraform-cost-ui",
  "private": true,
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "recharts": "^2.10.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.43",
    "@types/react-dom": "^18.2.17",
    "@typescript-eslint/eslint-plugin": "^6.14.0",
    "@typescript-eslint/parser": "^6.14.0",
    "@vitejs/plugin-react": "^4.2.1",
    "autoprefixer": "^10.4.16",
    "eslint": "^8.55.0",
    "eslint-plugin-react-hooks": "^4.6.0",
    "eslint-plugin-react-refresh": "^0.4.5",
    "postcss": "^8.4.32",
    "tailwindcss": "^3.4.0",
    "typescript": "^5.2.2",
    "vite": "^5.0.8"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\frontend\package-lock.json
# TYPE: json
# SIZE: 162196 bytes
################################################################################
{
  "name": "terraform-cost-ui",
  "version": "1.0.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "terraform-cost-ui",
      "version": "1.0.0",
      "dependencies": {
        "react": "^18.2.0",
        "react-dom": "^18.2.0",
        "recharts": "^2.10.0"
      },
      "devDependencies": {
        "@types/react": "^18.2.43",
        "@types/react-dom": "^18.2.17",
        "@typescript-eslint/eslint-plugin": "^6.14.0",
        "@typescript-eslint/parser": "^6.14.0",
        "@vitejs/plugin-react": "^4.2.1",
        "autoprefixer": "^10.4.16",
        "eslint": "^8.55.0",
        "eslint-plugin-react-hooks": "^4.6.0",
        "eslint-plugin-react-refresh": "^0.4.5",
        "postcss": "^8.4.32",
        "tailwindcss": "^3.4.0",
        "typescript": "^5.2.2",
        "vite": "^5.0.8"
      }
    },
    "node_modules/@alloc/quick-lru": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz",
      "integrity": "sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@babel/code-frame": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.28.6.tgz",
      "integrity": "sha512-JYgintcMjRiCvS8mMECzaEn+m3PfoQiyqukOMCCVQtoJGYJw8j/8LBJEiqkHLkfwCcs74E3pbAUFNg7d9VNJ+Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-validator-identifier": "^7.28.5",
        "js-tokens": "^4.0.0",
        "picocolors": "^1.1.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/compat-data": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/compat-data/-/compat-data-7.28.6.tgz",
      "integrity": "sha512-2lfu57JtzctfIrcGMz992hyLlByuzgIk58+hhGCxjKZ3rWI82NnVLjXcaTqkI2NvlcvOskZaiZ5kjUALo3Lpxg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/core": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/core/-/core-7.28.6.tgz",
      "integrity": "sha512-H3mcG6ZDLTlYfaSNi0iOKkigqMFvkTKlGUYlD8GW7nNOYRrevuA46iTypPyv+06V3fEmvvazfntkBU34L0azAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.28.6",
        "@babel/generator": "^7.28.6",
        "@babel/helper-compilation-targets": "^7.28.6",
        "@babel/helper-module-transforms": "^7.28.6",
        "@babel/helpers": "^7.28.6",
        "@babel/parser": "^7.28.6",
        "@babel/template": "^7.28.6",
        "@babel/traverse": "^7.28.6",
        "@babel/types": "^7.28.6",
        "@jridgewell/remapping": "^2.3.5",
        "convert-source-map": "^2.0.0",
        "debug": "^4.1.0",
        "gensync": "^1.0.0-beta.2",
        "json5": "^2.2.3",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/babel"
      }
    },
    "node_modules/@babel/core/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/@babel/generator": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/generator/-/generator-7.28.6.tgz",
      "integrity": "sha512-lOoVRwADj8hjf7al89tvQ2a1lf53Z+7tiXMgpZJL3maQPDxh0DgLMN62B2MKUOFcoodBHLMbDM6WAbKgNy5Suw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.28.6",
        "@babel/types": "^7.28.6",
        "@jridgewell/gen-mapping": "^0.3.12",
        "@jridgewell/trace-mapping": "^0.3.28",
        "jsesc": "^3.0.2"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-compilation-targets": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/helper-compilation-targets/-/helper-compilation-targets-7.28.6.tgz",
      "integrity": "sha512-JYtls3hqi15fcx5GaSNL7SCTJ2MNmjrkHXg4FSpOA/grxK8KwyZ5bubHsCq8FXCkua6xhuaaBit+3b7+VZRfcA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/compat-data": "^7.28.6",
        "@babel/helper-validator-option": "^7.27.1",
        "browserslist": "^4.24.0",
        "lru-cache": "^5.1.1",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-compilation-targets/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/@babel/helper-globals": {
      "version": "7.28.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-globals/-/helper-globals-7.28.0.tgz",
      "integrity": "sha512-+W6cISkXFa1jXsDEdYA8HeevQT/FULhxzR99pxphltZcVaugps53THCeiWA8SguxxpSp3gKPiuYfSWopkLQ4hw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-imports": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-imports/-/helper-module-imports-7.28.6.tgz",
      "integrity": "sha512-l5XkZK7r7wa9LucGw9LwZyyCUscb4x37JWTPz7swwFE/0FMQAGpiWUZn8u9DzkSBWEcK25jmvubfpw2dnAMdbw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/traverse": "^7.28.6",
        "@babel/types": "^7.28.6"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-transforms": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-transforms/-/helper-module-transforms-7.28.6.tgz",
      "integrity": "sha512-67oXFAYr2cDLDVGLXTEABjdBJZ6drElUSI7WKp70NrpyISso3plG9SAGEF6y7zbha/wOzUByWWTJvEDVNIUGcA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-imports": "^7.28.6",
        "@babel/helper-validator-identifier": "^7.28.5",
        "@babel/traverse": "^7.28.6"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/helper-plugin-utils": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/helper-plugin-utils/-/helper-plugin-utils-7.28.6.tgz",
      "integrity": "sha512-S9gzZ/bz83GRysI7gAD4wPT/AI3uCnY+9xn+Mx/KPs2JwHJIz1W8PZkg2cqyt3RNOBM8ejcXhV6y8Og7ly/Dug==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-string-parser": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/helper-string-parser/-/helper-string-parser-7.27.1.tgz",
      "integrity": "sha512-qMlSxKbpRlAridDExk92nSobyDdpPijUq2DW6oDnUqd0iOGxmQjyqhMIihI9+zv4LPyZdRje2cavWPbCbWm3eA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-identifier": {
      "version": "7.28.5",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.28.5.tgz",
      "integrity": "sha512-qSs4ifwzKJSV39ucNjsvc6WVHs6b7S03sOh2OcHF9UHfVPqWWALUsNUVzhSBiItjRZoLHx7nIarVjqKVusUZ1Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-option": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-option/-/helper-validator-option-7.27.1.tgz",
      "integrity": "sha512-YvjJow9FxbhFFKDSuFnVCe2WxXk1zWc22fFePVNEaWJEu8IrZVlda6N0uHwzZrUM1il7NC9Mlp4MaJYbYd9JSg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helpers": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/helpers/-/helpers-7.28.6.tgz",
      "integrity": "sha512-xOBvwq86HHdB7WUDTfKfT/Vuxh7gElQ+Sfti2Cy6yIWNW05P8iUslOVcZ4/sKbE+/jQaukQAdz/gf3724kYdqw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/template": "^7.28.6",
        "@babel/types": "^7.28.6"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/parser": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.28.6.tgz",
      "integrity": "sha512-TeR9zWR18BvbfPmGbLampPMW+uW1NZnJlRuuHso8i87QZNq2JRF9i6RgxRqtEq+wQGsS19NNTWr2duhnE49mfQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.28.6"
      },
      "bin": {
        "parser": "bin/babel-parser.js"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@babel/plugin-transform-react-jsx-self": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx-self/-/plugin-transform-react-jsx-self-7.27.1.tgz",
      "integrity": "sha512-6UzkCs+ejGdZ5mFFC/OCUrv028ab2fp1znZmCZjAOBKiBK2jXD1O+BPSfX8X2qjJ75fZBMSnQn3Rq2mrBJK2mw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.27.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-react-jsx-source": {
      "version": "7.27.1",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx-source/-/plugin-transform-react-jsx-source-7.27.1.tgz",
      "integrity": "sha512-zbwoTsBruTeKB9hSq73ha66iFeJHuaFkUbwvqElnygoNbj/jHRsSeokowZFN3CZ64IvEqcmmkVe89OPXc7ldAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.27.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/runtime": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/runtime/-/runtime-7.28.6.tgz",
      "integrity": "sha512-05WQkdpL9COIMz4LjTxGpPNCdlpyimKppYNoJ5Di5EUObifl8t4tuLuUBBZEpoLYOmfvIWrsp9fCl0HoPRVTdA==",
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/template": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/template/-/template-7.28.6.tgz",
      "integrity": "sha512-YA6Ma2KsCdGb+WC6UpBVFJGXL58MDA6oyONbjyF/+5sBgxY/dwkhLogbMT2GXXyU84/IhRw/2D1Os1B/giz+BQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.28.6",
        "@babel/parser": "^7.28.6",
        "@babel/types": "^7.28.6"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/traverse": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/traverse/-/traverse-7.28.6.tgz",
      "integrity": "sha512-fgWX62k02qtjqdSNTAGxmKYY/7FSL9WAS1o2Hu5+I5m9T0yxZzr4cnrfXQ/MX0rIifthCSs6FKTlzYbJcPtMNg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.28.6",
        "@babel/generator": "^7.28.6",
        "@babel/helper-globals": "^7.28.0",
        "@babel/parser": "^7.28.6",
        "@babel/template": "^7.28.6",
        "@babel/types": "^7.28.6",
        "debug": "^4.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/types": {
      "version": "7.28.6",
      "resolved": "https://registry.npmjs.org/@babel/types/-/types-7.28.6.tgz",
      "integrity": "sha512-0ZrskXVEHSWIqZM/sQZ4EV3jZJXRkio/WCxaqKZP1g//CEWEPSfeZFcms4XeKBCHU0ZKnIkdJeU/kF+eRp5lBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-string-parser": "^7.27.1",
        "@babel/helper-validator-identifier": "^7.28.5"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@esbuild/aix-ppc64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/aix-ppc64/-/aix-ppc64-0.21.5.tgz",
      "integrity": "sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "aix"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/android-arm": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm/-/android-arm-0.21.5.tgz",
      "integrity": "sha512-vCPvzSjpPHEi1siZdlvAlsPxXl7WbOVUBBAowWug4rJHb68Ox8KualB+1ocNvT5fjv6wpkX6o/iEpbDrf68zcg==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/android-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm64/-/android-arm64-0.21.5.tgz",
      "integrity": "sha512-c0uX9VAUBQ7dTDCjq+wdyGLowMdtR/GoC2U5IYk/7D1H1JYC0qseD7+11iMP2mRLN9RcCMRcjC4YMclCzGwS/A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/android-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/android-x64/-/android-x64-0.21.5.tgz",
      "integrity": "sha512-D7aPRUUNHRBwHxzxRvp856rjUHRFW1SdQATKXH2hqA0kAZb1hKmi02OpYRacl0TxIGz/ZmXWlbZgjwWYaCakTA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/darwin-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-arm64/-/darwin-arm64-0.21.5.tgz",
      "integrity": "sha512-DwqXqZyuk5AiWWf3UfLiRDJ5EDd49zg6O9wclZ7kUMv2WRFr4HKjXp/5t8JZ11QbQfUS6/cRCKGwYhtNAY88kQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/darwin-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-x64/-/darwin-x64-0.21.5.tgz",
      "integrity": "sha512-se/JjF8NlmKVG4kNIuyWMV/22ZaerB+qaSi5MdrXtd6R08kvs2qCN4C09miupktDitvh8jRFflwGFBQcxZRjbw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/freebsd-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-arm64/-/freebsd-arm64-0.21.5.tgz",
      "integrity": "sha512-5JcRxxRDUJLX8JXp/wcBCy3pENnCgBR9bN6JsY4OmhfUtIHe3ZW0mawA7+RDAcMLrMIZaf03NlQiX9DGyB8h4g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/freebsd-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-x64/-/freebsd-x64-0.21.5.tgz",
      "integrity": "sha512-J95kNBj1zkbMXtHVH29bBriQygMXqoVQOQYA+ISs0/2l3T9/kj42ow2mpqerRBxDJnmkUDCaQT/dfNXWX/ZZCQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-arm": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm/-/linux-arm-0.21.5.tgz",
      "integrity": "sha512-bPb5AHZtbeNGjCKVZ9UGqGwo8EUu4cLq68E95A53KlxAPRmUyYv2D6F0uUI65XisGOL1hBP5mTronbgo+0bFcA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm64/-/linux-arm64-0.21.5.tgz",
      "integrity": "sha512-ibKvmyYzKsBeX8d8I7MH/TMfWDXBF3db4qM6sy+7re0YXya+K1cem3on9XgdT2EQGMu4hQyZhan7TeQ8XkGp4Q==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-ia32": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ia32/-/linux-ia32-0.21.5.tgz",
      "integrity": "sha512-YvjXDqLRqPDl2dvRODYmmhz4rPeVKYvppfGYKSNGdyZkA01046pLWyRKKI3ax8fbJoK5QbxblURkwK/MWY18Tg==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-loong64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-loong64/-/linux-loong64-0.21.5.tgz",
      "integrity": "sha512-uHf1BmMG8qEvzdrzAqg2SIG/02+4/DHB6a9Kbya0XDvwDEKCoC8ZRWI5JJvNdUjtciBGFQ5PuBlpEOXQj+JQSg==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-mips64el": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-mips64el/-/linux-mips64el-0.21.5.tgz",
      "integrity": "sha512-IajOmO+KJK23bj52dFSNCMsz1QP1DqM6cwLUv3W1QwyxkyIWecfafnI555fvSGqEKwjMXVLokcV5ygHW5b3Jbg==",
      "cpu": [
        "mips64el"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-ppc64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ppc64/-/linux-ppc64-0.21.5.tgz",
      "integrity": "sha512-1hHV/Z4OEfMwpLO8rp7CvlhBDnjsC3CttJXIhBi+5Aj5r+MBvy4egg7wCbe//hSsT+RvDAG7s81tAvpL2XAE4w==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-riscv64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-riscv64/-/linux-riscv64-0.21.5.tgz",
      "integrity": "sha512-2HdXDMd9GMgTGrPWnJzP2ALSokE/0O5HhTUvWIbD3YdjME8JwvSCnNGBnTThKGEB91OZhzrJ4qIIxk/SBmyDDA==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-s390x": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-s390x/-/linux-s390x-0.21.5.tgz",
      "integrity": "sha512-zus5sxzqBJD3eXxwvjN1yQkRepANgxE9lgOW2qLnmr8ikMTphkjgXu1HR01K4FJg8h1kEEDAqDcZQtbrRnB41A==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-x64/-/linux-x64-0.21.5.tgz",
      "integrity": "sha512-1rYdTpyv03iycF1+BhzrzQJCdOuAOtaqHTWJZCWvijKD2N5Xu0TtVC8/+1faWqcP9iBCWOmjmhoH94dH82BxPQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/netbsd-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/netbsd-x64/-/netbsd-x64-0.21.5.tgz",
      "integrity": "sha512-Woi2MXzXjMULccIwMnLciyZH4nCIMpWQAs049KEeMvOcNADVxo0UBIQPfSmxB3CWKedngg7sWZdLvLczpe0tLg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "netbsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/openbsd-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/openbsd-x64/-/openbsd-x64-0.21.5.tgz",
      "integrity": "sha512-HLNNw99xsvx12lFBUwoT8EVCsSvRNDVxNpjZ7bPn947b8gJPzeHWyNVhFsaerc0n3TsbOINvRP2byTZ5LKezow==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/sunos-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/sunos-x64/-/sunos-x64-0.21.5.tgz",
      "integrity": "sha512-6+gjmFpfy0BHU5Tpptkuh8+uw3mnrvgs+dSPQXQOv3ekbordwnzTVEb4qnIvQcYXq6gzkyTnoZ9dZG+D4garKg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "sunos"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/win32-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-arm64/-/win32-arm64-0.21.5.tgz",
      "integrity": "sha512-Z0gOTd75VvXqyq7nsl93zwahcTROgqvuAcYDUr+vOv8uHhNSKROyU961kgtCD1e95IqPKSQKH7tBTslnS3tA8A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/win32-ia32": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-ia32/-/win32-ia32-0.21.5.tgz",
      "integrity": "sha512-SWXFF1CL2RVNMaVs+BBClwtfZSvDgtL//G/smwAc5oVK/UPu2Gu9tIaRgFmYFFKrmg3SyAjSrElf0TiJ1v8fYA==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/win32-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-x64/-/win32-x64-0.21.5.tgz",
      "integrity": "sha512-tQd/1efJuzPC6rCFwEvLtci/xNFcTZknmXs98FYDfGE4wP9ClFV98nyKrzJKVPMhdDnjzLhdUyMX4PsQAPjwIw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@eslint-community/eslint-utils": {
      "version": "4.9.1",
      "resolved": "https://registry.npmjs.org/@eslint-community/eslint-utils/-/eslint-utils-4.9.1.tgz",
      "integrity": "sha512-phrYmNiYppR7znFEdqgfWHXR6NCkZEK7hwWDHZUjit/2/U0r6XvkDl0SYnoM51Hq7FhCGdLDT6zxCCOY1hexsQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eslint-visitor-keys": "^3.4.3"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      },
      "peerDependencies": {
        "eslint": "^6.0.0 || ^7.0.0 || >=8.0.0"
      }
    },
    "node_modules/@eslint-community/regexpp": {
      "version": "4.12.2",
      "resolved": "https://registry.npmjs.org/@eslint-community/regexpp/-/regexpp-4.12.2.tgz",
      "integrity": "sha512-EriSTlt5OC9/7SXkRSCAhfSxxoSUgBm33OH+IkwbdpgoqsSsUg7y3uh+IICI/Qg4BBWr3U2i39RpmycbxMq4ew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.0.0 || ^14.0.0 || >=16.0.0"
      }
    },
    "node_modules/@eslint/eslintrc": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-2.1.4.tgz",
      "integrity": "sha512-269Z39MS6wVJtsoUl10L60WdkhJVdPG24Q4eZTH3nnF6lpvSShEK3wQjDX9JRWAUPvPh7COouPpU9IrqaZFvtQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ajv": "^6.12.4",
        "debug": "^4.3.2",
        "espree": "^9.6.0",
        "globals": "^13.19.0",
        "ignore": "^5.2.0",
        "import-fresh": "^3.2.1",
        "js-yaml": "^4.1.0",
        "minimatch": "^3.1.2",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint/eslintrc/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/@eslint/eslintrc/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/@eslint/js": {
      "version": "8.57.1",
      "resolved": "https://registry.npmjs.org/@eslint/js/-/js-8.57.1.tgz",
      "integrity": "sha512-d9zaMRSTIKDLhctzH12MtXvJKSSUhaHcjV+2Z+GK+EEY7XKpP5yR4x+N3TAcHTcu963nIr+TMcCb4DBCYX1z6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      }
    },
    "node_modules/@humanwhocodes/config-array": {
      "version": "0.13.0",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/config-array/-/config-array-0.13.0.tgz",
      "integrity": "sha512-DZLEEqFWQFiyK6h5YIeynKx7JlvCYWL0cImfSRXZ9l4Sg2efkFGTuFf6vzXjK1cq6IYkU+Eg/JizXw+TD2vRNw==",
      "deprecated": "Use @eslint/config-array instead",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@humanwhocodes/object-schema": "^2.0.3",
        "debug": "^4.3.1",
        "minimatch": "^3.0.5"
      },
      "engines": {
        "node": ">=10.10.0"
      }
    },
    "node_modules/@humanwhocodes/config-array/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/@humanwhocodes/config-array/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/@humanwhocodes/module-importer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/module-importer/-/module-importer-1.0.1.tgz",
      "integrity": "sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=12.22"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@humanwhocodes/object-schema": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/object-schema/-/object-schema-2.0.3.tgz",
      "integrity": "sha512-93zYdMES/c1D69yZiKDBj0V24vqNzB/koF26KPaagAfd3P/4gUlh3Dys5ogAK+Exi9QyzlD8x/08Zt7wIKcDcA==",
      "deprecated": "Use @eslint/object-schema instead",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.13",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.13.tgz",
      "integrity": "sha512-2kkt/7niJ6MgEPxF0bYdQ6etZaA+fQvDcLKckhy1yIQOzaoKjBBjSj63/aLVjYE3qhRt5dvM+uUyfCg6UKCBbA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/sourcemap-codec": "^1.5.0",
        "@jridgewell/trace-mapping": "^0.3.24"
      }
    },
    "node_modules/@jridgewell/remapping": {
      "version": "2.3.5",
      "resolved": "https://registry.npmjs.org/@jridgewell/remapping/-/remapping-2.3.5.tgz",
      "integrity": "sha512-LI9u/+laYG4Ds1TDKSJW2YPrIlcVYOwi2fUC6xB43lueCjgxV4lffOCZCtYFiH6TNOX+tQKXx97T4IKHbhyHEQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.5",
        "@jridgewell/trace-mapping": "^0.3.24"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.5",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.5.tgz",
      "integrity": "sha512-cYQ9310grqxueWbl+WuIUIaiUaDcj7WOq5fVhEljNVgRfOUhY9fy2zTvfoqWsnebh8Sl70VScFbICvJnLKB0Og==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.31",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.31.tgz",
      "integrity": "sha512-zzNR+SdQSDJzc8joaeP8QQoCQr8NuYx2dIIytl1QeBEZHJ9uW6hebsrYgbz8hJwUQao3TWCMtmfV8Nu1twOLAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@nodelib/fs.scandir": {
      "version": "2.1.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.scandir/-/fs.scandir-2.1.5.tgz",
      "integrity": "sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "2.0.5",
        "run-parallel": "^1.1.9"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.stat": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.stat/-/fs.stat-2.0.5.tgz",
      "integrity": "sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.walk": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.walk/-/fs.walk-1.2.8.tgz",
      "integrity": "sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.scandir": "2.1.5",
        "fastq": "^1.6.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@rolldown/pluginutils": {
      "version": "1.0.0-beta.27",
      "resolved": "https://registry.npmjs.org/@rolldown/pluginutils/-/pluginutils-1.0.0-beta.27.tgz",
      "integrity": "sha512-+d0F4MKMCbeVUJwG96uQ4SgAznZNSq93I3V+9NHA4OpvqG8mRCpGdKmK8l/dl02h2CCDHwW2FqilnTyDcAnqjA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@rollup/rollup-android-arm-eabi": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm-eabi/-/rollup-android-arm-eabi-4.55.1.tgz",
      "integrity": "sha512-9R0DM/ykwfGIlNu6+2U09ga0WXeZ9MRC2Ter8jnz8415VbuIykVuc6bhdrbORFZANDmTDvq26mJrEVTl8TdnDg==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-android-arm64": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm64/-/rollup-android-arm64-4.55.1.tgz",
      "integrity": "sha512-eFZCb1YUqhTysgW3sj/55du5cG57S7UTNtdMjCW7LwVcj3dTTcowCsC8p7uBdzKsZYa8J7IDE8lhMI+HX1vQvg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-darwin-arm64": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-arm64/-/rollup-darwin-arm64-4.55.1.tgz",
      "integrity": "sha512-p3grE2PHcQm2e8PSGZdzIhCKbMCw/xi9XvMPErPhwO17vxtvCN5FEA2mSLgmKlCjHGMQTP6phuQTYWUnKewwGg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-darwin-x64": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-x64/-/rollup-darwin-x64-4.55.1.tgz",
      "integrity": "sha512-rDUjG25C9qoTm+e02Esi+aqTKSBYwVTaoS1wxcN47/Luqef57Vgp96xNANwt5npq9GDxsH7kXxNkJVEsWEOEaQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-freebsd-arm64": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-freebsd-arm64/-/rollup-freebsd-arm64-4.55.1.tgz",
      "integrity": "sha512-+JiU7Jbp5cdxekIgdte0jfcu5oqw4GCKr6i3PJTlXTCU5H5Fvtkpbs4XJHRmWNXF+hKmn4v7ogI5OQPaupJgOg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@rollup/rollup-freebsd-x64": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-freebsd-x64/-/rollup-freebsd-x64-4.55.1.tgz",
      "integrity": "sha512-V5xC1tOVWtLLmr3YUk2f6EJK4qksksOYiz/TCsFHu/R+woubcLWdC9nZQmwjOAbmExBIVKsm1/wKmEy4z4u4Bw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-gnueabihf": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-gnueabihf/-/rollup-linux-arm-gnueabihf-4.55.1.tgz",
      "integrity": "sha512-Rn3n+FUk2J5VWx+ywrG/HGPTD9jXNbicRtTM11e/uorplArnXZYsVifnPPqNNP5BsO3roI4n8332ukpY/zN7rQ==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-musleabihf": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-musleabihf/-/rollup-linux-arm-musleabihf-4.55.1.tgz",
      "integrity": "sha512-grPNWydeKtc1aEdrJDWk4opD7nFtQbMmV7769hiAaYyUKCT1faPRm2av8CX1YJsZ4TLAZcg9gTR1KvEzoLjXkg==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-gnu": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-gnu/-/rollup-linux-arm64-gnu-4.55.1.tgz",
      "integrity": "sha512-a59mwd1k6x8tXKcUxSyISiquLwB5pX+fJW9TkWU46lCqD/GRDe9uDN31jrMmVP3feI3mhAdvcCClhV8V5MhJFQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-musl": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-musl/-/rollup-linux-arm64-musl-4.55.1.tgz",
      "integrity": "sha512-puS1MEgWX5GsHSoiAsF0TYrpomdvkaXm0CofIMG5uVkP6IBV+ZO9xhC5YEN49nsgYo1DuuMquF9+7EDBVYu4uA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-loong64-gnu": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-loong64-gnu/-/rollup-linux-loong64-gnu-4.55.1.tgz",
      "integrity": "sha512-r3Wv40in+lTsULSb6nnoudVbARdOwb2u5fpeoOAZjFLznp6tDU8kd+GTHmJoqZ9lt6/Sys33KdIHUaQihFcu7g==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-loong64-musl": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-loong64-musl/-/rollup-linux-loong64-musl-4.55.1.tgz",
      "integrity": "sha512-MR8c0+UxAlB22Fq4R+aQSPBayvYa3+9DrwG/i1TKQXFYEaoW3B5b/rkSRIypcZDdWjWnpcvxbNaAJDcSbJU3Lw==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-ppc64-gnu": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-ppc64-gnu/-/rollup-linux-ppc64-gnu-4.55.1.tgz",
      "integrity": "sha512-3KhoECe1BRlSYpMTeVrD4sh2Pw2xgt4jzNSZIIPLFEsnQn9gAnZagW9+VqDqAHgm1Xc77LzJOo2LdigS5qZ+gw==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-ppc64-musl": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-ppc64-musl/-/rollup-linux-ppc64-musl-4.55.1.tgz",
      "integrity": "sha512-ziR1OuZx0vdYZZ30vueNZTg73alF59DicYrPViG0NEgDVN8/Jl87zkAPu4u6VjZST2llgEUjaiNl9JM6HH1Vdw==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-riscv64-gnu": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-riscv64-gnu/-/rollup-linux-riscv64-gnu-4.55.1.tgz",
      "integrity": "sha512-uW0Y12ih2XJRERZ4jAfKamTyIHVMPQnTZcQjme2HMVDAHY4amf5u414OqNYC+x+LzRdRcnIG1YodLrrtA8xsxw==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-riscv64-musl": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-riscv64-musl/-/rollup-linux-riscv64-musl-4.55.1.tgz",
      "integrity": "sha512-u9yZ0jUkOED1BFrqu3BwMQoixvGHGZ+JhJNkNKY/hyoEgOwlqKb62qu+7UjbPSHYjiVy8kKJHvXKv5coH4wDeg==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-s390x-gnu": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-s390x-gnu/-/rollup-linux-s390x-gnu-4.55.1.tgz",
      "integrity": "sha512-/0PenBCmqM4ZUd0190j7J0UsQ/1nsi735iPRakO8iPciE7BQ495Y6msPzaOmvx0/pn+eJVVlZrNrSh4WSYLxNg==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-gnu": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-gnu/-/rollup-linux-x64-gnu-4.55.1.tgz",
      "integrity": "sha512-a8G4wiQxQG2BAvo+gU6XrReRRqj+pLS2NGXKm8io19goR+K8lw269eTrPkSdDTALwMmJp4th2Uh0D8J9bEV1vg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-musl": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-musl/-/rollup-linux-x64-musl-4.55.1.tgz",
      "integrity": "sha512-bD+zjpFrMpP/hqkfEcnjXWHMw5BIghGisOKPj+2NaNDuVT+8Ds4mPf3XcPHuat1tz89WRL+1wbcxKY3WSbiT7w==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-openbsd-x64": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-openbsd-x64/-/rollup-openbsd-x64-4.55.1.tgz",
      "integrity": "sha512-eLXw0dOiqE4QmvikfQ6yjgkg/xDM+MdU9YJuP4ySTibXU0oAvnEWXt7UDJmD4UkYialMfOGFPJnIHSe/kdzPxg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ]
    },
    "node_modules/@rollup/rollup-openharmony-arm64": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-openharmony-arm64/-/rollup-openharmony-arm64-4.55.1.tgz",
      "integrity": "sha512-xzm44KgEP11te3S2HCSyYf5zIzWmx3n8HDCc7EE59+lTcswEWNpvMLfd9uJvVX8LCg9QWG67Xt75AuHn4vgsXw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openharmony"
      ]
    },
    "node_modules/@rollup/rollup-win32-arm64-msvc": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-arm64-msvc/-/rollup-win32-arm64-msvc-4.55.1.tgz",
      "integrity": "sha512-yR6Bl3tMC/gBok5cz/Qi0xYnVbIxGx5Fcf/ca0eB6/6JwOY+SRUcJfI0OpeTpPls7f194as62thCt/2BjxYN8g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-ia32-msvc": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-ia32-msvc/-/rollup-win32-ia32-msvc-4.55.1.tgz",
      "integrity": "sha512-3fZBidchE0eY0oFZBnekYCfg+5wAB0mbpCBuofh5mZuzIU/4jIVkbESmd2dOsFNS78b53CYv3OAtwqkZZmU5nA==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-x64-gnu": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-x64-gnu/-/rollup-win32-x64-gnu-4.55.1.tgz",
      "integrity": "sha512-xGGY5pXj69IxKb4yv/POoocPy/qmEGhimy/FoTpTSVju3FYXUQQMFCaZZXJVidsmGxRioZAwpThl/4zX41gRKg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-x64-msvc": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-x64-msvc/-/rollup-win32-x64-msvc-4.55.1.tgz",
      "integrity": "sha512-SPEpaL6DX4rmcXtnhdrQYgzQ5W2uW3SCJch88lB2zImhJRhIIK44fkUrgIV/Q8yUNfw5oyZ5vkeQsZLhCb06lw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@types/babel__core": {
      "version": "7.20.5",
      "resolved": "https://registry.npmjs.org/@types/babel__core/-/babel__core-7.20.5.tgz",
      "integrity": "sha512-qoQprZvz5wQFJwMDqeseRXWv3rqMvhgpbXFfVyWhbx9X47POIA6i/+dXefEmZKoAgOaTdaIgNSMqMIU61yRyzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.20.7",
        "@babel/types": "^7.20.7",
        "@types/babel__generator": "*",
        "@types/babel__template": "*",
        "@types/babel__traverse": "*"
      }
    },
    "node_modules/@types/babel__generator": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@types/babel__generator/-/babel__generator-7.27.0.tgz",
      "integrity": "sha512-ufFd2Xi92OAVPYsy+P4n7/U7e68fex0+Ee8gSG9KX7eo084CWiQ4sdxktvdl0bOPupXtVJPY19zk6EwWqUQ8lg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__template": {
      "version": "7.4.4",
      "resolved": "https://registry.npmjs.org/@types/babel__template/-/babel__template-7.4.4.tgz",
      "integrity": "sha512-h/NUaSyG5EyxBIp8YRxo4RMe2/qQgvyowRwVMzhYhBCONbW8PUsg4lkFMrhgZhUe5z3L3MiLDuvyJ/CaPa2A8A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__traverse": {
      "version": "7.28.0",
      "resolved": "https://registry.npmjs.org/@types/babel__traverse/-/babel__traverse-7.28.0.tgz",
      "integrity": "sha512-8PvcXf70gTDZBgt9ptxJ8elBeBjcLOAcOtoO/mPJjtji1+CdGbHgm77om1GrsPxsiE+uXIpNSK64UYaIwQXd4Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.28.2"
      }
    },
    "node_modules/@types/d3-array": {
      "version": "3.2.2",
      "resolved": "https://registry.npmjs.org/@types/d3-array/-/d3-array-3.2.2.tgz",
      "integrity": "sha512-hOLWVbm7uRza0BYXpIIW5pxfrKe0W+D5lrFiAEYR+pb6w3N2SwSMaJbXdUfSEv+dT4MfHBLtn5js0LAWaO6otw==",
      "license": "MIT"
    },
    "node_modules/@types/d3-color": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/@types/d3-color/-/d3-color-3.1.3.tgz",
      "integrity": "sha512-iO90scth9WAbmgv7ogoq57O9YpKmFBbmoEoCHDB2xMBY0+/KVrqAaCDyCE16dUspeOvIxFFRI+0sEtqDqy2b4A==",
      "license": "MIT"
    },
    "node_modules/@types/d3-ease": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/@types/d3-ease/-/d3-ease-3.0.2.tgz",
      "integrity": "sha512-NcV1JjO5oDzoK26oMzbILE6HW7uVXOHLQvHshBUW4UMdZGfiY6v5BeQwh9a9tCzv+CeefZQHJt5SRgK154RtiA==",
      "license": "MIT"
    },
    "node_modules/@types/d3-interpolate": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/d3-interpolate/-/d3-interpolate-3.0.4.tgz",
      "integrity": "sha512-mgLPETlrpVV1YRJIglr4Ez47g7Yxjl1lj7YKsiMCb27VJH9W8NVM6Bb9d8kkpG/uAQS5AmbA48q2IAolKKo1MA==",
      "license": "MIT",
      "dependencies": {
        "@types/d3-color": "*"
      }
    },
    "node_modules/@types/d3-path": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/@types/d3-path/-/d3-path-3.1.1.tgz",
      "integrity": "sha512-VMZBYyQvbGmWyWVea0EHs/BwLgxc+MKi1zLDCONksozI4YJMcTt8ZEuIR4Sb1MMTE8MMW49v0IwI5+b7RmfWlg==",
      "license": "MIT"
    },
    "node_modules/@types/d3-scale": {
      "version": "4.0.9",
      "resolved": "https://registry.npmjs.org/@types/d3-scale/-/d3-scale-4.0.9.tgz",
      "integrity": "sha512-dLmtwB8zkAeO/juAMfnV+sItKjlsw2lKdZVVy6LRr0cBmegxSABiLEpGVmSJJ8O08i4+sGR6qQtb6WtuwJdvVw==",
      "license": "MIT",
      "dependencies": {
        "@types/d3-time": "*"
      }
    },
    "node_modules/@types/d3-shape": {
      "version": "3.1.8",
      "resolved": "https://registry.npmjs.org/@types/d3-shape/-/d3-shape-3.1.8.tgz",
      "integrity": "sha512-lae0iWfcDeR7qt7rA88BNiqdvPS5pFVPpo5OfjElwNaT2yyekbM0C9vK+yqBqEmHr6lDkRnYNoTBYlAgJa7a4w==",
      "license": "MIT",
      "dependencies": {
        "@types/d3-path": "*"
      }
    },
    "node_modules/@types/d3-time": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/d3-time/-/d3-time-3.0.4.tgz",
      "integrity": "sha512-yuzZug1nkAAaBlBBikKZTgzCeA+k1uy4ZFwWANOfKw5z5LRhV0gNA7gNkKm7HoK+HRN0wX3EkxGk0fpbWhmB7g==",
      "license": "MIT"
    },
    "node_modules/@types/d3-timer": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/@types/d3-timer/-/d3-timer-3.0.2.tgz",
      "integrity": "sha512-Ps3T8E8dZDam6fUyNiMkekK3XUsaUEik+idO9/YjPtfj2qruF8tFBXS7XhtE4iIXBLxhmLjP3SXpLhVf21I9Lw==",
      "license": "MIT"
    },
    "node_modules/@types/estree": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/@types/estree/-/estree-1.0.8.tgz",
      "integrity": "sha512-dWHzHa2WqEXI/O1E9OjrocMTKJl2mSrEolh1Iomrv6U+JuNwaHXsXx9bLu5gG7BUWFIN0skIQJQ/L1rIex4X6w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/json-schema": {
      "version": "7.0.15",
      "resolved": "https://registry.npmjs.org/@types/json-schema/-/json-schema-7.0.15.tgz",
      "integrity": "sha512-5+fP8P8MFNC+AyZCDxrB2pkZFPGzqQWUzpSeuuVLvm8VMcorNYavBqoFcxK8bQz4Qsbn4oUEEem4wDLfcysGHA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/prop-types": {
      "version": "15.7.15",
      "resolved": "https://registry.npmjs.org/@types/prop-types/-/prop-types-15.7.15.tgz",
      "integrity": "sha512-F6bEyamV9jKGAFBEmlQnesRPGOQqS2+Uwi0Em15xenOxHaf2hv6L8YCVn3rPdPJOiJfPiCnLIRyvwVaqMY3MIw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/react": {
      "version": "18.3.27",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-18.3.27.tgz",
      "integrity": "sha512-cisd7gxkzjBKU2GgdYrTdtQx1SORymWyaAFhaxQPK9bYO9ot3Y5OikQRvY0VYQtvwjeQnizCINJAenh/V7MK2w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/prop-types": "*",
        "csstype": "^3.2.2"
      }
    },
    "node_modules/@types/react-dom": {
      "version": "18.3.7",
      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-18.3.7.tgz",
      "integrity": "sha512-MEe3UeoENYVFXzoXEWsvcpg6ZvlrFNlOQ7EOsvhI3CfAXwzPfO8Qwuxd40nepsYKqyyVQnTdEfv68q91yLcKrQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "^18.0.0"
      }
    },
    "node_modules/@types/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/@types/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-FmgJfu+MOcQ370SD0ev7EI8TlCAfKYU+B4m5T3yXc1CiRN94g/SZPtsCkk506aUDtlMnFZvasDwHHUcZUEaYuA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@typescript-eslint/eslint-plugin": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/eslint-plugin/-/eslint-plugin-6.21.0.tgz",
      "integrity": "sha512-oy9+hTPCUFpngkEZUSzbf9MxI65wbKFoQYsgPdILTfbUldp5ovUuphZVe4i30emU9M/kP+T64Di0mxl7dSw3MA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@eslint-community/regexpp": "^4.5.1",
        "@typescript-eslint/scope-manager": "6.21.0",
        "@typescript-eslint/type-utils": "6.21.0",
        "@typescript-eslint/utils": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0",
        "debug": "^4.3.4",
        "graphemer": "^1.4.0",
        "ignore": "^5.2.4",
        "natural-compare": "^1.4.0",
        "semver": "^7.5.4",
        "ts-api-utils": "^1.0.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "@typescript-eslint/parser": "^6.0.0 || ^6.0.0-alpha",
        "eslint": "^7.0.0 || ^8.0.0"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/parser": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/parser/-/parser-6.21.0.tgz",
      "integrity": "sha512-tbsV1jPne5CkFQCgPBcDOt30ItF7aJoZL997JSF7MhGQqOeT3svWRYxiqlfA5RUdlHN6Fi+EI9bxqbdyAUZjYQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/scope-manager": "6.21.0",
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/typescript-estree": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0",
        "debug": "^4.3.4"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^7.0.0 || ^8.0.0"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/scope-manager": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/scope-manager/-/scope-manager-6.21.0.tgz",
      "integrity": "sha512-OwLUIWZJry80O99zvqXVEioyniJMa+d2GrqpUTqi5/v5D5rOrppJVBPa0yKCblcigC0/aYAzxxqQ1B+DS2RYsg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/type-utils": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/type-utils/-/type-utils-6.21.0.tgz",
      "integrity": "sha512-rZQI7wHfao8qMX3Rd3xqeYSMCL3SoiSQLBATSiVKARdFGCYSRvmViieZjqc58jKgs8Y8i9YvVVhRbHSTA4VBag==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/typescript-estree": "6.21.0",
        "@typescript-eslint/utils": "6.21.0",
        "debug": "^4.3.4",
        "ts-api-utils": "^1.0.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^7.0.0 || ^8.0.0"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/types": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/types/-/types-6.21.0.tgz",
      "integrity": "sha512-1kFmZ1rOm5epu9NZEZm1kckCDGj5UJEf7P1kliH4LKu/RkwpsfqqGmY2OOcUs18lSlQBKLDYBOGxRVtrMN5lpg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/typescript-estree/-/typescript-estree-6.21.0.tgz",
      "integrity": "sha512-6npJTkZcO+y2/kr+z0hc4HwNfrrP4kNYh57ek7yCNlrBjWQ1Y0OS7jiZTkgumrvkX5HkEKXFZkkdFNkaW2wmUQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/visitor-keys": "6.21.0",
        "debug": "^4.3.4",
        "globby": "^11.1.0",
        "is-glob": "^4.0.3",
        "minimatch": "9.0.3",
        "semver": "^7.5.4",
        "ts-api-utils": "^1.0.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/utils": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/utils/-/utils-6.21.0.tgz",
      "integrity": "sha512-NfWVaC8HP9T8cbKQxHcsJBY5YE1O33+jpMwN45qzWWaPDZgLIbo12toGMWnmhvCpd3sIxkpDw3Wv1B3dYrbDQQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.4.0",
        "@types/json-schema": "^7.0.12",
        "@types/semver": "^7.5.0",
        "@typescript-eslint/scope-manager": "6.21.0",
        "@typescript-eslint/types": "6.21.0",
        "@typescript-eslint/typescript-estree": "6.21.0",
        "semver": "^7.5.4"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^7.0.0 || ^8.0.0"
      }
    },
    "node_modules/@typescript-eslint/visitor-keys": {
      "version": "6.21.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/visitor-keys/-/visitor-keys-6.21.0.tgz",
      "integrity": "sha512-JJtkDduxLi9bivAB+cYOVMtbkqdPOhZ+ZI5LC47MIRrDV4Yn2o+ZnW10Nkmr28xRpSpdJ6Sm42Hjf2+REYXm0A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "6.21.0",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@ungap/structured-clone": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/@ungap/structured-clone/-/structured-clone-1.3.0.tgz",
      "integrity": "sha512-WmoN8qaIAo7WTYWbAZuG8PYEhn5fkz7dZrqTBZ7dtt//lL2Gwms1IcnQ5yHqjDfX8Ft5j4YzDM23f87zBfDe9g==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/@vitejs/plugin-react": {
      "version": "4.7.0",
      "resolved": "https://registry.npmjs.org/@vitejs/plugin-react/-/plugin-react-4.7.0.tgz",
      "integrity": "sha512-gUu9hwfWvvEDBBmgtAowQCojwZmJ5mcLn3aufeCsitijs3+f2NsrPtlAWIR6OPiqljl96GVCUbLe0HyqIpVaoA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.28.0",
        "@babel/plugin-transform-react-jsx-self": "^7.27.1",
        "@babel/plugin-transform-react-jsx-source": "^7.27.1",
        "@rolldown/pluginutils": "1.0.0-beta.27",
        "@types/babel__core": "^7.20.5",
        "react-refresh": "^0.17.0"
      },
      "engines": {
        "node": "^14.18.0 || >=16.0.0"
      },
      "peerDependencies": {
        "vite": "^4.2.0 || ^5.0.0 || ^6.0.0 || ^7.0.0"
      }
    },
    "node_modules/acorn": {
      "version": "8.15.0",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.15.0.tgz",
      "integrity": "sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-jsx": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/acorn-jsx/-/acorn-jsx-5.3.2.tgz",
      "integrity": "sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "acorn": "^6.0.0 || ^7.0.0 || ^8.0.0"
      }
    },
    "node_modules/ajv": {
      "version": "6.12.6",
      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.12.6.tgz",
      "integrity": "sha512-j3fVLgvTo527anyYyJOGTYJbG+vnnQYvE0m5mmkc1TK+nxAppkCLMIL0aZ4dblVCNoGShhm+kzE4ZUykBoMg4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fast-deep-equal": "^3.1.1",
        "fast-json-stable-stringify": "^2.0.0",
        "json-schema-traverse": "^0.4.1",
        "uri-js": "^4.2.2"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/epoberezkin"
      }
    },
    "node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/any-promise": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz",
      "integrity": "sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/anymatch": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz",
      "integrity": "sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "normalize-path": "^3.0.0",
        "picomatch": "^2.0.4"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/arg": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/arg/-/arg-5.0.2.tgz",
      "integrity": "sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/argparse": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-2.0.1.tgz",
      "integrity": "sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==",
      "dev": true,
      "license": "Python-2.0"
    },
    "node_modules/array-union": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/array-union/-/array-union-2.1.0.tgz",
      "integrity": "sha512-HGyxoOTYUyCM6stUe6EJgnd4EoewAI7zMdfqO+kGjnlZmBDz/cR5pf8r/cR4Wq60sL/p0IkcjUEEPwS3GFrIyw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/autoprefixer": {
      "version": "10.4.23",
      "resolved": "https://registry.npmjs.org/autoprefixer/-/autoprefixer-10.4.23.tgz",
      "integrity": "sha512-YYTXSFulfwytnjAPlw8QHncHJmlvFKtczb8InXaAx9Q0LbfDnfEYDE55omerIJKihhmU61Ft+cAOSzQVaBUmeA==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/autoprefixer"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "browserslist": "^4.28.1",
        "caniuse-lite": "^1.0.30001760",
        "fraction.js": "^5.3.4",
        "picocolors": "^1.1.1",
        "postcss-value-parser": "^4.2.0"
      },
      "bin": {
        "autoprefixer": "bin/autoprefixer"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      },
      "peerDependencies": {
        "postcss": "^8.1.0"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/baseline-browser-mapping": {
      "version": "2.9.15",
      "resolved": "https://registry.npmjs.org/baseline-browser-mapping/-/baseline-browser-mapping-2.9.15.tgz",
      "integrity": "sha512-kX8h7K2srmDyYnXRIppo4AH/wYgzWVCs+eKr3RusRSQ5PvRYoEFmR/I0PbdTjKFAoKqp5+kbxnNTFO9jOfSVJg==",
      "dev": true,
      "license": "Apache-2.0",
      "bin": {
        "baseline-browser-mapping": "dist/cli.js"
      }
    },
    "node_modules/binary-extensions": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz",
      "integrity": "sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/brace-expansion": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.2.tgz",
      "integrity": "sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/braces": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/braces/-/braces-3.0.3.tgz",
      "integrity": "sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fill-range": "^7.1.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/browserslist": {
      "version": "4.28.1",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.28.1.tgz",
      "integrity": "sha512-ZC5Bd0LgJXgwGqUknZY/vkUQ04r8NXnJZ3yYi4vDmSiZmC/pdSN0NbNRPxZpbtO4uAfDUAFffO8IZoM3Gj8IkA==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "baseline-browser-mapping": "^2.9.0",
        "caniuse-lite": "^1.0.30001759",
        "electron-to-chromium": "^1.5.263",
        "node-releases": "^2.0.27",
        "update-browserslist-db": "^1.2.0"
      },
      "bin": {
        "browserslist": "cli.js"
      },
      "engines": {
        "node": "^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/camelcase-css": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/camelcase-css/-/camelcase-css-2.0.1.tgz",
      "integrity": "sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001764",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001764.tgz",
      "integrity": "sha512-9JGuzl2M+vPL+pz70gtMF9sHdMFbY9FJaQBi186cHKH3pSzDvzoUJUPV6fqiKIMyXbud9ZLg4F3Yza1vJ1+93g==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "CC-BY-4.0"
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/chokidar": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz",
      "integrity": "sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "anymatch": "~3.1.2",
        "braces": "~3.0.2",
        "glob-parent": "~5.1.2",
        "is-binary-path": "~2.1.0",
        "is-glob": "~4.0.1",
        "normalize-path": "~3.0.0",
        "readdirp": "~3.6.0"
      },
      "engines": {
        "node": ">= 8.10.0"
      },
      "funding": {
        "url": "https://paulmillr.com/funding/"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/chokidar/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/clsx": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/clsx/-/clsx-2.1.1.tgz",
      "integrity": "sha512-eYm0QWBtUrBWZWG0d386OGAw16Z995PiOVo2B7bjWSbHedGl5e0ZWaq65kOGgUSNesEIDkB9ISbTg/JK9dhCZA==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/commander": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/commander/-/commander-4.1.1.tgz",
      "integrity": "sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/convert-source-map": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/convert-source-map/-/convert-source-map-2.0.0.tgz",
      "integrity": "sha512-Kvp459HrV2FEJ1CAsi1Ku+MY3kasH19TFykTz2xWmMeq6bk2NU3XXvfJ+Q61m0xktWwt+1HSYf3JZsTms3aRJg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cross-spawn": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz",
      "integrity": "sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/cssesc": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/cssesc/-/cssesc-3.0.0.tgz",
      "integrity": "sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "cssesc": "bin/cssesc"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/csstype": {
      "version": "3.2.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.2.3.tgz",
      "integrity": "sha512-z1HGKcYy2xA8AGQfwrn0PAy+PB7X/GSj3UVJW9qKyn43xWa+gl5nXmU4qqLMRzWVLFC8KusUX8T/0kCiOYpAIQ==",
      "license": "MIT"
    },
    "node_modules/d3-array": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/d3-array/-/d3-array-3.2.4.tgz",
      "integrity": "sha512-tdQAmyA18i4J7wprpYq8ClcxZy3SC31QMeByyCFyRt7BVHdREQZ5lpzoe5mFEYZUWe+oq8HBvk9JjpibyEV4Jg==",
      "license": "ISC",
      "dependencies": {
        "internmap": "1 - 2"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-color": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-color/-/d3-color-3.1.0.tgz",
      "integrity": "sha512-zg/chbXyeBtMQ1LbD/WSoW2DpC3I0mpmPdW+ynRTj/x2DAWYrIY7qeZIHidozwV24m4iavr15lNwIwLxRmOxhA==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-ease": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/d3-ease/-/d3-ease-3.0.1.tgz",
      "integrity": "sha512-wR/XK3D3XcLIZwpbvQwQ5fK+8Ykds1ip7A2Txe0yxncXSdq1L9skcG7blcedkOX+ZcgxGAmLX1FrRGbADwzi0w==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-format": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/d3-format/-/d3-format-3.1.2.tgz",
      "integrity": "sha512-AJDdYOdnyRDV5b6ArilzCPPwc1ejkHcoyFarqlPqT7zRYjhavcT3uSrqcMvsgh2CgoPbK3RCwyHaVyxYcP2Arg==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-interpolate": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/d3-interpolate/-/d3-interpolate-3.0.1.tgz",
      "integrity": "sha512-3bYs1rOD33uo8aqJfKP3JWPAibgw8Zm2+L9vBKEHJ2Rg+viTR7o5Mmv5mZcieN+FRYaAOWX5SJATX6k1PWz72g==",
      "license": "ISC",
      "dependencies": {
        "d3-color": "1 - 3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-path": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-path/-/d3-path-3.1.0.tgz",
      "integrity": "sha512-p3KP5HCf/bvjBSSKuXid6Zqijx7wIfNW+J/maPs+iwR35at5JCbLUT0LzF1cnjbCHWhqzQTIN2Jpe8pRebIEFQ==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-scale": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/d3-scale/-/d3-scale-4.0.2.tgz",
      "integrity": "sha512-GZW464g1SH7ag3Y7hXjf8RoUuAFIqklOAq3MRl4OaWabTFJY9PN/E1YklhXLh+OQ3fM9yS2nOkCoS+WLZ6kvxQ==",
      "license": "ISC",
      "dependencies": {
        "d3-array": "2.10.0 - 3",
        "d3-format": "1 - 3",
        "d3-interpolate": "1.2.0 - 3",
        "d3-time": "2.1.1 - 3",
        "d3-time-format": "2 - 4"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-shape": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/d3-shape/-/d3-shape-3.2.0.tgz",
      "integrity": "sha512-SaLBuwGm3MOViRq2ABk3eLoxwZELpH6zhl3FbAoJ7Vm1gofKx6El1Ib5z23NUEhF9AsGl7y+dzLe5Cw2AArGTA==",
      "license": "ISC",
      "dependencies": {
        "d3-path": "^3.1.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-time": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-time/-/d3-time-3.1.0.tgz",
      "integrity": "sha512-VqKjzBLejbSMT4IgbmVgDjpkYrNWUYJnbCGo874u7MMKIWsILRX+OpX/gTk8MqjpT1A/c6HY2dCA77ZN0lkQ2Q==",
      "license": "ISC",
      "dependencies": {
        "d3-array": "2 - 3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-time-format": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/d3-time-format/-/d3-time-format-4.1.0.tgz",
      "integrity": "sha512-dJxPBlzC7NugB2PDLwo9Q8JiTR3M3e4/XANkreKSUxF8vvXKqm1Yfq4Q5dl8budlunRVlUUaDUgFt7eA8D6NLg==",
      "license": "ISC",
      "dependencies": {
        "d3-time": "1 - 3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-timer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/d3-timer/-/d3-timer-3.0.1.tgz",
      "integrity": "sha512-ndfJ/JxxMd3nw31uyKoY2naivF+r29V+Lc0svZxe1JvvIRmi8hUsrMvdOwgS1o6uBHmiz91geQ0ylPP0aj1VUA==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/debug": {
      "version": "4.4.3",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.3.tgz",
      "integrity": "sha512-RGwwWnwQvkVfavKVt22FGLw+xYSdzARwm0ru6DhTVA3umU5hZc28V3kO4stgYryrTlLpuvgI9GiijltAjNbcqA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/decimal.js-light": {
      "version": "2.5.1",
      "resolved": "https://registry.npmjs.org/decimal.js-light/-/decimal.js-light-2.5.1.tgz",
      "integrity": "sha512-qIMFpTMZmny+MMIitAB6D7iVPEorVw6YQRWkvarTkT4tBeSLLiHzcwj6q0MmYSFCiVpiqPJTJEYIrpcPzVEIvg==",
      "license": "MIT"
    },
    "node_modules/deep-is": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/deep-is/-/deep-is-0.1.4.tgz",
      "integrity": "sha512-oIPzksmTg4/MriiaYGO+okXDT7ztn/w3Eptv/+gSIdMdKsJo0u4CfYNFJPy+4SKMuCqGw2wxnA+URMg3t8a/bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/didyoumean": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/didyoumean/-/didyoumean-1.2.2.tgz",
      "integrity": "sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/dir-glob": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/dir-glob/-/dir-glob-3.0.1.tgz",
      "integrity": "sha512-WkrWp9GR4KXfKGYzOLmTuGVi1UWFfws377n9cc55/tb6DuqyF6pcQ5AbiHEshaDpY9v6oaSr2XCDidGmMwdzIA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-type": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/dlv": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/dlv/-/dlv-1.1.3.tgz",
      "integrity": "sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/doctrine": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-3.0.0.tgz",
      "integrity": "sha512-yS+Q5i3hBf7GBkd4KG8a7eBNNWNGLTaEwwYWUijIYM7zrlYDM0BFXHjjPWlWZ1Rg7UaddZeIDmi9jF3HmqiQ2w==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/dom-helpers": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/dom-helpers/-/dom-helpers-5.2.1.tgz",
      "integrity": "sha512-nRCa7CK3VTrM2NmGkIy4cbK7IZlgBE/PYMn55rrXefr5xXDP0LdtfPnblFDoVdcAfslJ7or6iqAUnx0CCGIWQA==",
      "license": "MIT",
      "dependencies": {
        "@babel/runtime": "^7.8.7",
        "csstype": "^3.0.2"
      }
    },
    "node_modules/electron-to-chromium": {
      "version": "1.5.267",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.267.tgz",
      "integrity": "sha512-0Drusm6MVRXSOJpGbaSVgcQsuB4hEkMpHXaVstcPmhu5LIedxs1xNK/nIxmQIU/RPC0+1/o0AVZfBTkTNJOdUw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/esbuild": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/esbuild/-/esbuild-0.21.5.tgz",
      "integrity": "sha512-mg3OPMV4hXywwpoDxu3Qda5xCKQi+vCTZq8S9J/EpkhB2HzKXq4SNFZE3+NK93JYxc8VMSep+lOUSC/RVKaBqw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "bin": {
        "esbuild": "bin/esbuild"
      },
      "engines": {
        "node": ">=12"
      },
      "optionalDependencies": {
        "@esbuild/aix-ppc64": "0.21.5",
        "@esbuild/android-arm": "0.21.5",
        "@esbuild/android-arm64": "0.21.5",
        "@esbuild/android-x64": "0.21.5",
        "@esbuild/darwin-arm64": "0.21.5",
        "@esbuild/darwin-x64": "0.21.5",
        "@esbuild/freebsd-arm64": "0.21.5",
        "@esbuild/freebsd-x64": "0.21.5",
        "@esbuild/linux-arm": "0.21.5",
        "@esbuild/linux-arm64": "0.21.5",
        "@esbuild/linux-ia32": "0.21.5",
        "@esbuild/linux-loong64": "0.21.5",
        "@esbuild/linux-mips64el": "0.21.5",
        "@esbuild/linux-ppc64": "0.21.5",
        "@esbuild/linux-riscv64": "0.21.5",
        "@esbuild/linux-s390x": "0.21.5",
        "@esbuild/linux-x64": "0.21.5",
        "@esbuild/netbsd-x64": "0.21.5",
        "@esbuild/openbsd-x64": "0.21.5",
        "@esbuild/sunos-x64": "0.21.5",
        "@esbuild/win32-arm64": "0.21.5",
        "@esbuild/win32-ia32": "0.21.5",
        "@esbuild/win32-x64": "0.21.5"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/escape-string-regexp": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-4.0.0.tgz",
      "integrity": "sha512-TtpcNJ3XAzx3Gq8sWRzJaVajRs0uVxA2YAkdb1jm2YkPz4G6egUFAyA3n5vtEIZefPk5Wa4UXbKuS5fKkJWdgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/eslint": {
      "version": "8.57.1",
      "resolved": "https://registry.npmjs.org/eslint/-/eslint-8.57.1.tgz",
      "integrity": "sha512-ypowyDxpVSYpkXr9WPv2PAZCtNip1Mv5KTW0SCurXv/9iOpcrH9PaqUElksqEB6pChqHGDRCFTyrZlGhnLNGiA==",
      "deprecated": "This version is no longer supported. Please see https://eslint.org/version-support for other options.",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.2.0",
        "@eslint-community/regexpp": "^4.6.1",
        "@eslint/eslintrc": "^2.1.4",
        "@eslint/js": "8.57.1",
        "@humanwhocodes/config-array": "^0.13.0",
        "@humanwhocodes/module-importer": "^1.0.1",
        "@nodelib/fs.walk": "^1.2.8",
        "@ungap/structured-clone": "^1.2.0",
        "ajv": "^6.12.4",
        "chalk": "^4.0.0",
        "cross-spawn": "^7.0.2",
        "debug": "^4.3.2",
        "doctrine": "^3.0.0",
        "escape-string-regexp": "^4.0.0",
        "eslint-scope": "^7.2.2",
        "eslint-visitor-keys": "^3.4.3",
        "espree": "^9.6.1",
        "esquery": "^1.4.2",
        "esutils": "^2.0.2",
        "fast-deep-equal": "^3.1.3",
        "file-entry-cache": "^6.0.1",
        "find-up": "^5.0.0",
        "glob-parent": "^6.0.2",
        "globals": "^13.19.0",
        "graphemer": "^1.4.0",
        "ignore": "^5.2.0",
        "imurmurhash": "^0.1.4",
        "is-glob": "^4.0.0",
        "is-path-inside": "^3.0.3",
        "js-yaml": "^4.1.0",
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "levn": "^0.4.1",
        "lodash.merge": "^4.6.2",
        "minimatch": "^3.1.2",
        "natural-compare": "^1.4.0",
        "optionator": "^0.9.3",
        "strip-ansi": "^6.0.1",
        "text-table": "^0.2.0"
      },
      "bin": {
        "eslint": "bin/eslint.js"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-plugin-react-hooks": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-hooks/-/eslint-plugin-react-hooks-4.6.2.tgz",
      "integrity": "sha512-QzliNJq4GinDBcD8gPB5v0wh6g8q3SUi6EFF0x8N/BL9PoVs0atuGc47ozMRyOWAKdwaZ5OnbOEa3WR+dSGKuQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "eslint": "^3.0.0 || ^4.0.0 || ^5.0.0 || ^6.0.0 || ^7.0.0 || ^8.0.0-0"
      }
    },
    "node_modules/eslint-plugin-react-refresh": {
      "version": "0.4.26",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-refresh/-/eslint-plugin-react-refresh-0.4.26.tgz",
      "integrity": "sha512-1RETEylht2O6FM/MvgnyvT+8K21wLqDNg4qD51Zj3guhjt433XbnnkVttHMyaVyAFD03QSV4LPS5iE3VQmO7XQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "eslint": ">=8.40"
      }
    },
    "node_modules/eslint-scope": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/eslint-scope/-/eslint-scope-7.2.2.tgz",
      "integrity": "sha512-dOt21O7lTMhDM+X9mB4GX+DZrZtCUJPL/wlcTqxyrx5IvO0IYtILdtrQGQp+8n5S0gwSVmOf9NQrjMOgfQZlIg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "esrecurse": "^4.3.0",
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-visitor-keys": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-3.4.3.tgz",
      "integrity": "sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/eslint/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/espree": {
      "version": "9.6.1",
      "resolved": "https://registry.npmjs.org/espree/-/espree-9.6.1.tgz",
      "integrity": "sha512-oruZaFkjorTpF32kDSI5/75ViwGeZginGGy2NoOSg3Q9bnwlnmDm4HLnkl0RE3n+njDXR037aY1+x58Z/zFdwQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "acorn": "^8.9.0",
        "acorn-jsx": "^5.3.2",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/esquery": {
      "version": "1.7.0",
      "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.7.0.tgz",
      "integrity": "sha512-Ap6G0WQwcU/LHsvLwON1fAQX9Zp0A2Y6Y/cJBl9r/JbW90Zyg4/zbG6zzKa2OTALELarYHmKu0GhpM5EO+7T0g==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "estraverse": "^5.1.0"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/esrecurse": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/esrecurse/-/esrecurse-4.3.0.tgz",
      "integrity": "sha512-KmfKL3b6G+RXvP8N1vr3Tq1kL/oCFgn2NYXEtqP8/L3pKapUA4G8cFVaoF3SU323CD4XypR/ffioHmkti6/Tag==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estraverse": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/estraverse/-/estraverse-5.3.0.tgz",
      "integrity": "sha512-MMdARuVEQziNTeJD8DgMqmhwR11BRQ/cBP+pLtYdSTnf3MIO8fFeiINEbX36ZdNlfU/7A9f3gUw49B3oQsvwBA==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/esutils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.3.tgz",
      "integrity": "sha512-kVscqXk4OCp68SZ0dkgEKVi6/8ij300KBWTJq32P/dYeWTSwK41WyTxalN1eRmA5Z9UU/LX9D7FWSmV9SAYx6g==",
      "dev": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eventemitter3": {
      "version": "4.0.7",
      "resolved": "https://registry.npmjs.org/eventemitter3/-/eventemitter3-4.0.7.tgz",
      "integrity": "sha512-8guHBZCwKnFhYdHr2ysuRWErTwhoN2X8XELRlrRwpmfeY2jjuUN4taQMsULKUVo1K4DvZl+0pgfyoysHxvmvEw==",
      "license": "MIT"
    },
    "node_modules/fast-deep-equal": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
      "integrity": "sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-equals": {
      "version": "5.4.0",
      "resolved": "https://registry.npmjs.org/fast-equals/-/fast-equals-5.4.0.tgz",
      "integrity": "sha512-jt2DW/aNFNwke7AUd+Z+e6pz39KO5rzdbbFCg2sGafS4mk13MI7Z8O5z9cADNn5lhGODIgLwug6TZO2ctf7kcw==",
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/fast-glob": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/fast-glob/-/fast-glob-3.3.3.tgz",
      "integrity": "sha512-7MptL8U0cqcFdzIzwOTHoilX9x5BrNqye7Z/LuC7kCMRio1EMSyqRK3BEAUD7sXRq4iT4AzTVuZdhgQ2TCvYLg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "^2.0.2",
        "@nodelib/fs.walk": "^1.2.3",
        "glob-parent": "^5.1.2",
        "merge2": "^1.3.0",
        "micromatch": "^4.0.8"
      },
      "engines": {
        "node": ">=8.6.0"
      }
    },
    "node_modules/fast-glob/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-levenshtein": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/fast-levenshtein/-/fast-levenshtein-2.0.6.tgz",
      "integrity": "sha512-DCXu6Ifhqcks7TZKY3Hxp3y6qphY5SJZmrWMDrKcERSOXWQdMhU9Ig/PYrzyw/ul9jOIyh0N4M0tbC5hodg8dw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fastq": {
      "version": "1.20.1",
      "resolved": "https://registry.npmjs.org/fastq/-/fastq-1.20.1.tgz",
      "integrity": "sha512-GGToxJ/w1x32s/D2EKND7kTil4n8OVk/9mycTc4VDza13lOvpUZTGX3mFSCtV9ksdGBVzvsyAVLM6mHFThxXxw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "reusify": "^1.0.4"
      }
    },
    "node_modules/file-entry-cache": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/file-entry-cache/-/file-entry-cache-6.0.1.tgz",
      "integrity": "sha512-7Gps/XWymbLk2QLYK4NzpMOrYjMhdIxXuIvy2QBsLE6ljuodKvdkWs/cpyJJ3CVIVpH0Oi1Hvg1ovbMzLdFBBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flat-cache": "^3.0.4"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/fill-range": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz",
      "integrity": "sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "to-regex-range": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/find-up": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-5.0.0.tgz",
      "integrity": "sha512-78/PXT1wlLLDgTzDs7sjq9hzz0vXD+zn+7wypEe4fXQxCmdmqfGsEPQxmiCSQI3ajFV91bVSsvNtrJRiW6nGng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^6.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/flat-cache": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/flat-cache/-/flat-cache-3.2.0.tgz",
      "integrity": "sha512-CYcENa+FtcUKLmhhqyctpclsq7QF38pKjZHsGNiSQF5r4FtoKDWabFDl3hzaEQMvT1LHEysw5twgLvpYYb4vbw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flatted": "^3.2.9",
        "keyv": "^4.5.3",
        "rimraf": "^3.0.2"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/flatted": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/flatted/-/flatted-3.3.3.tgz",
      "integrity": "sha512-GX+ysw4PBCz0PzosHDepZGANEuFCMLrnRTiEy9McGjmkCQYwRq4A/X786G/fjM/+OjsWSU1ZrY5qyARZmO/uwg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/fraction.js": {
      "version": "5.3.4",
      "resolved": "https://registry.npmjs.org/fraction.js/-/fraction.js-5.3.4.tgz",
      "integrity": "sha512-1X1NTtiJphryn/uLQz3whtY6jK3fTqoE3ohKs0tT+Ujr1W59oopxmoEh7Lu5p6vBaPbgoM0bzveAW4Qi5RyWDQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "*"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/rawify"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/gensync": {
      "version": "1.0.0-beta.2",
      "resolved": "https://registry.npmjs.org/gensync/-/gensync-1.0.0-beta.2.tgz",
      "integrity": "sha512-3hN7NaskYvMDLQY55gnW3NQ+mesEAepTqlg+VEbj7zzqEMBVNhzcGYYeqFo/TlYz6eQiFcp1HcsCZO+nGgS8zg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/glob-parent": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-6.0.2.tgz",
      "integrity": "sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.3"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/glob/node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/glob/node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/globals": {
      "version": "13.24.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-13.24.0.tgz",
      "integrity": "sha512-AhO5QUcj8llrbG09iWhPU2B204J1xnPeL8kQmVorSsy+Sjj1sk8gIyh6cUocGmH4L0UuhAJy+hJMRA4mgA4mFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "type-fest": "^0.20.2"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/globby": {
      "version": "11.1.0",
      "resolved": "https://registry.npmjs.org/globby/-/globby-11.1.0.tgz",
      "integrity": "sha512-jhIXaOzy1sb8IyocaruWSn1TjmnBVs8Ayhcy83rmxNJ8q2uWKCAj3CnJY+KpGSXCueAPc0i05kVvVKtP1t9S3g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-union": "^2.1.0",
        "dir-glob": "^3.0.1",
        "fast-glob": "^3.2.9",
        "ignore": "^5.2.0",
        "merge2": "^1.4.1",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/graphemer": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/graphemer/-/graphemer-1.4.0.tgz",
      "integrity": "sha512-EtKwoO6kxCL9WO5xipiHTZlSzBm7WLT627TqC/uVRd0HKmq8NXyebnNYxDoBi7wt8eTWrUrKXCOVaFq9x1kgag==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/ignore": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-5.3.2.tgz",
      "integrity": "sha512-hsBTNUqQTDwkWtcdYI2i06Y/nUBEsNEDJKjWdigLvegy8kDuJAS8uRlpkkcQpyEXL0Z/pjDy5HBmMjRCJ2gq+g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/import-fresh": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/import-fresh/-/import-fresh-3.3.1.tgz",
      "integrity": "sha512-TR3KfrTZTYLPB6jUjfx6MF9WcWrHL9su5TObK4ZkYgBdWKPOFoSoQIdEuTuR82pmtxH2spWG9h6etwfr1pLBqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "parent-module": "^1.0.0",
        "resolve-from": "^4.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "deprecated": "This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/internmap": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/internmap/-/internmap-2.0.3.tgz",
      "integrity": "sha512-5Hh7Y1wQbvY5ooGgPbDaL5iYLAPzMTUrjMulskHLH6wnv/A+1q5rgEaiuqEjB+oxGXIVZs1FF+R/KPN3ZSQYYg==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/is-binary-path": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz",
      "integrity": "sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "binary-extensions": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-core-module": {
      "version": "2.16.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.16.1.tgz",
      "integrity": "sha512-UfoeMA6fIJ8wTYFEUjelnaGI67v6+N7qXJEvQuIGa99l4xsCruSYOVSQ0uPANn4dAzm8lkYPaKLrrijLq7x23w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-number": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz",
      "integrity": "sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.12.0"
      }
    },
    "node_modules/is-path-inside": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/is-path-inside/-/is-path-inside-3.0.3.tgz",
      "integrity": "sha512-Fd4gABb+ycGAmKou8eMftCupSir5lRxqf4aD/vd0cD2qc4HL07OjCeuHMr8Ro4CoMaeCKDB0/ECBOVWjTwUvPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/jiti": {
      "version": "1.21.7",
      "resolved": "https://registry.npmjs.org/jiti/-/jiti-1.21.7.tgz",
      "integrity": "sha512-/imKNG4EbWNrVjoNC/1H5/9GFy+tqjGBHCaSsN+P2RnPqjsLmv6UD3Ej+Kj8nBWaRAwyk7kK5ZUc+OEatnTR3A==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jiti": "bin/jiti.js"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
      "license": "MIT"
    },
    "node_modules/js-yaml": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.1.tgz",
      "integrity": "sha512-qQKT4zQxXl8lLwBtHMWwaTcGfFOZviOJet3Oy/xmGk2gZH677CJM9EvtfdSkgWcATZhj/55JZ0rmy3myCT5lsA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^2.0.1"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/jsesc": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/jsesc/-/jsesc-3.1.0.tgz",
      "integrity": "sha512-/sM3dO2FOzXjKQhJuo0Q173wf2KOo8t4I8vHy6lF9poUp7bKT0/NHE8fPX23PwfhnykfqnC2xRxOnVw5XuGIaA==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jsesc": "bin/jsesc"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/json-buffer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/json-buffer/-/json-buffer-3.0.1.tgz",
      "integrity": "sha512-4bV5BfR2mqfQTJm+V5tPPdf+ZpuhiIvTuAB5g8kcrXOZpTT/QwwVRWBywX1ozr6lEuPdbHxwaJlm9G6mI2sfSQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-schema-traverse": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-stable-stringify-without-jsonify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz",
      "integrity": "sha512-Bdboy+l7tA3OGW6FjyFHWkP5LuByj1Tk33Ljyq0axyzdk9//JSi2u3fP1QSmd1KNwq6VOKYGlAu87CisVir6Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json5": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/json5/-/json5-2.2.3.tgz",
      "integrity": "sha512-XmOWe7eyHYH14cLdVPoyg+GOH3rYX++KpzrylJwSW98t3Nk+U8XOl8FWKOgwtzdb8lXGf6zYwDUzeHMWfxasyg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "json5": "lib/cli.js"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/keyv": {
      "version": "4.5.4",
      "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
      "integrity": "sha512-oxVHkHR/EJf2CNXnWxRLW6mg7JyCCUcG0DtEGmL2ctUo1PNTin1PUil+r/+4r5MpVgC/fn1kjsx7mjSujKqIpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "json-buffer": "3.0.1"
      }
    },
    "node_modules/levn": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/levn/-/levn-0.4.1.tgz",
      "integrity": "sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1",
        "type-check": "~0.4.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/lilconfig": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/lilconfig/-/lilconfig-3.1.3.tgz",
      "integrity": "sha512-/vlFKAoH5Cgt3Ie+JLhRbwOsCQePABiU3tJ1egGvyQ+33R/vcwM2Zl2QR/LzjsBeItPt3oSVXapn+m4nQDvpzw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/antonk52"
      }
    },
    "node_modules/lines-and-columns": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz",
      "integrity": "sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/locate-path": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-6.0.0.tgz",
      "integrity": "sha512-iPZK6eYjbxRu3uB4/WZ3EsEIMJFMqAoopl3R+zuq0UjcAm/MO6KCweDgPfP3elTztoKP3KtnVHxTn2NHBSDVUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^5.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/lodash": {
      "version": "4.17.21",
      "resolved": "https://registry.npmjs.org/lodash/-/lodash-4.17.21.tgz",
      "integrity": "sha512-v2kDEe57lecTulaDIuNTPy3Ry4gLGJ6Z1O3vE1krgXZNrsQ+LFTGHVxVjcXPs17LhbZVGedAJv8XZ1tvj5FvSg==",
      "license": "MIT"
    },
    "node_modules/lodash.merge": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/lodash.merge/-/lodash.merge-4.6.2.tgz",
      "integrity": "sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/loose-envify": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/loose-envify/-/loose-envify-1.4.0.tgz",
      "integrity": "sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==",
      "license": "MIT",
      "dependencies": {
        "js-tokens": "^3.0.0 || ^4.0.0"
      },
      "bin": {
        "loose-envify": "cli.js"
      }
    },
    "node_modules/lru-cache": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-5.1.1.tgz",
      "integrity": "sha512-KpNARQA3Iwv+jTA0utUVVbrh+Jlrr1Fv0e56GGzAFOXN7dk/FviaDW8LHmK52DlcH4WP2n6gI8vN1aesBFgo9w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "yallist": "^3.0.2"
      }
    },
    "node_modules/merge2": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/merge2/-/merge2-1.4.1.tgz",
      "integrity": "sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/micromatch": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-4.0.8.tgz",
      "integrity": "sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "braces": "^3.0.3",
        "picomatch": "^2.3.1"
      },
      "engines": {
        "node": ">=8.6"
      }
    },
    "node_modules/minimatch": {
      "version": "9.0.3",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.3.tgz",
      "integrity": "sha512-RHiac9mvaRw0x3AYRgDC1CxAP7HTcNrrECeA8YYJeWnpo+2Q5CegtZjaotWTWxDG3UeGA1coE05iH1mPjT/2mg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/mz": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz",
      "integrity": "sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0",
        "object-assign": "^4.0.1",
        "thenify-all": "^1.0.0"
      }
    },
    "node_modules/nanoid": {
      "version": "3.3.11",
      "resolved": "https://registry.npmjs.org/nanoid/-/nanoid-3.3.11.tgz",
      "integrity": "sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "bin": {
        "nanoid": "bin/nanoid.cjs"
      },
      "engines": {
        "node": "^10 || ^12 || ^13.7 || ^14 || >=15.0.1"
      }
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/node-releases": {
      "version": "2.0.27",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.27.tgz",
      "integrity": "sha512-nmh3lCkYZ3grZvqcCH+fjmQ7X+H0OeZgP40OierEaAptX4XofMh5kwNbWh7lBduUzCcV/8kZ+NDLCwm2iorIlA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-hash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/object-hash/-/object-hash-3.0.0.tgz",
      "integrity": "sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/optionator": {
      "version": "0.9.4",
      "resolved": "https://registry.npmjs.org/optionator/-/optionator-0.9.4.tgz",
      "integrity": "sha512-6IpQ7mKUxRcZNLIObR0hz7lxsapSSIYNZJwXPGeF0mTVqGKFIXj1DQcMoT22S3ROcLyY/rz0PWaWZ9ayWmad9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "deep-is": "^0.1.3",
        "fast-levenshtein": "^2.0.6",
        "levn": "^0.4.1",
        "prelude-ls": "^1.2.1",
        "type-check": "^0.4.0",
        "word-wrap": "^1.2.5"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-5.0.0.tgz",
      "integrity": "sha512-LaNjtRWUBY++zB5nE/NwcaoMylSPk+S+ZHNB1TzdbMJMny6dynpAGt7X/tl/QYq3TIeE6nxHppbo2LGymrG5Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^3.0.2"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/parent-module": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.1.tgz",
      "integrity": "sha512-GQ2EWRpQV8/o+Aw8YqtfZZPfNRWZYkbidE9k5rpl/hC3vtHHBfGm2Ifi6qWV+coDGkrUKZAxE3Lot5kcsRlh+g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "callsites": "^3.0.0"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/path-type": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-type/-/path-type-4.0.0.tgz",
      "integrity": "sha512-gDKb8aZMDeD/tZWs9P6+q0J9Mwkdl6xMV8TjnGP3qJVJ06bdMgkbBlLU8IdfOsIsFz2BW1rNVT3XuNEl8zPAvw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/picomatch": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz",
      "integrity": "sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/pify": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/pify/-/pify-2.3.0.tgz",
      "integrity": "sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/pirates": {
      "version": "4.0.7",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.7.tgz",
      "integrity": "sha512-TfySrs/5nm8fQJDcBDuUng3VOUKsd7S+zqvbOTiGXHfxX4wK31ard+hoNuvkicM/2YFzlpDgABOevKSsB4G/FA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/postcss": {
      "version": "8.5.6",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.5.6.tgz",
      "integrity": "sha512-3Ybi1tAuwAP9s0r1UQ2J4n5Y0G05bJkpUIO0/bI9MhwmD70S5aTWbXGBwxHrelT+XM1k6dM0pk+SwNkpTRN7Pg==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.11",
        "picocolors": "^1.1.1",
        "source-map-js": "^1.2.1"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/postcss-import": {
      "version": "15.1.0",
      "resolved": "https://registry.npmjs.org/postcss-import/-/postcss-import-15.1.0.tgz",
      "integrity": "sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "postcss-value-parser": "^4.0.0",
        "read-cache": "^1.0.0",
        "resolve": "^1.1.7"
      },
      "engines": {
        "node": ">=14.0.0"
      },
      "peerDependencies": {
        "postcss": "^8.0.0"
      }
    },
    "node_modules/postcss-js": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/postcss-js/-/postcss-js-4.1.0.tgz",
      "integrity": "sha512-oIAOTqgIo7q2EOwbhb8UalYePMvYoIeRY2YKntdpFQXNosSu3vLrniGgmH9OKs/qAkfoj5oB3le/7mINW1LCfw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "camelcase-css": "^2.0.1"
      },
      "engines": {
        "node": "^12 || ^14 || >= 16"
      },
      "peerDependencies": {
        "postcss": "^8.4.21"
      }
    },
    "node_modules/postcss-load-config": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/postcss-load-config/-/postcss-load-config-6.0.1.tgz",
      "integrity": "sha512-oPtTM4oerL+UXmx+93ytZVN82RrlY/wPUV8IeDxFrzIjXOLF1pN+EmKPLbubvKHT2HC20xXsCAH2Z+CKV6Oz/g==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "lilconfig": "^3.1.1"
      },
      "engines": {
        "node": ">= 18"
      },
      "peerDependencies": {
        "jiti": ">=1.21.0",
        "postcss": ">=8.0.9",
        "tsx": "^4.8.1",
        "yaml": "^2.4.2"
      },
      "peerDependenciesMeta": {
        "jiti": {
          "optional": true
        },
        "postcss": {
          "optional": true
        },
        "tsx": {
          "optional": true
        },
        "yaml": {
          "optional": true
        }
      }
    },
    "node_modules/postcss-nested": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/postcss-nested/-/postcss-nested-6.2.0.tgz",
      "integrity": "sha512-HQbt28KulC5AJzG+cZtj9kvKB93CFCdLvog1WFLf1D+xmMvPGlBstkpTEZfK5+AN9hfJocyBFCNiqyS48bpgzQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "postcss-selector-parser": "^6.1.1"
      },
      "engines": {
        "node": ">=12.0"
      },
      "peerDependencies": {
        "postcss": "^8.2.14"
      }
    },
    "node_modules/postcss-selector-parser": {
      "version": "6.1.2",
      "resolved": "https://registry.npmjs.org/postcss-selector-parser/-/postcss-selector-parser-6.1.2.tgz",
      "integrity": "sha512-Q8qQfPiZ+THO/3ZrOrO0cJJKfpYCagtMUkXbnEfmgUjwXg6z/WBeOyS9APBBPCTSiDV+s4SwQGu8yFsiMRIudg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cssesc": "^3.0.0",
        "util-deprecate": "^1.0.2"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/postcss-value-parser": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/postcss-value-parser/-/postcss-value-parser-4.2.0.tgz",
      "integrity": "sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/prelude-ls": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/prelude-ls/-/prelude-ls-1.2.1.tgz",
      "integrity": "sha512-vkcDPrRZo1QZLbn5RLGPpg/WmIQ65qoWWhcGKf/b5eplkkarX0m9z8ppCat4mlOqUsWpyNuYgO3VRyrYHSzX5g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/prop-types": {
      "version": "15.8.1",
      "resolved": "https://registry.npmjs.org/prop-types/-/prop-types-15.8.1.tgz",
      "integrity": "sha512-oj87CgZICdulUohogVAR7AjlC0327U4el4L6eAvOqCeudMDVU0NThNaV+b9Df4dXgSP1gXMTnPdhfe/2qDH5cg==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.4.0",
        "object-assign": "^4.1.1",
        "react-is": "^16.13.1"
      }
    },
    "node_modules/prop-types/node_modules/react-is": {
      "version": "16.13.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-16.13.1.tgz",
      "integrity": "sha512-24e6ynE2H+OKt4kqsOvNd8kBpV65zoxbA4BVsEOB3ARVWQki/DHzaUoC5KuON/BiccDaCCTZBuOcfZs70kR8bQ==",
      "license": "MIT"
    },
    "node_modules/punycode": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.3.1.tgz",
      "integrity": "sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/queue-microtask": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/queue-microtask/-/queue-microtask-1.2.3.tgz",
      "integrity": "sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/react": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react/-/react-18.3.1.tgz",
      "integrity": "sha512-wS+hAgJShR0KhEvPJArfuPVN1+Hz1t0Y6n5jLrGQbkb4urgPE/0Rve+1kMB1v/oWgHgm4WIcV+i7F2pTVj+2iQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-dom": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-dom/-/react-dom-18.3.1.tgz",
      "integrity": "sha512-5m4nQKp+rZRb09LNH59GM4BxTh9251/ylbKIbpe7TpGxfJ+9kv6BLkLBXIjjspbgbnIBNqlI23tRnTWT0snUIw==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0",
        "scheduler": "^0.23.2"
      },
      "peerDependencies": {
        "react": "^18.3.1"
      }
    },
    "node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "license": "MIT"
    },
    "node_modules/react-refresh": {
      "version": "0.17.0",
      "resolved": "https://registry.npmjs.org/react-refresh/-/react-refresh-0.17.0.tgz",
      "integrity": "sha512-z6F7K9bV85EfseRCp2bzrpyQ0Gkw1uLoCel9XBVWPg/TjRj94SkJzUTGfOa4bs7iJvBWtQG0Wq7wnI0syw3EBQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-smooth": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/react-smooth/-/react-smooth-4.0.4.tgz",
      "integrity": "sha512-gnGKTpYwqL0Iii09gHobNolvX4Kiq4PKx6eWBCYYix+8cdw+cGo3do906l1NBPKkSWx1DghC1dlWG9L2uGd61Q==",
      "license": "MIT",
      "dependencies": {
        "fast-equals": "^5.0.1",
        "prop-types": "^15.8.1",
        "react-transition-group": "^4.4.5"
      },
      "peerDependencies": {
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0",
        "react-dom": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      }
    },
    "node_modules/react-transition-group": {
      "version": "4.4.5",
      "resolved": "https://registry.npmjs.org/react-transition-group/-/react-transition-group-4.4.5.tgz",
      "integrity": "sha512-pZcd1MCJoiKiBR2NRxeCRg13uCXbydPnmB4EOeRrY7480qNWO8IIgQG6zlDkm6uRMsURXPuKq0GWtiM59a5Q6g==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/runtime": "^7.5.5",
        "dom-helpers": "^5.0.1",
        "loose-envify": "^1.4.0",
        "prop-types": "^15.6.2"
      },
      "peerDependencies": {
        "react": ">=16.6.0",
        "react-dom": ">=16.6.0"
      }
    },
    "node_modules/read-cache": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/read-cache/-/read-cache-1.0.0.tgz",
      "integrity": "sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "pify": "^2.3.0"
      }
    },
    "node_modules/readdirp": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz",
      "integrity": "sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "picomatch": "^2.2.1"
      },
      "engines": {
        "node": ">=8.10.0"
      }
    },
    "node_modules/recharts": {
      "version": "2.15.4",
      "resolved": "https://registry.npmjs.org/recharts/-/recharts-2.15.4.tgz",
      "integrity": "sha512-UT/q6fwS3c1dHbXv2uFgYJ9BMFHu3fwnd7AYZaEQhXuYQ4hgsxLvsUXzGdKeZrW5xopzDCvuA2N41WJ88I7zIw==",
      "license": "MIT",
      "dependencies": {
        "clsx": "^2.0.0",
        "eventemitter3": "^4.0.1",
        "lodash": "^4.17.21",
        "react-is": "^18.3.1",
        "react-smooth": "^4.0.4",
        "recharts-scale": "^0.4.4",
        "tiny-invariant": "^1.3.1",
        "victory-vendor": "^36.6.8"
      },
      "engines": {
        "node": ">=14"
      },
      "peerDependencies": {
        "react": "^16.0.0 || ^17.0.0 || ^18.0.0 || ^19.0.0",
        "react-dom": "^16.0.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      }
    },
    "node_modules/recharts-scale": {
      "version": "0.4.5",
      "resolved": "https://registry.npmjs.org/recharts-scale/-/recharts-scale-0.4.5.tgz",
      "integrity": "sha512-kivNFO+0OcUNu7jQquLXAxz1FIwZj8nrj+YkOKc5694NbjCvcT6aSZiIzNzd2Kul4o4rTto8QVR9lMNtxD4G1w==",
      "license": "MIT",
      "dependencies": {
        "decimal.js-light": "^2.4.1"
      }
    },
    "node_modules/resolve": {
      "version": "1.22.11",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.11.tgz",
      "integrity": "sha512-RfqAvLnMl313r7c9oclB1HhUEAezcpLjz95wFH4LVuhk9JF/r22qmVP9AMmOU4vMX7Q8pN8jwNg/CSpdFnMjTQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.16.1",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-from": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-4.0.0.tgz",
      "integrity": "sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/reusify": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/reusify/-/reusify-1.1.0.tgz",
      "integrity": "sha512-g6QUff04oZpHs0eG5p83rFLhHeV00ug/Yf9nZM6fLeUrPguBTkTQOdpAWWspMh55TZfVQDPaN3NQJfbVRAxdIw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "iojs": ">=1.0.0",
        "node": ">=0.10.0"
      }
    },
    "node_modules/rimraf": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz",
      "integrity": "sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==",
      "deprecated": "Rimraf versions prior to v4 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "glob": "^7.1.3"
      },
      "bin": {
        "rimraf": "bin.js"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/rollup": {
      "version": "4.55.1",
      "resolved": "https://registry.npmjs.org/rollup/-/rollup-4.55.1.tgz",
      "integrity": "sha512-wDv/Ht1BNHB4upNbK74s9usvl7hObDnvVzknxqY/E/O3X6rW1U1rV1aENEfJ54eFZDTNo7zv1f5N4edCluH7+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/estree": "1.0.8"
      },
      "bin": {
        "rollup": "dist/bin/rollup"
      },
      "engines": {
        "node": ">=18.0.0",
        "npm": ">=8.0.0"
      },
      "optionalDependencies": {
        "@rollup/rollup-android-arm-eabi": "4.55.1",
        "@rollup/rollup-android-arm64": "4.55.1",
        "@rollup/rollup-darwin-arm64": "4.55.1",
        "@rollup/rollup-darwin-x64": "4.55.1",
        "@rollup/rollup-freebsd-arm64": "4.55.1",
        "@rollup/rollup-freebsd-x64": "4.55.1",
        "@rollup/rollup-linux-arm-gnueabihf": "4.55.1",
        "@rollup/rollup-linux-arm-musleabihf": "4.55.1",
        "@rollup/rollup-linux-arm64-gnu": "4.55.1",
        "@rollup/rollup-linux-arm64-musl": "4.55.1",
        "@rollup/rollup-linux-loong64-gnu": "4.55.1",
        "@rollup/rollup-linux-loong64-musl": "4.55.1",
        "@rollup/rollup-linux-ppc64-gnu": "4.55.1",
        "@rollup/rollup-linux-ppc64-musl": "4.55.1",
        "@rollup/rollup-linux-riscv64-gnu": "4.55.1",
        "@rollup/rollup-linux-riscv64-musl": "4.55.1",
        "@rollup/rollup-linux-s390x-gnu": "4.55.1",
        "@rollup/rollup-linux-x64-gnu": "4.55.1",
        "@rollup/rollup-linux-x64-musl": "4.55.1",
        "@rollup/rollup-openbsd-x64": "4.55.1",
        "@rollup/rollup-openharmony-arm64": "4.55.1",
        "@rollup/rollup-win32-arm64-msvc": "4.55.1",
        "@rollup/rollup-win32-ia32-msvc": "4.55.1",
        "@rollup/rollup-win32-x64-gnu": "4.55.1",
        "@rollup/rollup-win32-x64-msvc": "4.55.1",
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/run-parallel": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/run-parallel/-/run-parallel-1.2.0.tgz",
      "integrity": "sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "queue-microtask": "^1.2.2"
      }
    },
    "node_modules/scheduler": {
      "version": "0.23.2",
      "resolved": "https://registry.npmjs.org/scheduler/-/scheduler-0.23.2.tgz",
      "integrity": "sha512-UOShsPwz7NrMUqhR6t0hWjFduvOzbtv7toDH1/hIrfRNIDBnnBWd0CwJTGvTpngVlmwGCdP9/Zl/tVrDqcuYzQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      }
    },
    "node_modules/semver": {
      "version": "7.7.3",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.3.tgz",
      "integrity": "sha512-SdsKMrI9TdgjdweUSR9MweHA4EJ8YxHn8DFaDisvhVlUOe4BF1tLD7GAj0lIqWVl+dPb/rExr0Btby5loQm20Q==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/slash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-3.0.0.tgz",
      "integrity": "sha512-g9Q1haeby36OSStwb4ntCGGGaKsaVSjQ68fBxoQcutl5fS1vuY18H3wSt3jFyFtrkx+Kz0V1G85A4MyAdDMi2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/source-map-js": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.1.tgz",
      "integrity": "sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/sucrase": {
      "version": "3.35.1",
      "resolved": "https://registry.npmjs.org/sucrase/-/sucrase-3.35.1.tgz",
      "integrity": "sha512-DhuTmvZWux4H1UOnWMB3sk0sbaCVOoQZjv8u1rDoTV0HTdGem9hkAZtl4JZy8P2z4Bg0nT+YMeOFyVr4zcG5Tw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.2",
        "commander": "^4.0.0",
        "lines-and-columns": "^1.1.6",
        "mz": "^2.7.0",
        "pirates": "^4.0.1",
        "tinyglobby": "^0.2.11",
        "ts-interface-checker": "^0.1.9"
      },
      "bin": {
        "sucrase": "bin/sucrase",
        "sucrase-node": "bin/sucrase-node"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/tailwindcss": {
      "version": "3.4.19",
      "resolved": "https://registry.npmjs.org/tailwindcss/-/tailwindcss-3.4.19.tgz",
      "integrity": "sha512-3ofp+LL8E+pK/JuPLPggVAIaEuhvIz4qNcf3nA1Xn2o/7fb7s/TYpHhwGDv1ZU3PkBluUVaF8PyCHcm48cKLWQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@alloc/quick-lru": "^5.2.0",
        "arg": "^5.0.2",
        "chokidar": "^3.6.0",
        "didyoumean": "^1.2.2",
        "dlv": "^1.1.3",
        "fast-glob": "^3.3.2",
        "glob-parent": "^6.0.2",
        "is-glob": "^4.0.3",
        "jiti": "^1.21.7",
        "lilconfig": "^3.1.3",
        "micromatch": "^4.0.8",
        "normalize-path": "^3.0.0",
        "object-hash": "^3.0.0",
        "picocolors": "^1.1.1",
        "postcss": "^8.4.47",
        "postcss-import": "^15.1.0",
        "postcss-js": "^4.0.1",
        "postcss-load-config": "^4.0.2 || ^5.0 || ^6.0",
        "postcss-nested": "^6.2.0",
        "postcss-selector-parser": "^6.1.2",
        "resolve": "^1.22.8",
        "sucrase": "^3.35.0"
      },
      "bin": {
        "tailwind": "lib/cli.js",
        "tailwindcss": "lib/cli.js"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/text-table": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/text-table/-/text-table-0.2.0.tgz",
      "integrity": "sha512-N+8UisAXDGk8PFXP4HAzVR9nbfmVJ3zYLAWiTIoqC5v5isinhr+r5uaO8+7r3BMfuNIufIsA7RdpVgacC2cSpw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/thenify": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz",
      "integrity": "sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0"
      }
    },
    "node_modules/thenify-all": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz",
      "integrity": "sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "thenify": ">= 3.1.0 < 4"
      },
      "engines": {
        "node": ">=0.8"
      }
    },
    "node_modules/tiny-invariant": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/tiny-invariant/-/tiny-invariant-1.3.3.tgz",
      "integrity": "sha512-+FbBPE1o9QAYvviau/qC5SE3caw21q3xkvWKBtja5vgqOWIHHJ3ioaq1VPfn/Szqctz2bU/oYeKd9/z5BL+PVg==",
      "license": "MIT"
    },
    "node_modules/tinyglobby": {
      "version": "0.2.15",
      "resolved": "https://registry.npmjs.org/tinyglobby/-/tinyglobby-0.2.15.tgz",
      "integrity": "sha512-j2Zq4NyQYG5XMST4cbs02Ak8iJUdxRM0XI5QyxXuZOzKOINmWurp3smXu3y5wDcJrptwpSjgXHzIQxR0omXljQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fdir": "^6.5.0",
        "picomatch": "^4.0.3"
      },
      "engines": {
        "node": ">=12.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/SuperchupuDev"
      }
    },
    "node_modules/tinyglobby/node_modules/fdir": {
      "version": "6.5.0",
      "resolved": "https://registry.npmjs.org/fdir/-/fdir-6.5.0.tgz",
      "integrity": "sha512-tIbYtZbucOs0BRGqPJkshJUYdL+SDH7dVM8gjy+ERp3WAUjLEFJE+02kanyHtwjWOnwrKYBiwAmM0p4kLJAnXg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.0.0"
      },
      "peerDependencies": {
        "picomatch": "^3 || ^4"
      },
      "peerDependenciesMeta": {
        "picomatch": {
          "optional": true
        }
      }
    },
    "node_modules/tinyglobby/node_modules/picomatch": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-4.0.3.tgz",
      "integrity": "sha512-5gTmgEY/sqK6gFXLIsQNH19lWb4ebPDLA4SdLP7dsWkIXHWlG66oPuVvXSGFPppYZz8ZDZq0dYYrbHfBCVUb1Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/to-regex-range": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz",
      "integrity": "sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-number": "^7.0.0"
      },
      "engines": {
        "node": ">=8.0"
      }
    },
    "node_modules/ts-api-utils": {
      "version": "1.4.3",
      "resolved": "https://registry.npmjs.org/ts-api-utils/-/ts-api-utils-1.4.3.tgz",
      "integrity": "sha512-i3eMG77UTMD0hZhgRS562pv83RC6ukSAC2GMNWc+9dieh/+jDM5u5YG+NHX6VNDRHQcHwmsTHctP9LhbC3WxVw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=16"
      },
      "peerDependencies": {
        "typescript": ">=4.2.0"
      }
    },
    "node_modules/ts-interface-checker": {
      "version": "0.1.13",
      "resolved": "https://registry.npmjs.org/ts-interface-checker/-/ts-interface-checker-0.1.13.tgz",
      "integrity": "sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==",
      "dev": true,
      "license": "Apache-2.0"
    },
    "node_modules/type-check": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/type-check/-/type-check-0.4.0.tgz",
      "integrity": "sha512-XleUoc9uwGXqjWwXaUTZAmzMcFZ5858QA2vvx1Ur5xIcixXIP+8LnFDgRplU30us6teqdlskFfu+ae4K79Ooew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/type-fest": {
      "version": "0.20.2",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.20.2.tgz",
      "integrity": "sha512-Ne+eE4r0/iWnpAxD852z3A+N0Bt5RN//NjJwRd2VFHEmrywxf5vsZlh4R6lixl6B+wz/8d+maTSAkN1FIkI3LQ==",
      "dev": true,
      "license": "(MIT OR CC0-1.0)",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/typescript": {
      "version": "5.9.3",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.9.3.tgz",
      "integrity": "sha512-jl1vZzPDinLr9eUt3J/t7V6FgNEw9QjvBPdysz9KfQDD41fQrC2Y4vKQdiaUpFT4bXlb1RHhLpp8wtm6M5TgSw==",
      "dev": true,
      "license": "Apache-2.0",
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/update-browserslist-db": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.2.3.tgz",
      "integrity": "sha512-Js0m9cx+qOgDxo0eMiFGEueWztz+d4+M3rGlmKPT+T4IS/jP4ylw3Nwpu6cpTTP8R1MAC1kF4VbdLt3ARf209w==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "escalade": "^3.2.0",
        "picocolors": "^1.1.1"
      },
      "bin": {
        "update-browserslist-db": "cli.js"
      },
      "peerDependencies": {
        "browserslist": ">= 4.21.0"
      }
    },
    "node_modules/uri-js": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.4.1.tgz",
      "integrity": "sha512-7rKUyy33Q1yc98pQ1DAmLtwX109F7TIfWlW1Ydo8Wl1ii1SeHieeh0HHfPeL2fMXK6z0s8ecKs9frCuLJvndBg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "punycode": "^2.1.0"
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/victory-vendor": {
      "version": "36.9.2",
      "resolved": "https://registry.npmjs.org/victory-vendor/-/victory-vendor-36.9.2.tgz",
      "integrity": "sha512-PnpQQMuxlwYdocC8fIJqVXvkeViHYzotI+NJrCuav0ZYFoq912ZHBk3mCeuj+5/VpodOjPe1z0Fk2ihgzlXqjQ==",
      "license": "MIT AND ISC",
      "dependencies": {
        "@types/d3-array": "^3.0.3",
        "@types/d3-ease": "^3.0.0",
        "@types/d3-interpolate": "^3.0.1",
        "@types/d3-scale": "^4.0.2",
        "@types/d3-shape": "^3.1.0",
        "@types/d3-time": "^3.0.0",
        "@types/d3-timer": "^3.0.0",
        "d3-array": "^3.1.6",
        "d3-ease": "^3.0.1",
        "d3-interpolate": "^3.0.1",
        "d3-scale": "^4.0.2",
        "d3-shape": "^3.1.0",
        "d3-time": "^3.0.0",
        "d3-timer": "^3.0.1"
      }
    },
    "node_modules/vite": {
      "version": "5.4.21",
      "resolved": "https://registry.npmjs.org/vite/-/vite-5.4.21.tgz",
      "integrity": "sha512-o5a9xKjbtuhY6Bi5S3+HvbRERmouabWbyUcpXXUA1u+GNUKoROi9byOJ8M0nHbHYHkYICiMlqxkg1KkYmm25Sw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "esbuild": "^0.21.3",
        "postcss": "^8.4.43",
        "rollup": "^4.20.0"
      },
      "bin": {
        "vite": "bin/vite.js"
      },
      "engines": {
        "node": "^18.0.0 || >=20.0.0"
      },
      "funding": {
        "url": "https://github.com/vitejs/vite?sponsor=1"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.3"
      },
      "peerDependencies": {
        "@types/node": "^18.0.0 || >=20.0.0",
        "less": "*",
        "lightningcss": "^1.21.0",
        "sass": "*",
        "sass-embedded": "*",
        "stylus": "*",
        "sugarss": "*",
        "terser": "^5.4.0"
      },
      "peerDependenciesMeta": {
        "@types/node": {
          "optional": true
        },
        "less": {
          "optional": true
        },
        "lightningcss": {
          "optional": true
        },
        "sass": {
          "optional": true
        },
        "sass-embedded": {
          "optional": true
        },
        "stylus": {
          "optional": true
        },
        "sugarss": {
          "optional": true
        },
        "terser": {
          "optional": true
        }
      }
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/word-wrap": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/word-wrap/-/word-wrap-1.2.5.tgz",
      "integrity": "sha512-BN22B5eaMMI9UMtjrGd5g5eCYPpCPDUy0FJXbYsaT5zYxjFOckS53SQDE3pWkVoWpHXVb3BrYcEN4Twa55B5cA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/yallist": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/yallist/-/yallist-3.1.1.tgz",
      "integrity": "sha512-a4UGQaWPH59mOXUYnAG2ewncQS4i4F43Tv3JoAM+s2VDAmS9NsK8GpDMLrCHPksFT7h3K6TOoUNn2pb7RoXx4g==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    }
  }
}

################################################################################
# FILE: :\good projects\cost estimation\frontend\tsconfig.json
# TYPE: json
# SIZE: 872 bytes
################################################################################
{
    "compilerOptions": {
        "target": "ES2020",
        "useDefineForClassFields": true,
        "lib": [
            "ES2020",
            "DOM",
            "DOM.Iterable"
        ],
        "module": "ESNext",
        "skipLibCheck": true,
        "moduleResolution": "bundler",
        "allowImportingTsExtensions": true,
        "resolveJsonModule": true,
        "isolatedModules": true,
        "noEmit": true,
        "jsx": "react-jsx",
        "strict": true,
        "noUnusedLocals": true,
        "noUnusedParameters": true,
        "noFallthroughCasesInSwitch": true,
        "baseUrl": ".",
        "paths": {
            "@/*": [
                "src/*"
            ]
        }
    },
    "include": [
        "src"
    ],
    "references": [
        {
            "path": "./tsconfig.node.json"
        }
    ]
}

################################################################################
# FILE: :\good projects\cost estimation\frontend\tsconfig.node.json
# TYPE: json
# SIZE: 263 bytes
################################################################################
{
    "compilerOptions": {
        "composite": true,
        "skipLibCheck": true,
        "module": "ESNext",
        "moduleResolution": "bundler",
        "allowSyntheticDefaultImports": true
    },
    "include": [
        "vite.config.ts"
    ]
}

################################################################################
# FILE: :\good projects\cost estimation\internal\config\config.go
# TYPE: go
# SIZE: 4997 bytes
################################################################################
// Package config provides configuration management.
package config

import (
	"encoding/json"
	"os"
	"path/filepath"

	"terraform-cost/core/types"
	"terraform-cost/internal/logging"
)

// Config is the main application configuration
type Config struct {
	// Version is the configuration version
	Version string `json:"version"`

	// Pricing contains pricing configuration
	Pricing PricingConfig `json:"pricing"`

	// Output contains output configuration
	Output OutputConfig `json:"output"`

	// Cache contains cache configuration
	Cache CacheConfig `json:"cache"`

	// Logging contains logging configuration
	Logging logging.Config `json:"logging"`

	// AWS contains AWS-specific configuration
	AWS AWSConfig `json:"aws,omitempty"`

	// Azure contains Azure-specific configuration  
	Azure AzureConfig `json:"azure,omitempty"`

	// GCP contains GCP-specific configuration
	GCP GCPConfig `json:"gcp,omitempty"`
}

// PricingConfig contains pricing-related settings
type PricingConfig struct {
	// DefaultCurrency is the default currency
	DefaultCurrency types.Currency `json:"default_currency"`

	// CacheEnabled enables pricing caching
	CacheEnabled bool `json:"cache_enabled"`

	// CacheTTLSeconds is how long to cache prices
	CacheTTLSeconds int `json:"cache_ttl_seconds"`

	// DatabasePath is the path to the pricing database
	DatabasePath string `json:"database_path"`

	// RefreshOnStart refreshes pricing on startup
	RefreshOnStart bool `json:"refresh_on_start"`
}

// OutputConfig contains output-related settings
type OutputConfig struct {
	// DefaultFormat is the default output format
	DefaultFormat string `json:"default_format"`

	// ShowDetails shows detailed cost breakdown
	ShowDetails bool `json:"show_details"`

	// ShowConfidence shows confidence scores
	ShowConfidence bool `json:"show_confidence"`

	// GroupBy is the default grouping
	GroupBy string `json:"group_by"`
}

// CacheConfig contains cache-related settings
type CacheConfig struct {
	// Enabled enables caching
	Enabled bool `json:"enabled"`

	// Directory is the cache directory
	Directory string `json:"directory"`

	// MaxSizeMB is the maximum cache size in MB
	MaxSizeMB int `json:"max_size_mb"`
}

// AWSConfig contains AWS-specific settings
type AWSConfig struct {
	// DefaultRegion is the default AWS region
	DefaultRegion string `json:"default_region"`

	// Profile is the AWS profile to use
	Profile string `json:"profile,omitempty"`

	// Regions to include in pricing
	Regions []string `json:"regions,omitempty"`
}

// AzureConfig contains Azure-specific settings
type AzureConfig struct {
	// DefaultRegion is the default Azure region
	DefaultRegion string `json:"default_region"`

	// SubscriptionID is the Azure subscription
	SubscriptionID string `json:"subscription_id,omitempty"`
}

// GCPConfig contains GCP-specific settings
type GCPConfig struct {
	// DefaultRegion is the default GCP region
	DefaultRegion string `json:"default_region"`

	// Project is the GCP project
	Project string `json:"project,omitempty"`
}

// Default returns a default configuration
func Default() *Config {
	homeDir, _ := os.UserHomeDir()
	cacheDir := filepath.Join(homeDir, ".terraform-cost", "cache")
	dbPath := filepath.Join(homeDir, ".terraform-cost", "pricing.db")

	return &Config{
		Version: "1.0",
		Pricing: PricingConfig{
			DefaultCurrency: types.CurrencyUSD,
			CacheEnabled:    true,
			CacheTTLSeconds: 86400, // 24 hours
			DatabasePath:    dbPath,
			RefreshOnStart:  false,
		},
		Output: OutputConfig{
			DefaultFormat:  "cli",
			ShowDetails:    true,
			ShowConfidence: false,
			GroupBy:        "resource",
		},
		Cache: CacheConfig{
			Enabled:   true,
			Directory: cacheDir,
			MaxSizeMB: 100,
		},
		Logging: logging.DefaultConfig(),
		AWS: AWSConfig{
			DefaultRegion: "us-east-1",
		},
		Azure: AzureConfig{
			DefaultRegion: "eastus",
		},
		GCP: GCPConfig{
			DefaultRegion: "us-central1",
		},
	}
}

// Load loads configuration from a file
func Load(path string) (*Config, error) {
	data, err := os.ReadFile(path)
	if err != nil {
		if os.IsNotExist(err) {
			return Default(), nil
		}
		return nil, err
	}

	config := Default()
	if err := json.Unmarshal(data, config); err != nil {
		return nil, err
	}

	return config, nil
}

// Save saves configuration to a file
func (c *Config) Save(path string) error {
	// Ensure directory exists
	dir := filepath.Dir(path)
	if err := os.MkdirAll(dir, 0755); err != nil {
		return err
	}

	data, err := json.MarshalIndent(c, "", "  ")
	if err != nil {
		return err
	}

	return os.WriteFile(path, data, 0644)
}

// Global configuration instance
var globalConfig = Default()

// Get returns the global configuration
func Get() *Config {
	return globalConfig
}

// Set sets the global configuration
func Set(config *Config) {
	globalConfig = config
}

################################################################################
# FILE: :\good projects\cost estimation\internal\errors\errors.go
# TYPE: go
# SIZE: 3810 bytes
################################################################################
// Package errors provides error handling utilities.
package errors

import (
	"fmt"
)

// Type identifies the category of error
type Type string

const (
	// TypeInput indicates an input validation error
	TypeInput Type = "INPUT_ERROR"

	// TypeParsing indicates a parsing error
	TypeParsing Type = "PARSING_ERROR"

	// TypePricing indicates a pricing resolution error
	TypePricing Type = "PRICING_ERROR"

	// TypePolicy indicates a policy evaluation error
	TypePolicy Type = "POLICY_ERROR"

	// TypeConfig indicates a configuration error
	TypeConfig Type = "CONFIG_ERROR"

	// TypeNetwork indicates a network error
	TypeNetwork Type = "NETWORK_ERROR"

	// TypeInternal indicates an internal error
	TypeInternal Type = "INTERNAL_ERROR"

	// TypeNotFound indicates a resource not found error
	TypeNotFound Type = "NOT_FOUND"

	// TypeNotSupported indicates an unsupported operation
	TypeNotSupported Type = "NOT_SUPPORTED"
)

// Error represents a domain error with context
type Error struct {
	Type    Type                   `json:"type"`
	Message string                 `json:"message"`
	Cause   error                  `json:"-"`
	Context map[string]interface{} `json:"context,omitempty"`
}

// Error implements the error interface
func (e *Error) Error() string {
	if e.Cause != nil {
		return fmt.Sprintf("[%s] %s: %v", e.Type, e.Message, e.Cause)
	}
	return fmt.Sprintf("[%s] %s", e.Type, e.Message)
}

// Unwrap returns the underlying error
func (e *Error) Unwrap() error {
	return e.Cause
}

// Is checks if the error is of a specific type
func (e *Error) Is(t Type) bool {
	return e.Type == t
}

// WithContext adds context to the error
func (e *Error) WithContext(key string, value interface{}) *Error {
	if e.Context == nil {
		e.Context = make(map[string]interface{})
	}
	e.Context[key] = value
	return e
}

// New creates a new error
func New(errType Type, message string) *Error {
	return &Error{
		Type:    errType,
		Message: message,
	}
}

// Newf creates a new formatted error
func Newf(errType Type, format string, args ...interface{}) *Error {
	return &Error{
		Type:    errType,
		Message: fmt.Sprintf(format, args...),
	}
}

// Wrap wraps an error with context
func Wrap(errType Type, message string, cause error) *Error {
	return &Error{
		Type:    errType,
		Message: message,
		Cause:   cause,
	}
}

// Wrapf wraps an error with formatted context
func Wrapf(errType Type, cause error, format string, args ...interface{}) *Error {
	return &Error{
		Type:    errType,
		Message: fmt.Sprintf(format, args...),
		Cause:   cause,
	}
}

// IsType checks if an error is of a specific type
func IsType(err error, t Type) bool {
	if e, ok := err.(*Error); ok {
		return e.Type == t
	}
	return false
}

// Input creates an input error
func Input(message string) *Error {
	return New(TypeInput, message)
}

// Parsing creates a parsing error
func Parsing(message string, cause error) *Error {
	return Wrap(TypeParsing, message, cause)
}

// Pricing creates a pricing error
func Pricing(message string, cause error) *Error {
	return Wrap(TypePricing, message, cause)
}

// Policy creates a policy error
func Policy(message string) *Error {
	return New(TypePolicy, message)
}

// NotFound creates a not found error
func NotFound(resourceType, identifier string) *Error {
	return Newf(TypeNotFound, "%s not found: %s", resourceType, identifier)
}

// NotSupported creates a not supported error
func NotSupported(operation string) *Error {
	return Newf(TypeNotSupported, "operation not supported: %s", operation)
}

// Internal creates an internal error
func Internal(message string, cause error) *Error {
	return Wrap(TypeInternal, message, cause)
}

################################################################################
# FILE: :\good projects\cost estimation\internal\logging\logging.go
# TYPE: go
# SIZE: 3090 bytes
################################################################################
// Package logging provides structured logging utilities.
package logging

import (
	"os"

	"go.uber.org/zap"
	"go.uber.org/zap/zapcore"
)

var (
	// Logger is the global logger instance
	Logger *zap.Logger

	// Sugar is the sugared logger for convenience
	Sugar *zap.SugaredLogger
)

// Config contains logging configuration
type Config struct {
	// Level is the minimum log level
	Level string `json:"level"`

	// Format is the output format (json, console)
	Format string `json:"format"`

	// Output is the output destination (stdout, stderr, file path)
	Output string `json:"output"`

	// Development enables development mode
	Development bool `json:"development"`
}

// DefaultConfig returns sensible defaults
func DefaultConfig() Config {
	return Config{
		Level:       "info",
		Format:      "console",
		Output:      "stderr",
		Development: false,
	}
}

// Initialize sets up the global logger
func Initialize(cfg Config) error {
	level, err := zapcore.ParseLevel(cfg.Level)
	if err != nil {
		level = zapcore.InfoLevel
	}

	var encoder zapcore.Encoder
	encoderConfig := zap.NewProductionEncoderConfig()
	encoderConfig.TimeKey = "timestamp"
	encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder

	if cfg.Format == "console" {
		encoderConfig.EncodeLevel = zapcore.CapitalColorLevelEncoder
		encoder = zapcore.NewConsoleEncoder(encoderConfig)
	} else {
		encoder = zapcore.NewJSONEncoder(encoderConfig)
	}

	var writeSyncer zapcore.WriteSyncer
	switch cfg.Output {
	case "stdout":
		writeSyncer = zapcore.AddSync(os.Stdout)
	case "stderr":
		writeSyncer = zapcore.AddSync(os.Stderr)
	default:
		file, err := os.OpenFile(cfg.Output, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
		if err != nil {
			return err
		}
		writeSyncer = zapcore.AddSync(file)
	}

	core := zapcore.NewCore(encoder, writeSyncer, level)

	if cfg.Development {
		Logger = zap.New(core, zap.Development(), zap.AddCaller(), zap.AddStacktrace(zapcore.ErrorLevel))
	} else {
		Logger = zap.New(core, zap.AddCaller())
	}

	Sugar = Logger.Sugar()
	return nil
}

// InitializeDefault sets up the logger with default configuration
func InitializeDefault() {
	_ = Initialize(DefaultConfig())
}

// Sync flushes the logger
func Sync() {
	if Logger != nil {
		_ = Logger.Sync()
	}
}

// With returns a logger with additional fields
func With(fields ...zap.Field) *zap.Logger {
	return Logger.With(fields...)
}

// Debug logs at debug level
func Debug(msg string, fields ...zap.Field) {
	Logger.Debug(msg, fields...)
}

// Info logs at info level
func Info(msg string, fields ...zap.Field) {
	Logger.Info(msg, fields...)
}

// Warn logs at warn level
func Warn(msg string, fields ...zap.Field) {
	Logger.Warn(msg, fields...)
}

// Error logs at error level
func Error(msg string, fields ...zap.Field) {
	Logger.Error(msg, fields...)
}

// Fatal logs at fatal level and exits
func Fatal(msg string, fields ...zap.Field) {
	Logger.Fatal(msg, fields...)
}

func init() {
	InitializeDefault()
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\bad_configs\circular_dependency.tf
# TYPE: hcl
# SIZE: 606 bytes
################################################################################
# Bad Config: Circular dependency

resource "aws_security_group" "circular_a" {
  name   = "circular-a"
  vpc_id = "vpc-12345678"

  ingress {
    from_port       = 80
    to_port         = 80
    protocol        = "tcp"
    security_groups = [aws_security_group.circular_b.id]
  }
}

resource "aws_security_group" "circular_b" {
  name   = "circular-b"
  vpc_id = "vpc-12345678"

  ingress {
    from_port       = 443
    to_port         = 443
    protocol        = "tcp"
    security_groups = [aws_security_group.circular_a.id]
  }
}

# This will cause a Terraform cycle error

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\bad_configs\duplicate_resource.tf
# TYPE: hcl
# SIZE: 316 bytes
################################################################################
# Bad Config: Duplicate resource name

resource "aws_instance" "duplicate" {
  ami           = "ami-12345678"
  instance_type = "t3.micro"
}

# This would be a Terraform error - duplicate resource name
resource "aws_instance" "duplicate" {
  ami           = "ami-87654321"
  instance_type = "t3.small"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\bad_configs\invalid_for_each.tf
# TYPE: hcl
# SIZE: 341 bytes
################################################################################
# Bad Config: Invalid for_each (not map or set)

variable "instance_count" {
  type    = number
  default = 3
}

# for_each requires map or set, not number
resource "aws_instance" "invalid_for_each" {
  for_each = var.instance_count # ERROR: number is not valid

  ami           = "ami-12345678"
  instance_type = "t3.micro"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\bad_configs\missing_required.tf
# TYPE: hcl
# SIZE: 156 bytes
################################################################################
# Bad Config: Missing required attribute

resource "aws_instance" "missing_ami" {
  # Missing required 'ami' attribute
  instance_type = "t3.micro"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\bad_configs\syntax_error.tf
# TYPE: hcl
# SIZE: 195 bytes
################################################################################
# Bad Config: Syntax error

resource "aws_instance" "broken" {
  ami           = "ami-12345678"
  instance_type = "t3.micro"

  tags = {
    Name = "broken"
  # Missing closing brace
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\bad_configs\type_mismatch.tf
# TYPE: hcl
# SIZE: 548 bytes
################################################################################
# Bad Config: Type mismatch

variable "count_value" {
  type    = string  # Should be number
  default = "three" # Invalid for count
}

resource "aws_instance" "type_error" {
  count = var.count_value # ERROR: string to number

  ami           = "ami-12345678"
  instance_type = "t3.micro"
}

variable "for_each_value" {
  type    = number
  default = 5
}

resource "aws_instance" "for_each_error" {
  for_each = var.for_each_value # ERROR: number not valid

  ami           = "ami-12345678"
  instance_type = "t3.micro"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\basic\high_cost.tf
# TYPE: hcl
# SIZE: 1938 bytes
################################################################################
# Basic: High-cost infrastructure pattern

# NAT Gateways (expensive)
resource "aws_nat_gateway" "main" {
  count = 3

  allocation_id = "eipalloc-${count.index}"
  subnet_id     = "subnet-${count.index}"

  tags = {
    Name = "nat-${count.index}"
  }
}

# RDS Multi-AZ (expensive)
resource "aws_db_instance" "production" {
  identifier     = "production-db"
  engine         = "postgres"
  engine_version = "14"
  instance_class = "db.r6g.2xlarge"

  allocated_storage     = 500
  max_allocated_storage = 2000
  storage_type          = "io1"
  iops                  = 10000

  multi_az = true

  backup_retention_period = 30
  storage_encrypted       = true
}

# ElastiCache cluster (medium cost)
resource "aws_elasticache_replication_group" "main" {
  replication_group_id = "main-cache"
  description          = "Main cache cluster"

  node_type          = "cache.r6g.large"
  num_cache_clusters = 3
  engine             = "redis"
  engine_version     = "7.0"

  automatic_failover_enabled = true
  multi_az_enabled           = true
}

# EKS cluster (expensive with nodes)
resource "aws_eks_cluster" "main" {
  name     = "main-cluster"
  role_arn = "arn:aws:iam::123456789:role/eks-cluster-role"

  vpc_config {
    subnet_ids = ["subnet-1", "subnet-2", "subnet-3"]
  }
}

resource "aws_eks_node_group" "main" {
  cluster_name    = aws_eks_cluster.main.name
  node_group_name = "main-nodes"
  node_role_arn   = "arn:aws:iam::123456789:role/eks-node-role"
  subnet_ids      = ["subnet-1", "subnet-2", "subnet-3"]

  scaling_config {
    desired_size = 5
    max_size     = 10
    min_size     = 3
  }

  instance_types = ["m6i.2xlarge"]
}

# Kinesis (usage-based)
resource "aws_kinesis_stream" "events" {
  name             = "event-stream"
  shard_count      = 10
  retention_period = 168

  stream_mode_details {
    stream_mode = "PROVISIONED"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\basic\mixed_resources.tf
# TYPE: hcl
# SIZE: 1891 bytes
################################################################################
# Basic: Mixed resource types for cost estimation

# Compute
resource "aws_instance" "app" {
  count = 3

  ami           = "ami-12345678"
  instance_type = "t3.medium"

  root_block_device {
    volume_size = 30
    volume_type = "gp3"
  }

  tags = {
    Name = "app-${count.index}"
  }
}

# Database
resource "aws_db_instance" "main" {
  identifier     = "main-db"
  engine         = "postgres"
  engine_version = "14.8"
  instance_class = "db.t3.medium"

  allocated_storage     = 100
  max_allocated_storage = 500
  storage_type          = "gp3"

  db_name  = "appdb"
  username = "admin"
  password = "changeme123"

  multi_az            = true
  publicly_accessible = false

  backup_retention_period = 7

  tags = {
    Name = "main-database"
  }
}

# Storage
resource "aws_s3_bucket" "assets" {
  bucket = "my-app-assets-12345"
}

resource "aws_s3_bucket" "logs" {
  bucket = "my-app-logs-12345"
}

# Network
resource "aws_nat_gateway" "main" {
  allocation_id = "eipalloc-12345678"
  subnet_id     = "subnet-12345678"

  tags = {
    Name = "main-nat"
  }
}

resource "aws_lb" "app" {
  name               = "app-lb"
  internal           = false
  load_balancer_type = "application"
  subnets            = ["subnet-12345678", "subnet-87654321"]

  tags = {
    Name = "app-load-balancer"
  }
}

# Cache
resource "aws_elasticache_cluster" "session" {
  cluster_id      = "session-cache"
  engine          = "redis"
  node_type       = "cache.t3.micro"
  num_cache_nodes = 1
  port            = 6379
}

# Lambda
resource "aws_lambda_function" "processor" {
  function_name = "data-processor"
  role          = "arn:aws:iam::123456789:role/lambda-role"
  handler       = "index.handler"
  runtime       = "nodejs18.x"

  memory_size = 256
  timeout     = 30

  filename = "function.zip"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\basic\multiple_resources.tf
# TYPE: hcl
# SIZE: 925 bytes
################################################################################
# Basic Test: Multiple resource types

resource "aws_instance" "web" {
  ami           = "ami-12345678"
  instance_type = "t3.small"

  root_block_device {
    volume_size = 20
    volume_type = "gp3"
  }

  tags = {
    Name = "web-server"
  }
}

resource "aws_ebs_volume" "data" {
  availability_zone = "us-east-1a"
  size              = 100
  type              = "gp3"

  tags = {
    Name = "data-volume"
  }
}

resource "aws_volume_attachment" "data" {
  device_name = "/dev/sdf"
  volume_id   = aws_ebs_volume.data.id
  instance_id = aws_instance.web.id
}

resource "aws_s3_bucket" "logs" {
  bucket = "my-app-logs-bucket"
}

resource "aws_rds_instance" "db" {
  identifier     = "mydb"
  engine         = "mysql"
  engine_version = "8.0"
  instance_class = "db.t3.micro"

  allocated_storage = 20
  storage_type      = "gp2"

  tags = {
    Name = "app-database"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\basic\single_resource.tf
# TYPE: hcl
# SIZE: 225 bytes
################################################################################
# Basic Test: Simple single resource

resource "aws_instance" "simple" {
  ami           = "ami-12345678"
  instance_type = "t3.micro"

  tags = {
    Name        = "simple-instance"
    Environment = "test"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\dynamic_blocks\conditional_dynamic.tf
# TYPE: hcl
# SIZE: 1115 bytes
################################################################################
# Dynamic Block: Conditional dynamic block

variable "enable_logging" {
  type    = bool
  default = true
}

variable "access_logs_bucket" {
  type    = string
  default = "my-access-logs"
}

variable "enable_stickiness" {
  type    = bool
  default = false
}

resource "aws_lb" "conditional_dynamic" {
  name               = "conditional-lb"
  internal           = false
  load_balancer_type = "application"
  subnets            = ["subnet-12345678", "subnet-87654321"]

  # Conditional dynamic block for access logs
  dynamic "access_logs" {
    for_each = var.enable_logging ? [1] : []
    content {
      bucket  = var.access_logs_bucket
      prefix  = "lb-logs"
      enabled = true
    }
  }
}

resource "aws_lb_target_group" "conditional" {
  name     = "conditional-tg"
  port     = 80
  protocol = "HTTP"
  vpc_id   = "vpc-12345678"

  # Conditional stickiness
  dynamic "stickiness" {
    for_each = var.enable_stickiness ? [1] : []
    content {
      type            = "lb_cookie"
      cookie_duration = 86400
      enabled         = true
    }
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\dynamic_blocks\multiple_dynamic.tf
# TYPE: hcl
# SIZE: 1704 bytes
################################################################################
# Dynamic Blocks: Multiple dynamic blocks in one resource

variable "ingress_rules" {
  type = list(object({
    from_port   = number
    to_port     = number
    protocol    = string
    cidr_blocks = list(string)
    description = string
  }))
  default = [
    {
      from_port   = 80
      to_port     = 80
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
      description = "HTTP"
    },
    {
      from_port   = 443
      to_port     = 443
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
      description = "HTTPS"
    }
  ]
}

variable "egress_rules" {
  type = list(object({
    from_port   = number
    to_port     = number
    protocol    = string
    cidr_blocks = list(string)
  }))
  default = [
    {
      from_port   = 0
      to_port     = 0
      protocol    = "-1"
      cidr_blocks = ["0.0.0.0/0"]
    }
  ]
}

resource "aws_security_group" "multi_dynamic" {
  name        = "multi-dynamic-sg"
  description = "Security group with multiple dynamic blocks"
  vpc_id      = "vpc-12345678"

  dynamic "ingress" {
    for_each = var.ingress_rules
    content {
      from_port   = ingress.value.from_port
      to_port     = ingress.value.to_port
      protocol    = ingress.value.protocol
      cidr_blocks = ingress.value.cidr_blocks
      description = ingress.value.description
    }
  }

  dynamic "egress" {
    for_each = var.egress_rules
    content {
      from_port   = egress.value.from_port
      to_port     = egress.value.to_port
      protocol    = egress.value.protocol
      cidr_blocks = egress.value.cidr_blocks
    }
  }

  tags = {
    Name = "multi-dynamic"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\dynamic_blocks\nested_dynamic.tf
# TYPE: hcl
# SIZE: 1438 bytes
################################################################################
# Dynamic Block Test: Nested dynamic blocks

variable "load_balancer_config" {
  type = object({
    listeners = list(object({
      port     = number
      protocol = string
      rules = list(object({
        path    = string
        backend = string
      }))
    }))
  })
  default = {
    listeners = [
      {
        port     = 80
        protocol = "HTTP"
        rules = [
          { path = "/api", backend = "api-backend" },
          { path = "/web", backend = "web-backend" }
        ]
      },
      {
        port     = 443
        protocol = "HTTPS"
        rules = [
          { path = "/api", backend = "api-backend" },
          { path = "/admin", backend = "admin-backend" }
        ]
      }
    ]
  }
}

resource "aws_lb_listener" "main" {
  load_balancer_arn = "arn:aws:elasticloadbalancing:us-east-1:123456789:loadbalancer/app/main/abc123"

  dynamic "listener" {
    for_each = var.load_balancer_config.listeners
    content {
      port     = listener.value.port
      protocol = listener.value.protocol

      dynamic "action" {
        for_each = listener.value.rules
        content {
          type = "forward"

          forward {
            target_group_arn = action.value.backend
          }

          condition {
            path_pattern {
              values = [action.value.path]
            }
          }
        }
      }
    }
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\dynamic_blocks\single_dynamic.tf
# TYPE: hcl
# SIZE: 1055 bytes
################################################################################
# Dynamic Block Test: Single dynamic block

variable "ingress_rules" {
  type = list(object({
    port        = number
    protocol    = string
    cidr_blocks = list(string)
  }))
  default = [
    {
      port        = 80
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    },
    {
      port        = 443
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    },
    {
      port        = 22
      protocol    = "tcp"
      cidr_blocks = ["10.0.0.0/8"]
    }
  ]
}

resource "aws_security_group" "example" {
  name        = "dynamic-sg"
  description = "Security group with dynamic blocks"
  vpc_id      = "vpc-12345678"

  dynamic "ingress" {
    for_each = var.ingress_rules
    content {
      from_port   = ingress.value.port
      to_port     = ingress.value.port
      protocol    = ingress.value.protocol
      cidr_blocks = ingress.value.cidr_blocks
    }
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\circular_reference.tf
# TYPE: hcl
# SIZE: 633 bytes
################################################################################
# Edge Case: Circular reference between resources

resource "aws_security_group" "sg_a" {
  name        = "sg-a"
  description = "Security group A"
  vpc_id      = "vpc-12345678"

  ingress {
    from_port       = 80
    to_port         = 80
    protocol        = "tcp"
    security_groups = [aws_security_group.sg_b.id]
  }
}

resource "aws_security_group" "sg_b" {
  name        = "sg-b"
  description = "Security group B"
  vpc_id      = "vpc-12345678"

  ingress {
    from_port       = 443
    to_port         = 443
    protocol        = "tcp"
    security_groups = [aws_security_group.sg_a.id]
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\complex_locals.tf
# TYPE: hcl
# SIZE: 1283 bytes
################################################################################
# Edge Case: Local values with complex expressions

locals {
  # Nested locals referencing each other
  base_name = "myapp"
  env       = "production"
  full_name = "${local.base_name}-${local.env}"

  # Complex conditional
  instance_size = local.env == "production" ? (
    local.high_availability ? "large" : "medium"
  ) : "small"

  high_availability = local.env == "production"

  # Map transformation
  raw_instances = {
    web    = { count = 3, type = "t3.small" }
    api    = { count = 2, type = "t3.medium" }
    worker = { count = 1, type = "t3.large" }
  }

  # Flatten for iteration
  instance_list = flatten([
    for name, config in local.raw_instances : [
      for i in range(config.count) : {
        name = "${name}-${i}"
        type = config.type
        role = name
      }
    ]
  ])

  # Map by name
  instance_map = {
    for inst in local.instance_list :
    inst.name => inst
  }

  # Sum of counts
  total_instances = sum([for k, v in local.raw_instances : v.count])
}

resource "aws_instance" "from_locals" {
  for_each = local.instance_map

  ami           = "ami-12345678"
  instance_type = each.value.type

  tags = {
    Name = "${local.full_name}-${each.key}"
    Role = each.value.role
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\conditional_resource.tf
# TYPE: hcl
# SIZE: 642 bytes
################################################################################
# Edge Case: Conditional resource (count 0 or 1)

variable "create_instance" {
  type    = bool
  default = true
}

variable "create_bucket" {
  type    = bool
  default = false
}

resource "aws_instance" "conditional" {
  count = var.create_instance ? 1 : 0

  ami           = "ami-12345678"
  instance_type = "t3.micro"
}

resource "aws_s3_bucket" "conditional" {
  count = var.create_bucket ? 1 : 0

  bucket = "my-conditional-bucket"
}

# Resource that depends on conditional resource
resource "aws_eip" "instance_eip" {
  count    = var.create_instance ? 1 : 0
  instance = aws_instance.conditional[0].id
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\data_source_dependency.tf
# TYPE: hcl
# SIZE: 651 bytes
################################################################################
# Edge Case: Data source dependency

data "aws_ami" "latest" {
  most_recent = true

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }

  owners = ["amazon"]
}

data "aws_vpc" "selected" {
  default = true
}

data "aws_availability_zones" "available" {
  state = "available"
}

resource "aws_instance" "from_data" {
  ami               = data.aws_ami.latest.id
  instance_type     = "t3.micro"
  availability_zone = data.aws_availability_zones.available.names[0]

  vpc_security_group_ids = [data.aws_vpc.selected.default_security_group_id]

  tags = {
    Name = "from-data-sources"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\lifecycle.tf
# TYPE: hcl
# SIZE: 553 bytes
################################################################################
# Edge Case: Lifecycle with create_before_destroy

resource "aws_instance" "lifecycle_test" {
  ami           = "ami-12345678"
  instance_type = "t3.micro"

  lifecycle {
    create_before_destroy = true
    prevent_destroy       = false
    ignore_changes        = [tags, user_data]
  }

  tags = {
    Name = "lifecycle-test"
  }
}

resource "aws_launch_template" "lifecycle" {
  name_prefix   = "lifecycle-"
  instance_type = "t3.micro"
  image_id      = "ami-12345678"

  lifecycle {
    create_before_destroy = true
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\moved_import.tf
# TYPE: hcl
# SIZE: 462 bytes
################################################################################
# Edge Case: Resource moved block

# Simulate state moves
moved {
  from = aws_instance.old_name
  to   = aws_instance.new_name
}

resource "aws_instance" "new_name" {
  ami           = "ami-12345678"
  instance_type = "t3.micro"

  tags = {
    Name = "renamed-instance"
  }
}

# Import block
import {
  to = aws_s3_bucket.imported
  id = "my-existing-bucket"
}

resource "aws_s3_bucket" "imported" {
  bucket = "my-existing-bucket"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\null_optional.tf
# TYPE: hcl
# SIZE: 917 bytes
################################################################################
# Edge Case: Null values and optionals

variable "optional_config" {
  type = object({
    enabled       = optional(bool, false)
    instance_type = optional(string)
    volume_size   = optional(number, 20)
  })
  default = {}
}

variable "nullable_string" {
  type    = string
  default = null
}

resource "aws_instance" "optional_test" {
  count = var.optional_config.enabled ? 1 : 0

  ami           = "ami-12345678"
  instance_type = coalesce(var.optional_config.instance_type, "t3.micro")

  root_block_device {
    volume_size = var.optional_config.volume_size
  }

  # Using try() for safe access
  user_data = try(var.nullable_string, "default-user-data")

  tags = {
    Name = "optional-test"
  }
}

# Null resource for testing
resource "null_resource" "example" {
  count = var.nullable_string != null ? 1 : 0

  triggers = {
    value = var.nullable_string
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\self_reference.tf
# TYPE: hcl
# SIZE: 239 bytes
################################################################################
# Edge Case: Self-referencing count

resource "aws_instance" "self_ref" {
  count = length(aws_instance.self_ref) > 0 ? 2 : 1 # This is invalid but should be handled

  ami           = "ami-12345678"
  instance_type = "t3.micro"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\sensitive_values.tf
# TYPE: hcl
# SIZE: 721 bytes
################################################################################
# Edge Case: Sensitive values

variable "db_password" {
  type      = string
  sensitive = true
}

variable "api_key" {
  type      = string
  sensitive = true
  default   = "default-key"
}

resource "aws_db_instance" "sensitive" {
  identifier     = "sensitive-db"
  engine         = "mysql"
  instance_class = "db.t3.micro"

  username = "admin"
  password = var.db_password # Sensitive

  tags = {
    Name = "sensitive-db"
  }
}

resource "aws_secretsmanager_secret" "api" {
  name = "api-credentials"
}

resource "aws_secretsmanager_secret_version" "api" {
  secret_id = aws_secretsmanager_secret.api.id
  secret_string = jsonencode({
    api_key = var.api_key # Sensitive
  })
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\splat_expression.tf
# TYPE: hcl
# SIZE: 790 bytes
################################################################################
# Edge Case: Splat expression and resource references

variable "instance_count" {
  type    = number
  default = 3
}

resource "aws_instance" "cluster" {
  count = var.instance_count

  ami           = "ami-12345678"
  instance_type = "t3.micro"

  tags = {
    Name = "cluster-${count.index}"
  }
}

# Using splat expression
resource "aws_lb_target_group_attachment" "cluster" {
  count = var.instance_count

  target_group_arn = "arn:aws:elasticloadbalancing:us-east-1:123456789:targetgroup/main/abc123"
  target_id        = aws_instance.cluster[count.index].id
  port             = 80
}

# Using splat to get all IDs
output "instance_ids" {
  value = aws_instance.cluster[*].id
}

output "private_ips" {
  value = aws_instance.cluster[*].private_ip
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\terraform_functions.tf
# TYPE: hcl
# SIZE: 974 bytes
################################################################################
# Edge Case: Terraform functions in expressions

locals {
  environment = "production"

  # String functions
  upper_env = upper(local.environment)
  lower_env = lower(local.environment)

  # Collection functions
  instance_types = ["t3.micro", "t3.small", "t3.medium"]
  first_type     = element(local.instance_types, 0)
  type_count     = length(local.instance_types)

  # Numeric functions
  max_cpu = max(2, 4, 8)
  min_cpu = min(2, 4, 8)

  # Conditional
  instance_type = local.environment == "production" ? "t3.large" : "t3.micro"

  # Map functions
  tags = merge(
    {
      Environment = local.environment
    },
    {
      ManagedBy = "terraform"
    }
  )

  # Encoding
  encoded = base64encode("hello world")
}

resource "aws_instance" "with_functions" {
  ami           = "ami-12345678"
  instance_type = local.instance_type

  tags = merge(local.tags, {
    Name = format("web-%s-%d", local.environment, 1)
  })
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\unknown_count.tf
# TYPE: hcl
# SIZE: 280 bytes
################################################################################
# Edge Case: Unknown count value

variable "count_from_external" {
  type = number
  # No default - must be provided
}

resource "aws_instance" "unknown_count" {
  count         = var.count_from_external
  ami           = "ami-12345678"
  instance_type = "t3.micro"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\edge_cases\workspaces.tf
# TYPE: hcl
# SIZE: 901 bytes
################################################################################
# Edge Case: Terraform workspaces

terraform {
  backend "s3" {
    bucket         = "terraform-state"
    key            = "app/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-locks"
  }
}

locals {
  workspace_config = {
    default = {
      instance_type  = "t3.micro"
      instance_count = 1
    }
    staging = {
      instance_type  = "t3.small"
      instance_count = 2
    }
    production = {
      instance_type  = "t3.medium"
      instance_count = 3
    }
  }

  current_config = local.workspace_config[terraform.workspace]
}

resource "aws_instance" "app" {
  count = local.current_config.instance_count

  ami           = "ami-12345678"
  instance_type = local.current_config.instance_type

  tags = {
    Name        = "app-${terraform.workspace}-${count.index}"
    Environment = terraform.workspace
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\complex_for_each.tf
# TYPE: hcl
# SIZE: 1958 bytes
################################################################################
# Expansion: Complex for_each with nested objects

variable "services" {
  type = map(object({
    cpu         = number
    memory      = number
    ports       = list(number)
    replicas    = number
    environment = map(string)
  }))
  default = {
    api = {
      cpu      = 256
      memory   = 512
      ports    = [8080]
      replicas = 3
      environment = {
        NODE_ENV  = "production"
        LOG_LEVEL = "info"
      }
    }
    worker = {
      cpu      = 512
      memory   = 1024
      ports    = []
      replicas = 2
      environment = {
        QUEUE_URL = "https://sqs.example.com"
      }
    }
    scheduler = {
      cpu         = 128
      memory      = 256
      ports       = []
      replicas    = 1
      environment = {}
    }
  }
}

resource "aws_ecs_task_definition" "services" {
  for_each = var.services

  family                   = each.key
  requires_compatibilities = ["FARGATE"]
  network_mode             = "awsvpc"
  cpu                      = each.value.cpu
  memory                   = each.value.memory

  container_definitions = jsonencode([{
    name      = each.key
    image     = "my-app/${each.key}:latest"
    cpu       = each.value.cpu
    memory    = each.value.memory
    essential = true

    portMappings = [
      for port in each.value.ports : {
        containerPort = port
        hostPort      = port
        protocol      = "tcp"
      }
    ]

    environment = [
      for k, v in each.value.environment : {
        name  = k
        value = v
      }
    ]
  }])
}

resource "aws_ecs_service" "services" {
  for_each = var.services

  name            = each.key
  cluster         = "main-cluster"
  task_definition = aws_ecs_task_definition.services[each.key].arn
  desired_count   = each.value.replicas
  launch_type     = "FARGATE"

  network_configuration {
    subnets = ["subnet-12345678"]
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\count_from_length.tf
# TYPE: hcl
# SIZE: 898 bytes
################################################################################
# Expansion: count depending on length of list

variable "subnets" {
  type = list(object({
    cidr = string
    az   = string
  }))
  default = [
    { cidr = "10.0.1.0/24", az = "us-east-1a" },
    { cidr = "10.0.2.0/24", az = "us-east-1b" },
    { cidr = "10.0.3.0/24", az = "us-east-1c" }
  ]
}

resource "aws_subnet" "from_list" {
  count = length(var.subnets)

  vpc_id            = "vpc-12345678"
  cidr_block        = var.subnets[count.index].cidr
  availability_zone = var.subnets[count.index].az

  tags = {
    Name  = "subnet-${count.index}"
    Index = count.index
  }
}

# Instance per subnet
resource "aws_instance" "per_subnet" {
  count = length(aws_subnet.from_list)

  ami           = "ami-12345678"
  instance_type = "t3.micro"
  subnet_id     = aws_subnet.from_list[count.index].id

  tags = {
    Name = "instance-${count.index}"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\count_variable.tf
# TYPE: hcl
# SIZE: 309 bytes
################################################################################
# Expansion Test: count from variable

variable "instance_count" {
  type    = number
  default = 3
}

resource "aws_instance" "counted" {
  count         = var.instance_count
  ami           = "ami-12345678"
  instance_type = "t3.micro"

  tags = {
    Name = "instance-${count.index}"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\count_zero.tf
# TYPE: hcl
# SIZE: 168 bytes
################################################################################
# Expansion Test: count=0 produces nothing

resource "aws_instance" "zero" {
  count         = 0
  ami           = "ami-12345678"
  instance_type = "t3.micro"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\for_each_fileset.tf
# TYPE: hcl
# SIZE: 672 bytes
################################################################################
# Expansion: for_each with fileset

resource "aws_s3_object" "configs" {
  for_each = fileset("${path.module}/configs", "*.json")

  bucket = "my-config-bucket"
  key    = "configs/${each.value}"
  source = "${path.module}/configs/${each.value}"

  etag = filemd5("${path.module}/configs/${each.value}")
}

resource "aws_lambda_function" "handlers" {
  for_each = fileset("${path.module}/lambdas", "*/handler.py")

  function_name = replace(dirname(each.value), "/", "-")
  role          = "arn:aws:iam::123456789:role/lambda-role"
  handler       = "handler.main"
  runtime       = "python3.9"

  filename = "${path.module}/lambdas/${each.value}"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\for_each_map.tf
# TYPE: hcl
# SIZE: 678 bytes
################################################################################
# Expansion Test: for_each with map

variable "instances" {
  type = map(object({
    instance_type = string
    ami           = string
  }))
  default = {
    web = {
      instance_type = "t3.small"
      ami           = "ami-web12345"
    }
    api = {
      instance_type = "t3.medium"
      ami           = "ami-api12345"
    }
    worker = {
      instance_type = "t3.large"
      ami           = "ami-wrk12345"
    }
  }
}

resource "aws_instance" "multi" {
  for_each      = var.instances
  ami           = each.value.ami
  instance_type = each.value.instance_type

  tags = {
    Name = "instance-${each.key}"
    Role = each.key
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\for_each_set.tf
# TYPE: hcl
# SIZE: 712 bytes
################################################################################
# Expansion Test: for_each with set of strings

variable "availability_zones" {
  type    = set(string)
  default = ["us-east-1a", "us-east-1b", "us-east-1c"]
}

resource "aws_subnet" "main" {
  for_each = var.availability_zones

  vpc_id            = "vpc-12345678"
  cidr_block        = "10.0.${index(tolist(var.availability_zones), each.value)}.0/24"
  availability_zone = each.value

  tags = {
    Name = "subnet-${each.value}"
  }
}

# Resources using the subnets
resource "aws_instance" "per_az" {
  for_each = aws_subnet.main

  ami           = "ami-12345678"
  instance_type = "t3.micro"
  subnet_id     = each.value.id

  tags = {
    Name = "instance-${each.key}"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\for_each_toset.tf
# TYPE: hcl
# SIZE: 552 bytes
################################################################################
# Expansion: for_each with toset() conversion

variable "bucket_names" {
  type    = list(string)
  default = ["logs", "data", "backups", "archives"]
}

resource "aws_s3_bucket" "buckets" {
  for_each = toset(var.bucket_names)

  bucket = "${each.value}-bucket-12345"

  tags = {
    Name    = each.value
    Purpose = each.key
  }
}

# Dependent resource
resource "aws_s3_bucket_versioning" "buckets" {
  for_each = aws_s3_bucket.buckets

  bucket = each.value.id

  versioning_configuration {
    status = "Enabled"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\nested_count_for_each.tf
# TYPE: hcl
# SIZE: 857 bytes
################################################################################
# Expansion Test: Nested count inside for_each

variable "environments" {
  type = map(object({
    replica_count = number
  }))
  default = {
    dev     = { replica_count = 1 }
    staging = { replica_count = 2 }
    prod    = { replica_count = 3 }
  }
}

# Outer for_each
resource "aws_db_instance" "primary" {
  for_each = var.environments

  identifier     = "${each.key}-db-primary"
  engine         = "mysql"
  instance_class = each.key == "prod" ? "db.r5.large" : "db.t3.micro"

  tags = {
    Environment = each.key
    Role        = "primary"
  }
}

# This pattern (count inside module with for_each) is common
module "db_replicas" {
  source   = "./replica"
  for_each = var.environments

  count       = each.value.replica_count
  primary_id  = aws_db_instance.primary[each.key].id
  environment = each.key
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\expansion\triple_nested.tf
# TYPE: hcl
# SIZE: 1497 bytes
################################################################################
# Expansion: Triple nested for_each/count

variable "regions" {
  type = map(object({
    availability_zones = list(string)
    instance_per_az    = number
  }))
  default = {
    us-east-1 = {
      availability_zones = ["us-east-1a", "us-east-1b"]
      instance_per_az    = 2
    }
    us-west-2 = {
      availability_zones = ["us-west-2a"]
      instance_per_az    = 3
    }
  }
}

# Level 1: for_each on regions
module "regional" {
  source   = "./regional"
  for_each = var.regions

  region             = each.key
  availability_zones = each.value.availability_zones
  instance_per_az    = each.value.instance_per_az
}

# Simulating what the regional module might contain:
# Level 2: for_each on AZs (conceptually)
# Level 3: count on instances per AZ

# This flattening pattern is common
locals {
  all_instances = flatten([
    for region, config in var.regions : [
      for az in config.availability_zones : [
        for i in range(config.instance_per_az) : {
          region = region
          az     = az
          index  = i
          name   = "${region}-${az}-${i}"
        }
      ]
    ]
  ])
}

resource "aws_instance" "triple_nested" {
  for_each = { for inst in local.all_instances : inst.name => inst }

  ami               = "ami-12345678"
  instance_type     = "t3.micro"
  availability_zone = each.value.az

  tags = {
    Name   = each.key
    Region = each.value.region
    Index  = each.value.index
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\modules\local_module.tf
# TYPE: hcl
# SIZE: 305 bytes
################################################################################
# Module Test: Local module with count

variable "app_count" {
  type    = number
  default = 2
}

module "app" {
  source = "./app"
  count  = var.app_count

  name          = "app-${count.index}"
  instance_type = "t3.micro"
}

output "app_ids" {
  value = module.app[*].instance_id
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\modules\module_count.tf
# TYPE: hcl
# SIZE: 813 bytes
################################################################################
# Module: Passing count to module

variable "create_vpc" {
  type    = bool
  default = true
}

module "vpc" {
  source = "./vpc"
  count  = var.create_vpc ? 1 : 0

  cidr_block = "10.0.0.0/16"
  name       = "main-vpc"
}

# Accessing module with count
resource "aws_subnet" "public" {
  count = var.create_vpc ? 2 : 0

  vpc_id     = module.vpc[0].vpc_id
  cidr_block = "10.0.${count.index}.0/24"

  tags = {
    Name = "public-${count.index}"
  }
}

# Module with count creating multiple modules
variable "environment_count" {
  type    = number
  default = 3
}

module "environment" {
  source = "./environment"
  count  = var.environment_count

  name  = "env-${count.index}"
  index = count.index
}

output "environment_ids" {
  value = module.environment[*].id
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\modules\module_with_outputs.tf
# TYPE: hcl
# SIZE: 942 bytes
################################################################################
# Module: Module with outputs that reference each other

variable "name" {
  type    = string
  default = "test"
}

resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"

  tags = {
    Name = "${var.name}-vpc"
  }
}

resource "aws_subnet" "public" {
  count = 2

  vpc_id     = aws_vpc.main.id
  cidr_block = "10.0.${count.index}.0/24"

  tags = {
    Name = "${var.name}-public-${count.index}"
  }
}

resource "aws_subnet" "private" {
  count = 2

  vpc_id     = aws_vpc.main.id
  cidr_block = "10.0.${count.index + 10}.0/24"

  tags = {
    Name = "${var.name}-private-${count.index}"
  }
}

output "vpc_id" {
  value = aws_vpc.main.id
}

output "public_subnet_ids" {
  value = aws_subnet.public[*].id
}

output "private_subnet_ids" {
  value = aws_subnet.private[*].id
}

output "all_subnet_ids" {
  value = concat(
    aws_subnet.public[*].id,
    aws_subnet.private[*].id
  )
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\modules\nested_modules.tf
# TYPE: hcl
# SIZE: 645 bytes
################################################################################
# Module Test: Nested module with for_each

variable "environments" {
  type = map(object({
    instance_count = number
    instance_type  = string
  }))
  default = {
    dev = {
      instance_count = 1
      instance_type  = "t3.micro"
    }
    staging = {
      instance_count = 2
      instance_type  = "t3.small"
    }
    prod = {
      instance_count = 3
      instance_type  = "t3.medium"
    }
  }
}

module "environment" {
  source   = "./environment"
  for_each = var.environments

  name           = each.key
  instance_count = each.value.instance_count
  instance_type  = each.value.instance_type
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\providers\alias_basic.tf
# TYPE: hcl
# SIZE: 646 bytes
################################################################################
# Provider Test: Multiple regions with aliases

provider "aws" {
  region = "us-east-1"
}

provider "aws" {
  alias  = "west"
  region = "us-west-2"
}

provider "aws" {
  alias  = "eu"
  region = "eu-west-1"
}

resource "aws_instance" "east" {
  ami           = "ami-east12345"
  instance_type = "t3.micro"

  tags = {
    Region = "us-east-1"
  }
}

resource "aws_instance" "west" {
  provider      = aws.west
  ami           = "ami-west12345"
  instance_type = "t3.micro"

  tags = {
    Region = "us-west-2"
  }
}

resource "aws_s3_bucket" "eu_bucket" {
  provider = aws.eu
  bucket   = "my-eu-bucket"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\providers\alias_module_inherit.tf
# TYPE: hcl
# SIZE: 346 bytes
################################################################################
# Provider Test: Module inheriting provider alias

provider "aws" {
  region = "us-east-1"
}

provider "aws" {
  alias  = "west"
  region = "us-west-2"
}

module "app_east" {
  source = "./app"

  name = "app-east"
}

module "app_west" {
  source = "./app"

  providers = {
    aws = aws.west
  }

  name = "app-west"
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\providers\multi_region_modules.tf
# TYPE: hcl
# SIZE: 899 bytes
################################################################################
# Module: Passing providers to module

terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  alias  = "primary"
  region = "us-east-1"
}

provider "aws" {
  alias  = "dr"
  region = "us-west-2"
}

module "primary_infra" {
  source = "./infra"

  providers = {
    aws = aws.primary
  }

  environment = "primary"
  vpc_cidr    = "10.0.0.0/16"
}

module "dr_infra" {
  source = "./infra"

  providers = {
    aws = aws.dr
  }

  environment = "dr"
  vpc_cidr    = "10.1.0.0/16"
}

# Cross-region peering would reference both
resource "aws_vpc_peering_connection" "primary_to_dr" {
  provider = aws.primary

  vpc_id      = module.primary_infra.vpc_id
  peer_vpc_id = module.dr_infra.vpc_id
  peer_region = "us-west-2"

  tags = {
    Name = "primary-to-dr"
  }
}

################################################################################
# FILE: :\good projects\cost estimation\testdata\terraform\providers\multiple_same_type.tf
# TYPE: hcl
# SIZE: 1433 bytes
################################################################################
# Providers: Multiple providers same type

terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# Default provider
provider "aws" {
  region = "us-east-1"

  default_tags {
    tags = {
      Environment = "production"
      ManagedBy   = "terraform"
    }
  }
}

# Alternative region
provider "aws" {
  alias  = "west"
  region = "us-west-2"

  default_tags {
    tags = {
      Environment = "production"
      ManagedBy   = "terraform"
    }
  }
}

# Cross-account
provider "aws" {
  alias  = "shared"
  region = "us-east-1"

  assume_role {
    role_arn = "arn:aws:iam::987654321:role/terraform-cross-account"
  }
}

# Resources using different providers
resource "aws_s3_bucket" "primary" {
  bucket = "primary-bucket-12345"
}

resource "aws_s3_bucket" "west" {
  provider = aws.west
  bucket   = "west-bucket-12345"
}

resource "aws_s3_bucket" "shared" {
  provider = aws.shared
  bucket   = "shared-bucket-12345"
}

# Replication between regions
resource "aws_s3_bucket_replication_configuration" "primary_to_west" {
  bucket = aws_s3_bucket.primary.id
  role   = "arn:aws:iam::123456789:role/replication-role"

  rule {
    id     = "replicate-to-west"
    status = "Enabled"

    destination {
      bucket        = aws_s3_bucket.west.arn
      storage_class = "STANDARD"
    }
  }
}

################################################################################
#                              END OF FILE                                     #
################################################################################

================================================================================
                                SUMMARY
================================================================================

Total Files Combined: 271
Generated: 2026-01-17 12:44:55
Project: cost estimation

Files by Type:  .go : 209 files
  .tf : 46 files
  .json : 4 files
  .md : 3 files
  .sql : 3 files
  (no extension) : 2 files
  .mod : 1 files
  .gitignore : 1 files
  .ps1 : 1 files
  .yml : 1 files

================================================================================
